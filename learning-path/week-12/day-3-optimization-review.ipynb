{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "print(\"⚠️  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a7cd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Optimization Hierarchy\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              OPTIMIZATION PRIORITY ORDER                    │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  1. ALGORITHM CHOICE          ███████████████████ ~10-100x  │\n",
    "│     • Choose right algorithm                                │\n",
    "│     • Reduce algorithmic complexity                         │\n",
    "│                                                             │\n",
    "│  2. MEMORY ACCESS PATTERNS    ████████████████    ~5-20x    │\n",
    "│     • Coalesced access                                      │\n",
    "│     • Minimize global memory traffic                        │\n",
    "│     • Use shared memory                                     │\n",
    "│                                                             │\n",
    "│  3. OCCUPANCY & PARALLELISM   ████████████        ~2-5x     │\n",
    "│     • Enough threads to hide latency                        │\n",
    "│     • Balance resources per block                           │\n",
    "│                                                             │\n",
    "│  4. INSTRUCTION OPTIMIZATION  ████████            ~1.5-3x   │\n",
    "│     • Fast math functions                                   │\n",
    "│     • Avoid divergence                                      │\n",
    "│                                                             │\n",
    "│  5. CONCURRENCY               ██████              ~1.2-2x   │\n",
    "│     • Streams, graphs                                       │\n",
    "│     • Overlap compute/transfer                              │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a40c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Memory Optimization Techniques\n",
    "\n",
    "### 1.1 Coalesced Memory Access\n",
    "\n",
    "```cpp\n",
    "// GOOD: Coalesced - threads access consecutive memory\n",
    "__global__ void coalesced(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = data[tid] * 2.0f;  // Thread i accesses element i\n",
    "    }\n",
    "}\n",
    "\n",
    "// BAD: Strided - threads access with stride\n",
    "__global__ void strided(float* data, int n, int stride) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int idx = tid * stride;  // Thread i accesses element i*stride\n",
    "    if (idx < n) {\n",
    "        data[idx] = data[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### 1.2 Shared Memory Usage\n",
    "\n",
    "```cpp\n",
    "// Pattern: Load to shared -> Sync -> Process -> Sync -> Store\n",
    "__global__ void withShared(float* out, float* in, int n) {\n",
    "    __shared__ float smem[256];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int gid = blockIdx.x * blockDim.x + tid;\n",
    "    \n",
    "    // Load to shared memory\n",
    "    smem[tid] = (gid < n) ? in[gid] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Process using shared memory\n",
    "    float result = smem[tid];\n",
    "    if (tid > 0) result += smem[tid - 1];\n",
    "    if (tid < 255) result += smem[tid + 1];\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Write result\n",
    "    if (gid < n) out[gid] = result;\n",
    "}\n",
    "```\n",
    "\n",
    "### 1.3 Bank Conflict Avoidance\n",
    "\n",
    "```cpp\n",
    "// BAD: Bank conflicts (stride of 32)\n",
    "__shared__ float smem[32][32];\n",
    "smem[threadIdx.x][0] = value;  // All access bank 0!\n",
    "\n",
    "// GOOD: Padding to avoid conflicts\n",
    "__shared__ float smem[32][33];  // +1 padding\n",
    "smem[threadIdx.x][0] = value;   // Different banks\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile memory_patterns.cu\n",
    "// memory_patterns.cu - Memory optimization examples\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// GOOD: Coalesced - threads access consecutive memory\n",
    "__global__ void coalesced(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = data[tid] * 2.0f;  // Thread i accesses element i\n",
    "    }\n",
    "}\n",
    "\n",
    "// BAD: Strided - threads access with stride\n",
    "__global__ void strided(float* data, int n, int stride) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int idx = tid * stride;  // Thread i accesses element i*stride\n",
    "    if (idx < n) {\n",
    "        data[idx] = data[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern: Load to shared -> Sync -> Process -> Sync -> Store\n",
    "__global__ void withShared(float* out, float* in, int n) {\n",
    "    __shared__ float smem[256];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int gid = blockIdx.x * blockDim.x + tid;\n",
    "    \n",
    "    // Load to shared memory\n",
    "    smem[tid] = (gid < n) ? in[gid] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Process using shared memory\n",
    "    float result = smem[tid];\n",
    "    if (tid > 0) result += smem[tid - 1];\n",
    "    if (tid < 255) result += smem[tid + 1];\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Write result\n",
    "    if (gid < n) out[gid] = result;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data, *d_out;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    cudaMalloc(&d_out, N * sizeof(float));\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_data = new float[N];\n",
    "    for (int i = 0; i < N; i++) h_data[i] = 1.0f;\n",
    "    cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    // Test coalesced\n",
    "    coalesced<<<numBlocks, blockSize>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Coalesced access completed\\n\");\n",
    "    \n",
    "    // Test with shared memory\n",
    "    withShared<<<numBlocks, blockSize>>>(d_out, d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Shared memory pattern completed\\n\");\n",
    "    \n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_out);\n",
    "    delete[] h_data;\n",
    "    \n",
    "    printf(\"Memory patterns demo complete!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o memory_patterns memory_patterns.cu\n",
    "!./memory_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f68692",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Compute Optimization\n",
    "\n",
    "### 2.1 Instruction Throughput\n",
    "\n",
    "```cpp\n",
    "// Fast math intrinsics (less accurate, much faster)\n",
    "__device__ float fast_sin(float x) {\n",
    "    return __sinf(x);      // ~10x faster than sinf()\n",
    "}\n",
    "\n",
    "__device__ float fast_exp(float x) {\n",
    "    return __expf(x);      // ~10x faster than expf()\n",
    "}\n",
    "\n",
    "__device__ float fast_rsqrt(float x) {\n",
    "    return rsqrtf(x);      // 1/sqrt(x), very fast\n",
    "}\n",
    "```\n",
    "\n",
    "### 2.2 Warp Divergence\n",
    "\n",
    "```cpp\n",
    "// BAD: Divergent branches\n",
    "__global__ void divergent(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid % 2 == 0) {      // Half warp does one thing\n",
    "        data[tid] = expensive_op1(data[tid]);\n",
    "    } else {                 // Other half does another\n",
    "        data[tid] = expensive_op2(data[tid]);\n",
    "    }\n",
    "}\n",
    "\n",
    "// BETTER: Separate into different warps\n",
    "__global__ void nondivergent(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int warpId = tid / 32;\n",
    "    \n",
    "    if (warpId % 2 == 0) {   // Whole warp does one thing\n",
    "        data[tid] = expensive_op1(data[tid]);\n",
    "    } else {                 // Other warp does another\n",
    "        data[tid] = expensive_op2(data[tid]);\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### 2.3 Loop Unrolling\n",
    "\n",
    "```cpp\n",
    "// Manual unroll\n",
    "__global__ void unrolled(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    #pragma unroll 4\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        int idx = tid + i * blockDim.x * gridDim.x;\n",
    "        if (idx < n) data[idx] *= 2.0f;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile compute_optimization.cu\n",
    "// compute_optimization.cu - Compute optimization examples\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Fast math intrinsics (less accurate, much faster)\n",
    "__device__ float fast_computation(float x) {\n",
    "    float sin_val = __sinf(x);      // ~10x faster than sinf()\n",
    "    float exp_val = __expf(x);      // ~10x faster than expf()\n",
    "    float rsqrt_val = rsqrtf(x);    // 1/sqrt(x), very fast\n",
    "    return sin_val + exp_val * rsqrt_val;\n",
    "}\n",
    "\n",
    "// BETTER: Non-divergent - whole warps take same path\n",
    "__global__ void nondivergent(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int warpId = tid / 32;\n",
    "    \n",
    "    if (tid < n) {\n",
    "        if (warpId % 2 == 0) {   // Whole warp does one thing\n",
    "            data[tid] = __sinf(data[tid]);\n",
    "        } else {                 // Other warp does another\n",
    "            data[tid] = __cosf(data[tid]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Manual unroll\n",
    "__global__ void unrolled(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    #pragma unroll 4\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        int idx = tid + i * blockDim.x * gridDim.x;\n",
    "        if (idx < n) data[idx] *= 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_data = new float[N];\n",
    "    for (int i = 0; i < N; i++) h_data[i] = 1.0f + (float)i / N;\n",
    "    cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    // Test non-divergent\n",
    "    nondivergent<<<numBlocks, blockSize>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Non-divergent kernel completed\\n\");\n",
    "    \n",
    "    // Test unrolled\n",
    "    unrolled<<<numBlocks / 4, blockSize>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Unrolled kernel completed\\n\");\n",
    "    \n",
    "    cudaFree(d_data);\n",
    "    delete[] h_data;\n",
    "    \n",
    "    printf(\"Compute optimization demo complete!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o compute_optimization compute_optimization.cu\n",
    "!./compute_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544893c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Occupancy Optimization\n",
    "\n",
    "### 3.1 Resource Balancing\n",
    "\n",
    "```cpp\n",
    "// Query optimal block size\n",
    "int minGridSize, optBlockSize;\n",
    "cudaOccupancyMaxPotentialBlockSize(\n",
    "    &minGridSize, &optBlockSize, \n",
    "    myKernel, 0, 0);\n",
    "\n",
    "printf(\"Optimal block size: %d\\n\", optBlockSize);\n",
    "printf(\"Min grid size: %d\\n\", minGridSize);\n",
    "```\n",
    "\n",
    "### 3.2 Register Pressure\n",
    "\n",
    "```cpp\n",
    "// Limit registers to increase occupancy\n",
    "__global__ __launch_bounds__(256, 4)  // 256 threads, 4 blocks/SM\n",
    "void limitedRegisters(float* data) {\n",
    "    // Kernel code\n",
    "}\n",
    "\n",
    "// Compile with: nvcc -maxrregcount=32 kernel.cu\n",
    "```\n",
    "\n",
    "### 3.3 Shared Memory Configuration\n",
    "\n",
    "```cpp\n",
    "// Prefer more shared memory over L1 cache\n",
    "cudaFuncSetCacheConfig(myKernel, cudaFuncCachePreferShared);\n",
    "\n",
    "// Options:\n",
    "// cudaFuncCachePreferNone   - No preference\n",
    "// cudaFuncCachePreferShared - Prefer shared memory\n",
    "// cudaFuncCachePreferL1     - Prefer L1 cache\n",
    "// cudaFuncCachePreferEqual  - Equal split\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile occupancy_demo.cu\n",
    "// occupancy_demo.cu - Occupancy optimization examples\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Limit registers to increase occupancy\n",
    "__global__ __launch_bounds__(256, 4)  // 256 threads, 4 blocks/SM\n",
    "void limitedRegisters(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = data[tid] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void myKernel(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = sqrtf(data[tid]) * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    // Query optimal block size\n",
    "    int minGridSize, optBlockSize;\n",
    "    cudaOccupancyMaxPotentialBlockSize(\n",
    "        &minGridSize, &optBlockSize, \n",
    "        myKernel, 0, 0);\n",
    "    \n",
    "    printf(\"Optimal block size: %d\\n\", optBlockSize);\n",
    "    printf(\"Min grid size: %d\\n\", minGridSize);\n",
    "    \n",
    "    // Calculate occupancy\n",
    "    int numBlocks;\n",
    "    cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "        &numBlocks, myKernel, optBlockSize, 0);\n",
    "    \n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    \n",
    "    int maxBlocksPerSM = prop.maxThreadsPerMultiProcessor / optBlockSize;\n",
    "    float occupancy = (float)numBlocks / maxBlocksPerSM;\n",
    "    printf(\"Max blocks per SM: %d\\n\", maxBlocksPerSM);\n",
    "    printf(\"Achieved occupancy: %.1f%%\\n\", occupancy * 100);\n",
    "    \n",
    "    // Set cache preference\n",
    "    cudaFuncSetCacheConfig(myKernel, cudaFuncCachePreferShared);\n",
    "    printf(\"Set cache preference: PreferShared\\n\");\n",
    "    \n",
    "    // Launch kernel with optimal parameters\n",
    "    int numBlocksTotal = (N + optBlockSize - 1) / optBlockSize;\n",
    "    myKernel<<<numBlocksTotal, optBlockSize>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    printf(\"Kernel completed with optimal configuration!\\n\");\n",
    "    \n",
    "    cudaFree(d_data);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ea863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o occupancy_demo occupancy_demo.cu\n",
    "!./occupancy_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2baf9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Concurrency Optimization\n",
    "\n",
    "### 4.1 Stream Overlap Pattern\n",
    "\n",
    "```cpp\n",
    "// Chunk and overlap pattern\n",
    "const int NUM_STREAMS = 4;\n",
    "cudaStream_t streams[NUM_STREAMS];\n",
    "\n",
    "for (int i = 0; i < NUM_STREAMS; i++) {\n",
    "    cudaStreamCreate(&streams[i]);\n",
    "}\n",
    "\n",
    "int chunkSize = N / NUM_STREAMS;\n",
    "\n",
    "for (int i = 0; i < NUM_STREAMS; i++) {\n",
    "    int offset = i * chunkSize;\n",
    "    \n",
    "    // H2D for chunk i\n",
    "    cudaMemcpyAsync(d_in + offset, h_in + offset,\n",
    "                    chunkSize * sizeof(float),\n",
    "                    cudaMemcpyHostToDevice, streams[i]);\n",
    "    \n",
    "    // Compute chunk i\n",
    "    kernel<<<blocks, threads, 0, streams[i]>>>(\n",
    "        d_out + offset, d_in + offset, chunkSize);\n",
    "    \n",
    "    // D2H for chunk i\n",
    "    cudaMemcpyAsync(h_out + offset, d_out + offset,\n",
    "                    chunkSize * sizeof(float),\n",
    "                    cudaMemcpyDeviceToHost, streams[i]);\n",
    "}\n",
    "```\n",
    "\n",
    "### 4.2 CUDA Graphs for Repeated Patterns\n",
    "\n",
    "```cpp\n",
    "// Capture repeating pattern\n",
    "cudaGraph_t graph;\n",
    "cudaGraphExec_t instance;\n",
    "\n",
    "cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "\n",
    "// Pattern to repeat\n",
    "kernelA<<<...>>>(...);\n",
    "kernelB<<<...>>>(...);\n",
    "kernelC<<<...>>>(...);\n",
    "\n",
    "cudaStreamEndCapture(stream, &graph);\n",
    "cudaGraphInstantiate(&instance, graph, NULL, NULL, 0);\n",
    "\n",
    "// Execute efficiently many times\n",
    "for (int iter = 0; iter < 1000; iter++) {\n",
    "    cudaGraphLaunch(instance, stream);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile concurrency_demo.cu\n",
    "// concurrency_demo.cu - Stream overlap and CUDA Graphs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void kernel(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = sqrtf(data[tid]) * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 22;  // 4M elements\n",
    "    const int NUM_STREAMS = 4;\n",
    "    size_t bytes = N * sizeof(float);\n",
    "    int chunkSize = N / NUM_STREAMS;\n",
    "    \n",
    "    // Allocate pinned host memory\n",
    "    float *h_in, *h_out;\n",
    "    cudaMallocHost(&h_in, bytes);\n",
    "    cudaMallocHost(&h_out, bytes);\n",
    "    \n",
    "    // Initialize\n",
    "    for (int i = 0; i < N; i++) h_in[i] = (float)i;\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_in, *d_out;\n",
    "    cudaMalloc(&d_in, bytes);\n",
    "    cudaMalloc(&d_out, bytes);\n",
    "    \n",
    "    // Create streams\n",
    "    cudaStream_t streams[NUM_STREAMS];\n",
    "    for (int i = 0; i < NUM_STREAMS; i++) {\n",
    "        cudaStreamCreate(&streams[i]);\n",
    "    }\n",
    "    \n",
    "    int blockSize = 256;\n",
    "    int blocks = (chunkSize + blockSize - 1) / blockSize;\n",
    "    \n",
    "    // ============================================\n",
    "    // Stream Overlap Pattern\n",
    "    // ============================================\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    \n",
    "    for (int i = 0; i < NUM_STREAMS; i++) {\n",
    "        int offset = i * chunkSize;\n",
    "        \n",
    "        // H2D for chunk i\n",
    "        cudaMemcpyAsync(d_in + offset, h_in + offset,\n",
    "                        chunkSize * sizeof(float),\n",
    "                        cudaMemcpyHostToDevice, streams[i]);\n",
    "        \n",
    "        // Compute chunk i\n",
    "        kernel<<<blocks, blockSize, 0, streams[i]>>>(\n",
    "            d_in + offset, chunkSize);\n",
    "        \n",
    "        // D2H for chunk i\n",
    "        cudaMemcpyAsync(h_out + offset, d_in + offset,\n",
    "                        chunkSize * sizeof(float),\n",
    "                        cudaMemcpyDeviceToHost, streams[i]);\n",
    "    }\n",
    "    \n",
    "    // Sync all streams\n",
    "    for (int i = 0; i < NUM_STREAMS; i++) {\n",
    "        cudaStreamSynchronize(streams[i]);\n",
    "    }\n",
    "    \n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    printf(\"Stream overlap: %.2f ms\\n\", ms);\n",
    "    \n",
    "    // ============================================\n",
    "    // CUDA Graph for Repeated Pattern\n",
    "    // ============================================\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t instance;\n",
    "    \n",
    "    // Reset data\n",
    "    cudaMemcpy(d_in, h_in, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    cudaStreamBeginCapture(streams[0], cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    // Pattern to repeat: 3 kernel passes\n",
    "    kernel<<<(N + 255) / 256, 256, 0, streams[0]>>>(d_in, N);\n",
    "    kernel<<<(N + 255) / 256, 256, 0, streams[0]>>>(d_in, N);\n",
    "    kernel<<<(N + 255) / 256, 256, 0, streams[0]>>>(d_in, N);\n",
    "    \n",
    "    cudaStreamEndCapture(streams[0], &graph);\n",
    "    cudaGraphInstantiate(&instance, graph, NULL, NULL, 0);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    \n",
    "    // Execute graph 10 times\n",
    "    for (int iter = 0; iter < 10; iter++) {\n",
    "        cudaGraphLaunch(instance, streams[0]);\n",
    "    }\n",
    "    \n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    printf(\"CUDA Graph (10 iterations x 3 kernels): %.2f ms\\n\", ms);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(instance);\n",
    "    cudaGraphDestroy(graph);\n",
    "    \n",
    "    for (int i = 0; i < NUM_STREAMS; i++) {\n",
    "        cudaStreamDestroy(streams[i]);\n",
    "    }\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    cudaFreeHost(h_in);\n",
    "    cudaFreeHost(h_out);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    printf(\"Concurrency demo complete!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o concurrency_demo concurrency_demo.cu\n",
    "!./concurrency_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243256e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optimization Checklist\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              CUDA OPTIMIZATION CHECKLIST                    │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  □ MEMORY ACCESS                                            │\n",
    "│    □ Coalesced global memory access                         │\n",
    "│    □ Minimize global memory transactions                    │\n",
    "│    □ Use shared memory for reused data                      │\n",
    "│    □ Avoid bank conflicts in shared memory                  │\n",
    "│    □ Use __ldg() for read-only data                         │\n",
    "│    □ Use pinned memory for host-device transfers            │\n",
    "│                                                             │\n",
    "│  □ COMPUTE                                                  │\n",
    "│    □ Use fast math where precision allows                   │\n",
    "│    □ Minimize warp divergence                               │\n",
    "│    □ Use appropriate data types (float vs double)           │\n",
    "│    □ Unroll loops where beneficial                          │\n",
    "│    □ Use warp-level primitives                              │\n",
    "│                                                             │\n",
    "│  □ OCCUPANCY                                                │\n",
    "│    □ Use occupancy calculator for block size                │\n",
    "│    □ Balance registers vs occupancy                         │\n",
    "│    □ Balance shared memory vs occupancy                     │\n",
    "│    □ Ensure enough blocks to saturate GPU                   │\n",
    "│                                                             │\n",
    "│  □ CONCURRENCY                                              │\n",
    "│    □ Overlap compute and memory transfers                   │\n",
    "│    □ Use multiple streams for independent work              │\n",
    "│    □ Use CUDA Graphs for repeated patterns                  │\n",
    "│    □ Enable peer access for multi-GPU                       │\n",
    "│                                                             │\n",
    "│  □ PROFILING                                                │\n",
    "│    □ Profile with Nsight Compute                            │\n",
    "│    □ Check roofline position                                │\n",
    "│    □ Identify bottlenecks before optimizing                 │\n",
    "│    □ Measure improvement after each change                  │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76d81c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Complete Optimized Example: Matrix Transpose\n",
    "\n",
    "```cpp\n",
    "// optimized_transpose.cu - Fully optimized matrix transpose\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define TILE_DIM 32\n",
    "#define BLOCK_ROWS 8\n",
    "\n",
    "// Naive transpose (for comparison)\n",
    "__global__ void transposeNaive(float* out, float* in, int width, int height) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (x < width && y < height) {\n",
    "        out[x * height + y] = in[y * width + x];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Optimized transpose with shared memory and bank conflict avoidance\n",
    "__global__ void transposeOptimized(float* out, float* in, int width, int height) {\n",
    "    // +1 padding to avoid bank conflicts\n",
    "    __shared__ float tile[TILE_DIM][TILE_DIM + 1];\n",
    "    \n",
    "    int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
    "    int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
    "    \n",
    "    // Load tile (coalesced read)\n",
    "    #pragma unroll\n",
    "    for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS) {\n",
    "        if (x < width && (y + j) < height) {\n",
    "            tile[threadIdx.y + j][threadIdx.x] = in[(y + j) * width + x];\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    __syncthreads();\n",
    "    \n",
    "    // Transposed coordinates\n",
    "    x = blockIdx.y * TILE_DIM + threadIdx.x;\n",
    "    y = blockIdx.x * TILE_DIM + threadIdx.y;\n",
    "    \n",
    "    // Store transposed tile (coalesced write)\n",
    "    #pragma unroll\n",
    "    for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS) {\n",
    "        if (x < height && (y + j) < width) {\n",
    "            out[(y + j) * height + x] = tile[threadIdx.x][threadIdx.y + j];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int WIDTH = 4096, HEIGHT = 4096;\n",
    "    size_t bytes = WIDTH * HEIGHT * sizeof(float);\n",
    "    \n",
    "    float *d_in, *d_out;\n",
    "    cudaMalloc(&d_in, bytes);\n",
    "    cudaMalloc(&d_out, bytes);\n",
    "    \n",
    "    dim3 block(TILE_DIM, BLOCK_ROWS);\n",
    "    dim3 grid((WIDTH + TILE_DIM - 1) / TILE_DIM,\n",
    "              (HEIGHT + TILE_DIM - 1) / TILE_DIM);\n",
    "    \n",
    "    // Warmup\n",
    "    transposeOptimized<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    \n",
    "    // Benchmark\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    const int RUNS = 100;\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < RUNS; i++) {\n",
    "        transposeOptimized<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    float bandwidth = 2.0f * bytes / (ms / RUNS / 1000.0f) / 1e9;\n",
    "    printf(\"Optimized Transpose: %.2f GB/s\\n\", bandwidth);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e03de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile optimized_transpose.cu\n",
    "// optimized_transpose.cu - Fully optimized matrix transpose\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define TILE_DIM 32\n",
    "#define BLOCK_ROWS 8\n",
    "\n",
    "// Naive transpose (for comparison)\n",
    "__global__ void transposeNaive(float* out, float* in, int width, int height) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (x < width && y < height) {\n",
    "        out[x * height + y] = in[y * width + x];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Optimized transpose with shared memory and bank conflict avoidance\n",
    "__global__ void transposeOptimized(float* out, float* in, int width, int height) {\n",
    "    // +1 padding to avoid bank conflicts\n",
    "    __shared__ float tile[TILE_DIM][TILE_DIM + 1];\n",
    "    \n",
    "    int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
    "    int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
    "    \n",
    "    // Load tile (coalesced read)\n",
    "    #pragma unroll\n",
    "    for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS) {\n",
    "        if (x < width && (y + j) < height) {\n",
    "            tile[threadIdx.y + j][threadIdx.x] = in[(y + j) * width + x];\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    __syncthreads();\n",
    "    \n",
    "    // Transposed coordinates\n",
    "    x = blockIdx.y * TILE_DIM + threadIdx.x;\n",
    "    y = blockIdx.x * TILE_DIM + threadIdx.y;\n",
    "    \n",
    "    // Store transposed tile (coalesced write)\n",
    "    #pragma unroll\n",
    "    for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS) {\n",
    "        if (x < height && (y + j) < width) {\n",
    "            out[(y + j) * height + x] = tile[threadIdx.x][threadIdx.y + j];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int WIDTH = 4096, HEIGHT = 4096;\n",
    "    size_t bytes = WIDTH * HEIGHT * sizeof(float);\n",
    "    \n",
    "    float *d_in, *d_out;\n",
    "    cudaMalloc(&d_in, bytes);\n",
    "    cudaMalloc(&d_out, bytes);\n",
    "    \n",
    "    // Initialize input\n",
    "    float* h_in = new float[WIDTH * HEIGHT];\n",
    "    for (int i = 0; i < WIDTH * HEIGHT; i++) h_in[i] = (float)i;\n",
    "    cudaMemcpy(d_in, h_in, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 block(TILE_DIM, BLOCK_ROWS);\n",
    "    dim3 grid((WIDTH + TILE_DIM - 1) / TILE_DIM,\n",
    "              (HEIGHT + TILE_DIM - 1) / TILE_DIM);\n",
    "    \n",
    "    // Warmup\n",
    "    transposeOptimized<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Benchmark\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    const int RUNS = 100;\n",
    "    float ms;\n",
    "    \n",
    "    // Benchmark naive\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < RUNS; i++) {\n",
    "        transposeNaive<<<grid, dim3(32, 32)>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    float naiveBW = 2.0f * bytes / (ms / RUNS / 1000.0f) / 1e9;\n",
    "    printf(\"Naive Transpose:     %.2f GB/s\\n\", naiveBW);\n",
    "    \n",
    "    // Benchmark optimized\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < RUNS; i++) {\n",
    "        transposeOptimized<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    float optBW = 2.0f * bytes / (ms / RUNS / 1000.0f) / 1e9;\n",
    "    printf(\"Optimized Transpose: %.2f GB/s\\n\", optBW);\n",
    "    printf(\"Speedup: %.2fx\\n\", optBW / naiveBW);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    delete[] h_in;\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -O3 -o optimized_transpose optimized_transpose.cu\n",
    "!./optimized_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7911356",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              OPTIMIZATION SUMMARY                           │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  1. Profile First                                           │\n",
    "│     • Identify bottleneck before optimizing                 │\n",
    "│     • Don't guess, measure                                  │\n",
    "│                                                             │\n",
    "│  2. Memory is Usually the Bottleneck                        │\n",
    "│     • Coalescing is critical                                │\n",
    "│     • Shared memory for data reuse                          │\n",
    "│     • Minimize transfers                                    │\n",
    "│                                                             │\n",
    "│  3. Occupancy Matters (to a point)                          │\n",
    "│     • Need enough parallelism to hide latency               │\n",
    "│     • But higher isn't always better                        │\n",
    "│                                                             │\n",
    "│  4. Concurrency for Free Performance                        │\n",
    "│     • Overlap compute and transfers                         │\n",
    "│     • Use streams and graphs                                │\n",
    "│                                                             │\n",
    "│  5. Iterate and Measure                                     │\n",
    "│     • One optimization at a time                            │\n",
    "│     • Verify improvement after each change                  │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Next: Day 4 - Capstone Project"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
