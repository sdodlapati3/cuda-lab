{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "print(\"âš ï¸  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "print(\"âš ï¸  Multi-GPU patterns require multiple physical GPUs!\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d914d",
   "metadata": {},
   "source": [
    "# Day 2: Multi-GPU Patterns - Manager Coordinating Multiple Factories\n",
    "\n",
    "## ğŸ¯ The Hook: One Manager, Many Factories!\n",
    "\n",
    "**You've been promoted from warehouse manager to regional director!** You now oversee multiple factories, each producing parts of a larger product. Your challenge: **coordinate them to work as one efficient system**.\n",
    "\n",
    "Consider building a car:\n",
    "- **Factory 0**: Builds the front half (engine, headlights, hood)\n",
    "- **Factory 1**: Builds the rear half (trunk, taillights, bumper)\n",
    "- **The assembly line**: Needs parts from BOTH to create the final product\n",
    "\n",
    "But wait - what about the **middle of the car** where front meets rear? Both factories need to know about the boundaries to make parts that fit together perfectly!\n",
    "\n",
    "**This is multi-GPU programming at scale:**\n",
    "- **Domain decomposition**: Split the problem across GPUs\n",
    "- **Halo exchange**: Share boundary information\n",
    "- **Reduction patterns**: Combine partial results\n",
    "\n",
    "Today you'll learn to think like a regional director managing multiple factories! ğŸ­ğŸ­ğŸ­\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Implement domain decomposition** - Split arrays and matrices across GPUs evenly\n",
    "2. **Handle boundary conditions** - Exchange halo cells for stencil operations\n",
    "3. **Perform multi-GPU reductions** - Combine partial sums from each GPU efficiently\n",
    "4. **Choose load balancing strategies** - Static vs dynamic work distribution\n",
    "5. **Design scalable patterns** - Write code that works for 2, 4, or 8 GPUs\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ´ Concept Card: Manager Coordinating Multiple Factories\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            MANAGER COORDINATING MULTIPLE FACTORIES              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  PRODUCTION FLOW:                                               â”‚\n",
    "â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "â”‚        â”‚         FULL PRODUCT LINE            â”‚                 â”‚\n",
    "â”‚        â”‚    [Parts 0-3 | Parts 4-7 | 8-11]    â”‚                 â”‚\n",
    "â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "â”‚                â”‚            â”‚           â”‚                       â”‚\n",
    "â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”                  â”‚\n",
    "â”‚           â”‚ Factory â”‚  â”‚ Factory â”‚  â”‚ Factoryâ”‚                  â”‚\n",
    "â”‚           â”‚    0    â”‚  â”‚    1    â”‚  â”‚    2   â”‚                  â”‚\n",
    "â”‚           â”‚[0,1,2,3]â”‚  â”‚[4,5,6,7]â”‚  â”‚[8-11]  â”‚                  â”‚\n",
    "â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â”‚\n",
    "â”‚                â”‚  Boundary  â”‚           â”‚                       â”‚\n",
    "â”‚                â”‚â—„â”€â”€Shareâ”€â”€â–ºâ”‚â—„â”€â”€Shareâ”€â”€â–ºâ”‚                        â”‚\n",
    "â”‚                â”‚  (Halo)   â”‚  (Halo)   â”‚                        â”‚\n",
    "â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”                  â”‚\n",
    "â”‚           â”‚ Partial â”‚  â”‚ Partial â”‚  â”‚Partial â”‚                  â”‚\n",
    "â”‚           â”‚ Sum: 10 â”‚  â”‚ Sum: 26 â”‚  â”‚Sum: 38 â”‚                  â”‚\n",
    "â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â”‚\n",
    "â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
    "â”‚                          â–¼                                      â”‚\n",
    "â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚\n",
    "â”‚                  â”‚ FINAL: 74    â”‚ â† Reduction                   â”‚\n",
    "â”‚                  â”‚ (Combined)   â”‚                               â”‚\n",
    "â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  PATTERNS:                                                      â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  1ï¸âƒ£ DOMAIN DECOMPOSITION:                                      â”‚\n",
    "â”‚     N elements Ã· K GPUs = chunk per GPU                         â”‚\n",
    "â”‚     Handle remainder: GPU i gets extra if i < (N % K)           â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  2ï¸âƒ£ HALO EXCHANGE (for stencils):                              â”‚\n",
    "â”‚     Before compute: get neighbor's boundary                     â”‚\n",
    "â”‚     [ghost|real data...|ghost]                                  â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  3ï¸âƒ£ REDUCTION:                                                  â”‚\n",
    "â”‚     Each GPU: local reduce â†’ partial result                     â”‚\n",
    "â”‚     Manager: combine partials â†’ final result                    â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  ğŸ’¡ KEY INSIGHT:                                                â”‚\n",
    "â”‚  Good managers (you!) minimize communication between factories  â”‚\n",
    "â”‚  while ensuring everyone has what they need. Same with GPUs -   â”‚\n",
    "â”‚  minimize P2P transfers, maximize independent computation!      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fda62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Domain Decomposition\n",
    "\n",
    "### Splitting Work Across GPUs\n",
    "\n",
    "```\n",
    "1D Domain Decomposition:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Full Array: [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]\n",
    "                    â†“\n",
    "GPU 0:      [0 1 2 3 4 5 6 7]\n",
    "GPU 1:      [8 9 10 11 12 13 14 15]\n",
    "\n",
    "2D Domain Decomposition:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  GPU 0  â”‚  GPU 1  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  GPU 2  â”‚  GPU 3  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Domain Decomposition (Primary)\n",
    "\n",
    "```cpp\n",
    "// domain_decomp.cu - 1D domain decomposition\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processChunk(float* data, int n, int globalOffset) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        int globalIdx = globalOffset + tid;\n",
    "        data[tid] = sinf((float)globalIdx * 0.01f);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;  // 16M elements\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    printf(\"Using %d GPUs for %d elements\\n\", NUM_GPUS, TOTAL_N);\n",
    "    \n",
    "    // Calculate chunk sizes\n",
    "    int baseChunkSize = TOTAL_N / NUM_GPUS;\n",
    "    int remainder = TOTAL_N % NUM_GPUS;\n",
    "    \n",
    "    // Arrays for per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    int chunkSizes[NUM_GPUS];\n",
    "    int offsets[NUM_GPUS];\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // ============================================\n",
    "    // Calculate Per-GPU Chunks (Handle Remainder)\n",
    "    // ============================================\n",
    "    int currentOffset = 0;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        // Distribute remainder across first few GPUs\n",
    "        chunkSizes[gpu] = baseChunkSize + (gpu < remainder ? 1 : 0);\n",
    "        offsets[gpu] = currentOffset;\n",
    "        currentOffset += chunkSizes[gpu];\n",
    "        \n",
    "        printf(\"GPU %d: offset=%d, size=%d\\n\", \n",
    "               gpu, offsets[gpu], chunkSizes[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Allocate on Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], chunkSizes[gpu] * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Launch Kernels on Each GPU\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    \n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        int numBlocks = (chunkSizes[gpu] + blockSize - 1) / blockSize;\n",
    "        \n",
    "        processChunk<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_data[gpu], chunkSizes[gpu], offsets[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Synchronize All GPUs\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"All GPUs finished processing!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile domain_decomp.cu\n",
    "// domain_decomp.cu - 1D domain decomposition\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processChunk(float* data, int n, int globalOffset) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        int globalIdx = globalOffset + tid;\n",
    "        data[tid] = sinf((float)globalIdx * 0.01f);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;  // 16M elements\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    printf(\"Using %d GPUs for %d elements\\n\", NUM_GPUS, TOTAL_N);\n",
    "    \n",
    "    // Calculate chunk sizes\n",
    "    int baseChunkSize = TOTAL_N / NUM_GPUS;\n",
    "    int remainder = TOTAL_N % NUM_GPUS;\n",
    "    \n",
    "    // Arrays for per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    int chunkSizes[NUM_GPUS];\n",
    "    int offsets[NUM_GPUS];\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // ============================================\n",
    "    // Calculate Per-GPU Chunks (Handle Remainder)\n",
    "    // ============================================\n",
    "    int currentOffset = 0;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        // Distribute remainder across first few GPUs\n",
    "        chunkSizes[gpu] = baseChunkSize + (gpu < remainder ? 1 : 0);\n",
    "        offsets[gpu] = currentOffset;\n",
    "        currentOffset += chunkSizes[gpu];\n",
    "        \n",
    "        printf(\"GPU %d: offset=%d, size=%d\\n\", \n",
    "               gpu, offsets[gpu], chunkSizes[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Allocate on Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], chunkSizes[gpu] * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Launch Kernels on Each GPU\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    \n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        int numBlocks = (chunkSizes[gpu] + blockSize - 1) / blockSize;\n",
    "        \n",
    "        processChunk<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_data[gpu], chunkSizes[gpu], offsets[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Synchronize All GPUs\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"All GPUs finished processing!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6417cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o domain_decomp domain_decomp.cu\n",
    "!./domain_decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ae923e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Halo Exchange\n",
    "\n",
    "### Stencil Operations Require Boundary Data\n",
    "\n",
    "```\n",
    "Problem: Stencil needs neighbors\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "GPU 0 data:  [a b c d e | f g h]\n",
    "GPU 1 data:  [i j k | l m n o p]\n",
    "               â†‘       â†‘\n",
    "         Need f,g,h  Need e\n",
    "\n",
    "Solution: Halo/Ghost cells\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "GPU 0: [a b c d e | f g h] + [i j k]  â† halo from GPU 1\n",
    "GPU 1: [f g h] + [i j k | l m n o p]  â† halo from GPU 0\n",
    "        â†‘                     \n",
    "   halo from GPU 0\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Halo Exchange (Primary)\n",
    "\n",
    "```cpp\n",
    "// halo_exchange.cu - Exchange boundary data between GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define HALO_SIZE 3  // Stencil radius\n",
    "\n",
    "// Stencil kernel (5-point average)\n",
    "__global__ void stencil(float* out, float* in, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Skip halo regions for output\n",
    "    if (tid >= HALO_SIZE && tid < n - HALO_SIZE) {\n",
    "        out[tid] = 0.2f * (in[tid-2] + in[tid-1] + in[tid] + \n",
    "                          in[tid+1] + in[tid+2]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    if (deviceCount < 2) {\n",
    "        printf(\"Need 2 GPUs for halo exchange\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    const int CHUNK_SIZE = 1024;  // Data per GPU\n",
    "    const int TOTAL_SIZE = CHUNK_SIZE + 2 * HALO_SIZE;  // + halos\n",
    "    \n",
    "    float *d_in[2], *d_out[2];\n",
    "    cudaStream_t streams[2];\n",
    "    \n",
    "    // Enable P2P\n",
    "    int canP2P;\n",
    "    cudaDeviceCanAccessPeer(&canP2P, 0, 1);\n",
    "    if (canP2P) {\n",
    "        cudaSetDevice(0); cudaDeviceEnablePeerAccess(1, 0);\n",
    "        cudaSetDevice(1); cudaDeviceEnablePeerAccess(0, 0);\n",
    "    }\n",
    "    \n",
    "    // Allocate with halo space\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_in[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaMalloc(&d_out[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Initialize\n",
    "        cudaMemset(d_in[gpu], 0, TOTAL_SIZE * sizeof(float));\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Halo Exchange\n",
    "    // ============================================\n",
    "    // GPU 0's right boundary -> GPU 1's left halo\n",
    "    // GPU 1's left boundary -> GPU 0's right halo\n",
    "    \n",
    "    // GPU 0: Copy rightmost data to GPU 1's left halo\n",
    "    // d_in[0][HALO_SIZE + CHUNK_SIZE - HALO_SIZE ... ] -> d_in[1][0...]\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[1],                    // dst: GPU 1's left halo\n",
    "        1,                          // dst device\n",
    "        d_in[0] + CHUNK_SIZE,       // src: GPU 0's right boundary\n",
    "        0,                          // src device\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[0]);\n",
    "    \n",
    "    // GPU 1: Copy leftmost data to GPU 0's right halo\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[0] + HALO_SIZE + CHUNK_SIZE,  // dst: GPU 0's right halo\n",
    "        0,\n",
    "        d_in[1] + HALO_SIZE,               // src: GPU 1's left boundary\n",
    "        1,\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[1]);\n",
    "    \n",
    "    // Sync before compute\n",
    "    cudaSetDevice(0); cudaStreamSynchronize(streams[0]);\n",
    "    cudaSetDevice(1); cudaStreamSynchronize(streams[1]);\n",
    "    \n",
    "    // ============================================\n",
    "    // Compute Stencil\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (TOTAL_SIZE + blockSize - 1) / blockSize;\n",
    "    \n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        stencil<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_out[gpu], d_in[gpu], TOTAL_SIZE);\n",
    "    }\n",
    "    \n",
    "    // Sync\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"Halo exchange and stencil complete!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_in[gpu]);\n",
    "        cudaFree(d_out[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e53c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile halo_exchange.cu\n",
    "// halo_exchange.cu - Exchange boundary data between GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define HALO_SIZE 3  // Stencil radius\n",
    "\n",
    "// Stencil kernel (5-point average)\n",
    "__global__ void stencil(float* out, float* in, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Skip halo regions for output\n",
    "    if (tid >= HALO_SIZE && tid < n - HALO_SIZE) {\n",
    "        out[tid] = 0.2f * (in[tid-2] + in[tid-1] + in[tid] + \n",
    "                          in[tid+1] + in[tid+2]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    if (deviceCount < 2) {\n",
    "        printf(\"Need 2 GPUs for halo exchange\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    const int CHUNK_SIZE = 1024;  // Data per GPU\n",
    "    const int TOTAL_SIZE = CHUNK_SIZE + 2 * HALO_SIZE;  // + halos\n",
    "    \n",
    "    float *d_in[2], *d_out[2];\n",
    "    cudaStream_t streams[2];\n",
    "    \n",
    "    // Enable P2P\n",
    "    int canP2P;\n",
    "    cudaDeviceCanAccessPeer(&canP2P, 0, 1);\n",
    "    if (canP2P) {\n",
    "        cudaSetDevice(0); cudaDeviceEnablePeerAccess(1, 0);\n",
    "        cudaSetDevice(1); cudaDeviceEnablePeerAccess(0, 0);\n",
    "    }\n",
    "    \n",
    "    // Allocate with halo space\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_in[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaMalloc(&d_out[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Initialize\n",
    "        cudaMemset(d_in[gpu], 0, TOTAL_SIZE * sizeof(float));\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Halo Exchange\n",
    "    // ============================================\n",
    "    // GPU 0's right boundary -> GPU 1's left halo\n",
    "    // GPU 1's left boundary -> GPU 0's right halo\n",
    "    \n",
    "    // GPU 0: Copy rightmost data to GPU 1's left halo\n",
    "    // d_in[0][HALO_SIZE + CHUNK_SIZE - HALO_SIZE ... ] -> d_in[1][0...]\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[1],                    // dst: GPU 1's left halo\n",
    "        1,                          // dst device\n",
    "        d_in[0] + CHUNK_SIZE,       // src: GPU 0's right boundary\n",
    "        0,                          // src device\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[0]);\n",
    "    \n",
    "    // GPU 1: Copy leftmost data to GPU 0's right halo\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[0] + HALO_SIZE + CHUNK_SIZE,  // dst: GPU 0's right halo\n",
    "        0,\n",
    "        d_in[1] + HALO_SIZE,               // src: GPU 1's left boundary\n",
    "        1,\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[1]);\n",
    "    \n",
    "    // Sync before compute\n",
    "    cudaSetDevice(0); cudaStreamSynchronize(streams[0]);\n",
    "    cudaSetDevice(1); cudaStreamSynchronize(streams[1]);\n",
    "    \n",
    "    // ============================================\n",
    "    // Compute Stencil\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (TOTAL_SIZE + blockSize - 1) / blockSize;\n",
    "    \n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        stencil<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_out[gpu], d_in[gpu], TOTAL_SIZE);\n",
    "    }\n",
    "    \n",
    "    // Sync\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"Halo exchange and stencil complete!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_in[gpu]);\n",
    "        cudaFree(d_out[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc072b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o halo_exchange halo_exchange.cu\n",
    "!./halo_exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72151826",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Multi-GPU Reduction\n",
    "\n",
    "### Combining Results Across GPUs\n",
    "\n",
    "```cpp\n",
    "// multi_gpu_reduction.cu - Reduce across multiple GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Block reduction kernel\n",
    "__global__ void reduce(float* out, float* in, int n) {\n",
    "    extern __shared__ float sdata[];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    sdata[tid] = (idx < n) ? in[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        out[blockIdx.x] = sdata[0];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;\n",
    "    const int N_PER_GPU = TOTAL_N / NUM_GPUS;\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    const int NUM_BLOCKS = (N_PER_GPU + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    // Per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    float* d_partial[NUM_GPUS];\n",
    "    float h_partial[NUM_GPUS];  // Final partial sums\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // Allocate and initialize\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], N_PER_GPU * sizeof(float));\n",
    "        cudaMalloc(&d_partial[gpu], NUM_BLOCKS * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Init with 1s\n",
    "        float* h_temp = new float[N_PER_GPU];\n",
    "        for (int i = 0; i < N_PER_GPU; i++) h_temp[i] = 1.0f;\n",
    "        cudaMemcpy(d_data[gpu], h_temp, N_PER_GPU * sizeof(float),\n",
    "                   cudaMemcpyHostToDevice);\n",
    "        delete[] h_temp;\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 1: Reduce Within Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        reduce<<<NUM_BLOCKS, BLOCK_SIZE, BLOCK_SIZE * sizeof(float), \n",
    "                 streams[gpu]>>>(d_partial[gpu], d_data[gpu], N_PER_GPU);\n",
    "        \n",
    "        // Second reduction pass\n",
    "        int remaining = NUM_BLOCKS;\n",
    "        while (remaining > 1) {\n",
    "            int newBlocks = (remaining + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "            reduce<<<newBlocks, BLOCK_SIZE, BLOCK_SIZE * sizeof(float),\n",
    "                     streams[gpu]>>>(d_partial[gpu], d_partial[gpu], remaining);\n",
    "            remaining = newBlocks;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 2: Collect Partial Sums to Host\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMemcpyAsync(&h_partial[gpu], d_partial[gpu], sizeof(float),\n",
    "                        cudaMemcpyDeviceToHost, streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // Sync all\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 3: Final Sum on Host\n",
    "    // ============================================\n",
    "    float total = 0.0f;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        printf(\"GPU %d partial sum: %.0f\\n\", gpu, h_partial[gpu]);\n",
    "        total += h_partial[gpu];\n",
    "    }\n",
    "    \n",
    "    printf(\"Total sum: %.0f (expected %d)\\n\", total, TOTAL_N);\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaFree(d_partial[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multi_gpu_reduction.cu\n",
    "// multi_gpu_reduction.cu - Reduce across multiple GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Block reduction kernel\n",
    "__global__ void reduce(float* out, float* in, int n) {\n",
    "    extern __shared__ float sdata[];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    sdata[tid] = (idx < n) ? in[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        out[blockIdx.x] = sdata[0];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;\n",
    "    const int N_PER_GPU = TOTAL_N / NUM_GPUS;\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    const int NUM_BLOCKS = (N_PER_GPU + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    // Per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    float* d_partial[NUM_GPUS];\n",
    "    float h_partial[NUM_GPUS];  // Final partial sums\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // Allocate and initialize\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], N_PER_GPU * sizeof(float));\n",
    "        cudaMalloc(&d_partial[gpu], NUM_BLOCKS * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Init with 1s\n",
    "        float* h_temp = new float[N_PER_GPU];\n",
    "        for (int i = 0; i < N_PER_GPU; i++) h_temp[i] = 1.0f;\n",
    "        cudaMemcpy(d_data[gpu], h_temp, N_PER_GPU * sizeof(float),\n",
    "                   cudaMemcpyHostToDevice);\n",
    "        delete[] h_temp;\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 1: Reduce Within Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        reduce<<<NUM_BLOCKS, BLOCK_SIZE, BLOCK_SIZE * sizeof(float), \n",
    "                 streams[gpu]>>>(d_partial[gpu], d_data[gpu], N_PER_GPU);\n",
    "        \n",
    "        // Second reduction pass\n",
    "        int remaining = NUM_BLOCKS;\n",
    "        while (remaining > 1) {\n",
    "            int newBlocks = (remaining + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "            reduce<<<newBlocks, BLOCK_SIZE, BLOCK_SIZE * sizeof(float),\n",
    "                     streams[gpu]>>>(d_partial[gpu], d_partial[gpu], remaining);\n",
    "            remaining = newBlocks;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 2: Collect Partial Sums to Host\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMemcpyAsync(&h_partial[gpu], d_partial[gpu], sizeof(float),\n",
    "                        cudaMemcpyDeviceToHost, streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // Sync all\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 3: Final Sum on Host\n",
    "    // ============================================\n",
    "    float total = 0.0f;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        printf(\"GPU %d partial sum: %.0f\\n\", gpu, h_partial[gpu]);\n",
    "        total += h_partial[gpu];\n",
    "    }\n",
    "    \n",
    "    printf(\"Total sum: %.0f (expected %d)\\n\", total, TOTAL_N);\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaFree(d_partial[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfeaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o multi_gpu_reduction multi_gpu_reduction.cu\n",
    "!./multi_gpu_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6d9cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Load Balancing\n",
    "\n",
    "### Handling Non-Uniform Work\n",
    "\n",
    "```\n",
    "Static Partitioning (Simple but can be unbalanced):\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "GPU 0: [0, N/4)   â†’ May be easy work\n",
    "GPU 1: [N/4, N/2) â†’ May be hard work\n",
    "GPU 2: [N/2, 3N/4) â†’ Variable\n",
    "GPU 3: [3N/4, N)  â†’ Variable\n",
    "\n",
    "Dynamic Load Balancing:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "â€¢ Work queue with atomic counter\n",
    "â€¢ GPUs grab chunks as they finish\n",
    "â€¢ Better for non-uniform work\n",
    "```\n",
    "\n",
    "```cpp\n",
    "// Simple work-stealing pattern\n",
    "__device__ int workCounter = 0;\n",
    "\n",
    "__global__ void dynamicWork(float* data, int totalChunks, int chunkSize) {\n",
    "    while (true) {\n",
    "        // Atomically get next chunk\n",
    "        int myChunk = atomicAdd(&workCounter, 1);\n",
    "        \n",
    "        if (myChunk >= totalChunks) break;\n",
    "        \n",
    "        // Process chunk\n",
    "        int start = myChunk * chunkSize;\n",
    "        for (int i = threadIdx.x; i < chunkSize; i += blockDim.x) {\n",
    "            data[start + i] = processElement(data[start + i]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb3091",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a971595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multi_gpu_patterns_exercises.cu\n",
    "// multi_gpu_patterns_exercises.cu - Multi-GPU Pattern Exercises\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define CHECK_CUDA(call) { \\\n",
    "    cudaError_t err = call; \\\n",
    "    if (err != cudaSuccess) { \\\n",
    "        printf(\"CUDA error %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
    "               cudaGetErrorString(err)); \\\n",
    "        exit(1); \\\n",
    "    } \\\n",
    "}\n",
    "\n",
    "// ============================================\n",
    "// Exercise 1: 2D Domain Decomposition\n",
    "// ============================================\n",
    "__global__ void matrixScaleKernel(float* matrix, int width, int height, float scale) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (x < width && y < height) {\n",
    "        int idx = y * width + x;\n",
    "        matrix[idx] *= scale;\n",
    "    }\n",
    "}\n",
    "\n",
    "void test2DDecomposition() {\n",
    "    printf(\"\\n=== Exercise 1: 2D Domain Decomposition ===\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));\n",
    "    int numGPUs = (deviceCount >= 2) ? 2 : 1;\n",
    "    \n",
    "    const int WIDTH = 4096;\n",
    "    const int HEIGHT = 4096;\n",
    "    const size_t totalSize = WIDTH * HEIGHT * sizeof(float);\n",
    "    \n",
    "    printf(\"Matrix: %d x %d (%.0f MB)\\n\", WIDTH, HEIGHT, totalSize / (1024.0 * 1024.0));\n",
    "    printf(\"Using %d GPU(s) with row decomposition\\n\\n\", numGPUs);\n",
    "    \n",
    "    // Host matrix\n",
    "    float* h_matrix;\n",
    "    CHECK_CUDA(cudaMallocHost(&h_matrix, totalSize));\n",
    "    \n",
    "    // Initialize\n",
    "    for (int i = 0; i < WIDTH * HEIGHT; i++) {\n",
    "        h_matrix[i] = (float)(i % 100) / 100.0f;\n",
    "    }\n",
    "    \n",
    "    // Calculate row chunks per GPU\n",
    "    int rowsPerGPU = HEIGHT / numGPUs;\n",
    "    int remainderRows = HEIGHT % numGPUs;\n",
    "    \n",
    "    float* d_chunks[2];\n",
    "    cudaStream_t streams[2];\n",
    "    int rowOffsets[2], rowCounts[2];\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CHECK_CUDA(cudaSetDevice(0));\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Setup\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        rowOffsets[i] = i * rowsPerGPU;\n",
    "        rowCounts[i] = rowsPerGPU + (i == numGPUs - 1 ? remainderRows : 0);\n",
    "        size_t chunkSize = rowCounts[i] * WIDTH * sizeof(float);\n",
    "        \n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        CHECK_CUDA(cudaStreamCreate(&streams[i]));\n",
    "        CHECK_CUDA(cudaMalloc(&d_chunks[i], chunkSize));\n",
    "        \n",
    "        printf(\"GPU %d: rows %d-%d (%d rows, %.1f MB)\\n\",\n",
    "               i, rowOffsets[i], rowOffsets[i] + rowCounts[i] - 1,\n",
    "               rowCounts[i], chunkSize / (1024.0 * 1024.0));\n",
    "    }\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    \n",
    "    // Copy chunks to GPUs\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        size_t offset = rowOffsets[i] * WIDTH;\n",
    "        size_t chunkSize = rowCounts[i] * WIDTH * sizeof(float);\n",
    "        CHECK_CUDA(cudaMemcpyAsync(d_chunks[i], h_matrix + offset,\n",
    "                                   chunkSize, cudaMemcpyHostToDevice, streams[i]));\n",
    "    }\n",
    "    \n",
    "    // Process each chunk\n",
    "    dim3 blockDim(16, 16);\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        dim3 gridDim((WIDTH + blockDim.x - 1) / blockDim.x,\n",
    "                     (rowCounts[i] + blockDim.y - 1) / blockDim.y);\n",
    "        matrixScaleKernel<<<gridDim, blockDim, 0, streams[i]>>>(\n",
    "            d_chunks[i], WIDTH, rowCounts[i], 2.0f);\n",
    "    }\n",
    "    \n",
    "    // Copy back\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        size_t offset = rowOffsets[i] * WIDTH;\n",
    "        size_t chunkSize = rowCounts[i] * WIDTH * sizeof(float);\n",
    "        CHECK_CUDA(cudaMemcpyAsync(h_matrix + offset, d_chunks[i],\n",
    "                                   chunkSize, cudaMemcpyDeviceToHost, streams[i]));\n",
    "    }\n",
    "    \n",
    "    // Sync\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        CHECK_CUDA(cudaStreamSynchronize(streams[i]));\n",
    "    }\n",
    "    \n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    // Verify (check a few samples)\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        int idx = (i * WIDTH * HEIGHT / 10) % (WIDTH * HEIGHT);\n",
    "        float expected = ((idx % 100) / 100.0f) * 2.0f;\n",
    "        if (fabs(h_matrix[idx] - expected) > 1e-5) {\n",
    "            printf(\"Mismatch at %d: %.4f vs %.4f\\n\", idx, h_matrix[idx], expected);\n",
    "            correct = false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nTime: %.3f ms\\n\", ms);\n",
    "    printf(\"Throughput: %.2f GB/s\\n\", 2.0 * totalSize / (ms / 1000.0) / (1024*1024*1024));\n",
    "    printf(\"Result: %s\\n\", correct ? \"CORRECT âœ“\" : \"INCORRECT âœ—\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        cudaSetDevice(i);\n",
    "        cudaFree(d_chunks[i]);\n",
    "        cudaStreamDestroy(streams[i]);\n",
    "    }\n",
    "    cudaFreeHost(h_matrix);\n",
    "}\n",
    "\n",
    "// ============================================\n",
    "// Exercise 2: Ring AllReduce Sum\n",
    "// ============================================\n",
    "__global__ void partialSumKernel(float* data, float* result, int n) {\n",
    "    extern __shared__ float sdata[];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    sdata[tid] = (idx < n) ? data[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Reduction in shared memory\n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        atomicAdd(result, sdata[0]);\n",
    "    }\n",
    "}\n",
    "\n",
    "void testRingAllReduce() {\n",
    "    printf(\"\\n=== Exercise 2: Ring AllReduce Sum ===\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));\n",
    "    int numGPUs = (deviceCount >= 2) ? 2 : 1;\n",
    "    \n",
    "    const int N = 1024 * 1024;  // 1M elements per GPU\n",
    "    printf(\"Each GPU has %d elements\\n\", N);\n",
    "    printf(\"Using %d GPU(s)\\n\\n\", numGPUs);\n",
    "    \n",
    "    // Allocate and initialize on each GPU\n",
    "    float* d_data[2];\n",
    "    float* d_partialSum[2];\n",
    "    float h_partialSums[2];\n",
    "    \n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        CHECK_CUDA(cudaMalloc(&d_data[i], N * sizeof(float)));\n",
    "        CHECK_CUDA(cudaMalloc(&d_partialSum[i], sizeof(float)));\n",
    "        CHECK_CUDA(cudaMemset(d_partialSum[i], 0, sizeof(float)));\n",
    "        \n",
    "        // Initialize with GPU-specific pattern: GPU i has values i+1\n",
    "        float* h_temp = (float*)malloc(N * sizeof(float));\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            h_temp[j] = (float)(i + 1);\n",
    "        }\n",
    "        CHECK_CUDA(cudaMemcpy(d_data[i], h_temp, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "        free(h_temp);\n",
    "    }\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CHECK_CUDA(cudaSetDevice(0));\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    \n",
    "    // Step 1: Local reduction on each GPU\n",
    "    int blockSize = 256;\n",
    "    int gridSize = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        partialSumKernel<<<gridSize, blockSize, blockSize * sizeof(float)>>>(\n",
    "            d_data[i], d_partialSum[i], N);\n",
    "    }\n",
    "    \n",
    "    // Sync all GPUs\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    }\n",
    "    \n",
    "    // Step 2: Gather partial sums to host\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        CHECK_CUDA(cudaSetDevice(i));\n",
    "        CHECK_CUDA(cudaMemcpy(&h_partialSums[i], d_partialSum[i], \n",
    "                              sizeof(float), cudaMemcpyDeviceToHost));\n",
    "    }\n",
    "    \n",
    "    // Step 3: Final reduction on host (or could be on GPU 0)\n",
    "    float totalSum = 0;\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        printf(\"GPU %d partial sum: %.0f\\n\", i, h_partialSums[i]);\n",
    "        totalSum += h_partialSums[i];\n",
    "    }\n",
    "    \n",
    "    // Step 4: Broadcast back (in ring pattern for multi-GPU)\n",
    "    // For simplicity, we just compute expected\n",
    "    float expectedSum = 0;\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        expectedSum += (float)(i + 1) * N;  // Each GPU has N copies of (i+1)\n",
    "    }\n",
    "    \n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    printf(\"\\nTotal sum: %.0f\\n\", totalSum);\n",
    "    printf(\"Expected:  %.0f\\n\", expectedSum);\n",
    "    printf(\"Time: %.3f ms\\n\", ms);\n",
    "    printf(\"Result: %s\\n\", (totalSum == expectedSum) ? \"CORRECT âœ“\" : \"INCORRECT âœ—\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int i = 0; i < numGPUs; i++) {\n",
    "        cudaSetDevice(i);\n",
    "        cudaFree(d_data[i]);\n",
    "        cudaFree(d_partialSum[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "// ============================================\n",
    "// Exercise 3: Async Halo Exchange + Compute\n",
    "// ============================================\n",
    "__global__ void stencilInteriorKernel(float* data, float* output, int width, int height) {\n",
    "    // Process interior points (not touching boundaries)\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x + 1;  // Skip first column\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y + 1;  // Skip first row\n",
    "    \n",
    "    if (x < width - 1 && y < height - 1) {\n",
    "        int idx = y * width + x;\n",
    "        // 5-point stencil\n",
    "        output[idx] = 0.2f * (data[idx] + \n",
    "                              data[idx - 1] + data[idx + 1] +\n",
    "                              data[idx - width] + data[idx + width]);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void stencilBoundaryKernel(float* data, float* output, int width, int height,\n",
    "                                       int boundaryType) {\n",
    "    // boundaryType: 0=top, 1=bottom, 2=left, 3=right\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (boundaryType == 0 && tid > 0 && tid < width - 1) {\n",
    "        // Top row (y=1, after halo)\n",
    "        int idx = width + tid;  // Row 1\n",
    "        output[idx] = 0.2f * (data[idx] + data[idx-1] + data[idx+1] +\n",
    "                              data[idx-width] + data[idx+width]);\n",
    "    }\n",
    "    else if (boundaryType == 1 && tid > 0 && tid < width - 1) {\n",
    "        // Bottom row\n",
    "        int y = height - 2;\n",
    "        int idx = y * width + tid;\n",
    "        output[idx] = 0.2f * (data[idx] + data[idx-1] + data[idx+1] +\n",
    "                              data[idx-width] + data[idx+width]);\n",
    "    }\n",
    "}\n",
    "\n",
    "void testAsyncHaloExchange() {\n",
    "    printf(\"\\n=== Exercise 3: Async Halo Exchange + Compute ===\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));\n",
    "    \n",
    "    // This pattern is best demonstrated on a single GPU with streams\n",
    "    printf(\"Demonstrating overlapped halo exchange pattern on GPU 0\\n\\n\");\n",
    "    \n",
    "    const int WIDTH = 1024;\n",
    "    const int HEIGHT = 1024;\n",
    "    const int HALO = 1;  // 1-cell halo for 5-point stencil\n",
    "    \n",
    "    // Simulate 2 domains (top and bottom halves)\n",
    "    int halfHeight = HEIGHT / 2 + HALO;  // Include halo row\n",
    "    size_t domainSize = WIDTH * halfHeight * sizeof(float);\n",
    "    \n",
    "    printf(\"Domain: %d x %d, split into 2 halves\\n\", WIDTH, HEIGHT);\n",
    "    printf(\"Each half: %d x %d (including halo)\\n\\n\", WIDTH, halfHeight);\n",
    "    \n",
    "    CHECK_CUDA(cudaSetDevice(0));\n",
    "    \n",
    "    float *d_domain0, *d_domain1;\n",
    "    float *d_output0, *d_output1;\n",
    "    CHECK_CUDA(cudaMalloc(&d_domain0, domainSize));\n",
    "    CHECK_CUDA(cudaMalloc(&d_domain1, domainSize));\n",
    "    CHECK_CUDA(cudaMalloc(&d_output0, domainSize));\n",
    "    CHECK_CUDA(cudaMalloc(&d_output1, domainSize));\n",
    "    \n",
    "    // Initialize with pattern\n",
    "    float* h_init = (float*)malloc(domainSize);\n",
    "    for (int i = 0; i < WIDTH * halfHeight; i++) {\n",
    "        h_init[i] = 1.0f;\n",
    "    }\n",
    "    CHECK_CUDA(cudaMemcpy(d_domain0, h_init, domainSize, cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemcpy(d_domain1, h_init, domainSize, cudaMemcpyHostToDevice));\n",
    "    \n",
    "    cudaStream_t computeStream, haloStream;\n",
    "    cudaStreamCreate(&computeStream);\n",
    "    cudaStreamCreate(&haloStream);\n",
    "    \n",
    "    cudaEvent_t start, stop, haloComplete;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    cudaEventCreate(&haloComplete);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    \n",
    "    // === Overlapped execution pattern ===\n",
    "    \n",
    "    // 1. Start halo exchange (async copy of boundary rows)\n",
    "    float* haloBuffer;\n",
    "    CHECK_CUDA(cudaMallocHost(&haloBuffer, WIDTH * sizeof(float)));\n",
    "    \n",
    "    // Copy bottom row of domain0 to halo of domain1 (via host for demo)\n",
    "    int srcRow = halfHeight - HALO - 1;  // Last non-halo row of domain0\n",
    "    CHECK_CUDA(cudaMemcpyAsync(haloBuffer, d_domain0 + srcRow * WIDTH,\n",
    "                                WIDTH * sizeof(float), cudaMemcpyDeviceToHost, haloStream));\n",
    "    CHECK_CUDA(cudaMemcpyAsync(d_domain1, haloBuffer,  // First row (halo) of domain1\n",
    "                                WIDTH * sizeof(float), cudaMemcpyHostToDevice, haloStream));\n",
    "    cudaEventRecord(haloComplete, haloStream);\n",
    "    \n",
    "    // 2. Compute interior (can run in parallel with halo exchange)\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((WIDTH - 2 + blockDim.x - 1) / blockDim.x,\n",
    "                 (halfHeight - 2 + blockDim.y - 1) / blockDim.y);\n",
    "    \n",
    "    stencilInteriorKernel<<<gridDim, blockDim, 0, computeStream>>>(\n",
    "        d_domain0, d_output0, WIDTH, halfHeight);\n",
    "    stencilInteriorKernel<<<gridDim, blockDim, 0, computeStream>>>(\n",
    "        d_domain1, d_output1, WIDTH, halfHeight);\n",
    "    \n",
    "    // 3. Wait for halo exchange to complete\n",
    "    cudaStreamWaitEvent(computeStream, haloComplete, 0);\n",
    "    \n",
    "    // 4. Process boundary rows (depend on halo data)\n",
    "    int boundaryBlocks = (WIDTH + 255) / 256;\n",
    "    stencilBoundaryKernel<<<boundaryBlocks, 256, 0, computeStream>>>(\n",
    "        d_domain1, d_output1, WIDTH, halfHeight, 0);  // Top boundary of domain1\n",
    "    \n",
    "    cudaEventRecord(stop, computeStream);\n",
    "    CHECK_CUDA(cudaStreamSynchronize(computeStream));\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    printf(\"Stencil computation with overlapped halo exchange:\\n\");\n",
    "    printf(\"  Total time: %.3f ms\\n\", ms);\n",
    "    printf(\"  Pattern: Halo copy || Interior compute -> Boundary compute\\n\");\n",
    "    printf(\"\\nâœ“ Demonstrated async halo exchange pattern\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaStreamDestroy(computeStream);\n",
    "    cudaStreamDestroy(haloStream);\n",
    "    cudaFree(d_domain0);\n",
    "    cudaFree(d_domain1);\n",
    "    cudaFree(d_output0);\n",
    "    cudaFree(d_output1);\n",
    "    cudaFreeHost(haloBuffer);\n",
    "    free(h_init);\n",
    "}\n",
    "\n",
    "// ============================================\n",
    "// Main\n",
    "// ============================================\n",
    "int main() {\n",
    "    printf(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\");\n",
    "    printf(\"â•‘           MULTI-GPU PATTERNS - EXERCISES                      â•‘\\n\");\n",
    "    printf(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));\n",
    "    printf(\"\\nFound %d GPU(s)\\n\", deviceCount);\n",
    "    \n",
    "    test2DDecomposition();\n",
    "    testRingAllReduce();\n",
    "    testAsyncHaloExchange();\n",
    "    \n",
    "    printf(\"\\nâœ“ All exercises completed!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be373ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o multi_gpu_patterns_exercises multi_gpu_patterns_exercises.cu && ./multi_gpu_patterns_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0ffaf",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "### Exercise 1: 2D Decomposition\n",
    "Implement 2D domain decomposition for a matrix operation.\n",
    "\n",
    "### Exercise 2: Ring AllReduce\n",
    "Implement ring allreduce pattern for multi-GPU sum.\n",
    "\n",
    "### Exercise 3: Async Halo Exchange\n",
    "Overlap halo exchange with interior computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d8f75",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  MULTI-GPU PATTERNS                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  ğŸ­ THE FACTORY MANAGER MENTAL MODEL:                           â”‚\n",
    "â”‚  â€¢ You're the manager coordinating multiple factories (GPUs)    â”‚\n",
    "â”‚  â€¢ Each factory works independently on its chunk                â”‚\n",
    "â”‚  â€¢ Boundaries require communication (halo exchange)             â”‚\n",
    "â”‚  â€¢ Results need combination (reduction)                         â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  ğŸ“Š DOMAIN DECOMPOSITION:                                       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  int chunkSize = N / numGPUs;                                   â”‚\n",
    "â”‚  int remainder = N % numGPUs;                                   â”‚\n",
    "â”‚  // GPU i gets: chunkSize + (i < remainder ? 1 : 0)             â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  1D: Simple array split                                         â”‚\n",
    "â”‚  2D: Row-wise, column-wise, or tile-based                       â”‚\n",
    "â”‚  3D: Slab or cube decomposition                                 â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  ğŸ”„ HALO EXCHANGE (Stencil Operations):                         â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Pattern:                                                       â”‚\n",
    "â”‚  1. Allocate: realData + 2*haloSize                             â”‚\n",
    "â”‚  2. Copy: exchange boundaries with neighbors                    â”‚\n",
    "â”‚  3. Compute: include halo in stencil                            â”‚\n",
    "â”‚  4. Repeat: if iterative algorithm                              â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  âš¡ Optimization: Overlap halo copy with interior compute!      â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â• MULTI-GPU REDUCTION:                                        â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Strategy 1: Collect to Host                                    â”‚\n",
    "â”‚    Each GPU â†’ partial sum â†’ host combines                       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Strategy 2: Collect to GPU 0                                   â”‚\n",
    "â”‚    Each GPU â†’ partial sum â†’ P2P to GPU 0 â†’ GPU 0 combines       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Strategy 3: Ring AllReduce (advanced)                          â”‚\n",
    "â”‚    Circular passing + accumulation - all GPUs get result        â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  âš–ï¸ LOAD BALANCING:                                             â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Static: Simple, works for uniform work                         â”‚\n",
    "â”‚  Dynamic: Work queues for variable workloads (GPU grabs tasks)  â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  ğŸ’¡ Callback to Week 7: Remember occupancy? Now think about     â”‚\n",
    "â”‚  \"multi-GPU occupancy\" - keeping ALL GPUs busy!                 â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "You've learned to coordinate multiple factories. **Day 3** is your **comprehensive optimization review** - a full performance tuning checklist covering everything from Week 1 to now!\n",
    "\n",
    "Think of it as your quality control manual before the final capstone project. ğŸ“‹âœ“"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
