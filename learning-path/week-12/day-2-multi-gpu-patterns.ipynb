{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "print(\"⚠️  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "print(\"⚠️  Multi-GPU patterns require multiple physical GPUs!\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fda62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Domain Decomposition\n",
    "\n",
    "### Splitting Work Across GPUs\n",
    "\n",
    "```\n",
    "1D Domain Decomposition:\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Full Array: [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]\n",
    "                    ↓\n",
    "GPU 0:      [0 1 2 3 4 5 6 7]\n",
    "GPU 1:      [8 9 10 11 12 13 14 15]\n",
    "\n",
    "2D Domain Decomposition:\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "┌─────────┬─────────┐\n",
    "│  GPU 0  │  GPU 1  │\n",
    "├─────────┼─────────┤\n",
    "│  GPU 2  │  GPU 3  │\n",
    "└─────────┴─────────┘\n",
    "```\n",
    "\n",
    "### CUDA C++ Domain Decomposition (Primary)\n",
    "\n",
    "```cpp\n",
    "// domain_decomp.cu - 1D domain decomposition\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processChunk(float* data, int n, int globalOffset) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        int globalIdx = globalOffset + tid;\n",
    "        data[tid] = sinf((float)globalIdx * 0.01f);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;  // 16M elements\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    printf(\"Using %d GPUs for %d elements\\n\", NUM_GPUS, TOTAL_N);\n",
    "    \n",
    "    // Calculate chunk sizes\n",
    "    int baseChunkSize = TOTAL_N / NUM_GPUS;\n",
    "    int remainder = TOTAL_N % NUM_GPUS;\n",
    "    \n",
    "    // Arrays for per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    int chunkSizes[NUM_GPUS];\n",
    "    int offsets[NUM_GPUS];\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // ============================================\n",
    "    // Calculate Per-GPU Chunks (Handle Remainder)\n",
    "    // ============================================\n",
    "    int currentOffset = 0;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        // Distribute remainder across first few GPUs\n",
    "        chunkSizes[gpu] = baseChunkSize + (gpu < remainder ? 1 : 0);\n",
    "        offsets[gpu] = currentOffset;\n",
    "        currentOffset += chunkSizes[gpu];\n",
    "        \n",
    "        printf(\"GPU %d: offset=%d, size=%d\\n\", \n",
    "               gpu, offsets[gpu], chunkSizes[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Allocate on Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], chunkSizes[gpu] * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Launch Kernels on Each GPU\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    \n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        int numBlocks = (chunkSizes[gpu] + blockSize - 1) / blockSize;\n",
    "        \n",
    "        processChunk<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_data[gpu], chunkSizes[gpu], offsets[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Synchronize All GPUs\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"All GPUs finished processing!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile domain_decomp.cu\n",
    "// domain_decomp.cu - 1D domain decomposition\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processChunk(float* data, int n, int globalOffset) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        int globalIdx = globalOffset + tid;\n",
    "        data[tid] = sinf((float)globalIdx * 0.01f);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;  // 16M elements\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    printf(\"Using %d GPUs for %d elements\\n\", NUM_GPUS, TOTAL_N);\n",
    "    \n",
    "    // Calculate chunk sizes\n",
    "    int baseChunkSize = TOTAL_N / NUM_GPUS;\n",
    "    int remainder = TOTAL_N % NUM_GPUS;\n",
    "    \n",
    "    // Arrays for per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    int chunkSizes[NUM_GPUS];\n",
    "    int offsets[NUM_GPUS];\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // ============================================\n",
    "    // Calculate Per-GPU Chunks (Handle Remainder)\n",
    "    // ============================================\n",
    "    int currentOffset = 0;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        // Distribute remainder across first few GPUs\n",
    "        chunkSizes[gpu] = baseChunkSize + (gpu < remainder ? 1 : 0);\n",
    "        offsets[gpu] = currentOffset;\n",
    "        currentOffset += chunkSizes[gpu];\n",
    "        \n",
    "        printf(\"GPU %d: offset=%d, size=%d\\n\", \n",
    "               gpu, offsets[gpu], chunkSizes[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Allocate on Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], chunkSizes[gpu] * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Launch Kernels on Each GPU\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    \n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        int numBlocks = (chunkSizes[gpu] + blockSize - 1) / blockSize;\n",
    "        \n",
    "        processChunk<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_data[gpu], chunkSizes[gpu], offsets[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Synchronize All GPUs\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"All GPUs finished processing!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6417cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o domain_decomp domain_decomp.cu\n",
    "!./domain_decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ae923e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Halo Exchange\n",
    "\n",
    "### Stencil Operations Require Boundary Data\n",
    "\n",
    "```\n",
    "Problem: Stencil needs neighbors\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "GPU 0 data:  [a b c d e | f g h]\n",
    "GPU 1 data:  [i j k | l m n o p]\n",
    "               ↑       ↑\n",
    "         Need f,g,h  Need e\n",
    "\n",
    "Solution: Halo/Ghost cells\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "GPU 0: [a b c d e | f g h] + [i j k]  ← halo from GPU 1\n",
    "GPU 1: [f g h] + [i j k | l m n o p]  ← halo from GPU 0\n",
    "        ↑                     \n",
    "   halo from GPU 0\n",
    "```\n",
    "\n",
    "### CUDA C++ Halo Exchange (Primary)\n",
    "\n",
    "```cpp\n",
    "// halo_exchange.cu - Exchange boundary data between GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define HALO_SIZE 3  // Stencil radius\n",
    "\n",
    "// Stencil kernel (5-point average)\n",
    "__global__ void stencil(float* out, float* in, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Skip halo regions for output\n",
    "    if (tid >= HALO_SIZE && tid < n - HALO_SIZE) {\n",
    "        out[tid] = 0.2f * (in[tid-2] + in[tid-1] + in[tid] + \n",
    "                          in[tid+1] + in[tid+2]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    if (deviceCount < 2) {\n",
    "        printf(\"Need 2 GPUs for halo exchange\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    const int CHUNK_SIZE = 1024;  // Data per GPU\n",
    "    const int TOTAL_SIZE = CHUNK_SIZE + 2 * HALO_SIZE;  // + halos\n",
    "    \n",
    "    float *d_in[2], *d_out[2];\n",
    "    cudaStream_t streams[2];\n",
    "    \n",
    "    // Enable P2P\n",
    "    int canP2P;\n",
    "    cudaDeviceCanAccessPeer(&canP2P, 0, 1);\n",
    "    if (canP2P) {\n",
    "        cudaSetDevice(0); cudaDeviceEnablePeerAccess(1, 0);\n",
    "        cudaSetDevice(1); cudaDeviceEnablePeerAccess(0, 0);\n",
    "    }\n",
    "    \n",
    "    // Allocate with halo space\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_in[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaMalloc(&d_out[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Initialize\n",
    "        cudaMemset(d_in[gpu], 0, TOTAL_SIZE * sizeof(float));\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Halo Exchange\n",
    "    // ============================================\n",
    "    // GPU 0's right boundary -> GPU 1's left halo\n",
    "    // GPU 1's left boundary -> GPU 0's right halo\n",
    "    \n",
    "    // GPU 0: Copy rightmost data to GPU 1's left halo\n",
    "    // d_in[0][HALO_SIZE + CHUNK_SIZE - HALO_SIZE ... ] -> d_in[1][0...]\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[1],                    // dst: GPU 1's left halo\n",
    "        1,                          // dst device\n",
    "        d_in[0] + CHUNK_SIZE,       // src: GPU 0's right boundary\n",
    "        0,                          // src device\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[0]);\n",
    "    \n",
    "    // GPU 1: Copy leftmost data to GPU 0's right halo\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[0] + HALO_SIZE + CHUNK_SIZE,  // dst: GPU 0's right halo\n",
    "        0,\n",
    "        d_in[1] + HALO_SIZE,               // src: GPU 1's left boundary\n",
    "        1,\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[1]);\n",
    "    \n",
    "    // Sync before compute\n",
    "    cudaSetDevice(0); cudaStreamSynchronize(streams[0]);\n",
    "    cudaSetDevice(1); cudaStreamSynchronize(streams[1]);\n",
    "    \n",
    "    // ============================================\n",
    "    // Compute Stencil\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (TOTAL_SIZE + blockSize - 1) / blockSize;\n",
    "    \n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        stencil<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_out[gpu], d_in[gpu], TOTAL_SIZE);\n",
    "    }\n",
    "    \n",
    "    // Sync\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"Halo exchange and stencil complete!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_in[gpu]);\n",
    "        cudaFree(d_out[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e53c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile halo_exchange.cu\n",
    "// halo_exchange.cu - Exchange boundary data between GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define HALO_SIZE 3  // Stencil radius\n",
    "\n",
    "// Stencil kernel (5-point average)\n",
    "__global__ void stencil(float* out, float* in, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Skip halo regions for output\n",
    "    if (tid >= HALO_SIZE && tid < n - HALO_SIZE) {\n",
    "        out[tid] = 0.2f * (in[tid-2] + in[tid-1] + in[tid] + \n",
    "                          in[tid+1] + in[tid+2]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    if (deviceCount < 2) {\n",
    "        printf(\"Need 2 GPUs for halo exchange\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    const int CHUNK_SIZE = 1024;  // Data per GPU\n",
    "    const int TOTAL_SIZE = CHUNK_SIZE + 2 * HALO_SIZE;  // + halos\n",
    "    \n",
    "    float *d_in[2], *d_out[2];\n",
    "    cudaStream_t streams[2];\n",
    "    \n",
    "    // Enable P2P\n",
    "    int canP2P;\n",
    "    cudaDeviceCanAccessPeer(&canP2P, 0, 1);\n",
    "    if (canP2P) {\n",
    "        cudaSetDevice(0); cudaDeviceEnablePeerAccess(1, 0);\n",
    "        cudaSetDevice(1); cudaDeviceEnablePeerAccess(0, 0);\n",
    "    }\n",
    "    \n",
    "    // Allocate with halo space\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_in[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaMalloc(&d_out[gpu], TOTAL_SIZE * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Initialize\n",
    "        cudaMemset(d_in[gpu], 0, TOTAL_SIZE * sizeof(float));\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Halo Exchange\n",
    "    // ============================================\n",
    "    // GPU 0's right boundary -> GPU 1's left halo\n",
    "    // GPU 1's left boundary -> GPU 0's right halo\n",
    "    \n",
    "    // GPU 0: Copy rightmost data to GPU 1's left halo\n",
    "    // d_in[0][HALO_SIZE + CHUNK_SIZE - HALO_SIZE ... ] -> d_in[1][0...]\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[1],                    // dst: GPU 1's left halo\n",
    "        1,                          // dst device\n",
    "        d_in[0] + CHUNK_SIZE,       // src: GPU 0's right boundary\n",
    "        0,                          // src device\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[0]);\n",
    "    \n",
    "    // GPU 1: Copy leftmost data to GPU 0's right halo\n",
    "    cudaMemcpyPeerAsync(\n",
    "        d_in[0] + HALO_SIZE + CHUNK_SIZE,  // dst: GPU 0's right halo\n",
    "        0,\n",
    "        d_in[1] + HALO_SIZE,               // src: GPU 1's left boundary\n",
    "        1,\n",
    "        HALO_SIZE * sizeof(float),\n",
    "        streams[1]);\n",
    "    \n",
    "    // Sync before compute\n",
    "    cudaSetDevice(0); cudaStreamSynchronize(streams[0]);\n",
    "    cudaSetDevice(1); cudaStreamSynchronize(streams[1]);\n",
    "    \n",
    "    // ============================================\n",
    "    // Compute Stencil\n",
    "    // ============================================\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (TOTAL_SIZE + blockSize - 1) / blockSize;\n",
    "    \n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        stencil<<<numBlocks, blockSize, 0, streams[gpu]>>>(\n",
    "            d_out[gpu], d_in[gpu], TOTAL_SIZE);\n",
    "    }\n",
    "    \n",
    "    // Sync\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    printf(\"Halo exchange and stencil complete!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < 2; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_in[gpu]);\n",
    "        cudaFree(d_out[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc072b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o halo_exchange halo_exchange.cu\n",
    "!./halo_exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72151826",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Multi-GPU Reduction\n",
    "\n",
    "### Combining Results Across GPUs\n",
    "\n",
    "```cpp\n",
    "// multi_gpu_reduction.cu - Reduce across multiple GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Block reduction kernel\n",
    "__global__ void reduce(float* out, float* in, int n) {\n",
    "    extern __shared__ float sdata[];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    sdata[tid] = (idx < n) ? in[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        out[blockIdx.x] = sdata[0];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;\n",
    "    const int N_PER_GPU = TOTAL_N / NUM_GPUS;\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    const int NUM_BLOCKS = (N_PER_GPU + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    // Per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    float* d_partial[NUM_GPUS];\n",
    "    float h_partial[NUM_GPUS];  // Final partial sums\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // Allocate and initialize\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], N_PER_GPU * sizeof(float));\n",
    "        cudaMalloc(&d_partial[gpu], NUM_BLOCKS * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Init with 1s\n",
    "        float* h_temp = new float[N_PER_GPU];\n",
    "        for (int i = 0; i < N_PER_GPU; i++) h_temp[i] = 1.0f;\n",
    "        cudaMemcpy(d_data[gpu], h_temp, N_PER_GPU * sizeof(float),\n",
    "                   cudaMemcpyHostToDevice);\n",
    "        delete[] h_temp;\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 1: Reduce Within Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        reduce<<<NUM_BLOCKS, BLOCK_SIZE, BLOCK_SIZE * sizeof(float), \n",
    "                 streams[gpu]>>>(d_partial[gpu], d_data[gpu], N_PER_GPU);\n",
    "        \n",
    "        // Second reduction pass\n",
    "        int remaining = NUM_BLOCKS;\n",
    "        while (remaining > 1) {\n",
    "            int newBlocks = (remaining + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "            reduce<<<newBlocks, BLOCK_SIZE, BLOCK_SIZE * sizeof(float),\n",
    "                     streams[gpu]>>>(d_partial[gpu], d_partial[gpu], remaining);\n",
    "            remaining = newBlocks;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 2: Collect Partial Sums to Host\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMemcpyAsync(&h_partial[gpu], d_partial[gpu], sizeof(float),\n",
    "                        cudaMemcpyDeviceToHost, streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // Sync all\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 3: Final Sum on Host\n",
    "    // ============================================\n",
    "    float total = 0.0f;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        printf(\"GPU %d partial sum: %.0f\\n\", gpu, h_partial[gpu]);\n",
    "        total += h_partial[gpu];\n",
    "    }\n",
    "    \n",
    "    printf(\"Total sum: %.0f (expected %d)\\n\", total, TOTAL_N);\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaFree(d_partial[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multi_gpu_reduction.cu\n",
    "// multi_gpu_reduction.cu - Reduce across multiple GPUs\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Block reduction kernel\n",
    "__global__ void reduce(float* out, float* in, int n) {\n",
    "    extern __shared__ float sdata[];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    sdata[tid] = (idx < n) ? in[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        out[blockIdx.x] = sdata[0];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    const int NUM_GPUS = min(deviceCount, 4);\n",
    "    \n",
    "    const int TOTAL_N = 1 << 24;\n",
    "    const int N_PER_GPU = TOTAL_N / NUM_GPUS;\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    const int NUM_BLOCKS = (N_PER_GPU + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    // Per-GPU data\n",
    "    float* d_data[NUM_GPUS];\n",
    "    float* d_partial[NUM_GPUS];\n",
    "    float h_partial[NUM_GPUS];  // Final partial sums\n",
    "    cudaStream_t streams[NUM_GPUS];\n",
    "    \n",
    "    // Allocate and initialize\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMalloc(&d_data[gpu], N_PER_GPU * sizeof(float));\n",
    "        cudaMalloc(&d_partial[gpu], NUM_BLOCKS * sizeof(float));\n",
    "        cudaStreamCreate(&streams[gpu]);\n",
    "        \n",
    "        // Init with 1s\n",
    "        float* h_temp = new float[N_PER_GPU];\n",
    "        for (int i = 0; i < N_PER_GPU; i++) h_temp[i] = 1.0f;\n",
    "        cudaMemcpy(d_data[gpu], h_temp, N_PER_GPU * sizeof(float),\n",
    "                   cudaMemcpyHostToDevice);\n",
    "        delete[] h_temp;\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 1: Reduce Within Each GPU\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        reduce<<<NUM_BLOCKS, BLOCK_SIZE, BLOCK_SIZE * sizeof(float), \n",
    "                 streams[gpu]>>>(d_partial[gpu], d_data[gpu], N_PER_GPU);\n",
    "        \n",
    "        // Second reduction pass\n",
    "        int remaining = NUM_BLOCKS;\n",
    "        while (remaining > 1) {\n",
    "            int newBlocks = (remaining + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "            reduce<<<newBlocks, BLOCK_SIZE, BLOCK_SIZE * sizeof(float),\n",
    "                     streams[gpu]>>>(d_partial[gpu], d_partial[gpu], remaining);\n",
    "            remaining = newBlocks;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 2: Collect Partial Sums to Host\n",
    "    // ============================================\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaMemcpyAsync(&h_partial[gpu], d_partial[gpu], sizeof(float),\n",
    "                        cudaMemcpyDeviceToHost, streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // Sync all\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaStreamSynchronize(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 3: Final Sum on Host\n",
    "    // ============================================\n",
    "    float total = 0.0f;\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        printf(\"GPU %d partial sum: %.0f\\n\", gpu, h_partial[gpu]);\n",
    "        total += h_partial[gpu];\n",
    "    }\n",
    "    \n",
    "    printf(\"Total sum: %.0f (expected %d)\\n\", total, TOTAL_N);\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int gpu = 0; gpu < NUM_GPUS; gpu++) {\n",
    "        cudaSetDevice(gpu);\n",
    "        cudaFree(d_data[gpu]);\n",
    "        cudaFree(d_partial[gpu]);\n",
    "        cudaStreamDestroy(streams[gpu]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfeaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o multi_gpu_reduction multi_gpu_reduction.cu\n",
    "!./multi_gpu_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6d9cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Load Balancing\n",
    "\n",
    "### Handling Non-Uniform Work\n",
    "\n",
    "```\n",
    "Static Partitioning (Simple but can be unbalanced):\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "GPU 0: [0, N/4)   → May be easy work\n",
    "GPU 1: [N/4, N/2) → May be hard work\n",
    "GPU 2: [N/2, 3N/4) → Variable\n",
    "GPU 3: [3N/4, N)  → Variable\n",
    "\n",
    "Dynamic Load Balancing:\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "• Work queue with atomic counter\n",
    "• GPUs grab chunks as they finish\n",
    "• Better for non-uniform work\n",
    "```\n",
    "\n",
    "```cpp\n",
    "// Simple work-stealing pattern\n",
    "__device__ int workCounter = 0;\n",
    "\n",
    "__global__ void dynamicWork(float* data, int totalChunks, int chunkSize) {\n",
    "    while (true) {\n",
    "        // Atomically get next chunk\n",
    "        int myChunk = atomicAdd(&workCounter, 1);\n",
    "        \n",
    "        if (myChunk >= totalChunks) break;\n",
    "        \n",
    "        // Process chunk\n",
    "        int start = myChunk * chunkSize;\n",
    "        for (int i = threadIdx.x; i < chunkSize; i += blockDim.x) {\n",
    "            data[start + i] = processElement(data[start + i]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb3091",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: 2D Decomposition\n",
    "Implement 2D domain decomposition for a matrix operation.\n",
    "\n",
    "### Exercise 2: Ring AllReduce\n",
    "Implement ring allreduce pattern for multi-GPU sum.\n",
    "\n",
    "### Exercise 3: Async Halo Exchange\n",
    "Overlap halo exchange with interior computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d8f75",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│              MULTI-GPU PATTERNS                         │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│                                                         │\n",
    "│  Domain Decomposition:                                  │\n",
    "│  • Split data into chunks per GPU                       │\n",
    "│  • Handle remainder for non-divisible sizes             │\n",
    "│  • Each GPU processes its chunk independently           │\n",
    "│                                                         │\n",
    "│  Halo Exchange:                                         │\n",
    "│  • For stencil operations needing neighbors             │\n",
    "│  • Allocate extra space for ghost cells                 │\n",
    "│  • Exchange boundaries before compute                   │\n",
    "│                                                         │\n",
    "│  Reduction:                                             │\n",
    "│  • Reduce within each GPU first                         │\n",
    "│  • Collect partial sums to host or one GPU              │\n",
    "│  • Final reduction on collected values                  │\n",
    "│                                                         │\n",
    "│  Load Balancing:                                        │\n",
    "│  • Static: simple, good for uniform work                │\n",
    "│  • Dynamic: work queues for variable work               │\n",
    "│                                                         │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Next: Day 3 - Advanced Optimization Review"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
