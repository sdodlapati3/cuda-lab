{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7142e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"‚ö†Ô∏è  CUDA C++ is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db18c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Timing Fundamentals\n",
    "\n",
    "### CUDA Events (Gold Standard)\n",
    "\n",
    "```cpp\n",
    "cudaEvent_t start, stop;\n",
    "cudaEventCreate(&start);\n",
    "cudaEventCreate(&stop);\n",
    "\n",
    "cudaEventRecord(start);\n",
    "kernel<<<...>>>();\n",
    "cudaEventRecord(stop);\n",
    "\n",
    "cudaEventSynchronize(stop);\n",
    "float milliseconds = 0;\n",
    "cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "```\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "```\n",
    "‚ùå WRONG: Using CPU timers without sync\n",
    "   auto t1 = std::chrono::now();\n",
    "   kernel<<<...>>>();  // Async!\n",
    "   auto t2 = std::chrono::now();  // Only measures launch overhead\n",
    "\n",
    "‚úÖ CORRECT: Use CUDA events or synchronize\n",
    "   cudaDeviceSynchronize();\n",
    "   auto t1 = std::chrono::now();\n",
    "   kernel<<<...>>>();\n",
    "   cudaDeviceSynchronize();\n",
    "   auto t2 = std::chrono::now();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd0d29",
   "metadata": {},
   "source": [
    "### üî∑ CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d20e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile benchmark_framework.cu\n",
    "// benchmark_framework.cu - Professional benchmarking utilities\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <algorithm>\n",
    "#include <vector>\n",
    "#include <cmath>\n",
    "\n",
    "// Statistics structure\n",
    "struct BenchmarkStats {\n",
    "    float mean;\n",
    "    float std_dev;\n",
    "    float median;\n",
    "    float min;\n",
    "    float max;\n",
    "    float p95;  // 95th percentile\n",
    "};\n",
    "\n",
    "BenchmarkStats computeStats(std::vector<float>& times) {\n",
    "    BenchmarkStats stats;\n",
    "    int n = times.size();\n",
    "    \n",
    "    std::sort(times.begin(), times.end());\n",
    "    \n",
    "    // Mean\n",
    "    float sum = 0;\n",
    "    for (float t : times) sum += t;\n",
    "    stats.mean = sum / n;\n",
    "    \n",
    "    // Std dev\n",
    "    float sq_sum = 0;\n",
    "    for (float t : times) sq_sum += (t - stats.mean) * (t - stats.mean);\n",
    "    stats.std_dev = sqrtf(sq_sum / (n - 1));\n",
    "    \n",
    "    // Median\n",
    "    stats.median = (n % 2 == 0) ? \n",
    "        (times[n/2 - 1] + times[n/2]) / 2 : times[n/2];\n",
    "    \n",
    "    // Min, Max\n",
    "    stats.min = times[0];\n",
    "    stats.max = times[n-1];\n",
    "    \n",
    "    // 95th percentile\n",
    "    stats.p95 = times[(int)(n * 0.95)];\n",
    "    \n",
    "    return stats;\n",
    "}\n",
    "\n",
    "void printStats(const char* name, BenchmarkStats& stats) {\n",
    "    printf(\"%s:\\n\", name);\n",
    "    printf(\"  Mean:   %.3f ms\\n\", stats.mean);\n",
    "    printf(\"  Median: %.3f ms\\n\", stats.median);\n",
    "    printf(\"  StdDev: %.3f ms (%.1f%%)\\n\", stats.std_dev, 100 * stats.std_dev / stats.mean);\n",
    "    printf(\"  Min:    %.3f ms\\n\", stats.min);\n",
    "    printf(\"  Max:    %.3f ms\\n\", stats.max);\n",
    "    printf(\"  P95:    %.3f ms\\n\", stats.p95);\n",
    "}\n",
    "\n",
    "// Example kernel to benchmark\n",
    "__global__ void vector_add(float* a, float* b, float* c, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) c[idx] = a[idx] + b[idx];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Professional Benchmarking Framework ===\\n\\n\");\n",
    "    \n",
    "    const int N = 100000000;  // 100M elements\n",
    "    const int WARMUP = 10;\n",
    "    const int ITERATIONS = 100;\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, N * sizeof(float));\n",
    "    cudaMalloc(&d_b, N * sizeof(float));\n",
    "    cudaMalloc(&d_c, N * sizeof(float));\n",
    "    \n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    \n",
    "    // Warmup (important!)\n",
    "    printf(\"Warming up (%d iterations)...\\n\", WARMUP);\n",
    "    for (int i = 0; i < WARMUP; i++) {\n",
    "        vector_add<<<blocks, threads>>>(d_a, d_b, d_c, N);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Benchmark\n",
    "    printf(\"Benchmarking (%d iterations)...\\n\\n\", ITERATIONS);\n",
    "    \n",
    "    std::vector<float> times;\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        cudaEventRecord(start);\n",
    "        vector_add<<<blocks, threads>>>(d_a, d_b, d_c, N);\n",
    "        cudaEventRecord(stop);\n",
    "        cudaEventSynchronize(stop);\n",
    "        \n",
    "        float ms;\n",
    "        cudaEventElapsedTime(&ms, start, stop);\n",
    "        times.push_back(ms);\n",
    "    }\n",
    "    \n",
    "    auto stats = computeStats(times);\n",
    "    printStats(\"Vector Addition (100M elements)\", stats);\n",
    "    \n",
    "    // Calculate bandwidth\n",
    "    float gb = 3 * N * sizeof(float) / 1e9;  // Read a, b; write c\n",
    "    float bandwidth = gb / (stats.median / 1000);  // GB/s\n",
    "    printf(\"\\nBandwidth Analysis:\\n\");\n",
    "    printf(\"  Data moved: %.2f GB\\n\", gb);\n",
    "    printf(\"  Effective bandwidth: %.1f GB/s\\n\", bandwidth);\n",
    "    \n",
    "    // Get theoretical bandwidth\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    float peak_bw = prop.memoryClockRate * 1e3 * (prop.memoryBusWidth / 8) * 2 / 1e9;\n",
    "    printf(\"  Peak bandwidth: %.1f GB/s\\n\", peak_bw);\n",
    "    printf(\"  Efficiency: %.1f%%\\n\", 100 * bandwidth / peak_bw);\n",
    "    \n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    cudaEventDestroy(start); cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o benchmark_framework benchmark_framework.cu\n",
    "!./benchmark_framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae1bf9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Performance Metrics\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "```\n",
    "1. Memory Bandwidth (GB/s)\n",
    "   Bandwidth = Bytes Transferred / Time\n",
    "   \n",
    "   For memory-bound kernels, compare to peak:\n",
    "   - 80%+ efficiency = excellent\n",
    "   - 60-80% = good\n",
    "   - <60% = needs optimization\n",
    "\n",
    "2. Compute Throughput (FLOPS/TFLOPS)\n",
    "   FLOPS = Floating-point Operations / Time\n",
    "   \n",
    "   For compute-bound kernels:\n",
    "   - Compare to theoretical peak\n",
    "   - Consider Tensor Core vs CUDA Core\n",
    "\n",
    "3. Occupancy\n",
    "   Occupancy = Active Warps / Max Warps\n",
    "   \n",
    "   Limited by:\n",
    "   - Registers per thread\n",
    "   - Shared memory per block\n",
    "   - Threads per block\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6436798",
   "metadata": {},
   "source": [
    "### üî∑ CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f187c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile roofline_analysis.cu\n",
    "// roofline_analysis.cu - Roofline model analysis\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Memory-bound kernel (low arithmetic intensity)\n",
    "__global__ void memory_bound_kernel(float* in, float* out, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        out[idx] = in[idx] * 2.0f;  // 1 FLOP per 8 bytes\n",
    "    }\n",
    "}\n",
    "\n",
    "// Compute-bound kernel (high arithmetic intensity)\n",
    "__global__ void compute_bound_kernel(float* in, float* out, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        float val = in[idx];\n",
    "        // Lots of compute for same memory access\n",
    "        for (int i = 0; i < 100; i++) {\n",
    "            val = val * val + val;\n",
    "            val = sqrtf(fabsf(val)) + 1.0f;\n",
    "        }\n",
    "        out[idx] = val;\n",
    "    }\n",
    "}\n",
    "\n",
    "float benchmark(void (*kernel)(float*, float*, int), float* d_in, float* d_out, int n, const char* name) {\n",
    "    int threads = 256;\n",
    "    int blocks = (n + threads - 1) / threads;\n",
    "    \n",
    "    // Warmup\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        kernel<<<blocks, threads>>>(d_in, d_out, n);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        kernel<<<blocks, threads>>>(d_in, d_out, n);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    return ms / 100;  // Average per iteration\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Roofline Model Analysis ===\\n\\n\");\n",
    "    \n",
    "    const int N = 10000000;  // 10M elements\n",
    "    \n",
    "    float *d_in, *d_out;\n",
    "    cudaMalloc(&d_in, N * sizeof(float));\n",
    "    cudaMalloc(&d_out, N * sizeof(float));\n",
    "    \n",
    "    // Get device properties\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    \n",
    "    float peak_bw = prop.memoryClockRate * 1e3 * (prop.memoryBusWidth / 8) * 2 / 1e9;\n",
    "    float peak_flops = prop.clockRate * 1e3 * prop.multiProcessorCount * \n",
    "                       128 * 2 / 1e12;  // Approximate FP32 peak TFLOPS\n",
    "    \n",
    "    printf(\"Device: %s\\n\", prop.name);\n",
    "    printf(\"Peak Memory BW: %.0f GB/s\\n\", peak_bw);\n",
    "    printf(\"Peak FP32: ~%.1f TFLOPS\\n\\n\", peak_flops);\n",
    "    \n",
    "    // Memory-bound kernel\n",
    "    float mem_time = benchmark(memory_bound_kernel, d_in, d_out, N, \"Memory-bound\");\n",
    "    float mem_bytes = 2 * N * sizeof(float);  // Read + Write\n",
    "    float mem_bw = mem_bytes / (mem_time * 1e6);  // GB/s\n",
    "    float mem_flops = N;  // 1 multiply per element\n",
    "    float mem_ai = mem_flops / mem_bytes;  // Arithmetic intensity\n",
    "    \n",
    "    printf(\"Memory-Bound Kernel:\\n\");\n",
    "    printf(\"  Time: %.3f ms\\n\", mem_time);\n",
    "    printf(\"  Bandwidth: %.1f GB/s (%.1f%% of peak)\\n\", mem_bw, 100 * mem_bw / peak_bw);\n",
    "    printf(\"  Arithmetic Intensity: %.4f FLOP/Byte\\n\\n\", mem_ai);\n",
    "    \n",
    "    // Compute-bound kernel\n",
    "    float comp_time = benchmark(compute_bound_kernel, d_in, d_out, N, \"Compute-bound\");\n",
    "    float comp_bytes = 2 * N * sizeof(float);\n",
    "    float comp_flops = N * 100 * 4;  // ~4 ops per iteration * 100 iterations\n",
    "    float comp_gflops = comp_flops / (comp_time * 1e6);\n",
    "    float comp_ai = comp_flops / comp_bytes;\n",
    "    \n",
    "    printf(\"Compute-Bound Kernel:\\n\");\n",
    "    printf(\"  Time: %.3f ms\\n\", comp_time);\n",
    "    printf(\"  Throughput: %.1f GFLOPS\\n\", comp_gflops);\n",
    "    printf(\"  Arithmetic Intensity: %.1f FLOP/Byte\\n\\n\", comp_ai);\n",
    "    \n",
    "    // Roofline ridge point\n",
    "    float ridge = peak_flops * 1e3 / peak_bw;  // GFLOPS/GB/s = FLOP/Byte\n",
    "    printf(\"Roofline Analysis:\\n\");\n",
    "    printf(\"  Ridge Point: %.1f FLOP/Byte\\n\", ridge);\n",
    "    printf(\"  Memory-bound kernel: AI < ridge (limited by BW)\\n\");\n",
    "    printf(\"  Compute-bound kernel: AI > ridge (limited by compute)\\n\");\n",
    "    \n",
    "    cudaFree(d_in); cudaFree(d_out);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd277b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o roofline_analysis roofline_analysis.cu\n",
    "!./roofline_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af189e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Profiling Tools\n",
    "\n",
    "### NVIDIA Tools\n",
    "\n",
    "```bash\n",
    "# Nsight Compute (kernel analysis)\n",
    "ncu --target-processes all ./my_program\n",
    "ncu --set full -o profile ./my_program  # Full analysis\n",
    "\n",
    "# Nsight Systems (timeline)\n",
    "nsys profile ./my_program\n",
    "nsys profile --cuda-memory-usage=true ./my_program\n",
    "\n",
    "# Legacy nvprof (if available)\n",
    "nvprof ./my_program\n",
    "nvprof --metrics all ./my_program\n",
    "```\n",
    "\n",
    "### Key Metrics to Check\n",
    "\n",
    "```\n",
    "From ncu:\n",
    "  - SM Efficiency: Are SMs busy?\n",
    "  - Memory Throughput: How much BW used?\n",
    "  - Achieved Occupancy: Warps active?\n",
    "  - Warp Stall Reasons: What's blocking?\n",
    "  \n",
    "From nsys:\n",
    "  - Timeline: Overlap of compute/memory\n",
    "  - API calls: Host-side overhead\n",
    "  - Memory transfers: H2D/D2H bottlenecks\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d05b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available profiling tools\n",
    "!which ncu nsys nvprof 2>/dev/null || echo \"Profiling tools not in PATH\"\n",
    "!ncu --version 2>/dev/null || echo \"ncu not available\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d2385",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Exercises\n",
    "\n",
    "### üî∑ CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e518259",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile benchmarking_exercises.cu\n",
    "// CUDA C++ Exercises - Benchmarking\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "// Exercise 1: Implement proper CUDA event timing wrapper\n",
    "// TODO: Add your implementation here\n",
    "\n",
    "// Exercise 2: Create bandwidth calculation utility\n",
    "// TODO: Add your implementation here\n",
    "\n",
    "// Exercise 3: Build statistical analysis for benchmark runs\n",
    "// TODO: Add your implementation here\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Benchmarking Exercises ===\\n\");\n",
    "    printf(\"Implement the exercises above and run!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o benchmarking_exercises benchmarking_exercises.cu && ./benchmarking_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10f436",
   "metadata": {},
   "source": [
    "### üî∂ Python/Numba Exercises (Optional)\n",
    "\n",
    "The following exercises use Python and Numba for rapid prototyping. Complete the CUDA C++ exercises above first for the primary learning objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b9edc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Benchmarking Checklist\n",
    "\n",
    "‚úÖ **Always**:\n",
    "1. Use CUDA events for timing\n",
    "2. Run warmup iterations first\n",
    "3. Collect multiple samples\n",
    "4. Report median AND variance\n",
    "5. Calculate relevant metrics (BW or FLOPS)\n",
    "\n",
    "‚ùå **Never**:\n",
    "1. Use CPU timers without sync\n",
    "2. Report single-run results\n",
    "3. Ignore cold start effects\n",
    "4. Compare across different GPUs\n",
    "\n",
    "### Curriculum Complete! üéâ\n",
    "\n",
    "You've completed the 14-week CUDA curriculum covering:\n",
    "- GPU fundamentals and memory hierarchy\n",
    "- Kernel optimization techniques\n",
    "- Advanced topics (streams, multi-GPU)\n",
    "- Tensor Cores and mixed precision\n",
    "- Real-world applications and profiling"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
