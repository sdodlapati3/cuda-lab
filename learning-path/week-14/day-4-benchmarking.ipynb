{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b1b87a",
   "metadata": {},
   "source": [
    "# Day 4: Benchmarking â€“ The Scientific Method for GPU Performance\n",
    "\n",
    "> **Hook:** \"My kernel is fast!\" But is it? Imagine a runner claiming world record speed but timing themselves with a sundial while also including the walk to the starting line. Professional GPU benchmarking is like Olympic timing: precise, standardized, and reproducible. Without it, you're just guessing!\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. **Use** CUDA events for accurate sub-millisecond kernel timing\n",
    "2. **Design** proper benchmarking experiments with warmup and statistical analysis\n",
    "3. **Calculate** meaningful metrics (achieved bandwidth, FLOPS, roofline position)\n",
    "4. **Avoid** common pitfalls that lead to misleading performance numbers\n",
    "\n",
    "## ğŸ“š Prerequisites\n",
    "- All previous weeks of the curriculum\n",
    "- Understanding of memory bandwidth and compute throughput\n",
    "- Basic statistics (mean, median, standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7142e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"âš ï¸  CUDA C++ is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9d9e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ´ Concept Card: The Olympic Timing System Analogy\n",
    "\n",
    "### Benchmarking = Professional Sports Timing\n",
    "\n",
    "**Amateur Timing (Common Mistakes):**\n",
    "```\n",
    "â±ï¸ Coach with a stopwatch: \"Ready... GO!\" *press button*\n",
    "ğŸƒ Runner finishes\n",
    "â±ï¸ \"I think that was about 10 seconds\"\n",
    "âŒ Includes coach's reaction time, imprecise!\n",
    "```\n",
    "\n",
    "**Olympic Timing (CUDA Events):**\n",
    "```\n",
    "ğŸ¯ Laser at start line: records EXACT moment of crossing\n",
    "ğŸƒ Runner completes race\n",
    "ğŸ¯ Laser at finish line: records EXACT moment of crossing\n",
    "âœ… Sub-millisecond precision, no human error\n",
    "```\n",
    "\n",
    "**The GPU Translation:**\n",
    "| Olympics | GPU Benchmarking |\n",
    "|----------|------------------|\n",
    "| Stopwatch | CPU timer without sync (WRONG!) |\n",
    "| Photo finish laser | CUDA events |\n",
    "| Warmup laps | Warmup iterations |\n",
    "| Multiple heats | Multiple samples for statistics |\n",
    "| Different tracks | Different GPUs (can't compare directly) |\n",
    "\n",
    "**The Benchmarking Protocol:**\n",
    "```\n",
    "1. ğŸ”¥ WARMUP: Run kernel 10+ times (cold cache, JIT compilation)\n",
    "2. ğŸ“Š SAMPLE: Record 100+ timed iterations\n",
    "3. ğŸ“ˆ ANALYZE: Report median, variance, percentiles\n",
    "4. ğŸ§® METRICS: Calculate bandwidth OR FLOPS (pick the right one!)\n",
    "```\n",
    "\n",
    "**ğŸ’¡ Key Insight:** `cudaEventElapsedTime()` is your photo finish cameraâ€”it measures exactly what happened on the GPU, not when you pressed the button!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db18c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Timing Fundamentals\n",
    "\n",
    "### CUDA Events (Gold Standard)\n",
    "\n",
    "```cpp\n",
    "cudaEvent_t start, stop;\n",
    "cudaEventCreate(&start);\n",
    "cudaEventCreate(&stop);\n",
    "\n",
    "cudaEventRecord(start);\n",
    "kernel<<<...>>>();\n",
    "cudaEventRecord(stop);\n",
    "\n",
    "cudaEventSynchronize(stop);\n",
    "float milliseconds = 0;\n",
    "cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "```\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "```\n",
    "âŒ WRONG: Using CPU timers without sync\n",
    "   auto t1 = std::chrono::now();\n",
    "   kernel<<<...>>>();  // Async!\n",
    "   auto t2 = std::chrono::now();  // Only measures launch overhead\n",
    "\n",
    "âœ… CORRECT: Use CUDA events or synchronize\n",
    "   cudaDeviceSynchronize();\n",
    "   auto t1 = std::chrono::now();\n",
    "   kernel<<<...>>>();\n",
    "   cudaDeviceSynchronize();\n",
    "   auto t2 = std::chrono::now();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd0d29",
   "metadata": {},
   "source": [
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d20e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile benchmark_framework.cu\n",
    "// benchmark_framework.cu - Professional benchmarking utilities\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <algorithm>\n",
    "#include <vector>\n",
    "#include <cmath>\n",
    "\n",
    "// Statistics structure\n",
    "struct BenchmarkStats {\n",
    "    float mean;\n",
    "    float std_dev;\n",
    "    float median;\n",
    "    float min;\n",
    "    float max;\n",
    "    float p95;  // 95th percentile\n",
    "};\n",
    "\n",
    "BenchmarkStats computeStats(std::vector<float>& times) {\n",
    "    BenchmarkStats stats;\n",
    "    int n = times.size();\n",
    "    \n",
    "    std::sort(times.begin(), times.end());\n",
    "    \n",
    "    // Mean\n",
    "    float sum = 0;\n",
    "    for (float t : times) sum += t;\n",
    "    stats.mean = sum / n;\n",
    "    \n",
    "    // Std dev\n",
    "    float sq_sum = 0;\n",
    "    for (float t : times) sq_sum += (t - stats.mean) * (t - stats.mean);\n",
    "    stats.std_dev = sqrtf(sq_sum / (n - 1));\n",
    "    \n",
    "    // Median\n",
    "    stats.median = (n % 2 == 0) ? \n",
    "        (times[n/2 - 1] + times[n/2]) / 2 : times[n/2];\n",
    "    \n",
    "    // Min, Max\n",
    "    stats.min = times[0];\n",
    "    stats.max = times[n-1];\n",
    "    \n",
    "    // 95th percentile\n",
    "    stats.p95 = times[(int)(n * 0.95)];\n",
    "    \n",
    "    return stats;\n",
    "}\n",
    "\n",
    "void printStats(const char* name, BenchmarkStats& stats) {\n",
    "    printf(\"%s:\\n\", name);\n",
    "    printf(\"  Mean:   %.3f ms\\n\", stats.mean);\n",
    "    printf(\"  Median: %.3f ms\\n\", stats.median);\n",
    "    printf(\"  StdDev: %.3f ms (%.1f%%)\\n\", stats.std_dev, 100 * stats.std_dev / stats.mean);\n",
    "    printf(\"  Min:    %.3f ms\\n\", stats.min);\n",
    "    printf(\"  Max:    %.3f ms\\n\", stats.max);\n",
    "    printf(\"  P95:    %.3f ms\\n\", stats.p95);\n",
    "}\n",
    "\n",
    "// Example kernel to benchmark\n",
    "__global__ void vector_add(float* a, float* b, float* c, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) c[idx] = a[idx] + b[idx];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Professional Benchmarking Framework ===\\n\\n\");\n",
    "    \n",
    "    const int N = 100000000;  // 100M elements\n",
    "    const int WARMUP = 10;\n",
    "    const int ITERATIONS = 100;\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, N * sizeof(float));\n",
    "    cudaMalloc(&d_b, N * sizeof(float));\n",
    "    cudaMalloc(&d_c, N * sizeof(float));\n",
    "    \n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    \n",
    "    // Warmup (important!)\n",
    "    printf(\"Warming up (%d iterations)...\\n\", WARMUP);\n",
    "    for (int i = 0; i < WARMUP; i++) {\n",
    "        vector_add<<<blocks, threads>>>(d_a, d_b, d_c, N);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Benchmark\n",
    "    printf(\"Benchmarking (%d iterations)...\\n\\n\", ITERATIONS);\n",
    "    \n",
    "    std::vector<float> times;\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        cudaEventRecord(start);\n",
    "        vector_add<<<blocks, threads>>>(d_a, d_b, d_c, N);\n",
    "        cudaEventRecord(stop);\n",
    "        cudaEventSynchronize(stop);\n",
    "        \n",
    "        float ms;\n",
    "        cudaEventElapsedTime(&ms, start, stop);\n",
    "        times.push_back(ms);\n",
    "    }\n",
    "    \n",
    "    auto stats = computeStats(times);\n",
    "    printStats(\"Vector Addition (100M elements)\", stats);\n",
    "    \n",
    "    // Calculate bandwidth\n",
    "    float gb = 3 * N * sizeof(float) / 1e9;  // Read a, b; write c\n",
    "    float bandwidth = gb / (stats.median / 1000);  // GB/s\n",
    "    printf(\"\\nBandwidth Analysis:\\n\");\n",
    "    printf(\"  Data moved: %.2f GB\\n\", gb);\n",
    "    printf(\"  Effective bandwidth: %.1f GB/s\\n\", bandwidth);\n",
    "    \n",
    "    // Get theoretical bandwidth\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    float peak_bw = prop.memoryClockRate * 1e3 * (prop.memoryBusWidth / 8) * 2 / 1e9;\n",
    "    printf(\"  Peak bandwidth: %.1f GB/s\\n\", peak_bw);\n",
    "    printf(\"  Efficiency: %.1f%%\\n\", 100 * bandwidth / peak_bw);\n",
    "    \n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    cudaEventDestroy(start); cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o benchmark_framework benchmark_framework.cu\n",
    "!./benchmark_framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae1bf9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Performance Metrics\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "```\n",
    "1. Memory Bandwidth (GB/s)\n",
    "   Bandwidth = Bytes Transferred / Time\n",
    "   \n",
    "   For memory-bound kernels, compare to peak:\n",
    "   - 80%+ efficiency = excellent\n",
    "   - 60-80% = good\n",
    "   - <60% = needs optimization\n",
    "\n",
    "2. Compute Throughput (FLOPS/TFLOPS)\n",
    "   FLOPS = Floating-point Operations / Time\n",
    "   \n",
    "   For compute-bound kernels:\n",
    "   - Compare to theoretical peak\n",
    "   - Consider Tensor Core vs CUDA Core\n",
    "\n",
    "3. Occupancy\n",
    "   Occupancy = Active Warps / Max Warps\n",
    "   \n",
    "   Limited by:\n",
    "   - Registers per thread\n",
    "   - Shared memory per block\n",
    "   - Threads per block\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6436798",
   "metadata": {},
   "source": [
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f187c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile roofline_analysis.cu\n",
    "// roofline_analysis.cu - Roofline model analysis\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Memory-bound kernel (low arithmetic intensity)\n",
    "__global__ void memory_bound_kernel(float* in, float* out, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        out[idx] = in[idx] * 2.0f;  // 1 FLOP per 8 bytes\n",
    "    }\n",
    "}\n",
    "\n",
    "// Compute-bound kernel (high arithmetic intensity)\n",
    "__global__ void compute_bound_kernel(float* in, float* out, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        float val = in[idx];\n",
    "        // Lots of compute for same memory access\n",
    "        for (int i = 0; i < 100; i++) {\n",
    "            val = val * val + val;\n",
    "            val = sqrtf(fabsf(val)) + 1.0f;\n",
    "        }\n",
    "        out[idx] = val;\n",
    "    }\n",
    "}\n",
    "\n",
    "float benchmark(void (*kernel)(float*, float*, int), float* d_in, float* d_out, int n, const char* name) {\n",
    "    int threads = 256;\n",
    "    int blocks = (n + threads - 1) / threads;\n",
    "    \n",
    "    // Warmup\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        kernel<<<blocks, threads>>>(d_in, d_out, n);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        kernel<<<blocks, threads>>>(d_in, d_out, n);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    return ms / 100;  // Average per iteration\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Roofline Model Analysis ===\\n\\n\");\n",
    "    \n",
    "    const int N = 10000000;  // 10M elements\n",
    "    \n",
    "    float *d_in, *d_out;\n",
    "    cudaMalloc(&d_in, N * sizeof(float));\n",
    "    cudaMalloc(&d_out, N * sizeof(float));\n",
    "    \n",
    "    // Get device properties\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    \n",
    "    float peak_bw = prop.memoryClockRate * 1e3 * (prop.memoryBusWidth / 8) * 2 / 1e9;\n",
    "    float peak_flops = prop.clockRate * 1e3 * prop.multiProcessorCount * \n",
    "                       128 * 2 / 1e12;  // Approximate FP32 peak TFLOPS\n",
    "    \n",
    "    printf(\"Device: %s\\n\", prop.name);\n",
    "    printf(\"Peak Memory BW: %.0f GB/s\\n\", peak_bw);\n",
    "    printf(\"Peak FP32: ~%.1f TFLOPS\\n\\n\", peak_flops);\n",
    "    \n",
    "    // Memory-bound kernel\n",
    "    float mem_time = benchmark(memory_bound_kernel, d_in, d_out, N, \"Memory-bound\");\n",
    "    float mem_bytes = 2 * N * sizeof(float);  // Read + Write\n",
    "    float mem_bw = mem_bytes / (mem_time * 1e6);  // GB/s\n",
    "    float mem_flops = N;  // 1 multiply per element\n",
    "    float mem_ai = mem_flops / mem_bytes;  // Arithmetic intensity\n",
    "    \n",
    "    printf(\"Memory-Bound Kernel:\\n\");\n",
    "    printf(\"  Time: %.3f ms\\n\", mem_time);\n",
    "    printf(\"  Bandwidth: %.1f GB/s (%.1f%% of peak)\\n\", mem_bw, 100 * mem_bw / peak_bw);\n",
    "    printf(\"  Arithmetic Intensity: %.4f FLOP/Byte\\n\\n\", mem_ai);\n",
    "    \n",
    "    // Compute-bound kernel\n",
    "    float comp_time = benchmark(compute_bound_kernel, d_in, d_out, N, \"Compute-bound\");\n",
    "    float comp_bytes = 2 * N * sizeof(float);\n",
    "    float comp_flops = N * 100 * 4;  // ~4 ops per iteration * 100 iterations\n",
    "    float comp_gflops = comp_flops / (comp_time * 1e6);\n",
    "    float comp_ai = comp_flops / comp_bytes;\n",
    "    \n",
    "    printf(\"Compute-Bound Kernel:\\n\");\n",
    "    printf(\"  Time: %.3f ms\\n\", comp_time);\n",
    "    printf(\"  Throughput: %.1f GFLOPS\\n\", comp_gflops);\n",
    "    printf(\"  Arithmetic Intensity: %.1f FLOP/Byte\\n\\n\", comp_ai);\n",
    "    \n",
    "    // Roofline ridge point\n",
    "    float ridge = peak_flops * 1e3 / peak_bw;  // GFLOPS/GB/s = FLOP/Byte\n",
    "    printf(\"Roofline Analysis:\\n\");\n",
    "    printf(\"  Ridge Point: %.1f FLOP/Byte\\n\", ridge);\n",
    "    printf(\"  Memory-bound kernel: AI < ridge (limited by BW)\\n\");\n",
    "    printf(\"  Compute-bound kernel: AI > ridge (limited by compute)\\n\");\n",
    "    \n",
    "    cudaFree(d_in); cudaFree(d_out);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd277b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o roofline_analysis roofline_analysis.cu\n",
    "!./roofline_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af189e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Profiling Tools\n",
    "\n",
    "### NVIDIA Tools\n",
    "\n",
    "```bash\n",
    "# Nsight Compute (kernel analysis)\n",
    "ncu --target-processes all ./my_program\n",
    "ncu --set full -o profile ./my_program  # Full analysis\n",
    "\n",
    "# Nsight Systems (timeline)\n",
    "nsys profile ./my_program\n",
    "nsys profile --cuda-memory-usage=true ./my_program\n",
    "\n",
    "# Legacy nvprof (if available)\n",
    "nvprof ./my_program\n",
    "nvprof --metrics all ./my_program\n",
    "```\n",
    "\n",
    "### Key Metrics to Check\n",
    "\n",
    "```\n",
    "From ncu:\n",
    "  - SM Efficiency: Are SMs busy?\n",
    "  - Memory Throughput: How much BW used?\n",
    "  - Achieved Occupancy: Warps active?\n",
    "  - Warp Stall Reasons: What's blocking?\n",
    "  \n",
    "From nsys:\n",
    "  - Timeline: Overlap of compute/memory\n",
    "  - API calls: Host-side overhead\n",
    "  - Memory transfers: H2D/D2H bottlenecks\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d05b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available profiling tools\n",
    "!which ncu nsys nvprof 2>/dev/null || echo \"Profiling tools not in PATH\"\n",
    "!ncu --version 2>/dev/null || echo \"ncu not available\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d2385",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e518259",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile benchmarking_exercises.cu\n",
    "// CUDA C++ Exercises - Benchmarking\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "// Exercise 1: Implement proper CUDA event timing wrapper\n",
    "// TODO: Add your implementation here\n",
    "\n",
    "// Exercise 2: Create bandwidth calculation utility\n",
    "// TODO: Add your implementation here\n",
    "\n",
    "// Exercise 3: Build statistical analysis for benchmark runs\n",
    "// TODO: Add your implementation here\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Benchmarking Exercises ===\\n\");\n",
    "    printf(\"Implement the exercises above and run!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o benchmarking_exercises benchmarking_exercises.cu && ./benchmarking_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10f436",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "The following exercises use Python and Numba for rapid prototyping. Complete the CUDA C++ exercises above first for the primary learning objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b9edc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Summary & Key Takeaways\n",
    "\n",
    "### Benchmarking Checklist\n",
    "\n",
    "| Phase | Action | Why It Matters |\n",
    "|-------|--------|----------------|\n",
    "| ğŸ”¥ Warmup | 10+ iterations | JIT compilation, cache warming |\n",
    "| ğŸ“Š Sampling | 100+ timed runs | Statistical significance |\n",
    "| ğŸ“ˆ Analysis | Median + variance | Outliers don't dominate |\n",
    "| ğŸ§® Metrics | BW or FLOPS | Context for \"how fast\" |\n",
    "\n",
    "### ğŸ§  ML Optimization Pattern: The Roofline Model\n",
    "\n",
    "```\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Compute Ceiling (Peak FLOPS)\n",
    "    â”‚    â•±\n",
    "    â”‚   â•±  Your kernel should be near one of these lines!\n",
    "    â”‚  â•±\n",
    "    â”‚ â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Memory Ceiling (Peak BW)\n",
    "    â”‚â•±\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "      Arithmetic Intensity (FLOPS / Byte)\n",
    "      \n",
    "Memory-bound (left of ridge): Report Bandwidth\n",
    "Compute-bound (right of ridge): Report FLOPS\n",
    "```\n",
    "\n",
    "### ğŸ”‘ Key Insights\n",
    "\n",
    "1. **The Olympic Rule:** CUDA events are your photo finish cameraâ€”CPU timers are a coach with a stopwatch\n",
    "2. **Median Over Mean:** Outliers happen (OS interrupts, thermal throttling)â€”median is more robust\n",
    "3. **Compare Apples to Apples:** Same GPU, same data size, same precisionâ€”never compare across different setups\n",
    "\n",
    "### Common Pitfalls Avoided\n",
    "\n",
    "âŒ **CPU timing without sync** â†’ Only measures launch overhead\n",
    "âŒ **Single-run results** â†’ Could be warm cache or cold cache\n",
    "âŒ **Ignoring warmup** â†’ First run includes JIT compilation\n",
    "âŒ **Wrong metric** â†’ Reporting FLOPS for memory-bound kernel\n",
    "\n",
    "### ğŸ“ Curriculum Complete! ğŸ‰\n",
    "\n",
    "**Congratulations!** You've completed the 14-week CUDA curriculum!\n",
    "\n",
    "| Week | Topics Mastered |\n",
    "|------|-----------------|\n",
    "| 1-4 | GPU fundamentals, memory hierarchy, error handling |\n",
    "| 5-6 | Synchronization, atomics, reduction patterns |\n",
    "| 7-8 | Occupancy, profiling with Nsight |\n",
    "| 9-10 | Streams, concurrency, CUDA Graphs |\n",
    "| 11-12 | Cooperative groups, multi-GPU |\n",
    "| 13 | Tensor Cores, mixed precision |\n",
    "| 14 | ML optimization: fusion, attention, extensions, benchmarking |\n",
    "\n",
    "### ğŸš€ What's Next?\n",
    "\n",
    "- **Week 15-18:** Advanced specialization tracks\n",
    "- **Production:** Apply these techniques to real ML workloads\n",
    "- **Contribute:** Share your optimized kernels with the community!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
