{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ddfa01",
   "metadata": {},
   "source": [
    "# ğŸš€ Day 2: Thread Indexing Mastery\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapati3/cuda-lab/blob/main/learning-path/week-01/day-2-thread-indexing.ipynb)\n",
    "\n",
    "## Learning Philosophy\n",
    "\n",
    "> **CUDA C++ First, Python/Numba as Optional Backup**\n",
    "\n",
    "This notebook shows:\n",
    "1. **CUDA C++ code** - The PRIMARY implementation you should learn\n",
    "2. **Python/Numba code** - OPTIONAL for quick interactive testing in Colab\n",
    "\n",
    "> **Note:** If running on Google Colab, go to `Runtime â†’ Change runtime type â†’ T4 GPU` before starting!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84104aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify CUDA is available\n",
    "!nvcc --version\n",
    "!nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd4c3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 2: Thread Indexing Mastery\n",
    "\n",
    "**The most critical skill** in CUDA programming is understanding how to map threads to data.\n",
    "\n",
    "Today you'll learn:\n",
    "- The CUDA thread hierarchy: Grid â†’ Blocks â†’ Threads\n",
    "- 1D indexing formula and boundary checking\n",
    "- Grid-stride loops for any array size\n",
    "- 2D indexing for matrices and images\n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Thread Hierarchy\n",
    "\n",
    "CUDA organizes threads into a **3-level hierarchy**:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                           GRID                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚\n",
    "â”‚  â”‚   Block 0   â”‚  â”‚   Block 1   â”‚  â”‚   Block 2   â”‚  ...        â”‚\n",
    "â”‚  â”‚ â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”   â”‚  â”‚ â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”   â”‚  â”‚ â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”   â”‚             â”‚\n",
    "â”‚  â”‚ â”‚Tâ”‚Tâ”‚Tâ”‚Tâ”‚   â”‚  â”‚ â”‚Tâ”‚Tâ”‚Tâ”‚Tâ”‚   â”‚  â”‚ â”‚Tâ”‚Tâ”‚Tâ”‚Tâ”‚   â”‚             â”‚\n",
    "â”‚  â”‚ â”‚0â”‚1â”‚2â”‚3â”‚   â”‚  â”‚ â”‚0â”‚1â”‚2â”‚3â”‚   â”‚  â”‚ â”‚0â”‚1â”‚2â”‚3â”‚   â”‚             â”‚\n",
    "â”‚  â”‚ â””â”€â”´â”€â”´â”€â”´â”€â”˜   â”‚  â”‚ â””â”€â”´â”€â”´â”€â”´â”€â”˜   â”‚  â”‚ â””â”€â”´â”€â”´â”€â”´â”€â”˜   â”‚             â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Built-in variables:\n",
    "- gridDim.x     = Number of blocks in grid (3 in this example)\n",
    "- blockDim.x    = Number of threads per block (4 in this example)\n",
    "- blockIdx.x    = Current block index (0, 1, or 2)\n",
    "- threadIdx.x   = Thread index within block (0, 1, 2, or 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940bf526",
   "metadata": {},
   "source": [
    "## 2. 1D Indexing Formula\n",
    "\n",
    "To find the **global index** of a thread:\n",
    "\n",
    "```cpp\n",
    "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "```\n",
    "\n",
    "**Example:** Block 2, Thread 3 with 4 threads per block:\n",
    "```\n",
    "idx = 2 * 4 + 3 = 11\n",
    "```\n",
    "\n",
    "Let's visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62726964",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile thread_indexing_1d.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Kernel that prints thread indexing information\n",
    "__global__ void printIndices() {\n",
    "    // Calculate global thread index\n",
    "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Each thread prints its indices\n",
    "    printf(\"Block %d, Thread %d -> Global Index %d\\n\",\n",
    "           blockIdx.x, threadIdx.x, globalIdx);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== 1D Thread Indexing Demo ===\\n\\n\");\n",
    "    \n",
    "    // Launch with 3 blocks, 4 threads per block\n",
    "    int blocksPerGrid = 3;\n",
    "    int threadsPerBlock = 4;\n",
    "    \n",
    "    printf(\"Grid: %d blocks, %d threads/block = %d total threads\\n\\n\",\n",
    "           blocksPerGrid, threadsPerBlock, blocksPerGrid * threadsPerBlock);\n",
    "    \n",
    "    printIndices<<<blocksPerGrid, threadsPerBlock>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    printf(\"\\nFormula: idx = blockIdx.x * blockDim.x + threadIdx.x\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o thread_indexing_1d thread_indexing_1d.cu && ./thread_indexing_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e2456",
   "metadata": {},
   "source": [
    "## 3. Boundary Checking: Critical for Safety!\n",
    "\n",
    "**Problem:** We often launch more threads than we have data elements.\n",
    "\n",
    "```\n",
    "Array size: 10 elements\n",
    "Threads launched: 3 blocks Ã— 4 threads = 12 threads\n",
    "\n",
    "Threads 0-9: Process elements (valid)\n",
    "Threads 10-11: Must do NOTHING! (out of bounds)\n",
    "```\n",
    "\n",
    "**Always include boundary checks:**\n",
    "\n",
    "```cpp\n",
    "if (idx < n) {\n",
    "    // Safe to access array[idx]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b28d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile boundary_check.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Kernel with proper boundary checking\n",
    "__global__ void safeSquare(float* input, float* output, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // CRITICAL: Check bounds before accessing memory\n",
    "    if (idx < n) {\n",
    "        output[idx] = input[idx] * input[idx];\n",
    "    }\n",
    "    // Threads with idx >= n do nothing (safe!)\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 10;\n",
    "    const int THREADS_PER_BLOCK = 4;\n",
    "    \n",
    "    // Calculate grid size (rounds up!)\n",
    "    int blocksPerGrid = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
    "    int totalThreads = blocksPerGrid * THREADS_PER_BLOCK;\n",
    "    \n",
    "    printf(\"=== Boundary Checking Demo ===\\n\\n\");\n",
    "    printf(\"Array size:      %d elements\\n\", N);\n",
    "    printf(\"Threads/block:   %d\\n\", THREADS_PER_BLOCK);\n",
    "    printf(\"Blocks:          %d\\n\", blocksPerGrid);\n",
    "    printf(\"Total threads:   %d\\n\", totalThreads);\n",
    "    printf(\"Extra threads:   %d (will be idle)\\n\\n\", totalThreads - N);\n",
    "    \n",
    "    // Allocate and initialize host memory\n",
    "    float h_input[N], h_output[N];\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_input[i] = i + 1;  // 1, 2, 3, ..., 10\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, N * sizeof(float));\n",
    "    cudaMalloc(&d_output, N * sizeof(float));\n",
    "    \n",
    "    // Copy input to device\n",
    "    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch kernel\n",
    "    safeSquare<<<blocksPerGrid, THREADS_PER_BLOCK>>>(d_input, d_output, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Copy results back\n",
    "    cudaMemcpy(h_output, d_output, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Verify results\n",
    "    printf(\"Results:\\n\");\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        float expected = (i + 1) * (i + 1);\n",
    "        printf(\"  input[%d] = %.0f, output[%d] = %.0f (expected %.0f) %s\\n\",\n",
    "               i, h_input[i], i, h_output[i], expected,\n",
    "               (h_output[i] == expected) ? \"âœ“\" : \"âœ—\");\n",
    "        if (h_output[i] != expected) correct = false;\n",
    "    }\n",
    "    printf(\"\\n%s All results correct!\\n\", correct ? \"âœ…\" : \"âŒ\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ce8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o boundary_check boundary_check.cu && ./boundary_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930697c",
   "metadata": {},
   "source": [
    "## 4. Grid-Stride Loops: The Professional Pattern\n",
    "\n",
    "What if your array has **billions** of elements but you can only launch millions of threads?\n",
    "\n",
    "**Grid-stride loop:** Each thread processes multiple elements, striding by the total grid size.\n",
    "\n",
    "```\n",
    "Array: [0][1][2][3][4][5][6][7][8][9][10][11]...\n",
    "\n",
    "Grid size: 4 threads total\n",
    "\n",
    "Thread 0: processes indices 0, 4, 8, 12, ...\n",
    "Thread 1: processes indices 1, 5, 9, 13, ...\n",
    "Thread 2: processes indices 2, 6, 10, 14, ...\n",
    "Thread 3: processes indices 3, 7, 11, 15, ...\n",
    "```\n",
    "\n",
    "This pattern is **essential** for production code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0247e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile grid_stride_loop.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Grid-stride loop pattern - handles ANY array size\n",
    "__global__ void gridStrideSquare(float* input, float* output, int n) {\n",
    "    // Starting index for this thread\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Total number of threads in the grid\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    \n",
    "    // Grid-stride loop: each thread handles multiple elements\n",
    "    for (int i = idx; i < n; i += stride) {\n",
    "        output[i] = input[i] * input[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Large array with limited grid\n",
    "    const int N = 100000000;  // 100 million elements!\n",
    "    const int THREADS_PER_BLOCK = 256;\n",
    "    const int BLOCKS = 256;   // Only 256 blocks, but handles 100M elements!\n",
    "    \n",
    "    printf(\"=== Grid-Stride Loop Demo ===\\n\\n\");\n",
    "    printf(\"Array size:     %d elements (%.1f MB)\\n\", N, N * sizeof(float) / 1e6);\n",
    "    printf(\"Grid size:      %d blocks Ã— %d threads = %d threads\\n\",\n",
    "           BLOCKS, THREADS_PER_BLOCK, BLOCKS * THREADS_PER_BLOCK);\n",
    "    printf(\"Elements/thread: %.1f (average)\\n\\n\", (float)N / (BLOCKS * THREADS_PER_BLOCK));\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float *h_input = (float*)malloc(N * sizeof(float));\n",
    "    float *h_output = (float*)malloc(N * sizeof(float));\n",
    "    \n",
    "    // Initialize input\n",
    "    srand(42);\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_input[i] = (float)rand() / RAND_MAX;\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, N * sizeof(float));\n",
    "    cudaMalloc(&d_output, N * sizeof(float));\n",
    "    \n",
    "    // Copy to device\n",
    "    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Time the kernel\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    gridStrideSquare<<<BLOCKS, THREADS_PER_BLOCK>>>(d_input, d_output, N);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float milliseconds = 0;\n",
    "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "    \n",
    "    // Copy back and verify\n",
    "    cudaMemcpy(h_output, d_output, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Verify a few samples\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < 100 && correct; i++) {\n",
    "        int idx = (i * N) / 100;  // Sample across the array\n",
    "        float expected = h_input[idx] * h_input[idx];\n",
    "        if (fabsf(h_output[idx] - expected) > 1e-5) {\n",
    "            printf(\"Mismatch at %d: got %f, expected %f\\n\", idx, h_output[idx], expected);\n",
    "            correct = false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Calculate bandwidth\n",
    "    float dataGB = 2.0f * N * sizeof(float) / 1e9;  // Read + write\n",
    "    float bandwidth = dataGB / (milliseconds / 1000.0f);\n",
    "    \n",
    "    printf(\"â±ï¸  Kernel time: %.3f ms\\n\", milliseconds);\n",
    "    printf(\"ğŸ“Š Bandwidth:    %.1f GB/s\\n\", bandwidth);\n",
    "    printf(\"%s All results correct!\\n\", correct ? \"âœ…\" : \"âŒ\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    free(h_input);\n",
    "    free(h_output);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -o grid_stride_loop grid_stride_loop.cu && ./grid_stride_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6e4fc",
   "metadata": {},
   "source": [
    "## 5. 2D Indexing: Matrices and Images\n",
    "\n",
    "For 2D data (matrices, images), we use 2D thread blocks and grids:\n",
    "\n",
    "```\n",
    "Image (Height Ã— Width):\n",
    "â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”\n",
    "â”‚0,0â”‚0,1â”‚0,2â”‚0,3â”‚0,4â”‚  Row 0\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚1,0â”‚1,1â”‚1,2â”‚1,3â”‚1,4â”‚  Row 1\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚2,0â”‚2,1â”‚2,2â”‚2,3â”‚2,4â”‚  Row 2\n",
    "â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜\n",
    "\n",
    "Thread coordinates:\n",
    "  row = blockIdx.y * blockDim.y + threadIdx.y\n",
    "  col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "  \n",
    "Linear index (row-major): idx = row * width + col\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c33073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile indexing_2d.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// 2D kernel to double each element of a matrix\n",
    "__global__ void matrixDouble(float* matrix, int rows, int cols) {\n",
    "    // Calculate 2D thread coordinates\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    // Boundary check for both dimensions\n",
    "    if (row < rows && col < cols) {\n",
    "        // Convert 2D to 1D index (row-major order)\n",
    "        int idx = row * cols + col;\n",
    "        matrix[idx] *= 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Print matrix helper\n",
    "void printMatrix(float* matrix, int rows, int cols, const char* name) {\n",
    "    printf(\"%s:\\n\", name);\n",
    "    for (int r = 0; r < rows; r++) {\n",
    "        printf(\"  \");\n",
    "        for (int c = 0; c < cols; c++) {\n",
    "            printf(\"%5.0f \", matrix[r * cols + c]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int ROWS = 6;\n",
    "    const int COLS = 8;\n",
    "    const int SIZE = ROWS * COLS * sizeof(float);\n",
    "    \n",
    "    printf(\"=== 2D Indexing Demo ===\\n\\n\");\n",
    "    \n",
    "    // Allocate and initialize host matrix\n",
    "    float* h_matrix = (float*)malloc(SIZE);\n",
    "    for (int i = 0; i < ROWS * COLS; i++) {\n",
    "        h_matrix[i] = i;\n",
    "    }\n",
    "    \n",
    "    printMatrix(h_matrix, ROWS, COLS, \"Original matrix\");\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float* d_matrix;\n",
    "    cudaMalloc(&d_matrix, SIZE);\n",
    "    cudaMemcpy(d_matrix, h_matrix, SIZE, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Configure 2D grid\n",
    "    dim3 threadsPerBlock(4, 4);  // 4Ã—4 = 16 threads per block\n",
    "    dim3 blocksPerGrid(\n",
    "        (COLS + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "        (ROWS + threadsPerBlock.y - 1) / threadsPerBlock.y\n",
    "    );\n",
    "    \n",
    "    printf(\"Block size: %d Ã— %d = %d threads\\n\",\n",
    "           threadsPerBlock.x, threadsPerBlock.y,\n",
    "           threadsPerBlock.x * threadsPerBlock.y);\n",
    "    printf(\"Grid size:  %d Ã— %d = %d blocks\\n\\n\",\n",
    "           blocksPerGrid.x, blocksPerGrid.y,\n",
    "           blocksPerGrid.x * blocksPerGrid.y);\n",
    "    \n",
    "    // Launch kernel\n",
    "    matrixDouble<<<blocksPerGrid, threadsPerBlock>>>(d_matrix, ROWS, COLS);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Copy back and display\n",
    "    cudaMemcpy(h_matrix, d_matrix, SIZE, cudaMemcpyDeviceToHost);\n",
    "    printMatrix(h_matrix, ROWS, COLS, \"Doubled matrix\");\n",
    "    \n",
    "    // Verify\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < ROWS * COLS; i++) {\n",
    "        if (h_matrix[i] != i * 2.0f) {\n",
    "            correct = false;\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    printf(\"%s All results correct!\\n\", correct ? \"âœ…\" : \"âŒ\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_matrix);\n",
    "    free(h_matrix);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62335590",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o indexing_2d indexing_2d.cu && ./indexing_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da3e67",
   "metadata": {},
   "source": [
    "## 6. Practical Example: Image Grayscale Conversion\n",
    "\n",
    "Let's apply 2D indexing to convert an RGB image to grayscale.\n",
    "\n",
    "**Grayscale formula:** `Y = 0.299*R + 0.587*G + 0.114*B`\n",
    "\n",
    "(These weights match human perception - we're more sensitive to green than blue.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile rgb_to_gray.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <time.h>\n",
    "\n",
    "// GPU kernel: RGB to Grayscale conversion\n",
    "__global__ void rgbToGray(unsigned char* rgb, unsigned char* gray,\n",
    "                          int height, int width) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < height && col < width) {\n",
    "        // RGB image has 3 channels per pixel\n",
    "        int rgbIdx = (row * width + col) * 3;\n",
    "        int grayIdx = row * width + col;\n",
    "        \n",
    "        // Get RGB values\n",
    "        unsigned char r = rgb[rgbIdx + 0];\n",
    "        unsigned char g = rgb[rgbIdx + 1];\n",
    "        unsigned char b = rgb[rgbIdx + 2];\n",
    "        \n",
    "        // Luminance formula (human perception weighted)\n",
    "        float grayVal = 0.299f * r + 0.587f * g + 0.114f * b;\n",
    "        gray[grayIdx] = (unsigned char)grayVal;\n",
    "    }\n",
    "}\n",
    "\n",
    "// CPU reference implementation for comparison\n",
    "void rgbToGrayCPU(unsigned char* rgb, unsigned char* gray, int height, int width) {\n",
    "    for (int row = 0; row < height; row++) {\n",
    "        for (int col = 0; col < width; col++) {\n",
    "            int rgbIdx = (row * width + col) * 3;\n",
    "            int grayIdx = row * width + col;\n",
    "            float grayVal = 0.299f * rgb[rgbIdx] + 0.587f * rgb[rgbIdx + 1] + 0.114f * rgb[rgbIdx + 2];\n",
    "            gray[grayIdx] = (unsigned char)grayVal;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Full HD image\n",
    "    const int WIDTH = 1920;\n",
    "    const int HEIGHT = 1080;\n",
    "    const int RGB_SIZE = WIDTH * HEIGHT * 3;\n",
    "    const int GRAY_SIZE = WIDTH * HEIGHT;\n",
    "    \n",
    "    printf(\"=== RGB to Grayscale Conversion ===\\n\\n\");\n",
    "    printf(\"Image size: %d Ã— %d (%d pixels, %.1f MB RGB)\\n\",\n",
    "           WIDTH, HEIGHT, WIDTH * HEIGHT, RGB_SIZE / 1e6);\n",
    "    \n",
    "    // Allocate host memory\n",
    "    unsigned char* h_rgb = (unsigned char*)malloc(RGB_SIZE);\n",
    "    unsigned char* h_gray_gpu = (unsigned char*)malloc(GRAY_SIZE);\n",
    "    unsigned char* h_gray_cpu = (unsigned char*)malloc(GRAY_SIZE);\n",
    "    \n",
    "    // Generate random image\n",
    "    srand(42);\n",
    "    for (int i = 0; i < RGB_SIZE; i++) {\n",
    "        h_rgb[i] = rand() % 256;\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    unsigned char *d_rgb, *d_gray;\n",
    "    cudaMalloc(&d_rgb, RGB_SIZE);\n",
    "    cudaMalloc(&d_gray, GRAY_SIZE);\n",
    "    \n",
    "    // Copy to device\n",
    "    cudaMemcpy(d_rgb, h_rgb, RGB_SIZE, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Configure 2D grid (16Ã—16 threads per block is common for images)\n",
    "    dim3 threadsPerBlock(16, 16);\n",
    "    dim3 blocksPerGrid(\n",
    "        (WIDTH + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "        (HEIGHT + threadsPerBlock.y - 1) / threadsPerBlock.y\n",
    "    );\n",
    "    \n",
    "    printf(\"Thread block: %d Ã— %d = %d threads\\n\",\n",
    "           threadsPerBlock.x, threadsPerBlock.y,\n",
    "           threadsPerBlock.x * threadsPerBlock.y);\n",
    "    printf(\"Grid: %d Ã— %d = %d blocks\\n\\n\",\n",
    "           blocksPerGrid.x, blocksPerGrid.y,\n",
    "           blocksPerGrid.x * blocksPerGrid.y);\n",
    "    \n",
    "    // Time GPU\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    rgbToGray<<<blocksPerGrid, threadsPerBlock>>>(d_rgb, d_gray, HEIGHT, WIDTH);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float gpuTime;\n",
    "    cudaEventElapsedTime(&gpuTime, start, stop);\n",
    "    \n",
    "    // Copy back\n",
    "    cudaMemcpy(h_gray_gpu, d_gray, GRAY_SIZE, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Time CPU\n",
    "    clock_t cpuStart = clock();\n",
    "    rgbToGrayCPU(h_rgb, h_gray_cpu, HEIGHT, WIDTH);\n",
    "    clock_t cpuEnd = clock();\n",
    "    float cpuTime = (float)(cpuEnd - cpuStart) / CLOCKS_PER_SEC * 1000;\n",
    "    \n",
    "    // Verify\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < GRAY_SIZE && correct; i++) {\n",
    "        if (abs(h_gray_gpu[i] - h_gray_cpu[i]) > 1) {\n",
    "            printf(\"Mismatch at %d: GPU=%d, CPU=%d\\n\",\n",
    "                   i, h_gray_gpu[i], h_gray_cpu[i]);\n",
    "            correct = false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    printf(\"â±ï¸  GPU time: %.3f ms\\n\", gpuTime);\n",
    "    printf(\"â±ï¸  CPU time: %.3f ms\\n\", cpuTime);\n",
    "    printf(\"ğŸš€ Speedup:  %.1fx\\n\", cpuTime / gpuTime);\n",
    "    printf(\"%s Results match!\\n\", correct ? \"âœ…\" : \"âŒ\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_rgb);\n",
    "    cudaFree(d_gray);\n",
    "    free(h_rgb);\n",
    "    free(h_gray_gpu);\n",
    "    free(h_gray_cpu);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -o rgb_to_gray rgb_to_gray.cu && ./rgb_to_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99afb3d",
   "metadata": {},
   "source": [
    "## ğŸ¯ Exercises\n",
    "\n",
    "### Exercise 1: Manual Index Calculation\n",
    "Implement a kernel that adds two arrays, calculating the global index manually (don't rely on helpers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile exercise1_manual_index.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// TODO: Implement vector addition with manual index calculation\n",
    "__global__ void vectorAdd(float* a, float* b, float* c, int n) {\n",
    "    // TODO: Calculate global index manually using:\n",
    "    // blockIdx.x, blockDim.x, threadIdx.x\n",
    "    int idx = 0;  // FIX THIS!\n",
    "    \n",
    "    if (idx < n) {\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1000;\n",
    "    size_t size = N * sizeof(float);\n",
    "    \n",
    "    // TODO: Complete the implementation\n",
    "    // 1. Allocate host and device memory\n",
    "    // 2. Initialize input arrays\n",
    "    // 3. Copy to device\n",
    "    // 4. Launch kernel with proper configuration\n",
    "    // 5. Copy back and verify\n",
    "    \n",
    "    printf(\"Exercise 1: Implement manual index calculation!\\n\");\n",
    "    printf(\"Hint: idx = blockIdx.x * blockDim.x + threadIdx.x\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e7cc6",
   "metadata": {},
   "source": [
    "### Exercise 2: 2D Grid-Stride Loop\n",
    "Implement a 2D grid-stride loop for processing very large images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile exercise2_2d_grid_stride.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// TODO: Implement 2D grid-stride loop\n",
    "__global__ void processLargeImage(float* image, int height, int width) {\n",
    "    // Starting position\n",
    "    int startCol = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int startRow = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    // Stride (grid size in each dimension)\n",
    "    int strideX = blockDim.x * gridDim.x;\n",
    "    int strideY = blockDim.y * gridDim.y;\n",
    "    \n",
    "    // TODO: Implement 2D grid-stride loop\n",
    "    // Hint: Use nested for loops\n",
    "    // for (int row = startRow; row < height; row += strideY) {\n",
    "    //     for (int col = startCol; col < width; col += strideX) {\n",
    "    //         // Process image[row * width + col]\n",
    "    //         // Example: multiply by 2\n",
    "    //     }\n",
    "    // }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Exercise 2: Implement 2D grid-stride loop!\\n\");\n",
    "    printf(\"This pattern handles images larger than your grid size.\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4e808",
   "metadata": {},
   "source": [
    "### Exercise 3: Image Negative\n",
    "Create a kernel that inverts an image (negative): `output[i] = 255 - input[i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile exercise3_image_negative.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// TODO: Implement image negative kernel\n",
    "__global__ void imageNegative(unsigned char* input, unsigned char* output,\n",
    "                              int height, int width) {\n",
    "    // TODO: Implement using 2D indexing\n",
    "    // 1. Calculate row and col from thread indices\n",
    "    // 2. Check boundaries\n",
    "    // 3. Compute: output[idx] = 255 - input[idx]\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Exercise 3: Implement image negative!\\n\");\n",
    "    printf(\"For each pixel: output = 255 - input\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27926dc3",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### Today You Learned:\n",
    "\n",
    "1. **1D Indexing Formula**:\n",
    "   ```cpp\n",
    "   int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "   ```\n",
    "\n",
    "2. **2D Indexing Formula**:\n",
    "   ```cpp\n",
    "   int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "   int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "   int linearIdx = row * width + col;  // Row-major\n",
    "   ```\n",
    "\n",
    "3. **Always check boundaries**: `if (idx < n) { ... }`\n",
    "\n",
    "4. **Grid-stride loops** handle any array size with fixed grid:\n",
    "   ```cpp\n",
    "   int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "   int stride = blockDim.x * gridDim.x;\n",
    "   for (int i = idx; i < n; i += stride) {\n",
    "       // process element i\n",
    "   }\n",
    "   ```\n",
    "\n",
    "5. **Common block sizes**:\n",
    "   - 1D: 256 or 512 threads\n",
    "   - 2D: (16, 16) or (32, 32) threads\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Next Up: Day 3 - Memory Fundamentals\n",
    "- cudaMalloc vs cudaMallocManaged\n",
    "- Pinned vs pageable memory\n",
    "- Memory transfer optimization\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”— Resources\n",
    "- [Thread Hierarchy - Programming Guide](../../cuda-programming-guide/01-introduction/programming-model.md)\n",
    "- [Quick Reference](../../notes/cuda-quick-reference.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dae80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup generated files\n",
    "!rm -f thread_indexing_1d boundary_check grid_stride_loop indexing_2d rgb_to_gray\n",
    "!rm -f *.cu\n",
    "print(\"âœ… Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce586ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Colab/Local Setup - Run this first!\n",
    "# Python/Numba is OPTIONAL - for quick interactive testing only\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"ğŸ”§ Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"âœ… Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’» Running locally - make sure you have: pip install numba numpy\")\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "\n",
    "print(\"\\nâš ï¸  Remember: CUDA C++ code is the PRIMARY learning material!\")\n",
    "print(\"   Python/Numba is provided for quick interactive testing only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e64bf6",
   "metadata": {},
   "source": [
    "# Day 2: Thread Indexing Mastery\n",
    "\n",
    "Yesterday you launched your first CUDA kernel. Today we'll master the art of **thread indexing** - how each thread knows which data element to process.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand 1D, 2D, and 3D thread indexing\n",
    "- Master the relationship between blocks, threads, and global indices\n",
    "- Implement grid-stride loops for handling any array size\n",
    "- Apply indexing to real 2D problems (matrices, images)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Thread Hierarchy Recap\n",
    "\n",
    "### CUDA C++ Built-in Variables\n",
    "\n",
    "| CUDA C++ | Python/Numba | Description |\n",
    "|----------|--------------|-------------|\n",
    "| `threadIdx.x/y/z` | `cuda.threadIdx.x/y/z` | Thread index within block |\n",
    "| `blockIdx.x/y/z` | `cuda.blockIdx.x/y/z` | Block index within grid |\n",
    "| `blockDim.x/y/z` | `cuda.blockDim.x/y/z` | Threads per block |\n",
    "| `gridDim.x/y/z` | `cuda.gridDim.x/y/z` | Blocks in grid |\n",
    "\n",
    "```\n",
    "                           GRID\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,0)   (1,0)   (2,0)   â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,1)   (1,1)   (2,1)   â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        \n",
    "                      Each Block:\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,0)  (1,0)  (2,0)     â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,1)  (1,1)  (2,1)     â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Built-in Variables (in Numba):**\n",
    "- `cuda.threadIdx.x/y/z` - Thread index within block\n",
    "- `cuda.blockIdx.x/y/z` - Block index within grid\n",
    "- `cuda.blockDim.x/y/z` - Threads per block\n",
    "- `cuda.gridDim.x/y/z` - Blocks in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "\n",
    "print(\"CUDA available:\", cuda.is_available())\n",
    "print(\"Current device:\", cuda.get_current_device().name.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed9210",
   "metadata": {},
   "source": [
    "## 2. 1D Indexing: The Foundation\n",
    "\n",
    "For 1D arrays, each thread needs a unique **global index**:\n",
    "\n",
    "```\n",
    "Global Index = blockIdx.x * blockDim.x + threadIdx.x\n",
    "\n",
    "Example: 3 blocks Ã— 4 threads/block = 12 threads\n",
    "\n",
    "Block 0:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=0     idx=1     idx=2     idx=3\n",
    "          \n",
    "Block 1:  Thread 0  Thread 1  Thread 2  Thread 3  \n",
    "          idx=4     idx=5     idx=6     idx=7\n",
    "          \n",
    "Block 2:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=8     idx=9     idx=10    idx=11\n",
    "```\n",
    "\n",
    "Let's visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def print_1d_indices(output):\n",
    "    \"\"\"Each thread writes its indices to the output array\"\"\"\n",
    "    # Get indices manually\n",
    "    block_id = cuda.blockIdx.x\n",
    "    thread_id = cuda.threadIdx.x\n",
    "    block_size = cuda.blockDim.x\n",
    "    \n",
    "    # Calculate global index\n",
    "    global_idx = block_id * block_size + thread_id\n",
    "    \n",
    "    # Or use the convenient helper:\n",
    "    # global_idx = cuda.grid(1)\n",
    "    \n",
    "    if global_idx < output.shape[0]:\n",
    "        # Store: [global_idx, block_id, thread_id]\n",
    "        output[global_idx, 0] = global_idx\n",
    "        output[global_idx, 1] = block_id\n",
    "        output[global_idx, 2] = thread_id\n",
    "\n",
    "# Launch with 3 blocks Ã— 4 threads\n",
    "threads_per_block = 4\n",
    "blocks = 3\n",
    "total_threads = blocks * threads_per_block\n",
    "\n",
    "output = np.zeros((total_threads, 3), dtype=np.int32)\n",
    "output_d = cuda.to_device(output)\n",
    "\n",
    "print_1d_indices[blocks, threads_per_block](output_d)\n",
    "result = output_d.copy_to_host()\n",
    "\n",
    "print(\"1D Thread Indexing Visualization\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Configuration: {blocks} blocks Ã— {threads_per_block} threads/block\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Global Idx':^12} | {'Block ID':^10} | {'Thread ID':^10}\")\n",
    "print(\"-\" * 50)\n",
    "for row in result:\n",
    "    print(f\"{row[0]:^12} | {row[1]:^10} | {row[2]:^10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e9050",
   "metadata": {},
   "source": [
    "## 3. Boundary Checking: When Threads > Elements\n",
    "\n",
    "What happens when array size isn't a perfect multiple of block size?\n",
    "\n",
    "```\n",
    "Array size: 10 elements\n",
    "Block size: 4 threads\n",
    "Blocks needed: ceil(10/4) = 3\n",
    "Total threads: 3 Ã— 4 = 12\n",
    "\n",
    "Thread indices: 0  1  2  3  4  5  6  7  8  9  10  11\n",
    "Array elements: âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“   âœ—   âœ—\n",
    "                                               â†‘    â†‘\n",
    "                                          Out of bounds!\n",
    "```\n",
    "\n",
    "**Always add boundary checks!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def safe_square(input_arr, output_arr, n):\n",
    "    \"\"\"Square each element with proper boundary check\"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    # CRITICAL: Boundary check\n",
    "    if idx < n:\n",
    "        output_arr[idx] = input_arr[idx] ** 2\n",
    "\n",
    "# Array that's NOT a multiple of block size\n",
    "N = 1000\n",
    "a = np.arange(N, dtype=np.float32)\n",
    "b = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "threads_per_block = 256\n",
    "blocks = math.ceil(N / threads_per_block)\n",
    "\n",
    "print(f\"Array size: {N}\")\n",
    "print(f\"Threads per block: {threads_per_block}\")\n",
    "print(f\"Blocks needed: {blocks}\")\n",
    "print(f\"Total threads: {blocks * threads_per_block}\")\n",
    "print(f\"Extra threads (idle): {blocks * threads_per_block - N}\")\n",
    "\n",
    "a_d = cuda.to_device(a)\n",
    "b_d = cuda.to_device(b)\n",
    "\n",
    "safe_square[blocks, threads_per_block](a_d, b_d, N)\n",
    "result = b_d.copy_to_host()\n",
    "\n",
    "# Verify\n",
    "expected = a ** 2\n",
    "print(f\"\\nâœ… Correct: {np.allclose(result, expected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08549608",
   "metadata": {},
   "source": [
    "## 4. Grid-Stride Loops: The Professional Pattern\n",
    "\n",
    "What if your array has **billions** of elements but you can only launch millions of threads?\n",
    "\n",
    "**Grid-stride loop**: Each thread processes multiple elements, striding by the total grid size.\n",
    "\n",
    "```\n",
    "Array: [0][1][2][3][4][5][6][7][8][9][10][11]...\n",
    "\n",
    "Grid size: 4 threads\n",
    "\n",
    "Thread 0: processes indices 0, 4, 8, 12, ...\n",
    "Thread 1: processes indices 1, 5, 9, 13, ...\n",
    "Thread 2: processes indices 2, 6, 10, 14, ...\n",
    "Thread 3: processes indices 3, 7, 11, 15, ...\n",
    "```\n",
    "\n",
    "This pattern is **essential** for production code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def grid_stride_square(input_arr, output_arr, n):\n",
    "    \"\"\"Process arbitrary-sized arrays with grid-stride loop\"\"\"\n",
    "    # Starting index for this thread\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    # Total number of threads in the grid\n",
    "    stride = cuda.gridsize(1)  # = blockDim.x * gridDim.x\n",
    "    \n",
    "    # Grid-stride loop: each thread handles multiple elements\n",
    "    while idx < n:\n",
    "        output_arr[idx] = input_arr[idx] ** 2\n",
    "        idx += stride  # Jump to next element this thread handles\n",
    "\n",
    "# Huge array with limited grid\n",
    "N = 100_000_000  # 100 million elements!\n",
    "a = np.random.randn(N).astype(np.float32)\n",
    "b = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "# Fixed, reasonable grid size\n",
    "threads_per_block = 256\n",
    "blocks = 256  # Only 256 blocks, but handles 100M elements!\n",
    "\n",
    "print(f\"Array size: {N:,}\")\n",
    "print(f\"Grid size: {blocks} blocks Ã— {threads_per_block} threads = {blocks * threads_per_block:,} threads\")\n",
    "print(f\"Elements per thread (average): {N / (blocks * threads_per_block):.1f}\")\n",
    "\n",
    "a_d = cuda.to_device(a)\n",
    "b_d = cuda.to_device(b)\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "grid_stride_square[blocks, threads_per_block](a_d, b_d, N)\n",
    "cuda.synchronize()\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "result = b_d.copy_to_host()\n",
    "print(f\"\\nâ±ï¸  Time: {elapsed*1000:.2f} ms\")\n",
    "print(f\"âœ… Correct: {np.allclose(result, a**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaca503",
   "metadata": {},
   "source": [
    "## 5. 2D Indexing: Matrices and Images\n",
    "\n",
    "For 2D data (matrices, images), we use 2D thread blocks and grids:\n",
    "\n",
    "```\n",
    "Image (Height Ã— Width):\n",
    "â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”\n",
    "â”‚0,0â”‚0,1â”‚0,2â”‚0,3â”‚0,4â”‚  Row 0\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚1,0â”‚1,1â”‚1,2â”‚1,3â”‚1,4â”‚  Row 1\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚2,0â”‚2,1â”‚2,2â”‚2,3â”‚2,4â”‚  Row 2\n",
    "â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜\n",
    "\n",
    "Thread coordinates:\n",
    "  row = blockIdx.y * blockDim.y + threadIdx.y\n",
    "  col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matrix_double_2d(matrix, rows, cols):\n",
    "    \"\"\"Double each element using 2D indexing\"\"\"\n",
    "    # Get 2D thread coordinates\n",
    "    col, row = cuda.grid(2)  # Returns (x, y) = (col, row)\n",
    "    \n",
    "    # Boundary check for both dimensions\n",
    "    if row < rows and col < cols:\n",
    "        matrix[row, col] *= 2\n",
    "\n",
    "# Create a small matrix to visualize\n",
    "rows, cols = 6, 8\n",
    "matrix = np.arange(rows * cols, dtype=np.float32).reshape(rows, cols)\n",
    "\n",
    "print(\"Original matrix:\")\n",
    "print(matrix)\n",
    "print()\n",
    "\n",
    "# 2D block configuration\n",
    "threads_per_block_2d = (4, 4)  # 4Ã—4 = 16 threads per block\n",
    "blocks_per_grid_x = math.ceil(cols / threads_per_block_2d[0])\n",
    "blocks_per_grid_y = math.ceil(rows / threads_per_block_2d[1])\n",
    "blocks_per_grid_2d = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "print(f\"Block size: {threads_per_block_2d}\")\n",
    "print(f\"Grid size: {blocks_per_grid_2d}\")\n",
    "\n",
    "matrix_d = cuda.to_device(matrix)\n",
    "matrix_double_2d[blocks_per_grid_2d, threads_per_block_2d](matrix_d, rows, cols)\n",
    "result = matrix_d.copy_to_host()\n",
    "\n",
    "print(\"\\nDoubled matrix:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f2cc0",
   "metadata": {},
   "source": [
    "## 6. Practical Example: Image Processing (Grayscale)\n",
    "\n",
    "Let's apply 2D indexing to convert an RGB image to grayscale.\n",
    "\n",
    "Grayscale formula: `Y = 0.299*R + 0.587*G + 0.114*B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def rgb_to_grayscale(rgb_image, gray_image, height, width):\n",
    "    \"\"\"Convert RGB image to grayscale using 2D indexing\"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < height and col < width:\n",
    "        # RGB channels\n",
    "        r = rgb_image[row, col, 0]\n",
    "        g = rgb_image[row, col, 1]\n",
    "        b = rgb_image[row, col, 2]\n",
    "        \n",
    "        # Weighted sum (human perception weighting)\n",
    "        gray = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "        \n",
    "        gray_image[row, col] = gray\n",
    "\n",
    "# Create a synthetic RGB image (like a gradient)\n",
    "height, width = 1080, 1920  # Full HD\n",
    "rgb_image = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8).astype(np.float32)\n",
    "\n",
    "gray_image = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "# Configure 2D grid\n",
    "threads_per_block = (16, 16)  # 256 threads per block\n",
    "blocks_x = math.ceil(width / threads_per_block[0])\n",
    "blocks_y = math.ceil(height / threads_per_block[1])\n",
    "blocks_per_grid = (blocks_x, blocks_y)\n",
    "\n",
    "print(f\"Image size: {height} Ã— {width} ({height * width:,} pixels)\")\n",
    "print(f\"Thread block: {threads_per_block}\")\n",
    "print(f\"Grid: {blocks_per_grid}\")\n",
    "print(f\"Total threads: {blocks_x * threads_per_block[0]} Ã— {blocks_y * threads_per_block[1]}\")\n",
    "\n",
    "# Run on GPU\n",
    "rgb_d = cuda.to_device(rgb_image)\n",
    "gray_d = cuda.to_device(gray_image)\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "rgb_to_grayscale[blocks_per_grid, threads_per_block](rgb_d, gray_d, height, width)\n",
    "cuda.synchronize()\n",
    "gpu_time = time.perf_counter() - start\n",
    "\n",
    "gray_result = gray_d.copy_to_host()\n",
    "\n",
    "# Compare with NumPy (CPU)\n",
    "start = time.perf_counter()\n",
    "gray_cpu = 0.299 * rgb_image[:,:,0] + 0.587 * rgb_image[:,:,1] + 0.114 * rgb_image[:,:,2]\n",
    "cpu_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\nâ±ï¸  GPU time: {gpu_time*1000:.3f} ms\")\n",
    "print(f\"â±ï¸  CPU time: {cpu_time*1000:.3f} ms\")\n",
    "print(f\"ğŸš€ Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "print(f\"âœ… Correct: {np.allclose(gray_result, gray_cpu, atol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f05a7c",
   "metadata": {},
   "source": [
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Complete the exercises below in CUDA C++. These cover manual indexing, 2D grid-stride loops, and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile thread_indexing_exercises.cu\n",
    "// thread_indexing_exercises.cu - Thread indexing exercises\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error at %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
    "                    cudaGetErrorString(err)); \\\n",
    "            exit(EXIT_FAILURE); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 1: Manual Index Calculation\n",
    "// Implement 1D indexing WITHOUT using cuda.grid() - calculate manually\n",
    "// =============================================================================\n",
    "\n",
    "__global__ void manualIndexAdd(const float* a, const float* b, float* c, int n) {\n",
    "    // TODO: Calculate global index manually using blockIdx.x, blockDim.x, threadIdx.x\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;  // Manual calculation!\n",
    "    \n",
    "    if (idx < n) {\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 2: 2D Grid-Stride Loop\n",
    "// Process a very large matrix with 2D grid-stride loop pattern\n",
    "// =============================================================================\n",
    "\n",
    "__global__ void gridStride2D(float* matrix, int height, int width) {\n",
    "    // Starting position\n",
    "    int startCol = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int startRow = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    // Stride (grid size in each dimension)\n",
    "    int strideCol = blockDim.x * gridDim.x;\n",
    "    int strideRow = blockDim.y * gridDim.y;\n",
    "    \n",
    "    // 2D grid-stride loop\n",
    "    for (int row = startRow; row < height; row += strideRow) {\n",
    "        for (int col = startCol; col < width; col += strideCol) {\n",
    "            int idx = row * width + col;\n",
    "            matrix[idx] = matrix[idx] * 2.0f;  // Double each element\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 3: Image Negative\n",
    "// Invert an image: output = 255 - input\n",
    "// =============================================================================\n",
    "\n",
    "__global__ void imageNegative(const unsigned char* input, unsigned char* output, \n",
    "                               int height, int width) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        output[idx] = 255 - input[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Test harness\n",
    "// =============================================================================\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Thread Indexing Exercises ===\\n\\n\");\n",
    "    \n",
    "    // Exercise 1: Manual Index Addition\n",
    "    printf(\"Exercise 1: Manual Index Add\\n\");\n",
    "    printf(\"-\" \"-----------------------------\\n\");\n",
    "    {\n",
    "        const int N = 1000;\n",
    "        float *h_a = (float*)malloc(N * sizeof(float));\n",
    "        float *h_b = (float*)malloc(N * sizeof(float));\n",
    "        float *h_c = (float*)malloc(N * sizeof(float));\n",
    "        \n",
    "        for (int i = 0; i < N; i++) {\n",
    "            h_a[i] = (float)i;\n",
    "            h_b[i] = (float)(i * 2);\n",
    "        }\n",
    "        \n",
    "        float *d_a, *d_b, *d_c;\n",
    "        CUDA_CHECK(cudaMalloc(&d_a, N * sizeof(float)));\n",
    "        CUDA_CHECK(cudaMalloc(&d_b, N * sizeof(float)));\n",
    "        CUDA_CHECK(cudaMalloc(&d_c, N * sizeof(float)));\n",
    "        \n",
    "        CUDA_CHECK(cudaMemcpy(d_a, h_a, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "        CUDA_CHECK(cudaMemcpy(d_b, h_b, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "        \n",
    "        int threadsPerBlock = 256;\n",
    "        int blocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
    "        \n",
    "        manualIndexAdd<<<blocks, threadsPerBlock>>>(d_a, d_b, d_c, N);\n",
    "        CUDA_CHECK(cudaGetLastError());\n",
    "        CUDA_CHECK(cudaDeviceSynchronize());\n",
    "        \n",
    "        CUDA_CHECK(cudaMemcpy(h_c, d_c, N * sizeof(float), cudaMemcpyDeviceToHost));\n",
    "        \n",
    "        // Verify\n",
    "        bool correct = true;\n",
    "        for (int i = 0; i < N && correct; i++) {\n",
    "            if (h_c[i] != h_a[i] + h_b[i]) correct = false;\n",
    "        }\n",
    "        printf(\"Result: %s\\n\", correct ? \"âœ“ PASSED\" : \"âœ— FAILED\");\n",
    "        printf(\"Sample: c[0]=%.0f, c[999]=%.0f\\n\\n\", h_c[0], h_c[999]);\n",
    "        \n",
    "        cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "        free(h_a); free(h_b); free(h_c);\n",
    "    }\n",
    "    \n",
    "    // Exercise 2: 2D Grid-Stride Loop\n",
    "    printf(\"Exercise 2: 2D Grid-Stride Loop\\n\");\n",
    "    printf(\"-\" \"--------------------------------\\n\");\n",
    "    {\n",
    "        const int HEIGHT = 2048;\n",
    "        const int WIDTH = 2048;\n",
    "        size_t size = HEIGHT * WIDTH * sizeof(float);\n",
    "        \n",
    "        float *h_matrix = (float*)malloc(size);\n",
    "        for (int i = 0; i < HEIGHT * WIDTH; i++) {\n",
    "            h_matrix[i] = (float)(i % 100);\n",
    "        }\n",
    "        float original_val = h_matrix[0];\n",
    "        \n",
    "        float *d_matrix;\n",
    "        CUDA_CHECK(cudaMalloc(&d_matrix, size));\n",
    "        CUDA_CHECK(cudaMemcpy(d_matrix, h_matrix, size, cudaMemcpyHostToDevice));\n",
    "        \n",
    "        // Use small grid to force grid-stride behavior\n",
    "        dim3 threadsPerBlock(16, 16);\n",
    "        dim3 blocks(8, 8);  // Only 128x128 threads for 2048x2048 matrix\n",
    "        \n",
    "        gridStride2D<<<blocks, threadsPerBlock>>>(d_matrix, HEIGHT, WIDTH);\n",
    "        CUDA_CHECK(cudaGetLastError());\n",
    "        CUDA_CHECK(cudaDeviceSynchronize());\n",
    "        \n",
    "        CUDA_CHECK(cudaMemcpy(h_matrix, d_matrix, size, cudaMemcpyDeviceToHost));\n",
    "        \n",
    "        // Verify (all elements should be doubled)\n",
    "        bool correct = true;\n",
    "        for (int i = 0; i < 100 && correct; i++) {\n",
    "            float expected = (float)(i % 100) * 2.0f;\n",
    "            if (h_matrix[i] != expected) correct = false;\n",
    "        }\n",
    "        printf(\"Result: %s\\n\", correct ? \"âœ“ PASSED\" : \"âœ— FAILED\");\n",
    "        printf(\"Sample: matrix[0]=%.0f (was %.0f)\\n\\n\", h_matrix[0], original_val);\n",
    "        \n",
    "        cudaFree(d_matrix);\n",
    "        free(h_matrix);\n",
    "    }\n",
    "    \n",
    "    // Exercise 3: Image Negative\n",
    "    printf(\"Exercise 3: Image Negative\\n\");\n",
    "    printf(\"-\" \"--------------------------\\n\");\n",
    "    {\n",
    "        const int HEIGHT = 1080;\n",
    "        const int WIDTH = 1920;\n",
    "        size_t size = HEIGHT * WIDTH * sizeof(unsigned char);\n",
    "        \n",
    "        unsigned char *h_input = (unsigned char*)malloc(size);\n",
    "        unsigned char *h_output = (unsigned char*)malloc(size);\n",
    "        \n",
    "        // Create gradient image\n",
    "        for (int i = 0; i < HEIGHT * WIDTH; i++) {\n",
    "            h_input[i] = (unsigned char)(i % 256);\n",
    "        }\n",
    "        \n",
    "        unsigned char *d_input, *d_output;\n",
    "        CUDA_CHECK(cudaMalloc(&d_input, size));\n",
    "        CUDA_CHECK(cudaMalloc(&d_output, size));\n",
    "        \n",
    "        CUDA_CHECK(cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice));\n",
    "        \n",
    "        dim3 threadsPerBlock(32, 32);\n",
    "        dim3 blocks((WIDTH + 31) / 32, (HEIGHT + 31) / 32);\n",
    "        \n",
    "        imageNegative<<<blocks, threadsPerBlock>>>(d_input, d_output, HEIGHT, WIDTH);\n",
    "        CUDA_CHECK(cudaGetLastError());\n",
    "        CUDA_CHECK(cudaDeviceSynchronize());\n",
    "        \n",
    "        CUDA_CHECK(cudaMemcpy(h_output, d_output, size, cudaMemcpyDeviceToHost));\n",
    "        \n",
    "        // Verify\n",
    "        bool correct = true;\n",
    "        for (int i = 0; i < 256 && correct; i++) {\n",
    "            if (h_output[i] != (unsigned char)(255 - h_input[i])) correct = false;\n",
    "        }\n",
    "        printf(\"Result: %s\\n\", correct ? \"âœ“ PASSED\" : \"âœ— FAILED\");\n",
    "        printf(\"Sample: input[0]=%d â†’ output[0]=%d (expected %d)\\n\", \n",
    "               h_input[0], h_output[0], 255 - h_input[0]);\n",
    "        \n",
    "        cudaFree(d_input); cudaFree(d_output);\n",
    "        free(h_input); free(h_output);\n",
    "    }\n",
    "    \n",
    "    printf(\"\\n=== All exercises complete! ===\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e95ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o thread_indexing_exercises thread_indexing_exercises.cu && ./thread_indexing_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa8e5a",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "These exercises use Python/Numba for quick experimentation. Complete the C++ versions above first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 1: Manual indexing\n",
    "@cuda.jit\n",
    "def manual_index_add(a, b, c):\n",
    "    \"\"\"Add arrays using MANUAL index calculation\"\"\"\n",
    "    # TODO: Calculate global index manually\n",
    "    # idx = blockIdx.x * blockDim.x + threadIdx.x\n",
    "    idx = 0  # FIX THIS\n",
    "    \n",
    "    if idx < c.size:\n",
    "        c[idx] = a[idx] + b[idx]\n",
    "\n",
    "# Test your implementation\n",
    "# N = 1000\n",
    "# a = np.random.randn(N).astype(np.float32)\n",
    "# b = np.random.randn(N).astype(np.float32)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcfb60",
   "metadata": {},
   "source": [
    "### Exercise 2: 2D Grid-Stride Loop\n",
    "Implement a 2D grid-stride loop for processing very large images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 2: 2D Grid-Stride Loop\n",
    "@cuda.jit\n",
    "def grid_stride_2d(matrix, height, width):\n",
    "    \"\"\"Process large matrix with 2D grid-stride loop\"\"\"\n",
    "    # Starting position\n",
    "    start_col, start_row = cuda.grid(2)\n",
    "    \n",
    "    # Stride (grid size in each dimension)\n",
    "    stride_col, stride_row = cuda.gridsize(2)\n",
    "    \n",
    "    # TODO: Implement 2D grid-stride loop\n",
    "    # Hint: Use nested while loops\n",
    "    # row = start_row\n",
    "    # while row < height:\n",
    "    #     col = start_col\n",
    "    #     while col < width:\n",
    "    #         # process matrix[row, col]\n",
    "    #         col += stride_col\n",
    "    #     row += stride_row\n",
    "    pass\n",
    "\n",
    "# Test with a huge matrix\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86ad64",
   "metadata": {},
   "source": [
    "### Exercise 3: Image Negative\n",
    "Create a kernel that inverts an image (negative): `output[i,j] = 255 - input[i,j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 3: Image Negative\n",
    "@cuda.jit\n",
    "def image_negative(input_img, output_img, height, width):\n",
    "    \"\"\"Invert image: output = 255 - input\"\"\"\n",
    "    # TODO: Implement using 2D indexing\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806a8ff",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### Today You Learned:\n",
    "\n",
    "1. **1D Indexing Formula**:\n",
    "   ```\n",
    "   global_idx = blockIdx.x * blockDim.x + threadIdx.x\n",
    "   # Or simply: cuda.grid(1)\n",
    "   ```\n",
    "\n",
    "2. **2D Indexing Formula**:\n",
    "   ```\n",
    "   col, row = cuda.grid(2)\n",
    "   # Manually: \n",
    "   # row = blockIdx.y * blockDim.y + threadIdx.y\n",
    "   # col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "   ```\n",
    "\n",
    "3. **Always check boundaries**: `if idx < n:`\n",
    "\n",
    "4. **Grid-stride loops** handle any array size with fixed grid:\n",
    "   ```python\n",
    "   idx = cuda.grid(1)\n",
    "   stride = cuda.gridsize(1)\n",
    "   while idx < n:\n",
    "       # process element\n",
    "       idx += stride\n",
    "   ```\n",
    "\n",
    "5. **Common block sizes**:\n",
    "   - 1D: 256 or 512 threads\n",
    "   - 2D: (16, 16) or (32, 32) threads\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Next Up: Day 3 - Memory Fundamentals\n",
    "- cudaMalloc vs cudaMallocManaged\n",
    "- Pinned vs pageable memory\n",
    "- Memory transfer optimization\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”— Resources\n",
    "- [Thread Hierarchy - Programming Guide](../../cuda-programming-guide/01-introduction/programming-model.md)\n",
    "- [Quick Reference](../../notes/cuda-quick-reference.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
