{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ddfa01",
   "metadata": {},
   "source": [
    "# ğŸš€ Day 2: Thread Indexing Mastery\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapa/cuda-lab/blob/main/learning-path/week-01/day-2-thread-indexing.ipynb)\n",
    "\n",
    "> **Note:** If running on Google Colab, go to `Runtime â†’ Change runtime type â†’ T4 GPU` before starting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce586ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Colab Setup Cell - Run this first!\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"ğŸ”§ Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"âœ… Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’» Running locally - make sure you have: pip install numba numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e64bf6",
   "metadata": {},
   "source": [
    "# Day 2: Thread Indexing Mastery\n",
    "\n",
    "Yesterday you launched your first CUDA kernel. Today we'll master the art of **thread indexing** - how each thread knows which data element to process.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand 1D, 2D, and 3D thread indexing\n",
    "- Master the relationship between blocks, threads, and global indices\n",
    "- Implement grid-stride loops for handling any array size\n",
    "- Apply indexing to real 2D problems (matrices, images)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Thread Hierarchy Recap\n",
    "\n",
    "```\n",
    "                           GRID\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,0)   (1,0)   (2,0)   â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,1)   (1,1)   (2,1)   â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        \n",
    "                      Each Block:\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,0)  (1,0)  (2,0)     â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,1)  (1,1)  (2,1)     â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Built-in Variables (in Numba):**\n",
    "- `cuda.threadIdx.x/y/z` - Thread index within block\n",
    "- `cuda.blockIdx.x/y/z` - Block index within grid\n",
    "- `cuda.blockDim.x/y/z` - Threads per block\n",
    "- `cuda.gridDim.x/y/z` - Blocks in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "\n",
    "print(\"CUDA available:\", cuda.is_available())\n",
    "print(\"Current device:\", cuda.get_current_device().name.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed9210",
   "metadata": {},
   "source": [
    "## 2. 1D Indexing: The Foundation\n",
    "\n",
    "For 1D arrays, each thread needs a unique **global index**:\n",
    "\n",
    "```\n",
    "Global Index = blockIdx.x * blockDim.x + threadIdx.x\n",
    "\n",
    "Example: 3 blocks Ã— 4 threads/block = 12 threads\n",
    "\n",
    "Block 0:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=0     idx=1     idx=2     idx=3\n",
    "          \n",
    "Block 1:  Thread 0  Thread 1  Thread 2  Thread 3  \n",
    "          idx=4     idx=5     idx=6     idx=7\n",
    "          \n",
    "Block 2:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=8     idx=9     idx=10    idx=11\n",
    "```\n",
    "\n",
    "Let's visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def print_1d_indices(output):\n",
    "    \"\"\"Each thread writes its indices to the output array\"\"\"\n",
    "    # Get indices manually\n",
    "    block_id = cuda.blockIdx.x\n",
    "    thread_id = cuda.threadIdx.x\n",
    "    block_size = cuda.blockDim.x\n",
    "    \n",
    "    # Calculate global index\n",
    "    global_idx = block_id * block_size + thread_id\n",
    "    \n",
    "    # Or use the convenient helper:\n",
    "    # global_idx = cuda.grid(1)\n",
    "    \n",
    "    if global_idx < output.shape[0]:\n",
    "        # Store: [global_idx, block_id, thread_id]\n",
    "        output[global_idx, 0] = global_idx\n",
    "        output[global_idx, 1] = block_id\n",
    "        output[global_idx, 2] = thread_id\n",
    "\n",
    "# Launch with 3 blocks Ã— 4 threads\n",
    "threads_per_block = 4\n",
    "blocks = 3\n",
    "total_threads = blocks * threads_per_block\n",
    "\n",
    "output = np.zeros((total_threads, 3), dtype=np.int32)\n",
    "output_d = cuda.to_device(output)\n",
    "\n",
    "print_1d_indices[blocks, threads_per_block](output_d)\n",
    "result = output_d.copy_to_host()\n",
    "\n",
    "print(\"1D Thread Indexing Visualization\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Configuration: {blocks} blocks Ã— {threads_per_block} threads/block\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Global Idx':^12} | {'Block ID':^10} | {'Thread ID':^10}\")\n",
    "print(\"-\" * 50)\n",
    "for row in result:\n",
    "    print(f\"{row[0]:^12} | {row[1]:^10} | {row[2]:^10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e9050",
   "metadata": {},
   "source": [
    "## 3. Boundary Checking: When Threads > Elements\n",
    "\n",
    "What happens when array size isn't a perfect multiple of block size?\n",
    "\n",
    "```\n",
    "Array size: 10 elements\n",
    "Block size: 4 threads\n",
    "Blocks needed: ceil(10/4) = 3\n",
    "Total threads: 3 Ã— 4 = 12\n",
    "\n",
    "Thread indices: 0  1  2  3  4  5  6  7  8  9  10  11\n",
    "Array elements: âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“   âœ—   âœ—\n",
    "                                               â†‘    â†‘\n",
    "                                          Out of bounds!\n",
    "```\n",
    "\n",
    "**Always add boundary checks!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def safe_square(input_arr, output_arr, n):\n",
    "    \"\"\"Square each element with proper boundary check\"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    # CRITICAL: Boundary check\n",
    "    if idx < n:\n",
    "        output_arr[idx] = input_arr[idx] ** 2\n",
    "\n",
    "# Array that's NOT a multiple of block size\n",
    "N = 1000\n",
    "a = np.arange(N, dtype=np.float32)\n",
    "b = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "threads_per_block = 256\n",
    "blocks = math.ceil(N / threads_per_block)\n",
    "\n",
    "print(f\"Array size: {N}\")\n",
    "print(f\"Threads per block: {threads_per_block}\")\n",
    "print(f\"Blocks needed: {blocks}\")\n",
    "print(f\"Total threads: {blocks * threads_per_block}\")\n",
    "print(f\"Extra threads (idle): {blocks * threads_per_block - N}\")\n",
    "\n",
    "a_d = cuda.to_device(a)\n",
    "b_d = cuda.to_device(b)\n",
    "\n",
    "safe_square[blocks, threads_per_block](a_d, b_d, N)\n",
    "result = b_d.copy_to_host()\n",
    "\n",
    "# Verify\n",
    "expected = a ** 2\n",
    "print(f\"\\nâœ… Correct: {np.allclose(result, expected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08549608",
   "metadata": {},
   "source": [
    "## 4. Grid-Stride Loops: The Professional Pattern\n",
    "\n",
    "What if your array has **billions** of elements but you can only launch millions of threads?\n",
    "\n",
    "**Grid-stride loop**: Each thread processes multiple elements, striding by the total grid size.\n",
    "\n",
    "```\n",
    "Array: [0][1][2][3][4][5][6][7][8][9][10][11]...\n",
    "\n",
    "Grid size: 4 threads\n",
    "\n",
    "Thread 0: processes indices 0, 4, 8, 12, ...\n",
    "Thread 1: processes indices 1, 5, 9, 13, ...\n",
    "Thread 2: processes indices 2, 6, 10, 14, ...\n",
    "Thread 3: processes indices 3, 7, 11, 15, ...\n",
    "```\n",
    "\n",
    "This pattern is **essential** for production code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def grid_stride_square(input_arr, output_arr, n):\n",
    "    \"\"\"Process arbitrary-sized arrays with grid-stride loop\"\"\"\n",
    "    # Starting index for this thread\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    # Total number of threads in the grid\n",
    "    stride = cuda.gridsize(1)  # = blockDim.x * gridDim.x\n",
    "    \n",
    "    # Grid-stride loop: each thread handles multiple elements\n",
    "    while idx < n:\n",
    "        output_arr[idx] = input_arr[idx] ** 2\n",
    "        idx += stride  # Jump to next element this thread handles\n",
    "\n",
    "# Huge array with limited grid\n",
    "N = 100_000_000  # 100 million elements!\n",
    "a = np.random.randn(N).astype(np.float32)\n",
    "b = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "# Fixed, reasonable grid size\n",
    "threads_per_block = 256\n",
    "blocks = 256  # Only 256 blocks, but handles 100M elements!\n",
    "\n",
    "print(f\"Array size: {N:,}\")\n",
    "print(f\"Grid size: {blocks} blocks Ã— {threads_per_block} threads = {blocks * threads_per_block:,} threads\")\n",
    "print(f\"Elements per thread (average): {N / (blocks * threads_per_block):.1f}\")\n",
    "\n",
    "a_d = cuda.to_device(a)\n",
    "b_d = cuda.to_device(b)\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "grid_stride_square[blocks, threads_per_block](a_d, b_d, N)\n",
    "cuda.synchronize()\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "result = b_d.copy_to_host()\n",
    "print(f\"\\nâ±ï¸  Time: {elapsed*1000:.2f} ms\")\n",
    "print(f\"âœ… Correct: {np.allclose(result, a**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaca503",
   "metadata": {},
   "source": [
    "## 5. 2D Indexing: Matrices and Images\n",
    "\n",
    "For 2D data (matrices, images), we use 2D thread blocks and grids:\n",
    "\n",
    "```\n",
    "Image (Height Ã— Width):\n",
    "â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”\n",
    "â”‚0,0â”‚0,1â”‚0,2â”‚0,3â”‚0,4â”‚  Row 0\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚1,0â”‚1,1â”‚1,2â”‚1,3â”‚1,4â”‚  Row 1\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚2,0â”‚2,1â”‚2,2â”‚2,3â”‚2,4â”‚  Row 2\n",
    "â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜\n",
    "\n",
    "Thread coordinates:\n",
    "  row = blockIdx.y * blockDim.y + threadIdx.y\n",
    "  col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matrix_double_2d(matrix, rows, cols):\n",
    "    \"\"\"Double each element using 2D indexing\"\"\"\n",
    "    # Get 2D thread coordinates\n",
    "    col, row = cuda.grid(2)  # Returns (x, y) = (col, row)\n",
    "    \n",
    "    # Boundary check for both dimensions\n",
    "    if row < rows and col < cols:\n",
    "        matrix[row, col] *= 2\n",
    "\n",
    "# Create a small matrix to visualize\n",
    "rows, cols = 6, 8\n",
    "matrix = np.arange(rows * cols, dtype=np.float32).reshape(rows, cols)\n",
    "\n",
    "print(\"Original matrix:\")\n",
    "print(matrix)\n",
    "print()\n",
    "\n",
    "# 2D block configuration\n",
    "threads_per_block_2d = (4, 4)  # 4Ã—4 = 16 threads per block\n",
    "blocks_per_grid_x = math.ceil(cols / threads_per_block_2d[0])\n",
    "blocks_per_grid_y = math.ceil(rows / threads_per_block_2d[1])\n",
    "blocks_per_grid_2d = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "print(f\"Block size: {threads_per_block_2d}\")\n",
    "print(f\"Grid size: {blocks_per_grid_2d}\")\n",
    "\n",
    "matrix_d = cuda.to_device(matrix)\n",
    "matrix_double_2d[blocks_per_grid_2d, threads_per_block_2d](matrix_d, rows, cols)\n",
    "result = matrix_d.copy_to_host()\n",
    "\n",
    "print(\"\\nDoubled matrix:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f2cc0",
   "metadata": {},
   "source": [
    "## 6. Practical Example: Image Processing (Grayscale)\n",
    "\n",
    "Let's apply 2D indexing to convert an RGB image to grayscale.\n",
    "\n",
    "Grayscale formula: `Y = 0.299*R + 0.587*G + 0.114*B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def rgb_to_grayscale(rgb_image, gray_image, height, width):\n",
    "    \"\"\"Convert RGB image to grayscale using 2D indexing\"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < height and col < width:\n",
    "        # RGB channels\n",
    "        r = rgb_image[row, col, 0]\n",
    "        g = rgb_image[row, col, 1]\n",
    "        b = rgb_image[row, col, 2]\n",
    "        \n",
    "        # Weighted sum (human perception weighting)\n",
    "        gray = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "        \n",
    "        gray_image[row, col] = gray\n",
    "\n",
    "# Create a synthetic RGB image (like a gradient)\n",
    "height, width = 1080, 1920  # Full HD\n",
    "rgb_image = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8).astype(np.float32)\n",
    "\n",
    "gray_image = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "# Configure 2D grid\n",
    "threads_per_block = (16, 16)  # 256 threads per block\n",
    "blocks_x = math.ceil(width / threads_per_block[0])\n",
    "blocks_y = math.ceil(height / threads_per_block[1])\n",
    "blocks_per_grid = (blocks_x, blocks_y)\n",
    "\n",
    "print(f\"Image size: {height} Ã— {width} ({height * width:,} pixels)\")\n",
    "print(f\"Thread block: {threads_per_block}\")\n",
    "print(f\"Grid: {blocks_per_grid}\")\n",
    "print(f\"Total threads: {blocks_x * threads_per_block[0]} Ã— {blocks_y * threads_per_block[1]}\")\n",
    "\n",
    "# Run on GPU\n",
    "rgb_d = cuda.to_device(rgb_image)\n",
    "gray_d = cuda.to_device(gray_image)\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "rgb_to_grayscale[blocks_per_grid, threads_per_block](rgb_d, gray_d, height, width)\n",
    "cuda.synchronize()\n",
    "gpu_time = time.perf_counter() - start\n",
    "\n",
    "gray_result = gray_d.copy_to_host()\n",
    "\n",
    "# Compare with NumPy (CPU)\n",
    "start = time.perf_counter()\n",
    "gray_cpu = 0.299 * rgb_image[:,:,0] + 0.587 * rgb_image[:,:,1] + 0.114 * rgb_image[:,:,2]\n",
    "cpu_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\nâ±ï¸  GPU time: {gpu_time*1000:.3f} ms\")\n",
    "print(f\"â±ï¸  CPU time: {cpu_time*1000:.3f} ms\")\n",
    "print(f\"ğŸš€ Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "print(f\"âœ… Correct: {np.allclose(gray_result, gray_cpu, atol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f05a7c",
   "metadata": {},
   "source": [
    "## ğŸ¯ Exercises\n",
    "\n",
    "### Exercise 1: Manual Index Calculation\n",
    "Implement 1D indexing WITHOUT using `cuda.grid()` - calculate manually using `blockIdx`, `blockDim`, `threadIdx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 1: Manual indexing\n",
    "@cuda.jit\n",
    "def manual_index_add(a, b, c):\n",
    "    \"\"\"Add arrays using MANUAL index calculation\"\"\"\n",
    "    # TODO: Calculate global index manually\n",
    "    # idx = blockIdx.x * blockDim.x + threadIdx.x\n",
    "    idx = 0  # FIX THIS\n",
    "    \n",
    "    if idx < c.size:\n",
    "        c[idx] = a[idx] + b[idx]\n",
    "\n",
    "# Test your implementation\n",
    "# N = 1000\n",
    "# a = np.random.randn(N).astype(np.float32)\n",
    "# b = np.random.randn(N).astype(np.float32)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcfb60",
   "metadata": {},
   "source": [
    "### Exercise 2: 2D Grid-Stride Loop\n",
    "Implement a 2D grid-stride loop for processing very large images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 2: 2D Grid-Stride Loop\n",
    "@cuda.jit\n",
    "def grid_stride_2d(matrix, height, width):\n",
    "    \"\"\"Process large matrix with 2D grid-stride loop\"\"\"\n",
    "    # Starting position\n",
    "    start_col, start_row = cuda.grid(2)\n",
    "    \n",
    "    # Stride (grid size in each dimension)\n",
    "    stride_col, stride_row = cuda.gridsize(2)\n",
    "    \n",
    "    # TODO: Implement 2D grid-stride loop\n",
    "    # Hint: Use nested while loops\n",
    "    # row = start_row\n",
    "    # while row < height:\n",
    "    #     col = start_col\n",
    "    #     while col < width:\n",
    "    #         # process matrix[row, col]\n",
    "    #         col += stride_col\n",
    "    #     row += stride_row\n",
    "    pass\n",
    "\n",
    "# Test with a huge matrix\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86ad64",
   "metadata": {},
   "source": [
    "### Exercise 3: Image Negative\n",
    "Create a kernel that inverts an image (negative): `output[i,j] = 255 - input[i,j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 3: Image Negative\n",
    "@cuda.jit\n",
    "def image_negative(input_img, output_img, height, width):\n",
    "    \"\"\"Invert image: output = 255 - input\"\"\"\n",
    "    # TODO: Implement using 2D indexing\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806a8ff",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### Today You Learned:\n",
    "\n",
    "1. **1D Indexing Formula**:\n",
    "   ```\n",
    "   global_idx = blockIdx.x * blockDim.x + threadIdx.x\n",
    "   # Or simply: cuda.grid(1)\n",
    "   ```\n",
    "\n",
    "2. **2D Indexing Formula**:\n",
    "   ```\n",
    "   col, row = cuda.grid(2)\n",
    "   # Manually: \n",
    "   # row = blockIdx.y * blockDim.y + threadIdx.y\n",
    "   # col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "   ```\n",
    "\n",
    "3. **Always check boundaries**: `if idx < n:`\n",
    "\n",
    "4. **Grid-stride loops** handle any array size with fixed grid:\n",
    "   ```python\n",
    "   idx = cuda.grid(1)\n",
    "   stride = cuda.gridsize(1)\n",
    "   while idx < n:\n",
    "       # process element\n",
    "       idx += stride\n",
    "   ```\n",
    "\n",
    "5. **Common block sizes**:\n",
    "   - 1D: 256 or 512 threads\n",
    "   - 2D: (16, 16) or (32, 32) threads\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Next Up: Day 3 - Memory Fundamentals\n",
    "- cudaMalloc vs cudaMallocManaged\n",
    "- Pinned vs pageable memory\n",
    "- Memory transfer optimization\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”— Resources\n",
    "- [Thread Hierarchy - Programming Guide](../../cuda-programming-guide/01-introduction/programming-model.md)\n",
    "- [Quick Reference](../../notes/cuda-quick-reference.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
