{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666deb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "print(\"âš ï¸  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "print(\"âš ï¸  Grid-wide sync is a CUDA C++ feature requiring cooperative launch!\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814c0d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Grid-Wide Sync?\n",
    "\n",
    "### The Problem\n",
    "\n",
    "```\n",
    "Traditional CUDA - Multiple Kernel Launches:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "kernel1<<<blocks, threads>>>(data);  // Pass 1\n",
    "cudaDeviceSynchronize();              // Host overhead!\n",
    "kernel2<<<blocks, threads>>>(data);  // Pass 2\n",
    "cudaDeviceSynchronize();              // Host overhead!\n",
    "kernel3<<<blocks, threads>>>(data);  // Pass 3\n",
    "\n",
    "Problems:\n",
    "â€¢ Each launch has ~5-15Î¼s overhead\n",
    "â€¢ Data goes through L2 cache multiple times\n",
    "â€¢ Can't keep data in L1/registers between passes\n",
    "\n",
    "With Grid Sync - Single Kernel:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "__global__ void fusedKernel(data) {\n",
    "    // Pass 1\n",
    "    process1(data);\n",
    "    grid.sync();      // GPU-only sync, ~1Î¼s!\n",
    "    \n",
    "    // Pass 2\n",
    "    process2(data);\n",
    "    grid.sync();\n",
    "    \n",
    "    // Pass 3\n",
    "    process3(data);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b0c16b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Basic Grid Synchronization\n",
    "\n",
    "### ğŸ”· CUDA C++ Grid Group (Primary)\n",
    "\n",
    "Compile: `nvcc -arch=sm_75 -o grid_sync grid_sync.cu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9065b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile grid_sync.cu\n",
    "// grid_sync.cu - Basic grid-wide synchronization\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cooperative_groups.h>\n",
    "\n",
    "namespace cg = cooperative_groups;\n",
    "\n",
    "__global__ void gridSyncDemo(float* data, int n) {\n",
    "    // ============================================\n",
    "    // Get Grid Group\n",
    "    // ============================================\n",
    "    cg::grid_group grid = cg::this_grid();\n",
    "    \n",
    "    int tid = grid.thread_rank();  // Global thread index\n",
    "    int gridSize = grid.size();    // Total threads in grid\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        printf(\"Grid has %d threads\\n\", gridSize);\n",
    "    }\n",
    "    \n",
    "    // Pass 1: Multiply\n",
    "    if (tid < n) {\n",
    "        data[tid] *= 2.0f;\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Grid-Wide Synchronization\n",
    "    // ============================================\n",
    "    grid.sync();  // ALL blocks wait here!\n",
    "    \n",
    "    // Pass 2: Add (safe - all threads done with pass 1)\n",
    "    if (tid < n) {\n",
    "        data[tid] += 1.0f;\n",
    "    }\n",
    "    \n",
    "    grid.sync();  // Sync again\n",
    "    \n",
    "    // Pass 3: Sqrt\n",
    "    if (tid < n) {\n",
    "        data[tid] = sqrtf(data[tid]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    \n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_data = new float[N];\n",
    "    for (int i = 0; i < N; i++) h_data[i] = 4.0f;\n",
    "    cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // ============================================\n",
    "    // Query Maximum Blocks for Cooperative Launch\n",
    "    // ============================================\n",
    "    int device = 0;\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, device);\n",
    "    \n",
    "    int numBlocksPerSM;\n",
    "    cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "        &numBlocksPerSM, gridSyncDemo, BLOCK_SIZE, 0);\n",
    "    \n",
    "    int maxBlocks = numBlocksPerSM * prop.multiProcessorCount;\n",
    "    int numBlocks = min(maxBlocks, (N + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
    "    \n",
    "    printf(\"Using %d blocks (max %d)\\n\", numBlocks, maxBlocks);\n",
    "    \n",
    "    // ============================================\n",
    "    // Cooperative Kernel Launch\n",
    "    // ============================================\n",
    "    void* args[] = { &d_data, (void*)&N };\n",
    "    \n",
    "    cudaLaunchCooperativeKernel(\n",
    "        (void*)gridSyncDemo,\n",
    "        dim3(numBlocks),\n",
    "        dim3(BLOCK_SIZE),\n",
    "        args,\n",
    "        0,       // Shared memory\n",
    "        0        // Stream (default)\n",
    "    );\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Verify\n",
    "    cudaMemcpy(h_data, d_data, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Result[0] = %.4f (expected %.4f)\\n\", h_data[0], sqrtf(4.0f * 2.0f + 1.0f));\n",
    "    \n",
    "    delete[] h_data;\n",
    "    cudaFree(d_data);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eec0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o grid_sync grid_sync.cu\n",
    "!./grid_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5827a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Occupancy Requirements\n",
    "\n",
    "### Why Limit Grid Size?\n",
    "\n",
    "```\n",
    "Grid Sync Requirement:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "ALL blocks must be resident simultaneously!\n",
    "\n",
    "If you launch too many blocks:\n",
    "â€¢ Some blocks can't start\n",
    "â€¢ Running blocks wait at sync()\n",
    "â€¢ Waiting blocks never start\n",
    "â€¢ DEADLOCK!\n",
    "\n",
    "Solution: Query max occupancy\n",
    "\n",
    "cudaOccupancyMaxActiveBlocksPerMultiprocessor(&blocksPerSM, kernel, blockSize, sharedMem);\n",
    "maxBlocks = blocksPerSM Ã— numSMs;\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Occupancy Calculator (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile occupancy_check.cu\n",
    "// occupancy_check.cu - Calculate safe grid size\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cooperative_groups.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "namespace cg = cooperative_groups;\n",
    "\n",
    "__global__ void cooperativeKernel(float* data, int n) {\n",
    "    cg::grid_group grid = cg::this_grid();\n",
    "    // ... work ...\n",
    "    grid.sync();\n",
    "}\n",
    "\n",
    "int getMaxCooperativeBlocks(int blockSize, size_t sharedMem = 0) {\n",
    "    int device;\n",
    "    cudaGetDevice(&device);\n",
    "    \n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, device);\n",
    "    \n",
    "    // Check if cooperative launch is supported\n",
    "    if (!prop.cooperativeLaunch) {\n",
    "        printf(\"Cooperative launch not supported!\\n\");\n",
    "        return 0;\n",
    "    }\n",
    "    \n",
    "    int blocksPerSM;\n",
    "    cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "        &blocksPerSM, \n",
    "        cooperativeKernel, \n",
    "        blockSize, \n",
    "        sharedMem);\n",
    "    \n",
    "    return blocksPerSM * prop.multiProcessorCount;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Max cooperative blocks (256 threads): %d\\n\", getMaxCooperativeBlocks(256));\n",
    "    printf(\"Max cooperative blocks (512 threads): %d\\n\", getMaxCooperativeBlocks(512));\n",
    "    printf(\"Max cooperative blocks (1024 threads): %d\\n\", getMaxCooperativeBlocks(1024));\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o occupancy_check occupancy_check.cu\n",
    "!./occupancy_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7c89b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Practical Example - Multi-Pass Reduction\n",
    "\n",
    "### ğŸ”· CUDA C++ Grid Reduction (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile grid_reduction.cu\n",
    "// grid_reduction.cu - Single-kernel full reduction\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cooperative_groups.h>\n",
    "\n",
    "namespace cg = cooperative_groups;\n",
    "\n",
    "__device__ float warpReduce(cg::thread_block_tile<32>& warp, float val) {\n",
    "    for (int i = warp.size()/2; i > 0; i /= 2) {\n",
    "        val += warp.shfl_down(val, i);\n",
    "    }\n",
    "    return val;\n",
    "}\n",
    "\n",
    "__global__ void gridReduce(float* input, float* output, int n) {\n",
    "    cg::grid_group grid = cg::this_grid();\n",
    "    cg::thread_block block = cg::this_thread_block();\n",
    "    cg::thread_block_tile<32> warp = cg::tiled_partition<32>(block);\n",
    "    \n",
    "    extern __shared__ float sdata[];\n",
    "    \n",
    "    int tid = grid.thread_rank();\n",
    "    int gridSize = grid.size();\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 1: Grid-stride loop to load & reduce\n",
    "    // ============================================\n",
    "    float sum = 0.0f;\n",
    "    for (int i = tid; i < n; i += gridSize) {\n",
    "        sum += input[i];\n",
    "    }\n",
    "    \n",
    "    // Warp reduction\n",
    "    sum = warpReduce(warp, sum);\n",
    "    \n",
    "    // Store warp results to shared memory\n",
    "    int lane = warp.thread_rank();\n",
    "    int warp_id = block.thread_rank() / 32;\n",
    "    if (lane == 0) {\n",
    "        sdata[warp_id] = sum;\n",
    "    }\n",
    "    block.sync();\n",
    "    \n",
    "    // First warp reduces shared memory\n",
    "    int numWarps = (block.size() + 31) / 32;\n",
    "    sum = (block.thread_rank() < numWarps) ? sdata[block.thread_rank()] : 0.0f;\n",
    "    if (warp_id == 0) {\n",
    "        sum = warpReduce(warp, sum);\n",
    "    }\n",
    "    \n",
    "    // Block leader writes to global array\n",
    "    if (block.thread_rank() == 0) {\n",
    "        output[blockIdx.x] = sum;\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Grid Sync - Wait for all blocks\n",
    "    // ============================================\n",
    "    grid.sync();\n",
    "    \n",
    "    // ============================================\n",
    "    // Phase 2: Final reduction (first block only)\n",
    "    // ============================================\n",
    "    if (blockIdx.x == 0) {\n",
    "        int numBlocks = gridDim.x;\n",
    "        sum = 0.0f;\n",
    "        \n",
    "        // Each thread sums subset of block results\n",
    "        for (int i = block.thread_rank(); i < numBlocks; i += block.size()) {\n",
    "            sum += output[i];\n",
    "        }\n",
    "        \n",
    "        // Reduce within block\n",
    "        sum = warpReduce(warp, sum);\n",
    "        if (lane == 0) sdata[warp_id] = sum;\n",
    "        block.sync();\n",
    "        \n",
    "        sum = (block.thread_rank() < numWarps) ? sdata[block.thread_rank()] : 0.0f;\n",
    "        if (warp_id == 0) sum = warpReduce(warp, sum);\n",
    "        \n",
    "        // Final result\n",
    "        if (block.thread_rank() == 0) {\n",
    "            output[0] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 24;  // 16M elements\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    \n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, N * sizeof(float));\n",
    "    cudaMalloc(&d_output, 1024 * sizeof(float));  // Workspace\n",
    "    \n",
    "    // Initialize with 1s\n",
    "    float* h_input = new float[N];\n",
    "    for (int i = 0; i < N; i++) h_input[i] = 1.0f;\n",
    "    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Get max blocks\n",
    "    int device;\n",
    "    cudaGetDevice(&device);\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, device);\n",
    "    \n",
    "    int blocksPerSM;\n",
    "    cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "        &blocksPerSM, gridReduce, BLOCK_SIZE, 32 * sizeof(float));\n",
    "    int numBlocks = blocksPerSM * prop.multiProcessorCount;\n",
    "    \n",
    "    printf(\"Launching %d blocks\\n\", numBlocks);\n",
    "    \n",
    "    // Launch\n",
    "    void* args[] = { &d_input, &d_output, (void*)&N };\n",
    "    cudaLaunchCooperativeKernel(\n",
    "        (void*)gridReduce,\n",
    "        dim3(numBlocks),\n",
    "        dim3(BLOCK_SIZE),\n",
    "        args,\n",
    "        32 * sizeof(float),\n",
    "        0);\n",
    "    \n",
    "    float result;\n",
    "    cudaMemcpy(&result, d_output, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"Sum = %.0f (expected %d)\\n\", result, N);\n",
    "    \n",
    "    delete[] h_input;\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a37f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o grid_reduction grid_reduction.cu\n",
    "!./grid_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5da89",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile grid_sync_exercises.cu\n",
    "/*\n",
    " * Grid-Wide Synchronization Exercises\n",
    " * Exercise 1: Grid Prefix Sum - Blelloch scan with grid sync\n",
    " * Exercise 2: Iterative Solver - Jacobi iteration with grid sync\n",
    " * Exercise 3: Histogram with Grid Sync - Global histogram in single kernel\n",
    " */\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cooperative_groups.h>\n",
    "#include <stdio.h>\n",
    "#include <cmath>\n",
    "\n",
    "namespace cg = cooperative_groups;\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA error at %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
    "                   cudaGetErrorString(err)); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// =============================================================\n",
    "// Exercise 1: Grid Prefix Sum (Inclusive Scan)\n",
    "// Multi-phase scan using grid synchronization\n",
    "// =============================================================\n",
    "__global__ void gridPrefixSumKernel(int* data, int* blockSums, int n) {\n",
    "    cg::grid_group grid = cg::this_grid();\n",
    "    cg::thread_block block = cg::this_thread_block();\n",
    "    \n",
    "    extern __shared__ int sdata[];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Phase 1: Load data into shared memory\n",
    "    sdata[tid] = (globalIdx < n) ? data[globalIdx] : 0;\n",
    "    block.sync();\n",
    "    \n",
    "    // Phase 2: Block-level inclusive scan (Hillis-Steele)\n",
    "    for (int stride = 1; stride < blockDim.x; stride *= 2) {\n",
    "        int temp = 0;\n",
    "        if (tid >= stride) {\n",
    "            temp = sdata[tid - stride];\n",
    "        }\n",
    "        block.sync();\n",
    "        sdata[tid] += temp;\n",
    "        block.sync();\n",
    "    }\n",
    "    \n",
    "    // Store block sum (last element of each block's scan)\n",
    "    if (tid == blockDim.x - 1) {\n",
    "        blockSums[blockIdx.x] = sdata[tid];\n",
    "    }\n",
    "    \n",
    "    // Write partial results\n",
    "    if (globalIdx < n) {\n",
    "        data[globalIdx] = sdata[tid];\n",
    "    }\n",
    "    \n",
    "    // Grid sync: wait for all blocks to finish Phase 2\n",
    "    grid.sync();\n",
    "    \n",
    "    // Phase 3: Scan the block sums (only block 0 does this)\n",
    "    if (blockIdx.x == 0) {\n",
    "        // Load block sums into shared memory\n",
    "        if (tid < gridDim.x) {\n",
    "            sdata[tid] = blockSums[tid];\n",
    "        } else {\n",
    "            sdata[tid] = 0;\n",
    "        }\n",
    "        block.sync();\n",
    "        \n",
    "        // Scan block sums\n",
    "        for (int stride = 1; stride < gridDim.x; stride *= 2) {\n",
    "            int temp = 0;\n",
    "            if (tid >= stride && tid < gridDim.x) {\n",
    "                temp = sdata[tid - stride];\n",
    "            }\n",
    "            block.sync();\n",
    "            if (tid < gridDim.x) sdata[tid] += temp;\n",
    "            block.sync();\n",
    "        }\n",
    "        \n",
    "        // Store scanned block sums\n",
    "        if (tid < gridDim.x) {\n",
    "            blockSums[tid] = sdata[tid];\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Grid sync: wait for block sums to be scanned\n",
    "    grid.sync();\n",
    "    \n",
    "    // Phase 4: Add scanned block sums to elements\n",
    "    if (blockIdx.x > 0 && globalIdx < n) {\n",
    "        data[globalIdx] += blockSums[blockIdx.x - 1];\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise1_grid_prefix_sum() {\n",
    "    printf(\"\\n=== Exercise 1: Grid Prefix Sum ===\\n\");\n",
    "    \n",
    "    // Check for cooperative launch support\n",
    "    int device;\n",
    "    cudaDeviceProp prop;\n",
    "    CHECK_CUDA(cudaGetDevice(&device));\n",
    "    CHECK_CUDA(cudaGetDeviceProperties(&prop, device));\n",
    "    \n",
    "    if (!prop.cooperativeLaunch) {\n",
    "        printf(\"Device does not support cooperative launch. Skipping.\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    const int BLOCK_SIZE = 256;\n",
    "    const int N = BLOCK_SIZE * 4;  // 4 blocks worth\n",
    "    \n",
    "    int *h_data = new int[N];\n",
    "    int *h_result = new int[N];\n",
    "    int *h_expected = new int[N];\n",
    "    int *d_data, *d_blockSums;\n",
    "    \n",
    "    // Initialize: all ones (prefix sum should give 1, 2, 3, ...)\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_data[i] = 1;\n",
    "    }\n",
    "    \n",
    "    // Compute expected result\n",
    "    h_expected[0] = h_data[0];\n",
    "    for (int i = 1; i < N; i++) {\n",
    "        h_expected[i] = h_expected[i-1] + h_data[i];\n",
    "    }\n",
    "    \n",
    "    int numBlocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    CHECK_CUDA(cudaMalloc(&d_data, N * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_blockSums, numBlocks * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_data, h_data, N * sizeof(int), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // Launch cooperative kernel\n",
    "    void* kernelArgs[] = { &d_data, &d_blockSums, (void*)&N };\n",
    "    size_t sharedMem = BLOCK_SIZE * sizeof(int);\n",
    "    \n",
    "    CHECK_CUDA(cudaLaunchCooperativeKernel(\n",
    "        (void*)gridPrefixSumKernel,\n",
    "        dim3(numBlocks), dim3(BLOCK_SIZE),\n",
    "        kernelArgs, sharedMem, 0\n",
    "    ));\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(h_result, d_data, N * sizeof(int), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    // Verify\n",
    "    printf(\"Array size: %d, Blocks: %d\\n\", N, numBlocks);\n",
    "    printf(\"\\nSample results (every 64th element):\\n\");\n",
    "    printf(\"%-8s %-10s %-10s\\n\", \"Index\", \"Result\", \"Expected\");\n",
    "    \n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < N; i += 64) {\n",
    "        printf(\"%-8d %-10d %-10d\\n\", i, h_result[i], h_expected[i]);\n",
    "        if (h_result[i] != h_expected[i]) correct = false;\n",
    "    }\n",
    "    \n",
    "    // Also check boundaries\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        if (h_result[i] != h_expected[i]) correct = false;\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nVerification: %s\\n\", correct ? \"PASSED âœ“\" : \"FAILED âœ—\");\n",
    "    \n",
    "    delete[] h_data;\n",
    "    delete[] h_result;\n",
    "    delete[] h_expected;\n",
    "    CHECK_CUDA(cudaFree(d_data));\n",
    "    CHECK_CUDA(cudaFree(d_blockSums));\n",
    "}\n",
    "\n",
    "// =============================================================\n",
    "// Exercise 2: Jacobi Iteration with Grid Sync\n",
    "// Iterative solver that alternates between arrays\n",
    "// =============================================================\n",
    "__global__ void jacobiIterationKernel(float* u, float* u_new, float* errors, \n",
    "                                       int n, int numIterations) {\n",
    "    cg::grid_group grid = cg::this_grid();\n",
    "    \n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Pointers for double-buffering\n",
    "    float* src = u;\n",
    "    float* dst = u_new;\n",
    "    \n",
    "    for (int iter = 0; iter < numIterations; iter++) {\n",
    "        // Update interior points: u_new[i] = 0.5 * (u[i-1] + u[i+1])\n",
    "        if (idx > 0 && idx < n - 1) {\n",
    "            dst[idx] = 0.5f * (src[idx - 1] + src[idx + 1]);\n",
    "        } else if (idx == 0 || idx == n - 1) {\n",
    "            dst[idx] = src[idx];  // Boundary conditions\n",
    "        }\n",
    "        \n",
    "        // Grid sync before computing errors\n",
    "        grid.sync();\n",
    "        \n",
    "        // Compute local error\n",
    "        if (idx < n) {\n",
    "            errors[idx] = fabsf(dst[idx] - src[idx]);\n",
    "        }\n",
    "        \n",
    "        // Grid sync before next iteration\n",
    "        grid.sync();\n",
    "        \n",
    "        // Swap buffers\n",
    "        float* temp = src;\n",
    "        src = dst;\n",
    "        dst = temp;\n",
    "    }\n",
    "    \n",
    "    // Copy final result to u if needed\n",
    "    if (numIterations % 2 == 1 && idx < n) {\n",
    "        u[idx] = u_new[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise2_jacobi_iteration() {\n",
    "    printf(\"\\n=== Exercise 2: Jacobi Iteration ===\\n\");\n",
    "    \n",
    "    int device;\n",
    "    cudaDeviceProp prop;\n",
    "    CHECK_CUDA(cudaGetDevice(&device));\n",
    "    CHECK_CUDA(cudaGetDeviceProperties(&prop, device));\n",
    "    \n",
    "    if (!prop.cooperativeLaunch) {\n",
    "        printf(\"Device does not support cooperative launch. Skipping.\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    const int N = 256;\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    const int NUM_ITERATIONS = 100;\n",
    "    \n",
    "    float *h_u = new float[N];\n",
    "    float *h_result = new float[N];\n",
    "    float *d_u, *d_u_new, *d_errors;\n",
    "    \n",
    "    // Initialize: step function (boundary value problem)\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        if (i < N / 2) {\n",
    "            h_u[i] = 0.0f;\n",
    "        } else {\n",
    "            h_u[i] = 1.0f;\n",
    "        }\n",
    "    }\n",
    "    h_u[0] = 0.0f;      // Left boundary\n",
    "    h_u[N-1] = 1.0f;    // Right boundary\n",
    "    \n",
    "    printf(\"Solving 1D Laplace equation with Jacobi iteration\\n\");\n",
    "    printf(\"Domain size: %d, Iterations: %d\\n\", N, NUM_ITERATIONS);\n",
    "    \n",
    "    CHECK_CUDA(cudaMalloc(&d_u, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_u_new, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_errors, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_u, h_u, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemcpy(d_u_new, h_u, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    int numBlocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    // Launch cooperative kernel\n",
    "    void* kernelArgs[] = { &d_u, &d_u_new, &d_errors, (void*)&N, (void*)&NUM_ITERATIONS };\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CHECK_CUDA(cudaEventCreate(&start));\n",
    "    CHECK_CUDA(cudaEventCreate(&stop));\n",
    "    \n",
    "    CHECK_CUDA(cudaEventRecord(start));\n",
    "    CHECK_CUDA(cudaLaunchCooperativeKernel(\n",
    "        (void*)jacobiIterationKernel,\n",
    "        dim3(numBlocks), dim3(BLOCK_SIZE),\n",
    "        kernelArgs, 0, 0\n",
    "    ));\n",
    "    CHECK_CUDA(cudaEventRecord(stop));\n",
    "    CHECK_CUDA(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float gpuTime;\n",
    "    CHECK_CUDA(cudaEventElapsedTime(&gpuTime, start, stop));\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(h_result, d_u, N * sizeof(float), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    // Expected: linear interpolation from 0 to 1\n",
    "    printf(\"\\nSolution (sampled at 8 points):\\n\");\n",
    "    printf(\"%-8s %-12s %-12s\\n\", \"Index\", \"Computed\", \"Analytical\");\n",
    "    for (int i = 0; i < N; i += N/8) {\n",
    "        float analytical = (float)i / (N - 1);\n",
    "        printf(\"%-8d %-12.4f %-12.4f\\n\", i, h_result[i], analytical);\n",
    "    }\n",
    "    \n",
    "    // Check convergence to analytical solution\n",
    "    float maxError = 0.0f;\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        float analytical = (float)i / (N - 1);\n",
    "        float error = fabsf(h_result[i] - analytical);\n",
    "        maxError = fmaxf(maxError, error);\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nMax error from analytical solution: %.6f\\n\", maxError);\n",
    "    printf(\"GPU time: %.3f ms (%.1f iterations/ms)\\n\", gpuTime, NUM_ITERATIONS / gpuTime);\n",
    "    printf(\"Verification: %s\\n\", maxError < 0.01f ? \"PASSED âœ“\" : \"FAILED âœ—\");\n",
    "    \n",
    "    delete[] h_u;\n",
    "    delete[] h_result;\n",
    "    CHECK_CUDA(cudaEventDestroy(start));\n",
    "    CHECK_CUDA(cudaEventDestroy(stop));\n",
    "    CHECK_CUDA(cudaFree(d_u));\n",
    "    CHECK_CUDA(cudaFree(d_u_new));\n",
    "    CHECK_CUDA(cudaFree(d_errors));\n",
    "}\n",
    "\n",
    "// =============================================================\n",
    "// Exercise 3: Histogram with Grid Sync\n",
    "// Build global histogram in a single kernel using grid sync\n",
    "// =============================================================\n",
    "#define NUM_BINS 256\n",
    "\n",
    "__global__ void gridHistogramKernel(unsigned char* data, int* histogram, \n",
    "                                     int* blockHistograms, int n) {\n",
    "    cg::grid_group grid = cg::this_grid();\n",
    "    cg::thread_block block = cg::this_thread_block();\n",
    "    \n",
    "    // Each block has its own shared histogram\n",
    "    __shared__ int sharedHist[NUM_BINS];\n",
    "    \n",
    "    // Initialize shared histogram\n",
    "    for (int i = threadIdx.x; i < NUM_BINS; i += blockDim.x) {\n",
    "        sharedHist[i] = 0;\n",
    "    }\n",
    "    block.sync();\n",
    "    \n",
    "    // Phase 1: Compute block-local histograms\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    for (int i = idx; i < n; i += blockDim.x * gridDim.x) {\n",
    "        atomicAdd(&sharedHist[data[i]], 1);\n",
    "    }\n",
    "    block.sync();\n",
    "    \n",
    "    // Store block histogram to global memory\n",
    "    for (int i = threadIdx.x; i < NUM_BINS; i += blockDim.x) {\n",
    "        blockHistograms[blockIdx.x * NUM_BINS + i] = sharedHist[i];\n",
    "    }\n",
    "    \n",
    "    // Grid sync: wait for all block histograms\n",
    "    grid.sync();\n",
    "    \n",
    "    // Phase 2: Reduce block histograms to global histogram\n",
    "    // Each thread handles one or more bins\n",
    "    for (int bin = threadIdx.x + blockIdx.x * blockDim.x; \n",
    "         bin < NUM_BINS; \n",
    "         bin += blockDim.x * gridDim.x) {\n",
    "        \n",
    "        int sum = 0;\n",
    "        for (int b = 0; b < gridDim.x; b++) {\n",
    "            sum += blockHistograms[b * NUM_BINS + bin];\n",
    "        }\n",
    "        histogram[bin] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise3_histogram_grid_sync() {\n",
    "    printf(\"\\n=== Exercise 3: Histogram with Grid Sync ===\\n\");\n",
    "    \n",
    "    int device;\n",
    "    cudaDeviceProp prop;\n",
    "    CHECK_CUDA(cudaGetDevice(&device));\n",
    "    CHECK_CUDA(cudaGetDeviceProperties(&prop, device));\n",
    "    \n",
    "    if (!prop.cooperativeLaunch) {\n",
    "        printf(\"Device does not support cooperative launch. Skipping.\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    const int N = 1024 * 1024;\n",
    "    const int BLOCK_SIZE = 256;\n",
    "    \n",
    "    unsigned char *h_data = new unsigned char[N];\n",
    "    int *h_histogram = new int[NUM_BINS];\n",
    "    int *h_reference = new int[NUM_BINS];\n",
    "    \n",
    "    unsigned char *d_data;\n",
    "    int *d_histogram, *d_blockHistograms;\n",
    "    \n",
    "    // Initialize with random data\n",
    "    srand(42);\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_data[i] = rand() % 256;\n",
    "    }\n",
    "    \n",
    "    // CPU reference\n",
    "    memset(h_reference, 0, NUM_BINS * sizeof(int));\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_reference[h_data[i]]++;\n",
    "    }\n",
    "    \n",
    "    // Determine launch configuration\n",
    "    int numBlocksPerSM;\n",
    "    CHECK_CUDA(cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "        &numBlocksPerSM, gridHistogramKernel, BLOCK_SIZE, 0));\n",
    "    int numBlocks = prop.multiProcessorCount * numBlocksPerSM;\n",
    "    \n",
    "    printf(\"Data size: %d elements\\n\", N);\n",
    "    printf(\"Using %d blocks (%d blocks/SM Ã— %d SMs)\\n\", \n",
    "           numBlocks, numBlocksPerSM, prop.multiProcessorCount);\n",
    "    \n",
    "    CHECK_CUDA(cudaMalloc(&d_data, N * sizeof(unsigned char)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_histogram, NUM_BINS * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_blockHistograms, numBlocks * NUM_BINS * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_data, h_data, N, cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // Launch cooperative kernel\n",
    "    void* kernelArgs[] = { &d_data, &d_histogram, &d_blockHistograms, (void*)&N };\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CHECK_CUDA(cudaEventCreate(&start));\n",
    "    CHECK_CUDA(cudaEventCreate(&stop));\n",
    "    \n",
    "    CHECK_CUDA(cudaEventRecord(start));\n",
    "    CHECK_CUDA(cudaLaunchCooperativeKernel(\n",
    "        (void*)gridHistogramKernel,\n",
    "        dim3(numBlocks), dim3(BLOCK_SIZE),\n",
    "        kernelArgs, 0, 0\n",
    "    ));\n",
    "    CHECK_CUDA(cudaEventRecord(stop));\n",
    "    CHECK_CUDA(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float gpuTime;\n",
    "    CHECK_CUDA(cudaEventElapsedTime(&gpuTime, start, stop));\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(h_histogram, d_histogram, NUM_BINS * sizeof(int), \n",
    "                          cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    // Verify\n",
    "    bool correct = true;\n",
    "    int totalCount = 0;\n",
    "    for (int i = 0; i < NUM_BINS; i++) {\n",
    "        if (h_histogram[i] != h_reference[i]) {\n",
    "            correct = false;\n",
    "            printf(\"Mismatch at bin %d: got %d, expected %d\\n\", \n",
    "                   i, h_histogram[i], h_reference[i]);\n",
    "        }\n",
    "        totalCount += h_histogram[i];\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nHistogram statistics:\\n\");\n",
    "    printf(\"  Total elements counted: %d (expected %d)\\n\", totalCount, N);\n",
    "    printf(\"  Non-zero bins: \");\n",
    "    int nonZeroBins = 0;\n",
    "    for (int i = 0; i < NUM_BINS; i++) {\n",
    "        if (h_histogram[i] > 0) nonZeroBins++;\n",
    "    }\n",
    "    printf(\"%d\\n\", nonZeroBins);\n",
    "    \n",
    "    printf(\"\\nGPU time: %.3f ms\\n\", gpuTime);\n",
    "    printf(\"Throughput: %.2f GB/s\\n\", (N / 1e9) / (gpuTime / 1000.0));\n",
    "    printf(\"Verification: %s\\n\", correct ? \"PASSED âœ“\" : \"FAILED âœ—\");\n",
    "    \n",
    "    delete[] h_data;\n",
    "    delete[] h_histogram;\n",
    "    delete[] h_reference;\n",
    "    CHECK_CUDA(cudaEventDestroy(start));\n",
    "    CHECK_CUDA(cudaEventDestroy(stop));\n",
    "    CHECK_CUDA(cudaFree(d_data));\n",
    "    CHECK_CUDA(cudaFree(d_histogram));\n",
    "    CHECK_CUDA(cudaFree(d_blockHistograms));\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Grid-Wide Synchronization Exercises\\n\");\n",
    "    printf(\"====================================\\n\");\n",
    "    \n",
    "    int device;\n",
    "    cudaDeviceProp prop;\n",
    "    CHECK_CUDA(cudaGetDevice(&device));\n",
    "    CHECK_CUDA(cudaGetDeviceProperties(&prop, device));\n",
    "    printf(\"Device: %s (Compute %d.%d)\\n\", prop.name, prop.major, prop.minor);\n",
    "    printf(\"Cooperative launch support: %s\\n\", \n",
    "           prop.cooperativeLaunch ? \"Yes\" : \"No\");\n",
    "    \n",
    "    exercise1_grid_prefix_sum();\n",
    "    exercise2_jacobi_iteration();\n",
    "    exercise3_histogram_grid_sync();\n",
    "    \n",
    "    printf(\"\\nâœ“ All exercises completed!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a423336",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -rdc=true -o grid_sync_exercises grid_sync_exercises.cu -lcudadevrt && ./grid_sync_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab528cc",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "### Exercise 1: Grid Prefix Sum\n",
    "Implement Blelloch scan using grid sync for multiple phases.\n",
    "\n",
    "### Exercise 2: Iterative Solver\n",
    "Implement Jacobi iteration with grid sync between iterations.\n",
    "\n",
    "### Exercise 3: Histogram with Grid Sync\n",
    "Build a global histogram in a single kernel using grid sync."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5276da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           GRID-WIDE SYNCHRONIZATION                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Get Grid Group:                                        â”‚\n",
    "â”‚  cg::grid_group grid = cg::this_grid();                 â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Synchronize:                                           â”‚\n",
    "â”‚  grid.sync();  // All blocks wait here                  â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Launch Requirements:                                   â”‚\n",
    "â”‚  â€¢ Use cudaLaunchCooperativeKernel()                    â”‚\n",
    "â”‚  â€¢ Limit blocks to max occupancy                        â”‚\n",
    "â”‚  â€¢ Check prop.cooperativeLaunch                         â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Benefits:                                              â”‚\n",
    "â”‚  â€¢ Eliminate kernel launch overhead                     â”‚\n",
    "â”‚  â€¢ Keep data in cache between phases                    â”‚\n",
    "â”‚  â€¢ Single kernel for multi-pass algorithms              â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Limitations:                                           â”‚\n",
    "â”‚  â€¢ Grid size limited by occupancy                       â”‚\n",
    "â”‚  â€¢ Requires compute capability 3.5+                     â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Next: Day 3 - Dynamic Parallelism Basics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
