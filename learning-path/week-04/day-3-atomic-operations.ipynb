{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c9346d",
   "metadata": {},
   "source": [
    "# üöÄ Day 3: Atomic Operations\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapati3/cuda-lab/blob/main/learning-path/week-04/day-3-atomic-operations.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand race conditions and why atomics are needed\n",
    "- Use atomic add, max, min, CAS operations\n",
    "- Apply atomics to counting and reduction problems\n",
    "- Understand privatization for reducing atomic contention\n",
    "\n",
    "> **Primary Focus:** CUDA C++ code examples first, Python/Numba backup for interactive testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Colab/Local Setup - Run this first!\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"üîß Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"‚úÖ Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"üíª Running locally - make sure you have: pip install numba numpy\")\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(f\"\\nCUDA available: {cuda.is_available()}\")\n",
    "if cuda.is_available():\n",
    "    device = cuda.get_current_device()\n",
    "    print(f\"Device: {device.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3b6a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Race Condition Problem\n",
    "\n",
    "### What Goes Wrong Without Atomics?\n",
    "\n",
    "```\n",
    "Thread A reads counter (0)\n",
    "Thread B reads counter (0)     ‚Üê Same old value!\n",
    "Thread A writes counter+1 (1)\n",
    "Thread B writes counter+1 (1)  ‚Üê Overwrites A's work!\n",
    "\n",
    "Expected: 2, Actual: 1 ‚Üê DATA RACE!\n",
    "```\n",
    "\n",
    "### CUDA C++ Atomic Operations (Primary)\n",
    "\n",
    "The following CUDA C++ implementation demonstrates atomic operations for thread-safe memory updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile atomic_ops.cu\n",
    "// atomic_ops.cu - Thread-safe operations\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// BAD: Race condition!\n",
    "__global__ void raceCondition(int* counter) {\n",
    "    // Multiple threads read-modify-write simultaneously\n",
    "    counter[0] = counter[0] + 1;  // NOT SAFE!\n",
    "}\n",
    "\n",
    "// GOOD: Using atomicAdd\n",
    "__global__ void safeIncrement(int* counter, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        atomicAdd(counter, 1);  // Thread-safe!\n",
    "    }\n",
    "}\n",
    "\n",
    "// Common atomic operations:\n",
    "__global__ void atomicExamples(int* arr, float* farr) {\n",
    "    // Integer atomics\n",
    "    atomicAdd(&arr[0], 1);        // arr[0] += 1\n",
    "    atomicSub(&arr[1], 1);        // arr[1] -= 1\n",
    "    atomicMax(&arr[2], 100);      // arr[2] = max(arr[2], 100)\n",
    "    atomicMin(&arr[3], 0);        // arr[3] = min(arr[3], 0)\n",
    "    atomicExch(&arr[4], 42);      // arr[4] = 42, returns old value\n",
    "    atomicCAS(&arr[5], 0, 1);     // if (arr[5] == 0) arr[5] = 1\n",
    "    \n",
    "    // Floating-point atomics\n",
    "    atomicAdd(&farr[0], 1.0f);    // farr[0] += 1.0\n",
    "    // Note: atomicMax/Min for floats requires CUDA 11+\n",
    "}\n",
    "\n",
    "// Reduce with atomics (simple but slow)\n",
    "__global__ void atomicSum(const float* input, float* result, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    \n",
    "    float localSum = 0.0f;\n",
    "    for (int i = tid; i < n; i += stride) {\n",
    "        localSum += input[i];\n",
    "    }\n",
    "    \n",
    "    // One atomic per thread is MUCH better than one per element\n",
    "    atomicAdd(result, localSum);\n",
    "}\n",
    "\n",
    "// Privatization: reduce contention with per-block counters\n",
    "__global__ void countWithPrivatization(const int* data, int* blockCounts, int n) {\n",
    "    __shared__ int localCount;\n",
    "    \n",
    "    if (threadIdx.x == 0) {\n",
    "        localCount = 0;\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    \n",
    "    for (int i = tid; i < n; i += stride) {\n",
    "        if (data[i] > 0) {\n",
    "            atomicAdd(&localCount, 1);  // Shared memory atomic (fast)\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    if (threadIdx.x == 0) {\n",
    "        atomicAdd(&blockCounts[blockIdx.x], localCount);  // Global atomic once\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n = 1000;\n",
    "    int *d_counter;\n",
    "    cudaMalloc(&d_counter, sizeof(int));\n",
    "    cudaMemset(d_counter, 0, sizeof(int));\n",
    "    \n",
    "    safeIncrement<<<4, 256>>>(d_counter, n);\n",
    "    \n",
    "    int result;\n",
    "    cudaMemcpy(&result, d_counter, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Counter after %d increments: %d\\n\", n, result);\n",
    "    \n",
    "    cudaFree(d_counter);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o atomic_ops atomic_ops.cu\n",
    "!./atomic_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python demonstration of race condition\n",
    "@cuda.jit\n",
    "def race_condition_demo(counter):\n",
    "    \"\"\"\n",
    "    BAD: Multiple threads increment counter without protection.\n",
    "    \"\"\"\n",
    "    counter[0] = counter[0] + 1  # NOT ATOMIC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the race condition\n",
    "def test_race_condition(num_threads):\n",
    "    counter = np.zeros(1, dtype=np.int32)\n",
    "    d_counter = cuda.to_device(counter)\n",
    "    \n",
    "    threads_per_block = min(256, num_threads)\n",
    "    blocks = (num_threads + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    race_condition_demo[blocks, threads_per_block](d_counter)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    result = d_counter.copy_to_host()[0]\n",
    "    return result\n",
    "\n",
    "print(\"Race Condition Demo\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Threads':>10} | {'Expected':>10} | {'Actual':>10} | {'Lost':>10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for n in [100, 1000, 10000, 100000]:\n",
    "    actual = test_race_condition(n)\n",
    "    lost = n - actual\n",
    "    print(f\"{n:>10,} | {n:>10,} | {actual:>10,} | {lost:>10,}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Notice: Most increments are LOST due to race conditions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f34cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Atomic Operations\n",
    "\n",
    "### The Solution: Atomic Operations\n",
    "\n",
    "```\n",
    "Atomic = Indivisible\n",
    "\n",
    "Read-Modify-Write happens as ONE operation:\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ 1. Read old value      ‚îÇ\n",
    "‚îÇ 2. Compute new value   ‚îÇ  ‚Üê All protected!\n",
    "‚îÇ 3. Write new value     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Other threads must WAIT until this completes.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def atomic_increment(counter):\n",
    "    \"\"\"CORRECT: Use atomic operation for thread-safe increment.\"\"\"\n",
    "    cuda.atomic.add(counter, 0, 1)  # Atomically: counter[0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c102db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_atomic_increment(num_threads):\n",
    "    counter = np.zeros(1, dtype=np.int32)\n",
    "    d_counter = cuda.to_device(counter)\n",
    "    \n",
    "    threads_per_block = min(256, num_threads)\n",
    "    blocks = (num_threads + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    atomic_increment[blocks, threads_per_block](d_counter)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    return d_counter.copy_to_host()[0]\n",
    "\n",
    "print(\"Atomic Increment Demo\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Threads':>10} | {'Expected':>10} | {'Actual':>10} | {'Match':>10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for n in [100, 1000, 10000, 100000]:\n",
    "    actual = test_atomic_increment(n)\n",
    "    match = \"‚úì\" if actual == n else \"‚úó\"\n",
    "    print(f\"{n:>10,} | {n:>10,} | {actual:>10,} | {match:>10}\")\n",
    "\n",
    "print(\"\\n‚úì All increments are now counted correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7affc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Available Atomic Operations\n",
    "\n",
    "### Numba CUDA Atomic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available atomic operations in Numba CUDA:\n",
    "#\n",
    "# cuda.atomic.add(array, index, value)     # array[index] += value\n",
    "# cuda.atomic.max(array, index, value)     # array[index] = max(array[index], value)\n",
    "# cuda.atomic.min(array, index, value)     # array[index] = min(array[index], value)\n",
    "# cuda.atomic.compare_and_swap(array, old, val)  # CAS operation\n",
    "#\n",
    "# All return the OLD value before the operation\n",
    "\n",
    "@cuda.jit\n",
    "def demo_atomic_add(arr, values, result, n):\n",
    "    \"\"\"Sum values using atomic add.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.add(result, 0, values[tid])\n",
    "\n",
    "@cuda.jit\n",
    "def demo_atomic_max(arr, result, n):\n",
    "    \"\"\"Find maximum using atomic max.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.max(result, 0, arr[tid])\n",
    "\n",
    "@cuda.jit\n",
    "def demo_atomic_min(arr, result, n):\n",
    "    \"\"\"Find minimum using atomic min.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.min(result, 0, arr[tid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test atomic operations\n",
    "n = 10000\n",
    "arr = np.random.randint(1, 1000, n).astype(np.int32)\n",
    "\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "# Atomic add (sum)\n",
    "d_sum = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "demo_atomic_add[40, 256](d_arr, d_arr, d_sum, n)\n",
    "gpu_sum = d_sum.copy_to_host()[0]\n",
    "\n",
    "# Atomic max\n",
    "d_max = cuda.to_device(np.array([np.iinfo(np.int32).min], dtype=np.int32))\n",
    "demo_atomic_max[40, 256](d_arr, d_max, n)\n",
    "gpu_max = d_max.copy_to_host()[0]\n",
    "\n",
    "# Atomic min\n",
    "d_min = cuda.to_device(np.array([np.iinfo(np.int32).max], dtype=np.int32))\n",
    "demo_atomic_min[40, 256](d_arr, d_min, n)\n",
    "gpu_min = d_min.copy_to_host()[0]\n",
    "\n",
    "print(f\"Array: {n:,} random integers [1, 1000)\")\n",
    "print(f\"\\nAtomic Sum: {gpu_sum:,} (CPU: {np.sum(arr):,})\")\n",
    "print(f\"Atomic Max: {gpu_max} (CPU: {np.max(arr)})\")\n",
    "print(f\"Atomic Min: {gpu_min} (CPU: {np.min(arr)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641497a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Atomics Performance Problem\n",
    "\n",
    "### Atomic Contention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bde3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atomics are SLOW when many threads compete for same location!\n",
    "\n",
    "@cuda.jit\n",
    "def high_contention_atomic(result, n):\n",
    "    \"\"\"All threads atomically add to ONE location.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.add(result, 0, 1)  # Everyone fights for index 0!\n",
    "\n",
    "@cuda.jit\n",
    "def low_contention_atomic(result, n):\n",
    "    \"\"\"Threads spread across MULTIPLE locations.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        # Spread across 256 locations\n",
    "        bin_idx = tid % 256\n",
    "        cuda.atomic.add(result, bin_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark contention\n",
    "n = 1_000_000\n",
    "iterations = 100\n",
    "\n",
    "# High contention (1 location)\n",
    "d_result1 = cuda.device_array(1, dtype=np.int32)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result1 = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "    high_contention_atomic[4000, 256](d_result1, n)\n",
    "cuda.synchronize()\n",
    "high_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "# Low contention (256 locations)\n",
    "d_result256 = cuda.device_array(256, dtype=np.int32)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result256 = cuda.to_device(np.zeros(256, dtype=np.int32))\n",
    "    low_contention_atomic[4000, 256](d_result256, n)\n",
    "cuda.synchronize()\n",
    "low_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "print(f\"Atomic Contention Benchmark (N={n:,})\")\n",
    "print(f\"{'='*45}\")\n",
    "print(f\"High contention (1 loc):   {high_time:.3f} ms\")\n",
    "print(f\"Low contention (256 locs): {low_time:.3f} ms\")\n",
    "print(f\"Speedup:                   {high_time/low_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf5838",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Privatization Pattern\n",
    "\n",
    "### Reducing Contention with Local Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fcd9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def privatized_sum(arr, result, n):\n",
    "    \"\"\"\n",
    "    Privatization: Each block has its own accumulator in shared memory.\n",
    "    \n",
    "    1. Local accumulation in shared memory (no atomic)\n",
    "    2. Block-level reduction (no atomic)\n",
    "    3. Single atomic per block to global\n",
    "    \"\"\"\n",
    "    # Shared memory for block's local sum\n",
    "    shared = cuda.shared.array(256, dtype=np.float32)\n",
    "    \n",
    "    tid = cuda.threadIdx.x\n",
    "    bid = cuda.blockIdx.x\n",
    "    gid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    # Phase 1: Local accumulation\n",
    "    local_sum = 0.0\n",
    "    for i in range(gid, n, stride):\n",
    "        local_sum += arr[i]\n",
    "    \n",
    "    shared[tid] = local_sum\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Phase 2: Block reduction\n",
    "    s = cuda.blockDim.x // 2\n",
    "    while s > 0:\n",
    "        if tid < s:\n",
    "            shared[tid] += shared[tid + s]\n",
    "        cuda.syncthreads()\n",
    "        s //= 2\n",
    "    \n",
    "    # Phase 3: ONE atomic per block\n",
    "    if tid == 0:\n",
    "        cuda.atomic.add(result, 0, shared[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fbe705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare naive atomic vs privatized\n",
    "@cuda.jit\n",
    "def naive_atomic_sum(arr, result, n):\n",
    "    \"\"\"Naive: one atomic per element.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    for i in range(tid, n, stride):\n",
    "        cuda.atomic.add(result, 0, arr[i])\n",
    "\n",
    "n = 1_000_000\n",
    "arr = np.random.rand(n).astype(np.float32)\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "iterations = 50\n",
    "\n",
    "# Naive atomic\n",
    "d_result1 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "naive_atomic_sum[256, 256](d_arr, d_result1, n)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result1 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "    naive_atomic_sum[256, 256](d_arr, d_result1, n)\n",
    "cuda.synchronize()\n",
    "naive_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "# Privatized\n",
    "d_result2 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "privatized_sum[256, 256](d_arr, d_result2, n)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result2 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "    privatized_sum[256, 256](d_arr, d_result2, n)\n",
    "cuda.synchronize()\n",
    "priv_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "print(f\"Sum Benchmark (N={n:,})\")\n",
    "print(f\"{'='*45}\")\n",
    "print(f\"Naive atomic (N atomics): {naive_time:.3f} ms\")\n",
    "print(f\"Privatized (256 atomics): {priv_time:.3f} ms\")\n",
    "print(f\"Speedup:                  {naive_time/priv_time:.1f}x\")\n",
    "print(f\"\\nResults match: {'‚úì' if np.isclose(d_result1.copy_to_host()[0], d_result2.copy_to_host()[0], rtol=1e-4) else '‚úó'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047a053",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Shared Memory Atomics\n",
    "\n",
    "### Faster Atomics in Shared Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ceb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def count_values_global_atomic(arr, counts, n, num_bins):\n",
    "    \"\"\"Count values using global memory atomics (slow).\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    for i in range(tid, n, stride):\n",
    "        bin_idx = arr[i] % num_bins\n",
    "        cuda.atomic.add(counts, bin_idx, 1)  # Global atomic!\n",
    "\n",
    "@cuda.jit\n",
    "def count_values_shared_atomic(arr, counts, n, num_bins):\n",
    "    \"\"\"\n",
    "    Count values using shared memory atomics (faster).\n",
    "    \n",
    "    1. Accumulate in shared memory (fast atomics)\n",
    "    2. Merge to global memory (fewer atomics)\n",
    "    \"\"\"\n",
    "    # Shared memory histogram\n",
    "    shared_counts = cuda.shared.array(256, dtype=np.int32)\n",
    "    \n",
    "    tid = cuda.threadIdx.x\n",
    "    gid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    # Initialize shared memory\n",
    "    if tid < num_bins:\n",
    "        shared_counts[tid] = 0\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Phase 1: Count in shared memory\n",
    "    for i in range(gid, n, stride):\n",
    "        bin_idx = arr[i] % num_bins\n",
    "        cuda.atomic.add(shared_counts, bin_idx, 1)  # Shared atomic (fast!)\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Phase 2: Merge to global\n",
    "    if tid < num_bins:\n",
    "        cuda.atomic.add(counts, tid, shared_counts[tid])  # One global atomic per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark global vs shared atomics\n",
    "n = 10_000_000\n",
    "num_bins = 256\n",
    "\n",
    "arr = np.random.randint(0, num_bins, n).astype(np.int32)\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "iterations = 50\n",
    "\n",
    "# Global atomics\n",
    "d_counts1 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "count_values_global_atomic[256, 256](d_arr, d_counts1, n, num_bins)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_counts1 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "    count_values_global_atomic[256, 256](d_arr, d_counts1, n, num_bins)\n",
    "cuda.synchronize()\n",
    "global_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "# Shared atomics\n",
    "d_counts2 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "count_values_shared_atomic[256, 256](d_arr, d_counts2, n, num_bins)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_counts2 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "    count_values_shared_atomic[256, 256](d_arr, d_counts2, n, num_bins)\n",
    "cuda.synchronize()\n",
    "shared_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "print(f\"Counting Benchmark (N={n:,}, bins={num_bins})\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Global memory atomics: {global_time:.3f} ms\")\n",
    "print(f\"Shared memory atomics: {shared_time:.3f} ms\")\n",
    "print(f\"Speedup:               {global_time/shared_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e53fb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Compare-and-Swap (CAS)\n",
    "\n",
    "### Building Custom Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_and_swap(array, compare_val, new_val)\n",
    "# If array[0] == compare_val, set array[0] = new_val\n",
    "# Returns the OLD value\n",
    "#\n",
    "# This is the fundamental building block for all atomics!\n",
    "\n",
    "@cuda.jit\n",
    "def atomic_max_float_cas(arr, idx, val):\n",
    "    \"\"\"\n",
    "    Implement atomic max for float using CAS.\n",
    "    (Numba doesn't have native atomic max for float)\n",
    "    \"\"\"\n",
    "    # This is a pattern for implementing custom atomics\n",
    "    old = arr[idx]\n",
    "    \n",
    "    # Keep trying until we succeed\n",
    "    while val > old:\n",
    "        # Try to swap old with val\n",
    "        assumed = old\n",
    "        old = cuda.atomic.compare_and_swap(arr, assumed, val)\n",
    "        \n",
    "        # If old == assumed, swap succeeded\n",
    "        # If old != assumed, someone else updated, retry\n",
    "        if old == assumed:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd8a81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: When to Use What?\n",
    "\n",
    "### Decision Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë           WHEN TO USE REDUCTION VS ATOMICS                    ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                               ‚ïë\n",
    "‚ïë  Use REDUCTION when:                                          ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Computing single result (sum, max, min)                   ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Regular access pattern (element-wise)                     ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Maximum performance needed                                ‚ïë\n",
    "‚ïë  ‚îî‚îÄ Can use shared memory + warp primitives                   ‚ïë\n",
    "‚ïë                                                               ‚ïë\n",
    "‚ïë  Use ATOMICS when:                                            ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Multiple output locations (histogram)                     ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Irregular/data-dependent access pattern                   ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Simple counting/accumulation                              ‚ïë\n",
    "‚ïë  ‚îî‚îÄ Low contention (few conflicts per location)               ‚ïë\n",
    "‚ïë                                                               ‚ïë\n",
    "‚ïë  Use PRIVATIZATION when:                                      ‚ïë\n",
    "‚ïë  ‚îú‚îÄ High atomic contention expected                           ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Can accumulate locally first                              ‚ïë\n",
    "‚ïë  ‚îî‚îÄ Want best of both worlds                                  ‚ïë\n",
    "‚ïë                                                               ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85004042",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Count Specific Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6dba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count how many times each unique value appears in array\n",
    "# Use atomic add to shared memory, then merge to global\n",
    "\n",
    "@cuda.jit\n",
    "def count_occurrences(arr, counts, n):\n",
    "    \"\"\"Count occurrences of values 0-255 in array.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Test with arr = [0, 1, 1, 2, 2, 2, 3, 3, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c146f3b",
   "metadata": {},
   "source": [
    "### Exercise 2: Find First Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the index of first element > threshold\n",
    "# Use atomic min on the index\n",
    "\n",
    "@cuda.jit\n",
    "def find_first_above(arr, threshold, result_idx, n):\n",
    "    \"\"\"Find index of first element > threshold.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    # TODO: For each element > threshold, do atomic min on result_idx\n",
    "    # Initialize result_idx to n (meaning \"not found\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a26c38",
   "metadata": {},
   "source": [
    "### Exercise 3: Parallel Counter with Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a counter that stops at a maximum value\n",
    "# Use compare_and_swap to implement saturating increment\n",
    "\n",
    "@cuda.jit\n",
    "def saturating_increment(counter, max_val):\n",
    "    \"\"\"Increment counter, but don't exceed max_val.\"\"\"\n",
    "    # Hint: Loop with CAS until either:\n",
    "    # 1. Successfully incremented, or\n",
    "    # 2. Counter already at max_val\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55da2d52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Atomic Operations Reference\n",
    "\n",
    "| Operation | Syntax | Description |\n",
    "|-----------|--------|-------------|\n",
    "| Add | `cuda.atomic.add(arr, idx, val)` | arr[idx] += val |\n",
    "| Max | `cuda.atomic.max(arr, idx, val)` | arr[idx] = max(...) |\n",
    "| Min | `cuda.atomic.min(arr, idx, val)` | arr[idx] = min(...) |\n",
    "| CAS | `cuda.atomic.compare_and_swap(arr, old, new)` | Conditional swap |\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "```\n",
    "1. MINIMIZE CONTENTION\n",
    "   ‚Ä¢ Spread atomics across locations\n",
    "   ‚Ä¢ Use privatization pattern\n",
    "\n",
    "2. PREFER SHARED MEMORY ATOMICS\n",
    "   ‚Ä¢ ~10x faster than global\n",
    "   ‚Ä¢ Merge to global at end\n",
    "\n",
    "3. USE REDUCTION WHEN POSSIBLE\n",
    "   ‚Ä¢ No atomics needed for sum/max/min\n",
    "   ‚Ä¢ Faster than any atomic approach\n",
    "\n",
    "4. BATCH UPDATES\n",
    "   ‚Ä¢ Accumulate locally first\n",
    "   ‚Ä¢ One atomic per thread/warp/block\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Race conditions break correctness** - use atomics!\n",
    "2. **Atomics serialize threads** - minimize contention\n",
    "3. **Shared memory atomics are faster** than global\n",
    "4. **Privatization reduces contention** dramatically\n",
    "5. **CAS is fundamental** - all atomics built on it\n",
    "\n",
    "### Next: Day 4 - Histogram & Counting\n",
    "Apply atomics to build practical histogram kernels!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
