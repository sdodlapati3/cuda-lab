{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c9346d",
   "metadata": {},
   "source": [
    "# ğŸš€ Day 3: Atomic Operations\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapati3/cuda-lab/blob/main/learning-path/week-04/day-3-atomic-operations.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand race conditions and why atomics are needed\n",
    "- Use atomic add, max, min, CAS operations\n",
    "- Apply atomics to counting and reduction problems\n",
    "- Understand privatization for reducing atomic contention\n",
    "\n",
    "> **Primary Focus:** CUDA C++ code examples first, Python/Numba backup for interactive testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Colab/Local Setup - Run this first!\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"ğŸ”§ Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"âœ… Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’» Running locally - make sure you have: pip install numba numpy\")\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(f\"\\nCUDA available: {cuda.is_available()}\")\n",
    "if cuda.is_available():\n",
    "    device = cuda.get_current_device()\n",
    "    print(f\"Device: {device.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3b6a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Race Condition Problem\n",
    "\n",
    "### What Goes Wrong Without Atomics?\n",
    "\n",
    "```\n",
    "Thread A reads counter (0)\n",
    "Thread B reads counter (0)     â† Same old value!\n",
    "Thread A writes counter+1 (1)\n",
    "Thread B writes counter+1 (1)  â† Overwrites A's work!\n",
    "\n",
    "Expected: 2, Actual: 1 â† DATA RACE!\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "The following CUDA C++ implementation demonstrates atomic operations for thread-safe memory updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile atomic_ops.cu\n",
    "// atomic_ops.cu - Thread-safe operations\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// BAD: Race condition!\n",
    "__global__ void raceCondition(int* counter) {\n",
    "    // Multiple threads read-modify-write simultaneously\n",
    "    counter[0] = counter[0] + 1;  // NOT SAFE!\n",
    "}\n",
    "\n",
    "// GOOD: Using atomicAdd\n",
    "__global__ void safeIncrement(int* counter, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        atomicAdd(counter, 1);  // Thread-safe!\n",
    "    }\n",
    "}\n",
    "\n",
    "// Common atomic operations:\n",
    "__global__ void atomicExamples(int* arr, float* farr) {\n",
    "    // Integer atomics\n",
    "    atomicAdd(&arr[0], 1);        // arr[0] += 1\n",
    "    atomicSub(&arr[1], 1);        // arr[1] -= 1\n",
    "    atomicMax(&arr[2], 100);      // arr[2] = max(arr[2], 100)\n",
    "    atomicMin(&arr[3], 0);        // arr[3] = min(arr[3], 0)\n",
    "    atomicExch(&arr[4], 42);      // arr[4] = 42, returns old value\n",
    "    atomicCAS(&arr[5], 0, 1);     // if (arr[5] == 0) arr[5] = 1\n",
    "    \n",
    "    // Floating-point atomics\n",
    "    atomicAdd(&farr[0], 1.0f);    // farr[0] += 1.0\n",
    "    // Note: atomicMax/Min for floats requires CUDA 11+\n",
    "}\n",
    "\n",
    "// Reduce with atomics (simple but slow)\n",
    "__global__ void atomicSum(const float* input, float* result, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    \n",
    "    float localSum = 0.0f;\n",
    "    for (int i = tid; i < n; i += stride) {\n",
    "        localSum += input[i];\n",
    "    }\n",
    "    \n",
    "    // One atomic per thread is MUCH better than one per element\n",
    "    atomicAdd(result, localSum);\n",
    "}\n",
    "\n",
    "// Privatization: reduce contention with per-block counters\n",
    "__global__ void countWithPrivatization(const int* data, int* blockCounts, int n) {\n",
    "    __shared__ int localCount;\n",
    "    \n",
    "    if (threadIdx.x == 0) {\n",
    "        localCount = 0;\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    \n",
    "    for (int i = tid; i < n; i += stride) {\n",
    "        if (data[i] > 0) {\n",
    "            atomicAdd(&localCount, 1);  // Shared memory atomic (fast)\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    if (threadIdx.x == 0) {\n",
    "        atomicAdd(&blockCounts[blockIdx.x], localCount);  // Global atomic once\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n = 1000;\n",
    "    int *d_counter;\n",
    "    cudaMalloc(&d_counter, sizeof(int));\n",
    "    cudaMemset(d_counter, 0, sizeof(int));\n",
    "    \n",
    "    safeIncrement<<<4, 256>>>(d_counter, n);\n",
    "    \n",
    "    int result;\n",
    "    cudaMemcpy(&result, d_counter, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Counter after %d increments: %d\\n\", n, result);\n",
    "    \n",
    "    cudaFree(d_counter);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o atomic_ops atomic_ops.cu\n",
    "!./atomic_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f2f2c",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba (Optional - Quick Testing)\n",
    "\n",
    "Python demonstration of race conditions and atomic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python demonstration of race condition\n",
    "@cuda.jit\n",
    "def race_condition_demo(counter):\n",
    "    \"\"\"\n",
    "    BAD: Multiple threads increment counter without protection.\n",
    "    \"\"\"\n",
    "    counter[0] = counter[0] + 1  # NOT ATOMIC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the race condition\n",
    "def test_race_condition(num_threads):\n",
    "    counter = np.zeros(1, dtype=np.int32)\n",
    "    d_counter = cuda.to_device(counter)\n",
    "    \n",
    "    threads_per_block = min(256, num_threads)\n",
    "    blocks = (num_threads + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    race_condition_demo[blocks, threads_per_block](d_counter)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    result = d_counter.copy_to_host()[0]\n",
    "    return result\n",
    "\n",
    "print(\"Race Condition Demo\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Threads':>10} | {'Expected':>10} | {'Actual':>10} | {'Lost':>10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for n in [100, 1000, 10000, 100000]:\n",
    "    actual = test_race_condition(n)\n",
    "    lost = n - actual\n",
    "    print(f\"{n:>10,} | {n:>10,} | {actual:>10,} | {lost:>10,}\")\n",
    "\n",
    "print(\"\\nâš ï¸  Notice: Most increments are LOST due to race conditions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f34cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Atomic Operations\n",
    "\n",
    "### The Solution: Atomic Operations\n",
    "\n",
    "```\n",
    "Atomic = Indivisible\n",
    "\n",
    "Read-Modify-Write happens as ONE operation:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 1. Read old value      â”‚\n",
    "â”‚ 2. Compute new value   â”‚  â† All protected!\n",
    "â”‚ 3. Write new value     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Other threads must WAIT until this completes.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def atomic_increment(counter):\n",
    "    \"\"\"CORRECT: Use atomic operation for thread-safe increment.\"\"\"\n",
    "    cuda.atomic.add(counter, 0, 1)  # Atomically: counter[0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c102db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_atomic_increment(num_threads):\n",
    "    counter = np.zeros(1, dtype=np.int32)\n",
    "    d_counter = cuda.to_device(counter)\n",
    "    \n",
    "    threads_per_block = min(256, num_threads)\n",
    "    blocks = (num_threads + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    atomic_increment[blocks, threads_per_block](d_counter)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    return d_counter.copy_to_host()[0]\n",
    "\n",
    "print(\"Atomic Increment Demo\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Threads':>10} | {'Expected':>10} | {'Actual':>10} | {'Match':>10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for n in [100, 1000, 10000, 100000]:\n",
    "    actual = test_atomic_increment(n)\n",
    "    match = \"âœ“\" if actual == n else \"âœ—\"\n",
    "    print(f\"{n:>10,} | {n:>10,} | {actual:>10,} | {match:>10}\")\n",
    "\n",
    "print(\"\\nâœ“ All increments are now counted correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7affc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Available Atomic Operations\n",
    "\n",
    "### Numba CUDA Atomic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available atomic operations in Numba CUDA:\n",
    "#\n",
    "# cuda.atomic.add(array, index, value)     # array[index] += value\n",
    "# cuda.atomic.max(array, index, value)     # array[index] = max(array[index], value)\n",
    "# cuda.atomic.min(array, index, value)     # array[index] = min(array[index], value)\n",
    "# cuda.atomic.compare_and_swap(array, old, val)  # CAS operation\n",
    "#\n",
    "# All return the OLD value before the operation\n",
    "\n",
    "@cuda.jit\n",
    "def demo_atomic_add(arr, values, result, n):\n",
    "    \"\"\"Sum values using atomic add.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.add(result, 0, values[tid])\n",
    "\n",
    "@cuda.jit\n",
    "def demo_atomic_max(arr, result, n):\n",
    "    \"\"\"Find maximum using atomic max.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.max(result, 0, arr[tid])\n",
    "\n",
    "@cuda.jit\n",
    "def demo_atomic_min(arr, result, n):\n",
    "    \"\"\"Find minimum using atomic min.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.min(result, 0, arr[tid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test atomic operations\n",
    "n = 10000\n",
    "arr = np.random.randint(1, 1000, n).astype(np.int32)\n",
    "\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "# Atomic add (sum)\n",
    "d_sum = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "demo_atomic_add[40, 256](d_arr, d_arr, d_sum, n)\n",
    "gpu_sum = d_sum.copy_to_host()[0]\n",
    "\n",
    "# Atomic max\n",
    "d_max = cuda.to_device(np.array([np.iinfo(np.int32).min], dtype=np.int32))\n",
    "demo_atomic_max[40, 256](d_arr, d_max, n)\n",
    "gpu_max = d_max.copy_to_host()[0]\n",
    "\n",
    "# Atomic min\n",
    "d_min = cuda.to_device(np.array([np.iinfo(np.int32).max], dtype=np.int32))\n",
    "demo_atomic_min[40, 256](d_arr, d_min, n)\n",
    "gpu_min = d_min.copy_to_host()[0]\n",
    "\n",
    "print(f\"Array: {n:,} random integers [1, 1000)\")\n",
    "print(f\"\\nAtomic Sum: {gpu_sum:,} (CPU: {np.sum(arr):,})\")\n",
    "print(f\"Atomic Max: {gpu_max} (CPU: {np.max(arr)})\")\n",
    "print(f\"Atomic Min: {gpu_min} (CPU: {np.min(arr)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641497a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Atomics Performance Problem\n",
    "\n",
    "### Atomic Contention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bde3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atomics are SLOW when many threads compete for same location!\n",
    "\n",
    "@cuda.jit\n",
    "def high_contention_atomic(result, n):\n",
    "    \"\"\"All threads atomically add to ONE location.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        cuda.atomic.add(result, 0, 1)  # Everyone fights for index 0!\n",
    "\n",
    "@cuda.jit\n",
    "def low_contention_atomic(result, n):\n",
    "    \"\"\"Threads spread across MULTIPLE locations.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n:\n",
    "        # Spread across 256 locations\n",
    "        bin_idx = tid % 256\n",
    "        cuda.atomic.add(result, bin_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark contention\n",
    "n = 1_000_000\n",
    "iterations = 100\n",
    "\n",
    "# High contention (1 location)\n",
    "d_result1 = cuda.device_array(1, dtype=np.int32)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result1 = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "    high_contention_atomic[4000, 256](d_result1, n)\n",
    "cuda.synchronize()\n",
    "high_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "# Low contention (256 locations)\n",
    "d_result256 = cuda.device_array(256, dtype=np.int32)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result256 = cuda.to_device(np.zeros(256, dtype=np.int32))\n",
    "    low_contention_atomic[4000, 256](d_result256, n)\n",
    "cuda.synchronize()\n",
    "low_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "print(f\"Atomic Contention Benchmark (N={n:,})\")\n",
    "print(f\"{'='*45}\")\n",
    "print(f\"High contention (1 loc):   {high_time:.3f} ms\")\n",
    "print(f\"Low contention (256 locs): {low_time:.3f} ms\")\n",
    "print(f\"Speedup:                   {high_time/low_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf5838",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Privatization Pattern\n",
    "\n",
    "### Reducing Contention with Local Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fcd9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def privatized_sum(arr, result, n):\n",
    "    \"\"\"\n",
    "    Privatization: Each block has its own accumulator in shared memory.\n",
    "    \n",
    "    1. Local accumulation in shared memory (no atomic)\n",
    "    2. Block-level reduction (no atomic)\n",
    "    3. Single atomic per block to global\n",
    "    \"\"\"\n",
    "    # Shared memory for block's local sum\n",
    "    shared = cuda.shared.array(256, dtype=np.float32)\n",
    "    \n",
    "    tid = cuda.threadIdx.x\n",
    "    bid = cuda.blockIdx.x\n",
    "    gid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    # Phase 1: Local accumulation\n",
    "    local_sum = 0.0\n",
    "    for i in range(gid, n, stride):\n",
    "        local_sum += arr[i]\n",
    "    \n",
    "    shared[tid] = local_sum\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Phase 2: Block reduction\n",
    "    s = cuda.blockDim.x // 2\n",
    "    while s > 0:\n",
    "        if tid < s:\n",
    "            shared[tid] += shared[tid + s]\n",
    "        cuda.syncthreads()\n",
    "        s //= 2\n",
    "    \n",
    "    # Phase 3: ONE atomic per block\n",
    "    if tid == 0:\n",
    "        cuda.atomic.add(result, 0, shared[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fbe705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare naive atomic vs privatized\n",
    "@cuda.jit\n",
    "def naive_atomic_sum(arr, result, n):\n",
    "    \"\"\"Naive: one atomic per element.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    for i in range(tid, n, stride):\n",
    "        cuda.atomic.add(result, 0, arr[i])\n",
    "\n",
    "n = 1_000_000\n",
    "arr = np.random.rand(n).astype(np.float32)\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "iterations = 50\n",
    "\n",
    "# Naive atomic\n",
    "d_result1 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "naive_atomic_sum[256, 256](d_arr, d_result1, n)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result1 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "    naive_atomic_sum[256, 256](d_arr, d_result1, n)\n",
    "cuda.synchronize()\n",
    "naive_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "# Privatized\n",
    "d_result2 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "privatized_sum[256, 256](d_arr, d_result2, n)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_result2 = cuda.to_device(np.zeros(1, dtype=np.float32))\n",
    "    privatized_sum[256, 256](d_arr, d_result2, n)\n",
    "cuda.synchronize()\n",
    "priv_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "print(f\"Sum Benchmark (N={n:,})\")\n",
    "print(f\"{'='*45}\")\n",
    "print(f\"Naive atomic (N atomics): {naive_time:.3f} ms\")\n",
    "print(f\"Privatized (256 atomics): {priv_time:.3f} ms\")\n",
    "print(f\"Speedup:                  {naive_time/priv_time:.1f}x\")\n",
    "print(f\"\\nResults match: {'âœ“' if np.isclose(d_result1.copy_to_host()[0], d_result2.copy_to_host()[0], rtol=1e-4) else 'âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047a053",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Shared Memory Atomics\n",
    "\n",
    "### Faster Atomics in Shared Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ceb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def count_values_global_atomic(arr, counts, n, num_bins):\n",
    "    \"\"\"Count values using global memory atomics (slow).\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    for i in range(tid, n, stride):\n",
    "        bin_idx = arr[i] % num_bins\n",
    "        cuda.atomic.add(counts, bin_idx, 1)  # Global atomic!\n",
    "\n",
    "@cuda.jit\n",
    "def count_values_shared_atomic(arr, counts, n, num_bins):\n",
    "    \"\"\"\n",
    "    Count values using shared memory atomics (faster).\n",
    "    \n",
    "    1. Accumulate in shared memory (fast atomics)\n",
    "    2. Merge to global memory (fewer atomics)\n",
    "    \"\"\"\n",
    "    # Shared memory histogram\n",
    "    shared_counts = cuda.shared.array(256, dtype=np.int32)\n",
    "    \n",
    "    tid = cuda.threadIdx.x\n",
    "    gid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    # Initialize shared memory\n",
    "    if tid < num_bins:\n",
    "        shared_counts[tid] = 0\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Phase 1: Count in shared memory\n",
    "    for i in range(gid, n, stride):\n",
    "        bin_idx = arr[i] % num_bins\n",
    "        cuda.atomic.add(shared_counts, bin_idx, 1)  # Shared atomic (fast!)\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Phase 2: Merge to global\n",
    "    if tid < num_bins:\n",
    "        cuda.atomic.add(counts, tid, shared_counts[tid])  # One global atomic per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark global vs shared atomics\n",
    "n = 10_000_000\n",
    "num_bins = 256\n",
    "\n",
    "arr = np.random.randint(0, num_bins, n).astype(np.int32)\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "iterations = 50\n",
    "\n",
    "# Global atomics\n",
    "d_counts1 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "count_values_global_atomic[256, 256](d_arr, d_counts1, n, num_bins)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_counts1 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "    count_values_global_atomic[256, 256](d_arr, d_counts1, n, num_bins)\n",
    "cuda.synchronize()\n",
    "global_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "# Shared atomics\n",
    "d_counts2 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "count_values_shared_atomic[256, 256](d_arr, d_counts2, n, num_bins)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(iterations):\n",
    "    d_counts2 = cuda.to_device(np.zeros(num_bins, dtype=np.int32))\n",
    "    count_values_shared_atomic[256, 256](d_arr, d_counts2, n, num_bins)\n",
    "cuda.synchronize()\n",
    "shared_time = (time.perf_counter() - start) / iterations * 1000\n",
    "\n",
    "print(f\"Counting Benchmark (N={n:,}, bins={num_bins})\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Global memory atomics: {global_time:.3f} ms\")\n",
    "print(f\"Shared memory atomics: {shared_time:.3f} ms\")\n",
    "print(f\"Speedup:               {global_time/shared_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e53fb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Compare-and-Swap (CAS)\n",
    "\n",
    "### Building Custom Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_and_swap(array, compare_val, new_val)\n",
    "# If array[0] == compare_val, set array[0] = new_val\n",
    "# Returns the OLD value\n",
    "#\n",
    "# This is the fundamental building block for all atomics!\n",
    "\n",
    "@cuda.jit\n",
    "def atomic_max_float_cas(arr, idx, val):\n",
    "    \"\"\"\n",
    "    Implement atomic max for float using CAS.\n",
    "    (Numba doesn't have native atomic max for float)\n",
    "    \"\"\"\n",
    "    # This is a pattern for implementing custom atomics\n",
    "    old = arr[idx]\n",
    "    \n",
    "    # Keep trying until we succeed\n",
    "    while val > old:\n",
    "        # Try to swap old with val\n",
    "        assumed = old\n",
    "        old = cuda.atomic.compare_and_swap(arr, assumed, val)\n",
    "        \n",
    "        # If old == assumed, swap succeeded\n",
    "        # If old != assumed, someone else updated, retry\n",
    "        if old == assumed:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd8a81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: When to Use What?\n",
    "\n",
    "### Decision Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           WHEN TO USE REDUCTION VS ATOMICS                    â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                               â•‘\n",
    "â•‘  Use REDUCTION when:                                          â•‘\n",
    "â•‘  â”œâ”€ Computing single result (sum, max, min)                   â•‘\n",
    "â•‘  â”œâ”€ Regular access pattern (element-wise)                     â•‘\n",
    "â•‘  â”œâ”€ Maximum performance needed                                â•‘\n",
    "â•‘  â””â”€ Can use shared memory + warp primitives                   â•‘\n",
    "â•‘                                                               â•‘\n",
    "â•‘  Use ATOMICS when:                                            â•‘\n",
    "â•‘  â”œâ”€ Multiple output locations (histogram)                     â•‘\n",
    "â•‘  â”œâ”€ Irregular/data-dependent access pattern                   â•‘\n",
    "â•‘  â”œâ”€ Simple counting/accumulation                              â•‘\n",
    "â•‘  â””â”€ Low contention (few conflicts per location)               â•‘\n",
    "â•‘                                                               â•‘\n",
    "â•‘  Use PRIVATIZATION when:                                      â•‘\n",
    "â•‘  â”œâ”€ High atomic contention expected                           â•‘\n",
    "â•‘  â”œâ”€ Can accumulate locally first                              â•‘\n",
    "â•‘  â””â”€ Want best of both worlds                                  â•‘\n",
    "â•‘                                                               â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85004042",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile atomic_exercises.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "// Error checking macro\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA Error: %s at line %d\\n\", cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 1: Count Occurrences of Values (Histogram-style)\n",
    "// ============================================================\n",
    "// Count how many times each value 0-255 appears in an array\n",
    "// Use shared memory atomics for local counts, then merge to global\n",
    "\n",
    "__global__ void countOccurrences(const int* arr, int* counts, int n) {\n",
    "    __shared__ int localCounts[256];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    \n",
    "    // Initialize shared memory (each thread clears multiple bins)\n",
    "    for (int i = tid; i < 256; i += blockDim.x) {\n",
    "        localCounts[i] = 0;\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Count in shared memory\n",
    "    for (int i = globalIdx; i < n; i += stride) {\n",
    "        int val = arr[i];\n",
    "        if (val >= 0 && val < 256) {\n",
    "            atomicAdd(&localCounts[val], 1);\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Merge to global counts\n",
    "    for (int i = tid; i < 256; i += blockDim.x) {\n",
    "        if (localCounts[i] > 0) {\n",
    "            atomicAdd(&counts[i], localCounts[i]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 2: Find First Occurrence Above Threshold\n",
    "// ============================================================\n",
    "// Find the index of the first element greater than threshold\n",
    "// Use atomicMin on the result index\n",
    "\n",
    "__global__ void findFirstAbove(const float* arr, float threshold, int* resultIdx, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    \n",
    "    for (int i = tid; i < n; i += stride) {\n",
    "        if (arr[i] > threshold) {\n",
    "            // Use atomicMin to find the smallest index\n",
    "            atomicMin(resultIdx, i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 3: Saturating Counter with Compare-and-Swap\n",
    "// ============================================================\n",
    "// Increment counter but don't exceed maxVal\n",
    "// Use atomicCAS for safe concurrent updates\n",
    "\n",
    "__global__ void saturatingIncrement(int* counter, int maxVal, int numIncrements) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    for (int i = tid; i < numIncrements; i += blockDim.x * gridDim.x) {\n",
    "        // CAS loop for saturating increment\n",
    "        int old = *counter;\n",
    "        while (old < maxVal) {\n",
    "            int assumed = old;\n",
    "            old = atomicCAS(counter, assumed, assumed + 1);\n",
    "            if (old == assumed) {\n",
    "                // Successfully incremented\n",
    "                break;\n",
    "            }\n",
    "            // Otherwise, old was updated by another thread, try again\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Bonus: Lock-Free Stack Push (Advanced CAS usage)\n",
    "// ============================================================\n",
    "struct Node {\n",
    "    int value;\n",
    "    int next;  // Index to next node (-1 = end)\n",
    "};\n",
    "\n",
    "__global__ void lockFreeStackPush(Node* nodes, int* head, int* freeListHead, int value) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Get a free node (simplified - assume one push per thread)\n",
    "    int newNodeIdx = tid;\n",
    "    nodes[newNodeIdx].value = value + tid;\n",
    "    \n",
    "    // CAS loop to push onto stack\n",
    "    int oldHead = *head;\n",
    "    int newHead;\n",
    "    do {\n",
    "        nodes[newNodeIdx].next = oldHead;\n",
    "        newHead = atomicCAS(head, oldHead, newNodeIdx);\n",
    "        if (newHead == oldHead) break;\n",
    "        oldHead = newHead;\n",
    "    } while (true);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Test Functions\n",
    "// ============================================================\n",
    "void testCountOccurrences() {\n",
    "    printf(\"=== Exercise 1: Count Occurrences ===\\n\");\n",
    "    \n",
    "    const int N = 100000;\n",
    "    int* h_arr = (int*)malloc(N * sizeof(int));\n",
    "    int* h_counts = (int*)calloc(256, sizeof(int));\n",
    "    \n",
    "    // Generate test data with known distribution\n",
    "    srand(42);\n",
    "    int expectedCounts[256] = {0};\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_arr[i] = rand() % 10;  // Values 0-9 only\n",
    "        expectedCounts[h_arr[i]]++;\n",
    "    }\n",
    "    \n",
    "    int* d_arr, *d_counts;\n",
    "    CHECK_CUDA(cudaMalloc(&d_arr, N * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_counts, 256 * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_arr, h_arr, N * sizeof(int), cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemset(d_counts, 0, 256 * sizeof(int)));\n",
    "    \n",
    "    countOccurrences<<<256, 256>>>(d_arr, d_counts, N);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(h_counts, d_counts, 256 * sizeof(int), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    printf(\"Value counts for 0-9:\\n\");\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        printf(\"  Value %d: counted=%d, expected=%d %s\\n\", \n",
    "               i, h_counts[i], expectedCounts[i],\n",
    "               h_counts[i] == expectedCounts[i] ? \"âœ“\" : \"âœ—\");\n",
    "        if (h_counts[i] != expectedCounts[i]) correct = false;\n",
    "    }\n",
    "    printf(\"Test %s\\n\\n\", correct ? \"PASSED âœ“\" : \"FAILED âœ—\");\n",
    "    \n",
    "    cudaFree(d_arr);\n",
    "    cudaFree(d_counts);\n",
    "    free(h_arr);\n",
    "    free(h_counts);\n",
    "}\n",
    "\n",
    "void testFindFirstAbove() {\n",
    "    printf(\"=== Exercise 2: Find First Above Threshold ===\\n\");\n",
    "    \n",
    "    const int N = 1000;\n",
    "    float* h_arr = (float*)malloc(N * sizeof(float));\n",
    "    \n",
    "    // Create sorted-ish array where first element > 0.5 is at index 350\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_arr[i] = (float)i / 700.0f;  // 0.5 crossed at i=350\n",
    "    }\n",
    "    \n",
    "    float* d_arr;\n",
    "    int* d_result;\n",
    "    int h_result = N;  // Initialize to \"not found\"\n",
    "    \n",
    "    CHECK_CUDA(cudaMalloc(&d_arr, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_result, sizeof(int)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_arr, h_arr, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemcpy(d_result, &h_result, sizeof(int), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    findFirstAbove<<<16, 256>>>(d_arr, 0.5f, d_result, N);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(&h_result, d_result, sizeof(int), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    printf(\"First index where value > 0.5: %d\\n\", h_result);\n",
    "    printf(\"Value at that index: %.4f\\n\", h_arr[h_result]);\n",
    "    printf(\"Expected: ~351 (0.5014...)\\n\");\n",
    "    printf(\"Test %s\\n\\n\", (h_result == 351) ? \"PASSED âœ“\" : \"FAILED âœ—\");\n",
    "    \n",
    "    cudaFree(d_arr);\n",
    "    cudaFree(d_result);\n",
    "    free(h_arr);\n",
    "}\n",
    "\n",
    "void testSaturatingIncrement() {\n",
    "    printf(\"=== Exercise 3: Saturating Counter ===\\n\");\n",
    "    \n",
    "    int h_counter = 0;\n",
    "    int maxVal = 100;\n",
    "    int numIncrements = 10000;  // Try to increment way more than max\n",
    "    \n",
    "    int* d_counter;\n",
    "    CHECK_CUDA(cudaMalloc(&d_counter, sizeof(int)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_counter, &h_counter, sizeof(int), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    saturatingIncrement<<<32, 256>>>(d_counter, maxVal, numIncrements);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(&h_counter, d_counter, sizeof(int), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    printf(\"Counter after %d increment attempts (max=%d): %d\\n\", \n",
    "           numIncrements, maxVal, h_counter);\n",
    "    printf(\"Test %s\\n\\n\", (h_counter == maxVal) ? \"PASSED âœ“\" : \"FAILED âœ—\");\n",
    "    \n",
    "    cudaFree(d_counter);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\");\n",
    "    printf(\"â•‘           CUDA Atomic Operations Exercises                   â•‘\\n\");\n",
    "    printf(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\");\n",
    "    \n",
    "    // Print device info\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    printf(\"Device: %s\\n\", prop.name);\n",
    "    printf(\"Compute Capability: %d.%d\\n\\n\", prop.major, prop.minor);\n",
    "    \n",
    "    testCountOccurrences();\n",
    "    testFindFirstAbove();\n",
    "    testSaturatingIncrement();\n",
    "    \n",
    "    printf(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    printf(\"                    All exercises completed!\\n\");\n",
    "    printf(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502256bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o atomic_exercises atomic_exercises.cu && ./atomic_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828b59c",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "### Exercise 1: Count Specific Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6dba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count how many times each unique value appears in array\n",
    "# Use atomic add to shared memory, then merge to global\n",
    "\n",
    "@cuda.jit\n",
    "def count_occurrences(arr, counts, n):\n",
    "    \"\"\"Count occurrences of values 0-255 in array.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Test with arr = [0, 1, 1, 2, 2, 2, 3, 3, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c146f3b",
   "metadata": {},
   "source": [
    "### Exercise 2: Find First Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the index of first element > threshold\n",
    "# Use atomic min on the index\n",
    "\n",
    "@cuda.jit\n",
    "def find_first_above(arr, threshold, result_idx, n):\n",
    "    \"\"\"Find index of first element > threshold.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    # TODO: For each element > threshold, do atomic min on result_idx\n",
    "    # Initialize result_idx to n (meaning \"not found\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a26c38",
   "metadata": {},
   "source": [
    "### Exercise 3: Parallel Counter with Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a counter that stops at a maximum value\n",
    "# Use compare_and_swap to implement saturating increment\n",
    "\n",
    "@cuda.jit\n",
    "def saturating_increment(counter, max_val):\n",
    "    \"\"\"Increment counter, but don't exceed max_val.\"\"\"\n",
    "    # Hint: Loop with CAS until either:\n",
    "    # 1. Successfully incremented, or\n",
    "    # 2. Counter already at max_val\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55da2d52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Atomic Operations Reference\n",
    "\n",
    "| Operation | Syntax | Description |\n",
    "|-----------|--------|-------------|\n",
    "| Add | `cuda.atomic.add(arr, idx, val)` | arr[idx] += val |\n",
    "| Max | `cuda.atomic.max(arr, idx, val)` | arr[idx] = max(...) |\n",
    "| Min | `cuda.atomic.min(arr, idx, val)` | arr[idx] = min(...) |\n",
    "| CAS | `cuda.atomic.compare_and_swap(arr, old, new)` | Conditional swap |\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "```\n",
    "1. MINIMIZE CONTENTION\n",
    "   â€¢ Spread atomics across locations\n",
    "   â€¢ Use privatization pattern\n",
    "\n",
    "2. PREFER SHARED MEMORY ATOMICS\n",
    "   â€¢ ~10x faster than global\n",
    "   â€¢ Merge to global at end\n",
    "\n",
    "3. USE REDUCTION WHEN POSSIBLE\n",
    "   â€¢ No atomics needed for sum/max/min\n",
    "   â€¢ Faster than any atomic approach\n",
    "\n",
    "4. BATCH UPDATES\n",
    "   â€¢ Accumulate locally first\n",
    "   â€¢ One atomic per thread/warp/block\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Race conditions break correctness** - use atomics!\n",
    "2. **Atomics serialize threads** - minimize contention\n",
    "3. **Shared memory atomics are faster** than global\n",
    "4. **Privatization reduces contention** dramatically\n",
    "5. **CAS is fundamental** - all atomics built on it\n",
    "\n",
    "### Next: Day 4 - Histogram & Counting\n",
    "Apply atomics to build practical histogram kernels!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
