{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efc9b5f",
   "metadata": {},
   "source": [
    "# Day 1: Virtual Memory Management Fundamentals\n",
    "\n",
    "> ğŸˆ **\"What if GPU memory worked like elastic balloons that expand as needed, rather than rigid containers you must size upfront?\"**\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this session, you will be able to:\n",
    "1. Explain the difference between virtual address reservation and physical memory allocation\n",
    "2. Use VMM APIs to create growable GPU data structures\n",
    "3. Apply alignment requirements for virtual memory operations\n",
    "4. Configure memory access permissions for security and correctness\n",
    "\n",
    "## Why Virtual Memory Management?\n",
    "\n",
    "Traditional `cudaMalloc`:\n",
    "- Allocates both virtual address AND physical memory together\n",
    "- Fixed size - cannot grow without copy\n",
    "- Simple but inflexible\n",
    "\n",
    "VMM approach:\n",
    "- Reserve virtual address range (cheap, can be huge)\n",
    "- Allocate physical memory separately\n",
    "- Map physical to virtual on demand\n",
    "- **Growable data structures without copying!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afbc06",
   "metadata": {},
   "source": [
    "## ğŸˆ Concept Card: Virtual Memory as Elastic Storage Balloons\n",
    "\n",
    "**The Analogy:** Traditional memory allocation is like buying fixed-size storage boxesâ€”you must guess the right size upfront. VMM is like having **elastic storage balloons**:\n",
    "\n",
    "```\n",
    "ğŸˆ ELASTIC BALLOON STORAGE\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Traditional cudaMalloc:          VMM Approach:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Fixed Box      â”‚              â”‚  ğŸˆ Elastic Balloon     â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚                         â”‚\n",
    "â”‚  â”‚  10 GB    â”‚  â”‚              â”‚  Reserve 100GB space    â”‚\n",
    "â”‚  â”‚  (wasted  â”‚  â”‚              â”‚  (empty balloon shape)  â”‚\n",
    "â”‚  â”‚   space!) â”‚  â”‚              â”‚                         â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  Inflate to 1GB â†’ 5GB   â”‚\n",
    "â”‚                 â”‚              â”‚  â†’ 20GB as needed!      â”‚\n",
    "â”‚  Can't grow!    â”‚              â”‚                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â†“                                  â†“\n",
    "   Guess wrong â†’                  Expand smoothly â†’\n",
    "   Copy everything!               Zero-copy growth!\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n",
    "**The Balloon Stages:**\n",
    "| Stage | Balloon Action | VMM Operation |\n",
    "|-------|---------------|---------------|\n",
    "| **Reserve** | Claim balloon shape/space | `cuMemAddressReserve()` - reserve VA range |\n",
    "| **Allocate** | Buy actual air canisters | `cuMemCreate()` - allocate physical memory |\n",
    "| **Inflate** | Fill balloon with air | `cuMemMap()` - map physical to virtual |\n",
    "| **Use** | Open valve for access | `cuMemSetAccess()` - set R/W permissions |\n",
    "| **Expand** | Add more air when needed | Map more physical to same VA range |\n",
    "\n",
    "**Why This Matters:** Like a balloon that can expand without changing its location in your room, VMM lets data structures grow without movingâ€”no expensive copy operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile vmm_basics.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void fillKernel(int* data, int n, int value) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = value;\n",
    "}\n",
    "\n",
    "__global__ void sumKernel(int* data, int n, long long* result) {\n",
    "    __shared__ long long sdata[256];\n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    sdata[tid] = (idx < n) ? data[idx] : 0;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = 128; s > 0; s >>= 1) {\n",
    "        if (tid < s) sdata[tid] += sdata[tid + s];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) atomicAdd(result, sdata[0]);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Initialize CUDA Driver API\n",
    "    cuInit(0);\n",
    "    \n",
    "    int device = 0;\n",
    "    cudaSetDevice(device);\n",
    "    \n",
    "    // Step 1: Get allocation properties and granularity\n",
    "    CUmemAllocationProp prop = {};\n",
    "    prop.type = CU_MEM_ALLOCATION_TYPE_PINNED;\n",
    "    prop.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n",
    "    prop.location.id = device;\n",
    "    \n",
    "    size_t granularity;\n",
    "    cuMemGetAllocationGranularity(&granularity, &prop,\n",
    "                                  CU_MEM_ALLOC_GRANULARITY_MINIMUM);\n",
    "    printf(\"Allocation granularity: %zu bytes\\n\", granularity);\n",
    "    \n",
    "    // Step 2: Reserve virtual address range (1 GB)\n",
    "    size_t reserveSize = 1ULL << 30;  // 1 GB\n",
    "    CUdeviceptr ptr;\n",
    "    CUresult res = cuMemAddressReserve(&ptr, reserveSize, granularity, 0, 0);\n",
    "    if (res != CUDA_SUCCESS) {\n",
    "        printf(\"Failed to reserve address: %d\\n\", res);\n",
    "        return 1;\n",
    "    }\n",
    "    printf(\"Reserved %zu MB virtual address at 0x%llx\\n\", \n",
    "           reserveSize / (1024*1024), (unsigned long long)ptr);\n",
    "    \n",
    "    // Step 3: Create physical memory (1 MB initially)\n",
    "    size_t physSize = 1 << 20;  // 1 MB\n",
    "    physSize = ((physSize + granularity - 1) / granularity) * granularity;\n",
    "    \n",
    "    CUmemGenericAllocationHandle handle;\n",
    "    res = cuMemCreate(&handle, physSize, &prop, 0);\n",
    "    if (res != CUDA_SUCCESS) {\n",
    "        printf(\"Failed to create physical memory: %d\\n\", res);\n",
    "        return 1;\n",
    "    }\n",
    "    printf(\"Created %zu KB physical memory\\n\", physSize / 1024);\n",
    "    \n",
    "    // Step 4: Map physical to virtual\n",
    "    res = cuMemMap(ptr, physSize, 0, handle, 0);\n",
    "    if (res != CUDA_SUCCESS) {\n",
    "        printf(\"Failed to map memory: %d\\n\", res);\n",
    "        return 1;\n",
    "    }\n",
    "    printf(\"Mapped physical to virtual\\n\");\n",
    "    \n",
    "    // Step 5: Set access permissions\n",
    "    CUmemAccessDesc accessDesc = {};\n",
    "    accessDesc.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n",
    "    accessDesc.location.id = device;\n",
    "    accessDesc.flags = CU_MEM_ACCESS_FLAGS_PROT_READWRITE;\n",
    "    \n",
    "    res = cuMemSetAccess(ptr, physSize, &accessDesc, 1);\n",
    "    if (res != CUDA_SUCCESS) {\n",
    "        printf(\"Failed to set access: %d\\n\", res);\n",
    "        return 1;\n",
    "    }\n",
    "    printf(\"Access permissions set\\n\");\n",
    "    \n",
    "    // Use the memory!\n",
    "    int n = physSize / sizeof(int);\n",
    "    int* data = (int*)ptr;\n",
    "    \n",
    "    fillKernel<<<(n+255)/256, 256>>>(data, n, 1);\n",
    "    \n",
    "    long long* d_sum;\n",
    "    cudaMalloc(&d_sum, sizeof(long long));\n",
    "    cudaMemset(d_sum, 0, sizeof(long long));\n",
    "    \n",
    "    sumKernel<<<(n+255)/256, 256>>>(data, n, d_sum);\n",
    "    \n",
    "    long long h_sum;\n",
    "    cudaMemcpy(&h_sum, d_sum, sizeof(long long), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Sum of %d ones = %lld\\n\", n, h_sum);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_sum);\n",
    "    cuMemUnmap(ptr, physSize);\n",
    "    cuMemRelease(handle);\n",
    "    cuMemAddressFree(ptr, reserveSize);\n",
    "    \n",
    "    printf(\"\\nVMM workflow complete!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc vmm_basics.cu -o vmm_basics -lcuda && ./vmm_basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14037f",
   "metadata": {},
   "source": [
    "## VMM Workflow Summary\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  Virtual Address Space               â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚ cuMemAddressReserve (1 GB)                     â”‚ â”‚\n",
    "â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚ â”‚\n",
    "â”‚  â”‚ â”‚ Mapped   â”‚ â† cuMemMap                        â”‚ â”‚\n",
    "â”‚  â”‚ â”‚ (1 MB)   â”‚                                   â”‚ â”‚\n",
    "â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚ â”‚\n",
    "â”‚  â”‚ [Unmapped space - can grow into later]         â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â†‘\n",
    "           â”‚ cuMemMap\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              Physical Memory (GPU RAM)              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚\n",
    "â”‚  â”‚ cuMemCreate (1 MB)                               â”‚\n",
    "â”‚  â”‚ (handle)  â”‚                                       â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0187255",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Complete these exercises to practice VMM fundamentals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60526fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile vmm_exercises.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "/*\n",
    " * VMM Fundamentals Exercises\n",
    " * \n",
    " * Exercise 1: Implement a growable array using VMM\n",
    " * - Reserve a large virtual address range (e.g., 1GB)\n",
    " * - Start with a small physical allocation\n",
    " * - Implement grow() that adds more physical memory without copying\n",
    " * \n",
    " * Exercise 2: Implement a sparse matrix using VMM\n",
    " * - Reserve VA for entire dense matrix\n",
    " * - Only allocate physical memory for non-zero blocks\n",
    " * \n",
    " * Exercise 3: Measure and compare allocation overhead\n",
    " * - Compare cuMemCreate+cuMemMap vs cudaMalloc timing\n",
    " */\n",
    "\n",
    "// Helper macro for CUDA Driver API error checking\n",
    "#define CU_CHECK(call) do { \\\n",
    "    CUresult err = call; \\\n",
    "    if (err != CUDA_SUCCESS) { \\\n",
    "        const char* errStr; \\\n",
    "        cuGetErrorString(err, &errStr); \\\n",
    "        printf(\"CUDA Driver Error: %s at %s:%d\\n\", errStr, __FILE__, __LINE__); \\\n",
    "        exit(1); \\\n",
    "    } \\\n",
    "} while(0)\n",
    "\n",
    "// Exercise 1: Growable Array Structure\n",
    "class GrowableVMMArray {\n",
    "    CUdeviceptr vaBase;      // Virtual address base\n",
    "    size_t vaSize;           // Total reserved VA size\n",
    "    size_t physAllocated;    // Currently allocated physical memory\n",
    "    size_t granularity;      // Allocation granularity\n",
    "    int device;\n",
    "    CUmemAllocationProp prop;\n",
    "    \n",
    "public:\n",
    "    GrowableVMMArray(size_t maxSize) : vaSize(maxSize), physAllocated(0) {\n",
    "        cuInit(0);\n",
    "        cudaGetDevice(&device);\n",
    "        \n",
    "        // Get allocation properties\n",
    "        memset(&prop, 0, sizeof(prop));\n",
    "        prop.type = CU_MEM_ALLOCATION_TYPE_PINNED;\n",
    "        prop.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n",
    "        prop.location.id = device;\n",
    "        \n",
    "        // Get granularity\n",
    "        CU_CHECK(cuMemGetAllocationGranularity(&granularity, &prop, \n",
    "                                                CU_MEM_ALLOC_GRANULARITY_MINIMUM));\n",
    "        \n",
    "        // Round up VA size\n",
    "        vaSize = ((vaSize + granularity - 1) / granularity) * granularity;\n",
    "        \n",
    "        // TODO Exercise 1a: Reserve virtual address range\n",
    "        // Hint: Use cuMemAddressReserve(&vaBase, vaSize, granularity, 0, 0)\n",
    "        printf(\"Exercise 1a: Reserve %zu bytes of virtual address space\\n\", vaSize);\n",
    "        \n",
    "        // YOUR CODE HERE:\n",
    "        // CU_CHECK(cuMemAddressReserve(...));\n",
    "    }\n",
    "    \n",
    "    bool grow(size_t additionalBytes) {\n",
    "        // Round up to granularity\n",
    "        additionalBytes = ((additionalBytes + granularity - 1) / granularity) * granularity;\n",
    "        \n",
    "        if (physAllocated + additionalBytes > vaSize) {\n",
    "            printf(\"Cannot grow: exceeds reserved VA space\\n\");\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        // TODO Exercise 1b: Allocate physical memory\n",
    "        // Hint: cuMemCreate(&handle, additionalBytes, &prop, 0)\n",
    "        printf(\"Exercise 1b: Allocate %zu bytes of physical memory\\n\", additionalBytes);\n",
    "        \n",
    "        // YOUR CODE HERE:\n",
    "        // CUmemGenericAllocationHandle handle;\n",
    "        // CU_CHECK(cuMemCreate(&handle, additionalBytes, &prop, 0));\n",
    "        \n",
    "        // TODO Exercise 1c: Map physical to virtual\n",
    "        // Hint: cuMemMap(vaBase + physAllocated, additionalBytes, 0, handle, 0)\n",
    "        printf(\"Exercise 1c: Map physical memory to virtual address\\n\");\n",
    "        \n",
    "        // YOUR CODE HERE:\n",
    "        // CU_CHECK(cuMemMap(...));\n",
    "        \n",
    "        // TODO Exercise 1d: Set access permissions\n",
    "        // Hint: cuMemSetAccess with CU_MEM_ACCESS_FLAGS_PROT_READWRITE\n",
    "        printf(\"Exercise 1d: Set read/write access permissions\\n\");\n",
    "        \n",
    "        // YOUR CODE HERE:\n",
    "        // CUmemAccessDesc accessDesc = {};\n",
    "        // accessDesc.location = prop.location;\n",
    "        // accessDesc.flags = CU_MEM_ACCESS_FLAGS_PROT_READWRITE;\n",
    "        // CU_CHECK(cuMemSetAccess(...));\n",
    "        \n",
    "        physAllocated += additionalBytes;\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    CUdeviceptr getPtr() const { return vaBase; }\n",
    "    size_t getAllocatedSize() const { return physAllocated; }\n",
    "    size_t getReservedSize() const { return vaSize; }\n",
    "    \n",
    "    ~GrowableVMMArray() {\n",
    "        // TODO: Cleanup - unmap, release handle, free VA\n",
    "        if (vaBase) {\n",
    "            cuMemUnmap(vaBase, physAllocated);\n",
    "            cuMemAddressFree(vaBase, vaSize);\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "// Exercise 2: Sparse Matrix Block\n",
    "struct SparseBlock {\n",
    "    CUmemGenericAllocationHandle handle;\n",
    "    bool allocated;\n",
    "};\n",
    "\n",
    "// Exercise 3: Timing comparison\n",
    "void benchmarkAllocationMethods() {\n",
    "    const size_t SIZE = 1 << 24;  // 16MB\n",
    "    const int ITERATIONS = 100;\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // TODO Exercise 3: Implement timing comparison\n",
    "    // Compare:\n",
    "    // 1. cudaMalloc/cudaFree\n",
    "    // 2. cuMemCreate + cuMemMap + cuMemSetAccess / cuMemUnmap + cuMemRelease\n",
    "    \n",
    "    printf(\"\\nExercise 3: Benchmark allocation methods\\n\");\n",
    "    printf(\"Compare cudaMalloc vs VMM allocation for %zu bytes\\n\", SIZE);\n",
    "    \n",
    "    // Method 1: cudaMalloc timing\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        void* ptr;\n",
    "        cudaMalloc(&ptr, SIZE);\n",
    "        cudaFree(ptr);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float mallocMs;\n",
    "    cudaEventElapsedTime(&mallocMs, start, stop);\n",
    "    printf(\"cudaMalloc/Free: %.3f ms for %d iterations (%.3f us/alloc)\\n\", \n",
    "           mallocMs, ITERATIONS, mallocMs * 1000 / ITERATIONS);\n",
    "    \n",
    "    // YOUR CODE HERE for VMM timing comparison\n",
    "    \n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== VMM Fundamentals Exercises ===\\n\\n\");\n",
    "    \n",
    "    // Test Exercise 1: Growable array\n",
    "    printf(\"--- Exercise 1: Growable Array ---\\n\");\n",
    "    size_t maxSize = 1ULL << 30;  // Reserve 1GB VA space\n",
    "    GrowableVMMArray growable(maxSize);\n",
    "    \n",
    "    // Try growing in steps\n",
    "    size_t step = 1 << 20;  // 1MB at a time\n",
    "    for (int i = 0; i < 3; i++) {\n",
    "        printf(\"Growing by %zu bytes...\\n\", step);\n",
    "        growable.grow(step);\n",
    "        printf(\"Current allocated: %zu / %zu bytes\\n\\n\", \n",
    "               growable.getAllocatedSize(), growable.getReservedSize());\n",
    "    }\n",
    "    \n",
    "    // Exercise 3: Benchmark\n",
    "    printf(\"\\n--- Exercise 3: Allocation Benchmark ---\\n\");\n",
    "    benchmarkAllocationMethods();\n",
    "    \n",
    "    printf(\"\\n=== Exercises Complete ===\\n\");\n",
    "    printf(\"Fill in the TODO sections to complete the exercises!\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ee7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o vmm_exercises vmm_exercises.cu -lcuda && ./vmm_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b571b",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "The following exercises use Python concepts related to VMM. Note that direct VMM access requires CUDA Driver API bindings.\n",
    "\n",
    "1. **Memory pool simulation**: Create a Python class that simulates VMM behavior using NumPy arrays\n",
    "2. **Growable buffer pattern**: Implement a buffer that doubles in size using `cuda.to_device()` with copying\n",
    "3. **Allocation profiling**: Use `cuda.current_context().memory_info()` to track memory usage patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7010def",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### ğŸˆ Memory Management Patterns Learned\n",
    "\n",
    "| Pattern | Traditional | VMM Approach | Benefit |\n",
    "|---------|-------------|--------------|---------|\n",
    "| **Growable Buffers** | Reallocate + copy | Map more physical | Zero-copy growth |\n",
    "| **Large Sparse Data** | Waste memory | Reserve VA, map on-demand | Memory efficiency |\n",
    "| **Dynamic Workloads** | Over-provision | Allocate physical as needed | Cost savings |\n",
    "\n",
    "### Core VMM Concepts\n",
    "\n",
    "1. **Virtual â‰  Physical** - Reserve huge VA space (cheap!), allocate small physical memory\n",
    "2. **Granularity Alignment** - Query and respect allocation granularity requirements\n",
    "3. **Access Control** - Must explicitly set R/W permissions before kernel access\n",
    "4. **Growth Without Copy** - Map additional physical memory to reserved VA range\n",
    "\n",
    "### ğŸˆ The Elastic Balloon Model\n",
    "```\n",
    "Reserve (VA Space) â†’ Allocate (Physical) â†’ Map (Connect) â†’ Access (Permissions)\n",
    "     ğŸˆ Shape          ğŸ’¨ Air Canisters       ğŸ”— Inflate        ğŸ”“ Open Valve\n",
    "```\n",
    "\n",
    "**Next:** Stream-ordered allocation for async-friendly memory management!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
