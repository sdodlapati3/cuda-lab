{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c10def",
   "metadata": {},
   "source": [
    "## Why Custom Allocators?\n",
    "\n",
    "- **Reduce fragmentation** - Pool similar-sized allocations\n",
    "- **Avoid synchronization** - Pre-allocate memory\n",
    "- **Enable growth** - Expand without copy using VMM\n",
    "- **Application-specific** - Optimize for your workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd23296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simple_pool_allocator.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <vector>\n",
    "#include <stack>\n",
    "\n",
    "// Simple fixed-size block pool allocator\n",
    "class BlockPoolAllocator {\n",
    "    char* pool;\n",
    "    size_t blockSize;\n",
    "    size_t numBlocks;\n",
    "    std::stack<void*> freeBlocks;\n",
    "    \n",
    "public:\n",
    "    BlockPoolAllocator(size_t blockSz, size_t nBlocks) \n",
    "        : blockSize(blockSz), numBlocks(nBlocks) {\n",
    "        // Allocate entire pool\n",
    "        cudaMalloc(&pool, blockSize * numBlocks);\n",
    "        \n",
    "        // Initialize free list\n",
    "        for (size_t i = 0; i < numBlocks; i++) {\n",
    "            freeBlocks.push(pool + i * blockSize);\n",
    "        }\n",
    "        \n",
    "        printf(\"Created pool: %zu blocks of %zu bytes\\n\", numBlocks, blockSize);\n",
    "    }\n",
    "    \n",
    "    void* allocate() {\n",
    "        if (freeBlocks.empty()) return nullptr;\n",
    "        \n",
    "        void* block = freeBlocks.top();\n",
    "        freeBlocks.pop();\n",
    "        return block;\n",
    "    }\n",
    "    \n",
    "    void deallocate(void* ptr) {\n",
    "        freeBlocks.push(ptr);\n",
    "    }\n",
    "    \n",
    "    size_t available() const { return freeBlocks.size(); }\n",
    "    \n",
    "    ~BlockPoolAllocator() {\n",
    "        cudaFree(pool);\n",
    "    }\n",
    "};\n",
    "\n",
    "__global__ void useBlock(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = (float)idx;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Create pool of 1KB blocks\n",
    "    size_t blockSize = 1024 * sizeof(float);  // 4KB\n",
    "    size_t numBlocks = 100;\n",
    "    \n",
    "    BlockPoolAllocator pool(blockSize, numBlocks);\n",
    "    \n",
    "    printf(\"Available blocks: %zu\\n\", pool.available());\n",
    "    \n",
    "    // Allocate several blocks\n",
    "    std::vector<void*> allocated;\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        void* ptr = pool.allocate();\n",
    "        if (ptr) {\n",
    "            allocated.push_back(ptr);\n",
    "            useBlock<<<1, 256>>>((float*)ptr, 1024);\n",
    "        }\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    printf(\"After 10 allocations: %zu available\\n\", pool.available());\n",
    "    \n",
    "    // Return blocks to pool\n",
    "    for (void* ptr : allocated) {\n",
    "        pool.deallocate(ptr);\n",
    "    }\n",
    "    \n",
    "    printf(\"After deallocation: %zu available\\n\", pool.available());\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ebd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc simple_pool_allocator.cu -o simple_pool_allocator && ./simple_pool_allocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110a638",
   "metadata": {},
   "source": [
    "## VMM-Based Growable Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile vmm_growable_buffer.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <vector>\n",
    "\n",
    "class GrowableGPUBuffer {\n",
    "    CUdeviceptr ptr;\n",
    "    size_t reservedSize;\n",
    "    size_t mappedSize;\n",
    "    size_t granularity;\n",
    "    int device;\n",
    "    CUmemAllocationProp prop;\n",
    "    CUmemAccessDesc accessDesc;\n",
    "    std::vector<CUmemGenericAllocationHandle> handles;\n",
    "    \n",
    "public:\n",
    "    GrowableGPUBuffer(size_t maxSize) : mappedSize(0) {\n",
    "        cuInit(0);\n",
    "        cudaGetDevice(&device);\n",
    "        \n",
    "        // Setup allocation properties\n",
    "        memset(&prop, 0, sizeof(prop));\n",
    "        prop.type = CU_MEM_ALLOCATION_TYPE_PINNED;\n",
    "        prop.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n",
    "        prop.location.id = device;\n",
    "        \n",
    "        cuMemGetAllocationGranularity(&granularity, &prop,\n",
    "                                      CU_MEM_ALLOC_GRANULARITY_MINIMUM);\n",
    "        \n",
    "        // Reserve virtual address space\n",
    "        reservedSize = align(maxSize);\n",
    "        cuMemAddressReserve(&ptr, reservedSize, granularity, 0, 0);\n",
    "        \n",
    "        // Setup access descriptor\n",
    "        memset(&accessDesc, 0, sizeof(accessDesc));\n",
    "        accessDesc.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n",
    "        accessDesc.location.id = device;\n",
    "        accessDesc.flags = CU_MEM_ACCESS_FLAGS_PROT_READWRITE;\n",
    "        \n",
    "        printf(\"GrowableBuffer: Reserved %zu MB\\n\", reservedSize / (1024*1024));\n",
    "    }\n",
    "    \n",
    "    size_t align(size_t size) {\n",
    "        return ((size + granularity - 1) / granularity) * granularity;\n",
    "    }\n",
    "    \n",
    "    bool grow(size_t newSize) {\n",
    "        newSize = align(newSize);\n",
    "        if (newSize <= mappedSize) return true;\n",
    "        if (newSize > reservedSize) return false;\n",
    "        \n",
    "        size_t toMap = newSize - mappedSize;\n",
    "        \n",
    "        // Create new physical allocation\n",
    "        CUmemGenericAllocationHandle handle;\n",
    "        CUresult res = cuMemCreate(&handle, toMap, &prop, 0);\n",
    "        if (res != CUDA_SUCCESS) return false;\n",
    "        \n",
    "        // Map to virtual address\n",
    "        res = cuMemMap(ptr + mappedSize, toMap, 0, handle, 0);\n",
    "        if (res != CUDA_SUCCESS) {\n",
    "            cuMemRelease(handle);\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        // Set access\n",
    "        res = cuMemSetAccess(ptr + mappedSize, toMap, &accessDesc, 1);\n",
    "        if (res != CUDA_SUCCESS) return false;\n",
    "        \n",
    "        handles.push_back(handle);\n",
    "        mappedSize = newSize;\n",
    "        \n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    void* data() { return (void*)ptr; }\n",
    "    size_t size() { return mappedSize; }\n",
    "    size_t capacity() { return reservedSize; }\n",
    "    \n",
    "    ~GrowableGPUBuffer() {\n",
    "        cuMemUnmap(ptr, mappedSize);\n",
    "        for (auto& h : handles) cuMemRelease(h);\n",
    "        cuMemAddressFree(ptr, reservedSize);\n",
    "    }\n",
    "};\n",
    "\n",
    "__global__ void fillKernel(int* data, int n, int value) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = value;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Create buffer with 1GB max capacity\n",
    "    GrowableGPUBuffer buffer(1ULL << 30);\n",
    "    \n",
    "    // Start with 1MB\n",
    "    size_t size1 = 1 << 20;\n",
    "    buffer.grow(size1);\n",
    "    printf(\"After grow(1MB): %zu bytes mapped\\n\", buffer.size());\n",
    "    \n",
    "    int n1 = size1 / sizeof(int);\n",
    "    fillKernel<<<(n1+255)/256, 256>>>((int*)buffer.data(), n1, 1);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Grow to 100MB - NO COPY NEEDED!\n",
    "    size_t size2 = 100 << 20;\n",
    "    buffer.grow(size2);\n",
    "    printf(\"After grow(100MB): %zu bytes mapped\\n\", buffer.size());\n",
    "    \n",
    "    // Original data still at same address, new space available\n",
    "    int n2 = size2 / sizeof(int);\n",
    "    fillKernel<<<(n2+255)/256, 256>>>((int*)buffer.data() + n1, n2 - n1, 2);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Verify\n",
    "    int h_val1, h_val2;\n",
    "    cudaMemcpy(&h_val1, buffer.data(), sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(&h_val2, (int*)buffer.data() + n1, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"Original region value: %d (expected 1)\\n\", h_val1);\n",
    "    printf(\"New region value: %d (expected 2)\\n\", h_val2);\n",
    "    \n",
    "    printf(\"\\nGrowable buffer SUCCESS - no copying during growth!\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc vmm_growable_buffer.cu -o vmm_growable_buffer -lcuda && ./vmm_growable_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afefd5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Exercises\n",
    "\n",
    "### ðŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Complete these exercises to practice custom allocator design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile custom_allocator_exercises.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <vector>\n",
    "#include <stack>\n",
    "#include <map>\n",
    "\n",
    "/*\n",
    " * Custom Allocator Exercises\n",
    " * \n",
    " * Exercise 1: Slab Allocator\n",
    " * - Manage multiple size classes (small, medium, large)\n",
    " * - Each size class has its own pool\n",
    " * - Reduces fragmentation for varied allocation sizes\n",
    " * \n",
    " * Exercise 2: Buddy Allocator\n",
    " * - Binary tree-based allocation\n",
    " * - Efficient splitting and coalescing\n",
    " * - Power-of-2 sizes\n",
    " * \n",
    " * Exercise 3: Arena Allocator with VMM\n",
    " * - Fast bump-pointer allocation\n",
    " * - Expand arena using VMM when needed\n",
    " * - Bulk deallocation (reset)\n",
    " */\n",
    "\n",
    "#define CU_CHECK(call) do { \\\n",
    "    CUresult err = call; \\\n",
    "    if (err != CUDA_SUCCESS) { \\\n",
    "        const char* errStr; \\\n",
    "        cuGetErrorString(err, &errStr); \\\n",
    "        printf(\"CUDA Driver Error: %s at %s:%d\\n\", errStr, __FILE__, __LINE__); \\\n",
    "        exit(1); \\\n",
    "    } \\\n",
    "} while(0)\n",
    "\n",
    "#define CUDA_CHECK(call) do { \\\n",
    "    cudaError_t err = call; \\\n",
    "    if (err != cudaSuccess) { \\\n",
    "        printf(\"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(err), __FILE__, __LINE__); \\\n",
    "        exit(1); \\\n",
    "    } \\\n",
    "} while(0)\n",
    "\n",
    "// Exercise 1: Slab Allocator\n",
    "class SlabAllocator {\n",
    "    struct Slab {\n",
    "        char* base;\n",
    "        size_t blockSize;\n",
    "        size_t numBlocks;\n",
    "        std::stack<void*> freeList;\n",
    "    };\n",
    "    \n",
    "    std::map<size_t, Slab> slabs;  // size class -> slab\n",
    "    \n",
    "public:\n",
    "    SlabAllocator() {\n",
    "        // TODO Exercise 1a: Initialize size classes\n",
    "        // Common sizes: 256B, 1KB, 4KB, 16KB, 64KB\n",
    "        printf(\"Exercise 1: Slab Allocator\\n\");\n",
    "        printf(\"Initialize size classes: 256B, 1KB, 4KB, 16KB, 64KB\\n\\n\");\n",
    "        \n",
    "        // YOUR CODE HERE:\n",
    "        // std::vector<size_t> sizes = {256, 1024, 4096, 16384, 65536};\n",
    "        // for (size_t sz : sizes) {\n",
    "        //     initSlab(sz, 100);  // 100 blocks per slab\n",
    "        // }\n",
    "    }\n",
    "    \n",
    "    void initSlab(size_t blockSize, size_t numBlocks) {\n",
    "        Slab slab;\n",
    "        slab.blockSize = blockSize;\n",
    "        slab.numBlocks = numBlocks;\n",
    "        \n",
    "        // Allocate slab memory\n",
    "        CUDA_CHECK(cudaMalloc(&slab.base, blockSize * numBlocks));\n",
    "        \n",
    "        // Initialize free list\n",
    "        for (size_t i = 0; i < numBlocks; i++) {\n",
    "            slab.freeList.push(slab.base + i * blockSize);\n",
    "        }\n",
    "        \n",
    "        slabs[blockSize] = slab;\n",
    "        printf(\"Created slab: %zu blocks of %zu bytes\\n\", numBlocks, blockSize);\n",
    "    }\n",
    "    \n",
    "    void* allocate(size_t size) {\n",
    "        // TODO Exercise 1b: Find appropriate size class\n",
    "        // Round up to nearest size class\n",
    "        \n",
    "        // YOUR CODE HERE:\n",
    "        // for (auto& [blockSize, slab] : slabs) {\n",
    "        //     if (size <= blockSize && !slab.freeList.empty()) {\n",
    "        //         void* ptr = slab.freeList.top();\n",
    "        //         slab.freeList.pop();\n",
    "        //         return ptr;\n",
    "        //     }\n",
    "        // }\n",
    "        \n",
    "        printf(\"Allocate %zu bytes - find matching slab\\n\", size);\n",
    "        return nullptr;\n",
    "    }\n",
    "    \n",
    "    void deallocate(void* ptr, size_t size) {\n",
    "        // TODO Exercise 1c: Return to appropriate slab\n",
    "        // YOUR CODE HERE\n",
    "        printf(\"Deallocate pointer back to slab\\n\");\n",
    "    }\n",
    "    \n",
    "    void printStats() {\n",
    "        printf(\"\\nSlab Statistics:\\n\");\n",
    "        for (auto& [blockSize, slab] : slabs) {\n",
    "            size_t used = slab.numBlocks - slab.freeList.size();\n",
    "            printf(\"  %zu B: %zu/%zu used\\n\", blockSize, used, slab.numBlocks);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ~SlabAllocator() {\n",
    "        for (auto& [_, slab] : slabs) {\n",
    "            cudaFree(slab.base);\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "// Exercise 2: Simple Buddy Allocator\n",
    "class BuddyAllocator {\n",
    "    char* pool;\n",
    "    size_t poolSize;\n",
    "    size_t minBlockSize;\n",
    "    int levels;\n",
    "    \n",
    "    // Bitmap for tracking allocations at each level\n",
    "    std::vector<std::vector<bool>> allocated;\n",
    "    \n",
    "public:\n",
    "    BuddyAllocator(size_t size, size_t minBlock = 256) \n",
    "        : minBlockSize(minBlock) {\n",
    "        // Round up to power of 2\n",
    "        poolSize = 1;\n",
    "        while (poolSize < size) poolSize <<= 1;\n",
    "        \n",
    "        // Calculate levels\n",
    "        levels = 0;\n",
    "        size_t s = poolSize;\n",
    "        while (s >= minBlockSize) {\n",
    "            levels++;\n",
    "            s >>= 1;\n",
    "        }\n",
    "        \n",
    "        printf(\"Exercise 2: Buddy Allocator\\n\");\n",
    "        printf(\"Pool size: %zu, Min block: %zu, Levels: %d\\n\\n\", \n",
    "               poolSize, minBlockSize, levels);\n",
    "        \n",
    "        // TODO Exercise 2a: Allocate pool memory\n",
    "        // CUDA_CHECK(cudaMalloc(&pool, poolSize));\n",
    "        \n",
    "        // TODO Exercise 2b: Initialize allocation bitmaps\n",
    "        // allocated.resize(levels);\n",
    "        // for (int i = 0; i < levels; i++) {\n",
    "        //     allocated[i].resize(1 << i, false);\n",
    "        // }\n",
    "    }\n",
    "    \n",
    "    void* allocate(size_t size) {\n",
    "        // TODO Exercise 2c: Find appropriate level and allocate\n",
    "        // 1. Round size up to power of 2\n",
    "        // 2. Find the level for this size\n",
    "        // 3. Find a free block at this level (split larger if needed)\n",
    "        // 4. Mark block as allocated\n",
    "        \n",
    "        printf(\"Allocate %zu bytes using buddy algorithm\\n\", size);\n",
    "        return nullptr;\n",
    "    }\n",
    "    \n",
    "    void deallocate(void* ptr, size_t size) {\n",
    "        // TODO Exercise 2d: Deallocate and coalesce\n",
    "        // 1. Find the block in the tree\n",
    "        // 2. Mark as free\n",
    "        // 3. Check if buddy is also free\n",
    "        // 4. If so, coalesce and repeat at parent level\n",
    "        \n",
    "        printf(\"Deallocate and coalesce with buddy if free\\n\");\n",
    "    }\n",
    "    \n",
    "    ~BuddyAllocator() {\n",
    "        if (pool) cudaFree(pool);\n",
    "    }\n",
    "};\n",
    "\n",
    "// Exercise 3: Arena Allocator with VMM\n",
    "class VMMArenaAllocator {\n",
    "    CUdeviceptr vaBase;\n",
    "    size_t vaSize;         // Total reserved VA\n",
    "    size_t committed;      // Currently mapped physical memory\n",
    "    size_t used;           // Current allocation offset\n",
    "    size_t granularity;\n",
    "    CUmemAllocationProp prop;\n",
    "    std::vector<CUmemGenericAllocationHandle> handles;\n",
    "    \n",
    "public:\n",
    "    VMMArenaAllocator(size_t maxSize) : vaSize(maxSize), committed(0), used(0) {\n",
    "        printf(\"Exercise 3: VMM Arena Allocator\\n\");\n",
    "        printf(\"Reserve %zu bytes of virtual address space\\n\\n\", maxSize);\n",
    "        \n",
    "        cuInit(0);\n",
    "        \n",
    "        int device;\n",
    "        cudaGetDevice(&device);\n",
    "        \n",
    "        memset(&prop, 0, sizeof(prop));\n",
    "        prop.type = CU_MEM_ALLOCATION_TYPE_PINNED;\n",
    "        prop.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n",
    "        prop.location.id = device;\n",
    "        \n",
    "        CU_CHECK(cuMemGetAllocationGranularity(&granularity, &prop, \n",
    "                                                CU_MEM_ALLOC_GRANULARITY_MINIMUM));\n",
    "        \n",
    "        // TODO Exercise 3a: Reserve virtual address range\n",
    "        // vaSize = ((vaSize + granularity - 1) / granularity) * granularity;\n",
    "        // CU_CHECK(cuMemAddressReserve(&vaBase, vaSize, granularity, 0, 0));\n",
    "        \n",
    "        printf(\"Arena initialized with granularity: %zu bytes\\n\", granularity);\n",
    "    }\n",
    "    \n",
    "    void* allocate(size_t size) {\n",
    "        // Align to 256 bytes\n",
    "        size = ((size + 255) / 256) * 256;\n",
    "        \n",
    "        // TODO Exercise 3b: Expand if needed\n",
    "        if (used + size > committed) {\n",
    "            size_t needed = used + size - committed;\n",
    "            needed = ((needed + granularity - 1) / granularity) * granularity;\n",
    "            \n",
    "            printf(\"Expanding arena by %zu bytes\\n\", needed);\n",
    "            \n",
    "            // YOUR CODE HERE:\n",
    "            // CUmemGenericAllocationHandle handle;\n",
    "            // CU_CHECK(cuMemCreate(&handle, needed, &prop, 0));\n",
    "            // CU_CHECK(cuMemMap(vaBase + committed, needed, 0, handle, 0));\n",
    "            // \n",
    "            // CUmemAccessDesc accessDesc = {};\n",
    "            // accessDesc.location = prop.location;\n",
    "            // accessDesc.flags = CU_MEM_ACCESS_FLAGS_PROT_READWRITE;\n",
    "            // CU_CHECK(cuMemSetAccess(vaBase + committed, needed, &accessDesc, 1));\n",
    "            // \n",
    "            // handles.push_back(handle);\n",
    "            // committed += needed;\n",
    "        }\n",
    "        \n",
    "        // Bump allocation\n",
    "        void* ptr = (void*)(vaBase + used);\n",
    "        used += size;\n",
    "        \n",
    "        printf(\"Allocated %zu bytes at offset %zu\\n\", size, used - size);\n",
    "        return ptr;\n",
    "    }\n",
    "    \n",
    "    void reset() {\n",
    "        // TODO Exercise 3c: Reset arena (keep memory mapped)\n",
    "        printf(\"Reset arena - used: %zu -> 0, committed: %zu (unchanged)\\n\", \n",
    "               used, committed);\n",
    "        used = 0;\n",
    "    }\n",
    "    \n",
    "    size_t getUsed() const { return used; }\n",
    "    size_t getCommitted() const { return committed; }\n",
    "    size_t getReserved() const { return vaSize; }\n",
    "    \n",
    "    ~VMMArenaAllocator() {\n",
    "        // Cleanup\n",
    "        if (vaBase) {\n",
    "            cuMemUnmap(vaBase, committed);\n",
    "            for (auto& handle : handles) {\n",
    "                cuMemRelease(handle);\n",
    "            }\n",
    "            cuMemAddressFree(vaBase, vaSize);\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "// Test kernel\n",
    "__global__ void testKernel(int* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = idx;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Custom Allocator Exercises ===\\n\\n\");\n",
    "    \n",
    "    // Exercise 1: Slab Allocator\n",
    "    printf(\"--- Exercise 1: Slab Allocator ---\\n\");\n",
    "    SlabAllocator slab;\n",
    "    // Test allocations of various sizes\n",
    "    printf(\"Test allocating: 100B, 500B, 2KB, 10KB\\n\");\n",
    "    void* p1 = slab.allocate(100);   // Should use 256B slab\n",
    "    void* p2 = slab.allocate(500);   // Should use 1KB slab\n",
    "    void* p3 = slab.allocate(2048);  // Should use 4KB slab\n",
    "    void* p4 = slab.allocate(10000); // Should use 16KB slab\n",
    "    slab.printStats();\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    // Exercise 2: Buddy Allocator\n",
    "    printf(\"--- Exercise 2: Buddy Allocator ---\\n\");\n",
    "    BuddyAllocator buddy(1 << 20, 256);  // 1MB pool, 256B minimum\n",
    "    printf(\"Test allocating: 1KB, 4KB, 16KB\\n\");\n",
    "    void* b1 = buddy.allocate(1024);\n",
    "    void* b2 = buddy.allocate(4096);\n",
    "    void* b3 = buddy.allocate(16384);\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    // Exercise 3: VMM Arena\n",
    "    printf(\"--- Exercise 3: VMM Arena Allocator ---\\n\");\n",
    "    VMMArenaAllocator arena(1ULL << 30);  // 1GB reserve\n",
    "    printf(\"Test sequential allocations:\\n\");\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        arena.allocate(1 << 20);  // 1MB each\n",
    "    }\n",
    "    printf(\"Used: %zu, Committed: %zu, Reserved: %zu\\n\",\n",
    "           arena.getUsed(), arena.getCommitted(), arena.getReserved());\n",
    "    \n",
    "    printf(\"Reset arena...\\n\");\n",
    "    arena.reset();\n",
    "    printf(\"After reset - Used: %zu\\n\", arena.getUsed());\n",
    "    \n",
    "    printf(\"\\n=== Exercises Complete ===\\n\");\n",
    "    printf(\"Uncomment TODO sections to implement each allocator!\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff87a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o custom_allocator_exercises custom_allocator_exercises.cu -lcuda && ./custom_allocator_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b53c29",
   "metadata": {},
   "source": [
    "### ðŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "The following exercises explore allocator concepts in Python:\n",
    "\n",
    "1. **Pool allocator simulation**: Implement a Python class that pre-allocates device arrays and manages a free list\n",
    "2. **Memory tracking**: Create a wrapper around `cuda.to_device()` that tracks allocations and reports fragmentation\n",
    "3. **Arena pattern**: Implement a bump allocator using a pre-allocated NumPy/CuPy array with offset tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b78f0a",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Block pools** - Fast allocation for fixed-size objects\n",
    "2. **VMM growable** - Expand without copying\n",
    "3. **Pre-allocation** - Avoid runtime allocation overhead\n",
    "4. **Application-specific** - Design for your workload patterns"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
