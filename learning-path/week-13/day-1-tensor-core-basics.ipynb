{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"âš ï¸  CUDA C++ is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb2fb0",
   "metadata": {},
   "source": [
    "# Day 1: Tensor Core Basics - The Matrix Multiplication Accelerators\n",
    "\n",
    "> **\"Why use one LEGO brick at a time when you can snap together entire 4Ã—4 blocks in a single motion?\"** That's the power of Tensor Cores!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this session, you will:\n",
    "1. **Understand** what Tensor Cores are and why they deliver 8-16Ã— speedups\n",
    "2. **Compare** CUDA Core vs Tensor Core execution models\n",
    "3. **Identify** supported precision formats (FP16, TF32, BF16, INT8)\n",
    "4. **Recognize** when to leverage Tensor Cores in your applications\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¨ Concept Card: LEGO Brick Assembly\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ğŸ§± TENSOR CORES = LEGO BLOCK FACTORY                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  CUDA Core (One Brick at a Time):                               â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â” + â”Œâ”€â”€â”€â” = â”Œâ”€â”€â”€â”                                          â”‚\n",
    "â”‚  â”‚ Ã— â”‚   â”‚ + â”‚   â”‚ = â”‚   One FMA, one result                    â”‚\n",
    "â”‚  â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜                                          â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Tensor Core (Entire 4Ã—4 Block at Once):                        â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”     â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”     â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ A â”‚ A â”‚ A â”‚ A â”‚     â”‚ B â”‚ B â”‚ B â”‚ B â”‚     â”‚ C â”‚ C â”‚ C â”‚ C â”‚  â”‚\n",
    "â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  Ã—  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  +  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”‚\n",
    "â”‚  â”‚ A â”‚ A â”‚ A â”‚ A â”‚     â”‚ B â”‚ B â”‚ B â”‚ B â”‚     â”‚ C â”‚ C â”‚ C â”‚ C â”‚  â”‚\n",
    "â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”‚\n",
    "â”‚  â”‚ A â”‚ A â”‚ A â”‚ A â”‚     â”‚ B â”‚ B â”‚ B â”‚ B â”‚     â”‚ C â”‚ C â”‚ C â”‚ C â”‚  â”‚\n",
    "â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”‚\n",
    "â”‚  â”‚ A â”‚ A â”‚ A â”‚ A â”‚     â”‚ B â”‚ B â”‚ B â”‚ B â”‚     â”‚ C â”‚ C â”‚ C â”‚ C â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜     â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜     â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜  â”‚\n",
    "â”‚         â”‚                     â”‚                     â”‚           â”‚\n",
    "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â”‚                               â–¼                                 â”‚\n",
    "â”‚                    64 FMAs in ONE operation!                    â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  ğŸ’¡ Key Insight:                                                â”‚\n",
    "â”‚  â€¢ CUDA Core:   1 operation per cycle                           â”‚\n",
    "â”‚  â€¢ Tensor Core: 64 operations per cycle (128 FLOPs!)            â”‚\n",
    "â”‚  â€¢ Like assembling a 4Ã—4 LEGO section vs individual bricks      â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: What Are Tensor Cores?\n",
    "\n",
    "### CUDA Cores vs Tensor Cores\n",
    "\n",
    "```\n",
    "CUDA Core (Traditional):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  One FMA per cycle                  â”‚\n",
    "â”‚  D = A Ã— B + C                      â”‚\n",
    "â”‚  (scalar operation)                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Tensor Core:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  4Ã—4Ã—4 Matrix FMA per cycle         â”‚\n",
    "â”‚  D[4Ã—4] = A[4Ã—4] Ã— B[4Ã—4] + C[4Ã—4]  â”‚\n",
    "â”‚  (64 FMAs = 128 operations!)        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Tensor Core Pipeline\n",
    "\n",
    "```\n",
    "Warp (32 threads) cooperates on:\n",
    "\n",
    "    A (16Ã—16)      B (16Ã—16)      C (16Ã—16)\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ FP16 â”‚   Ã—   â”‚ FP16 â”‚   +   â”‚ FP32 â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚              â”‚              â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â–¼\n",
    "                   D (16Ã—16)\n",
    "                   â”Œâ”€â”€â”€â”€â”€â”€â”\n",
    "                   â”‚ FP32 â”‚\n",
    "                   â””â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "One WMMA operation = 16Ã—16Ã—16 matrix multiply\n",
    "```\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "| GPU | FP32 CUDA Cores | FP16 Tensor Cores |\n",
    "|-----|-----------------|-------------------|\n",
    "| V100 | 15.7 TFLOPS | 125 TFLOPS |\n",
    "| A100 | 19.5 TFLOPS | 312 TFLOPS |\n",
    "| H100 | 67 TFLOPS | 989 TFLOPS |\n",
    "\n",
    "**8-16Ã— speedup for matrix operations!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ce114",
   "metadata": {},
   "source": [
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b679ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tensor_core_check.cu\n",
    "// tensor_core_check.cu - Check Tensor Core support\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "void checkTensorCoreSupport() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    printf(\"=== Tensor Core Support Check ===\\n\\n\");\n",
    "    \n",
    "    for (int i = 0; i < deviceCount; i++) {\n",
    "        cudaDeviceProp prop;\n",
    "        cudaGetDeviceProperties(&prop, i);\n",
    "        \n",
    "        printf(\"Device %d: %s\\n\", i, prop.name);\n",
    "        printf(\"  Compute Capability: %d.%d\\n\", prop.major, prop.minor);\n",
    "        \n",
    "        // Tensor Cores require SM 7.0+\n",
    "        int smVersion = prop.major * 10 + prop.minor;\n",
    "        \n",
    "        if (smVersion >= 70) {\n",
    "            printf(\"  Tensor Cores: âœ… SUPPORTED\\n\");\n",
    "            \n",
    "            // Determine supported data types\n",
    "            printf(\"  Supported Types:\\n\");\n",
    "            printf(\"    - FP16 (half precision)\\n\");\n",
    "            \n",
    "            if (smVersion >= 75) {\n",
    "                printf(\"    - INT8, INT4\\n\");\n",
    "            }\n",
    "            if (smVersion >= 80) {\n",
    "                printf(\"    - BF16 (bfloat16)\\n\");\n",
    "                printf(\"    - TF32 (TensorFloat-32)\\n\");\n",
    "            }\n",
    "            if (smVersion >= 90) {\n",
    "                printf(\"    - FP8\\n\");\n",
    "            }\n",
    "        } else {\n",
    "            printf(\"  Tensor Cores: âŒ NOT SUPPORTED (need SM 7.0+)\\n\");\n",
    "        }\n",
    "        \n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    checkTensorCoreSupport();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o tensor_core_check tensor_core_check.cu\n",
    "!./tensor_core_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57707c62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: WMMA (Warp Matrix Multiply-Accumulate)\n",
    "\n",
    "### WMMA Fragment Types\n",
    "\n",
    "```\n",
    "WMMA API uses \"fragments\" - distributed matrix pieces:\n",
    "\n",
    "fragment<matrix_a, M, N, K, half, row_major> a_frag;\n",
    "fragment<matrix_b, M, N, K, half, col_major> b_frag;\n",
    "fragment<accumulator, M, N, K, float> c_frag;\n",
    "\n",
    "Supported shapes (MÃ—NÃ—K):\n",
    "  - 16Ã—16Ã—16 (most common)\n",
    "  - 32Ã—8Ã—16\n",
    "  - 8Ã—32Ã—16\n",
    "```\n",
    "\n",
    "### WMMA Operations\n",
    "\n",
    "```cpp\n",
    "// 1. Load matrices into fragments\n",
    "load_matrix_sync(a_frag, A_ptr, lda);\n",
    "load_matrix_sync(b_frag, B_ptr, ldb);\n",
    "fill_fragment(c_frag, 0.0f);\n",
    "\n",
    "// 2. Matrix multiply-accumulate\n",
    "mma_sync(c_frag, a_frag, b_frag, c_frag);\n",
    "\n",
    "// 3. Store result\n",
    "store_matrix_sync(C_ptr, c_frag, ldc, mem_row_major);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7c816",
   "metadata": {},
   "source": [
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wmma_basic.cu\n",
    "// wmma_basic.cu - Basic WMMA example\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <mma.h>\n",
    "#include <cuda_fp16.h>\n",
    "\n",
    "using namespace nvcuda;\n",
    "\n",
    "// WMMA dimensions\n",
    "const int WMMA_M = 16;\n",
    "const int WMMA_N = 16;\n",
    "const int WMMA_K = 16;\n",
    "\n",
    "__global__ void wmma_matmul_simple(\n",
    "    half* A, half* B, float* C,\n",
    "    int M, int N, int K\n",
    ") {\n",
    "    // Each warp computes one 16x16 tile of C\n",
    "    int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / 32;\n",
    "    int warpN = blockIdx.y;\n",
    "    \n",
    "    // Bounds check\n",
    "    if (warpM * WMMA_M >= M || warpN * WMMA_N >= N) return;\n",
    "    \n",
    "    // Declare fragments\n",
    "    wmma::fragment<wmma::matrix_a, WMMA_M, WMMA_N, WMMA_K, half, wmma::row_major> a_frag;\n",
    "    wmma::fragment<wmma::matrix_b, WMMA_M, WMMA_N, WMMA_K, half, wmma::col_major> b_frag;\n",
    "    wmma::fragment<wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, float> c_frag;\n",
    "    \n",
    "    // Initialize accumulator to zero\n",
    "    wmma::fill_fragment(c_frag, 0.0f);\n",
    "    \n",
    "    // Loop over K dimension in tiles of WMMA_K\n",
    "    for (int k = 0; k < K; k += WMMA_K) {\n",
    "        int aRow = warpM * WMMA_M;\n",
    "        int aCol = k;\n",
    "        int bRow = k;\n",
    "        int bCol = warpN * WMMA_N;\n",
    "        \n",
    "        // Load A and B tiles\n",
    "        wmma::load_matrix_sync(a_frag, A + aRow * K + aCol, K);\n",
    "        wmma::load_matrix_sync(b_frag, B + bRow * N + bCol, N);\n",
    "        \n",
    "        // Perform matrix multiply-accumulate\n",
    "        wmma::mma_sync(c_frag, a_frag, b_frag, c_frag);\n",
    "    }\n",
    "    \n",
    "    // Store result\n",
    "    int cRow = warpM * WMMA_M;\n",
    "    int cCol = warpN * WMMA_N;\n",
    "    wmma::store_matrix_sync(C + cRow * N + cCol, c_frag, N, wmma::mem_row_major);\n",
    "}\n",
    "\n",
    "// Helper to convert float to half\n",
    "__global__ void float2half(float* in, half* out, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        out[idx] = __float2half(in[idx]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int M = 256, N = 256, K = 256;\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float *h_A = new float[M * K];\n",
    "    float *h_B = new float[K * N];\n",
    "    float *h_C = new float[M * N];\n",
    "    \n",
    "    // Initialize with simple values\n",
    "    for (int i = 0; i < M * K; i++) h_A[i] = 1.0f;\n",
    "    for (int i = 0; i < K * N; i++) h_B[i] = 1.0f;\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_A_float, *d_B_float, *d_C;\n",
    "    half *d_A, *d_B;\n",
    "    \n",
    "    cudaMalloc(&d_A_float, M * K * sizeof(float));\n",
    "    cudaMalloc(&d_B_float, K * N * sizeof(float));\n",
    "    cudaMalloc(&d_A, M * K * sizeof(half));\n",
    "    cudaMalloc(&d_B, K * N * sizeof(half));\n",
    "    cudaMalloc(&d_C, M * N * sizeof(float));\n",
    "    \n",
    "    // Copy and convert to half precision\n",
    "    cudaMemcpy(d_A_float, h_A, M * K * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B_float, h_B, K * N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    float2half<<<(M*K+255)/256, 256>>>(d_A_float, d_A, M*K);\n",
    "    float2half<<<(K*N+255)/256, 256>>>(d_B_float, d_B, K*N);\n",
    "    \n",
    "    // Launch WMMA kernel\n",
    "    // Each block has 4 warps (128 threads), each warp handles 16x16 tile\n",
    "    dim3 block(128);\n",
    "    dim3 grid((M / WMMA_M + 3) / 4, N / WMMA_N);\n",
    "    \n",
    "    // Warmup\n",
    "    wmma_matmul_simple<<<grid, block>>>(d_A, d_B, d_C, M, N, K);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Benchmark\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        wmma_matmul_simple<<<grid, block>>>(d_A, d_B, d_C, M, N, K);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    // Copy result back\n",
    "    cudaMemcpy(h_C, d_C, M * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Verify (each element should be K = 256)\n",
    "    printf(\"WMMA Matrix Multiply Results:\\n\");\n",
    "    printf(\"  Matrix size: %d x %d x %d\\n\", M, N, K);\n",
    "    printf(\"  C[0,0] = %.1f (expected: %d)\\n\", h_C[0], K);\n",
    "    printf(\"  C[M-1,N-1] = %.1f (expected: %d)\\n\", h_C[M*N-1], K);\n",
    "    printf(\"  Time: %.3f ms (100 iterations)\\n\", ms);\n",
    "    printf(\"  Avg time: %.3f ms\\n\", ms / 100);\n",
    "    \n",
    "    // Calculate TFLOPS\n",
    "    double flops = 2.0 * M * N * K;  // multiply-add = 2 ops\n",
    "    double tflops = (flops * 100) / (ms * 1e9);\n",
    "    printf(\"  Performance: %.2f TFLOPS\\n\", tflops);\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] h_A; delete[] h_B; delete[] h_C;\n",
    "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
    "    cudaFree(d_A_float); cudaFree(d_B_float);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o wmma_basic wmma_basic.cu\n",
    "!./wmma_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4206b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Data Types for Tensor Cores\n",
    "\n",
    "### Precision Hierarchy\n",
    "\n",
    "```\n",
    "FP32 (32-bit float)\n",
    "â”œâ”€â”€ Full precision, traditional CUDA\n",
    "â”œâ”€â”€ 1 sign + 8 exp + 23 mantissa\n",
    "â””â”€â”€ Range: Â±3.4 Ã— 10^38\n",
    "\n",
    "TF32 (TensorFloat-32) - Ampere+\n",
    "â”œâ”€â”€ 19-bit format (stored as FP32)\n",
    "â”œâ”€â”€ 1 sign + 8 exp + 10 mantissa  \n",
    "â”œâ”€â”€ Same range as FP32, less precision\n",
    "â””â”€â”€ Automatic in cuBLAS!\n",
    "\n",
    "FP16 (16-bit half)\n",
    "â”œâ”€â”€ 1 sign + 5 exp + 10 mantissa\n",
    "â”œâ”€â”€ Range: Â±65,504\n",
    "â””â”€â”€ 2x memory bandwidth\n",
    "\n",
    "BF16 (bfloat16) - Ampere+\n",
    "â”œâ”€â”€ 1 sign + 8 exp + 7 mantissa\n",
    "â”œâ”€â”€ Same range as FP32\n",
    "â””â”€â”€ Truncated FP32, easy conversion\n",
    "```\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "| Type | Best For | Gotchas |\n",
    "|------|----------|--------|\n",
    "| FP32 | Baseline, accumulation | Slow on Tensor Cores |\n",
    "| TF32 | Drop-in FP32 speedup | Ampere+ only |\n",
    "| FP16 | Training, inference | Narrow range, overflow |\n",
    "| BF16 | Training stability | Ampere+ only |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd2931",
   "metadata": {},
   "source": [
    "### ğŸ”· CUDA C++ Implementation (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94050062",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile data_types.cu\n",
    "// data_types.cu - Understanding FP16, BF16, TF32\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cuda_fp16.h>\n",
    "\n",
    "// Analyze floating point representations\n",
    "void analyzeFloat(float val) {\n",
    "    printf(\"\\nAnalyzing: %f\\n\", val);\n",
    "    \n",
    "    // FP32 bits\n",
    "    unsigned int* fp32_bits = (unsigned int*)&val;\n",
    "    printf(\"  FP32: 0x%08X\\n\", *fp32_bits);\n",
    "    printf(\"    Sign: %d, Exp: %d, Mantissa: 0x%06X\\n\",\n",
    "           (*fp32_bits >> 31) & 1,\n",
    "           ((*fp32_bits >> 23) & 0xFF) - 127,\n",
    "           *fp32_bits & 0x7FFFFF);\n",
    "    \n",
    "    // Convert to FP16\n",
    "    half h_val = __float2half(val);\n",
    "    unsigned short* fp16_bits = (unsigned short*)&h_val;\n",
    "    printf(\"  FP16: 0x%04X\\n\", *fp16_bits);\n",
    "    printf(\"    Sign: %d, Exp: %d, Mantissa: 0x%03X\\n\",\n",
    "           (*fp16_bits >> 15) & 1,\n",
    "           ((*fp16_bits >> 10) & 0x1F) - 15,\n",
    "           *fp16_bits & 0x3FF);\n",
    "    \n",
    "    // Round-trip precision loss\n",
    "    float back = __half2float(h_val);\n",
    "    printf(\"  Round-trip: %f -> FP16 -> %f (error: %e)\\n\",\n",
    "           val, back, fabs(val - back));\n",
    "}\n",
    "\n",
    "__global__ void fp16_overflow_demo(half* out) {\n",
    "    // FP16 max is ~65504\n",
    "    half a = __float2half(60000.0f);\n",
    "    half b = __float2half(60000.0f);\n",
    "    half c = __hadd(a, b);  // Will overflow!\n",
    "    out[0] = c;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Floating Point Data Types ===\\n\");\n",
    "    \n",
    "    analyzeFloat(1.0f);\n",
    "    analyzeFloat(3.14159f);\n",
    "    analyzeFloat(0.00001f);\n",
    "    analyzeFloat(65504.0f);  // FP16 max\n",
    "    \n",
    "    // Demonstrate FP16 overflow\n",
    "    printf(\"\\n=== FP16 Overflow Demo ===\\n\");\n",
    "    half *d_out, h_out;\n",
    "    cudaMalloc(&d_out, sizeof(half));\n",
    "    fp16_overflow_demo<<<1, 1>>>(d_out);\n",
    "    cudaMemcpy(&h_out, d_out, sizeof(half), cudaMemcpyDeviceToHost);\n",
    "    printf(\"60000 + 60000 in FP16 = %f (overflow!)\\n\", __half2float(h_out));\n",
    "    \n",
    "    // Show FP16 range limits\n",
    "    printf(\"\\n=== FP16 Limits ===\\n\");\n",
    "    printf(\"  Max positive: 65504\\n\");\n",
    "    printf(\"  Min positive (normalized): ~6.1e-5\\n\");\n",
    "    printf(\"  Min positive (denorm): ~5.96e-8\\n\");\n",
    "    \n",
    "    cudaFree(d_out);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4429453",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o data_types data_types.cu\n",
    "!./data_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c113df5",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba (Optional - Quick Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd75a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python - Understanding precision differences\n",
    "import numpy as np\n",
    "\n",
    "def compare_precisions():\n",
    "    \"\"\"Compare FP32 vs FP16 precision.\"\"\"\n",
    "    print(\"Precision Comparison\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test values\n",
    "    values = [1.0, 3.14159, 0.00001, 65504.0, 70000.0]\n",
    "    \n",
    "    for v in values:\n",
    "        fp32 = np.float32(v)\n",
    "        fp16 = np.float16(v)\n",
    "        error = abs(float(fp32) - float(fp16))\n",
    "        \n",
    "        print(f\"\\nValue: {v}\")\n",
    "        print(f\"  FP32: {fp32}\")\n",
    "        print(f\"  FP16: {fp16}\")\n",
    "        print(f\"  Error: {error}\")\n",
    "        \n",
    "        if np.isinf(fp16):\n",
    "            print(\"  âš ï¸ OVERFLOW in FP16!\")\n",
    "\n",
    "compare_precisions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac80350",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Tensor Core Requirements\n",
    "\n",
    "### Memory Alignment\n",
    "\n",
    "```\n",
    "Tensor Cores require aligned memory:\n",
    "\n",
    "  âœ… Aligned (works):    address % 256 == 0\n",
    "  âŒ Unaligned (slow):   random address\n",
    "\n",
    "Leading dimension constraints:\n",
    "  - Must be multiple of 8 for FP16\n",
    "  - Must be multiple of 4 for TF32\n",
    "```\n",
    "\n",
    "### Matrix Shape Requirements\n",
    "\n",
    "```\n",
    "M, N, K should be multiples of:\n",
    "  - 16 for FP16 WMMA\n",
    "  - 8 for TF32\n",
    "\n",
    "For non-conforming sizes:\n",
    "  1. Pad matrices to required multiple\n",
    "  2. Or handle edge tiles specially\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80611dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_core_requirements():\n",
    "    \"\"\"Print Tensor Core requirements.\"\"\"\n",
    "    print(\"Tensor Core Requirements Checklist\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"1. GPU REQUIREMENTS\")\n",
    "    print(\"   â–¡ Compute Capability 7.0+ (Volta, Turing, Ampere)\")\n",
    "    print(\"   â–¡ Tensor Cores present\")\n",
    "    print()\n",
    "    print(\"2. MATRIX DIMENSIONS\")\n",
    "    print(\"   â–¡ M, N, K multiples of 16 (FP16 WMMA)\")\n",
    "    print(\"   â–¡ M, N, K multiples of 8 (TF32)\")\n",
    "    print(\"   â–¡ Or handle edge tiles explicitly\")\n",
    "    print()\n",
    "    print(\"3. MEMORY ALIGNMENT\")\n",
    "    print(\"   â–¡ Matrix pointers 256-byte aligned\")\n",
    "    print(\"   â–¡ Leading dimensions multiple of 8 (FP16)\")\n",
    "    print(\"   â–¡ Use cudaMalloc (automatically aligned)\")\n",
    "    print()\n",
    "    print(\"4. DATA TYPES\")\n",
    "    print(\"   â–¡ Input: FP16 (half), BF16, TF32, or INT8\")\n",
    "    print(\"   â–¡ Accumulator: FP32 or FP16\")\n",
    "    print()\n",
    "    print(\"5. THREAD ORGANIZATION\")\n",
    "    print(\"   â–¡ Warp-level operations (32 threads)\")\n",
    "    print(\"   â–¡ All threads in warp must participate\")\n",
    "\n",
    "tensor_core_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a7e17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17331d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tensor_core_exercises.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <cuda_fp16.h>\n",
    "#include <mma.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "using namespace nvcuda;\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA Error: %s at line %d\\n\", cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 1: Check GPU Tensor Core Support\n",
    "// ============================================================\n",
    "\n",
    "void exercise1_checkTensorCoreSupport() {\n",
    "    printf(\"=== Exercise 1: Check Tensor Core Support ===\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    for (int dev = 0; dev < deviceCount; dev++) {\n",
    "        cudaDeviceProp prop;\n",
    "        cudaGetDeviceProperties(&prop, dev);\n",
    "        \n",
    "        int major = prop.major;\n",
    "        int minor = prop.minor;\n",
    "        \n",
    "        printf(\"Device %d: %s\\n\", dev, prop.name);\n",
    "        printf(\"  Compute Capability: %d.%d\\n\", major, minor);\n",
    "        \n",
    "        // Tensor Core support check\n",
    "        bool hasTensorCores = false;\n",
    "        const char* tcType = \"None\";\n",
    "        \n",
    "        if (major >= 7) {\n",
    "            hasTensorCores = true;\n",
    "            if (major == 7 && minor == 0) tcType = \"V100 (FP16)\";\n",
    "            else if (major == 7 && minor == 5) tcType = \"Turing (FP16, INT8)\";\n",
    "            else if (major == 8 && minor == 0) tcType = \"A100 (FP16, TF32, BF16, INT8)\";\n",
    "            else if (major == 8 && minor == 6) tcType = \"RTX 30xx (FP16, TF32, BF16)\";\n",
    "            else if (major >= 9) tcType = \"Latest (FP16, TF32, BF16, FP8)\";\n",
    "            else tcType = \"Generic Tensor Cores\";\n",
    "        }\n",
    "        \n",
    "        printf(\"  Tensor Cores: %s (%s)\\n\", hasTensorCores ? \"YES\" : \"NO\", tcType);\n",
    "        printf(\"  Max Threads/Block: %d\\n\", prop.maxThreadsPerBlock);\n",
    "        printf(\"  Shared Memory/Block: %zu KB\\n\\n\", prop.sharedMemPerBlock / 1024);\n",
    "    }\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 2: Precision Analysis (FP32 vs FP16)\n",
    "// ============================================================\n",
    "\n",
    "__global__ void matmulFP32(const float* A, const float* B, float* C, int M, int N, int K) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (row < M && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < K; k++) {\n",
    "            sum += A[row * K + k] * B[k * N + col];\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void matmulFP16(const half* A, const half* B, float* C, int M, int N, int K) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (row < M && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < K; k++) {\n",
    "            sum += __half2float(A[row * K + k]) * __half2float(B[k * N + col]);\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise2_precisionAnalysis() {\n",
    "    printf(\"=== Exercise 2: Precision Analysis ===\\n\");\n",
    "    \n",
    "    const int M = 256, N = 256, K = 256;\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float* h_A = (float*)malloc(M * K * sizeof(float));\n",
    "    float* h_B = (float*)malloc(K * N * sizeof(float));\n",
    "    float* h_C_fp32 = (float*)malloc(M * N * sizeof(float));\n",
    "    float* h_C_fp16 = (float*)malloc(M * N * sizeof(float));\n",
    "    \n",
    "    // Initialize with random values\n",
    "    for (int i = 0; i < M * K; i++) h_A[i] = (float)(rand() % 100) / 100.0f;\n",
    "    for (int i = 0; i < K * N; i++) h_B[i] = (float)(rand() % 100) / 100.0f;\n",
    "    \n",
    "    // Device memory\n",
    "    float *d_A_fp32, *d_B_fp32, *d_C_fp32;\n",
    "    half *d_A_fp16, *d_B_fp16;\n",
    "    float *d_C_fp16;\n",
    "    \n",
    "    CHECK_CUDA(cudaMalloc(&d_A_fp32, M * K * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_B_fp32, K * N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_C_fp32, M * N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_A_fp16, M * K * sizeof(half)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_B_fp16, K * N * sizeof(half)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_C_fp16, M * N * sizeof(float)));\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(d_A_fp32, h_A, M * K * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemcpy(d_B_fp32, h_B, K * N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // Convert to FP16\n",
    "    half* h_A_fp16 = (half*)malloc(M * K * sizeof(half));\n",
    "    half* h_B_fp16 = (half*)malloc(K * N * sizeof(half));\n",
    "    for (int i = 0; i < M * K; i++) h_A_fp16[i] = __float2half(h_A[i]);\n",
    "    for (int i = 0; i < K * N; i++) h_B_fp16[i] = __float2half(h_B[i]);\n",
    "    CHECK_CUDA(cudaMemcpy(d_A_fp16, h_A_fp16, M * K * sizeof(half), cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemcpy(d_B_fp16, h_B_fp16, K * N * sizeof(half), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    dim3 block(16, 16);\n",
    "    dim3 grid((N + 15) / 16, (M + 15) / 16);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // FP32 benchmark\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        matmulFP32<<<grid, block>>>(d_A_fp32, d_B_fp32, d_C_fp32, M, N, K);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float fp32Ms;\n",
    "    cudaEventElapsedTime(&fp32Ms, start, stop);\n",
    "    \n",
    "    // FP16 benchmark\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        matmulFP16<<<grid, block>>>(d_A_fp16, d_B_fp16, d_C_fp16, M, N, K);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float fp16Ms;\n",
    "    cudaEventElapsedTime(&fp16Ms, start, stop);\n",
    "    \n",
    "    // Copy results back\n",
    "    CHECK_CUDA(cudaMemcpy(h_C_fp32, d_C_fp32, M * N * sizeof(float), cudaMemcpyDeviceToHost));\n",
    "    CHECK_CUDA(cudaMemcpy(h_C_fp16, d_C_fp16, M * N * sizeof(float), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    // Compute error metrics\n",
    "    float maxError = 0.0f;\n",
    "    float meanAbsError = 0.0f;\n",
    "    for (int i = 0; i < M * N; i++) {\n",
    "        float error = fabsf(h_C_fp32[i] - h_C_fp16[i]);\n",
    "        maxError = fmaxf(maxError, error);\n",
    "        meanAbsError += error;\n",
    "    }\n",
    "    meanAbsError /= (M * N);\n",
    "    \n",
    "    printf(\"Matrix size: %d x %d x %d\\n\", M, N, K);\n",
    "    printf(\"FP32 time: %.2f ms\\n\", fp32Ms);\n",
    "    printf(\"FP16 time: %.2f ms\\n\", fp16Ms);\n",
    "    printf(\"Speedup: %.2fx\\n\", fp32Ms / fp16Ms);\n",
    "    printf(\"Max element-wise error: %.6f\\n\", maxError);\n",
    "    printf(\"Mean absolute error: %.6f\\n\\n\", meanAbsError);\n",
    "    \n",
    "    // Cleanup\n",
    "    free(h_A); free(h_B); free(h_C_fp32); free(h_C_fp16);\n",
    "    free(h_A_fp16); free(h_B_fp16);\n",
    "    cudaFree(d_A_fp32); cudaFree(d_B_fp32); cudaFree(d_C_fp32);\n",
    "    cudaFree(d_A_fp16); cudaFree(d_B_fp16); cudaFree(d_C_fp16);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 3: Basic WMMA Matrix Multiply\n",
    "// ============================================================\n",
    "\n",
    "const int WMMA_M = 16;\n",
    "const int WMMA_N = 16;\n",
    "const int WMMA_K = 16;\n",
    "\n",
    "__global__ void wmmaMatmul(const half* A, const half* B, float* C, int M, int N, int K) {\n",
    "    // Calculate warp position\n",
    "    int warpM = (blockIdx.y * blockDim.y + threadIdx.y) / 32;\n",
    "    int warpN = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Skip if out of bounds\n",
    "    if (warpM * WMMA_M >= M || warpN * WMMA_N >= N) return;\n",
    "    \n",
    "    // Declare fragments\n",
    "    wmma::fragment<wmma::matrix_a, WMMA_M, WMMA_N, WMMA_K, half, wmma::row_major> a_frag;\n",
    "    wmma::fragment<wmma::matrix_b, WMMA_M, WMMA_N, WMMA_K, half, wmma::row_major> b_frag;\n",
    "    wmma::fragment<wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, float> c_frag;\n",
    "    \n",
    "    // Initialize accumulator\n",
    "    wmma::fill_fragment(c_frag, 0.0f);\n",
    "    \n",
    "    // Loop over K dimension\n",
    "    for (int k = 0; k < K; k += WMMA_K) {\n",
    "        int aRow = warpM * WMMA_M;\n",
    "        int aCol = k;\n",
    "        int bRow = k;\n",
    "        int bCol = warpN * WMMA_N;\n",
    "        \n",
    "        // Load fragments\n",
    "        wmma::load_matrix_sync(a_frag, A + aRow * K + aCol, K);\n",
    "        wmma::load_matrix_sync(b_frag, B + bRow * N + bCol, N);\n",
    "        \n",
    "        // Perform WMMA\n",
    "        wmma::mma_sync(c_frag, a_frag, b_frag, c_frag);\n",
    "    }\n",
    "    \n",
    "    // Store result\n",
    "    int cRow = warpM * WMMA_M;\n",
    "    int cCol = warpN * WMMA_N;\n",
    "    wmma::store_matrix_sync(C + cRow * N + cCol, c_frag, N, wmma::mem_row_major);\n",
    "}\n",
    "\n",
    "void exercise3_basicWMMA() {\n",
    "    printf(\"=== Exercise 3: Basic WMMA Matrix Multiply ===\\n\");\n",
    "    \n",
    "    // Check compute capability\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    if (prop.major < 7) {\n",
    "        printf(\"WMMA requires compute capability 7.0+. Skipping.\\n\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    const int M = 256, N = 256, K = 256;\n",
    "    \n",
    "    half* h_A = (half*)malloc(M * K * sizeof(half));\n",
    "    half* h_B = (half*)malloc(K * N * sizeof(half));\n",
    "    float* h_C = (float*)malloc(M * N * sizeof(float));\n",
    "    \n",
    "    for (int i = 0; i < M * K; i++) h_A[i] = __float2half((float)(rand() % 10) / 10.0f);\n",
    "    for (int i = 0; i < K * N; i++) h_B[i] = __float2half((float)(rand() % 10) / 10.0f);\n",
    "    \n",
    "    half *d_A, *d_B;\n",
    "    float *d_C;\n",
    "    CHECK_CUDA(cudaMalloc(&d_A, M * K * sizeof(half)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_B, K * N * sizeof(half)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_C, M * N * sizeof(float)));\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(d_A, h_A, M * K * sizeof(half), cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemcpy(d_B, h_B, K * N * sizeof(half), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // Launch with one warp per WMMA tile\n",
    "    dim3 block(N / WMMA_N, 32);  // 32 threads = 1 warp per column\n",
    "    dim3 grid(1, M / WMMA_M);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        wmmaMatmul<<<grid, block>>>(d_A, d_B, d_C, M, N, K);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    printf(\"WMMA Matrix Multiply (%dx%dx%d): %.2f ms (100 iters)\\n\", M, N, K, ms);\n",
    "    printf(\"Performance: %.2f GFLOPS\\n\\n\", \n",
    "           (2.0 * M * N * K * 100) / (ms * 1e6));\n",
    "    \n",
    "    free(h_A); free(h_B); free(h_C);\n",
    "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\");\n",
    "    printf(\"â•‘              Tensor Core Basics Exercises                    â•‘\\n\");\n",
    "    printf(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\");\n",
    "    \n",
    "    exercise1_checkTensorCoreSupport();\n",
    "    exercise2_precisionAnalysis();\n",
    "    exercise3_basicWMMA();\n",
    "    \n",
    "    printf(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    printf(\"                    All exercises completed!\\n\");\n",
    "    printf(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o tensor_core_exercises tensor_core_exercises.cu && ./tensor_core_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca0bf8",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "### Exercise 1: Check Your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Determine if your GPU supports Tensor Cores\n",
    "# and what data types it supports\n",
    "\n",
    "!nvidia-smi --query-gpu=name,compute_cap --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd34a8e",
   "metadata": {},
   "source": [
    "### Exercise 2: Precision Analysis\n",
    "\n",
    "Run a matrix multiply in FP32 vs FP16 and measure:\n",
    "1. Maximum element-wise error\n",
    "2. Mean absolute error\n",
    "3. Speedup ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014a44f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Key Takeaways\n",
    "\n",
    "### Tensor Core Mental Model\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ğŸ§± LEGO BLOCK ASSEMBLY COMPLETE!                               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  What You Learned:                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚ Individual bricks (CUDA Core)  â†’  Block sections (TC)  â”‚    â”‚\n",
    "â”‚  â”‚ 1 FMA per cycle               â†’  64 FMAs per cycle     â”‚    â”‚\n",
    "â”‚  â”‚ Scalar operations             â†’  Matrix operations     â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  When to Use Tensor Cores:                                      â”‚\n",
    "â”‚  âœ… Matrix multiplications (AI/ML)                              â”‚\n",
    "â”‚  âœ… Convolutions (CNNs)                                         â”‚\n",
    "â”‚  âœ… Attention mechanisms (Transformers)                         â”‚\n",
    "â”‚  âŒ Irregular memory access patterns                            â”‚\n",
    "â”‚  âŒ Small matrices (< 16Ã—16)                                    â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Concept | Description | LEGO Analogy |\n",
    "|---------|-------------|--------------|\n",
    "| Tensor Core | Matrix multiply unit | Block assembly station |\n",
    "| WMMA | Warp Matrix Multiply API | Assembly instructions |\n",
    "| Fragment | Matrix piece per thread | Piece of the block |\n",
    "| FP16/TF32 | Reduced precision | Simplified brick shapes |\n",
    "\n",
    "### Performance Checklist\n",
    "\n",
    "- [ ] Matrices padded to multiples of 16\n",
    "- [ ] Memory aligned for coalesced access\n",
    "- [ ] Using WMMA-friendly dimensions\n",
    "- [ ] Precision chosen for task (FP16/TF32/BF16)\n",
    "\n",
    "### Tomorrow: WMMA Deep Dive\n",
    "We'll implement optimized matrix multiply using WMMA with shared memory tiling."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
