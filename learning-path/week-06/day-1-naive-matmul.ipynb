{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab901f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(\"⚠️  CUDA C++ is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7a402",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Matrix Multiplication Basics\n",
    "\n",
    "### The Algorithm\n",
    "\n",
    "```\n",
    "C = A × B\n",
    "\n",
    "Where:\n",
    "  A is M × K\n",
    "  B is K × N\n",
    "  C is M × N\n",
    "\n",
    "Each element:\n",
    "  C[i,j] = Σ A[i,k] * B[k,j]  for k = 0 to K-1\n",
    "\n",
    "Example (2×3 @ 3×2 = 2×2):\n",
    "\n",
    "A = [1 2 3]    B = [1 4]    C = [1*1+2*2+3*3  1*4+2*5+3*6] = [14 32]\n",
    "    [4 5 6]        [2 5]        [4*1+5*2+6*3  4*4+5*5+6*6]   [32 77]\n",
    "                   [3 6]\n",
    "```\n",
    "\n",
    "### Parallelization Strategy\n",
    "\n",
    "```\n",
    "Key insight: Each C[i,j] is INDEPENDENT!\n",
    "\n",
    "GPU mapping:\n",
    "• One thread per output element\n",
    "• Thread (i, j) computes C[i,j]\n",
    "• 2D grid/block structure natural fit\n",
    "\n",
    "Grid dimensions:\n",
    "  gridDim.x = ceil(N / blockDim.x)\n",
    "  gridDim.y = ceil(M / blockDim.y)\n",
    "```\n",
    "\n",
    "### CUDA C++ Implementation (Primary)\n",
    "\n",
    "### Python/Numba (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile naive_matmul.cu\n",
    "// naive_matmul.cu - Basic matrix multiplication\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define BLOCK_SIZE 16\n",
    "\n",
    "// Naive matrix multiplication: C = A × B\n",
    "// A: M×K, B: K×N, C: M×N\n",
    "__global__ void matmul_naive(const float* A, const float* B, float* C,\n",
    "                              int M, int N, int K) {\n",
    "    // Calculate row and column for this thread\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Bounds check\n",
    "    if (row < M && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        \n",
    "        // Dot product of row of A and column of B\n",
    "        for (int k = 0; k < K; k++) {\n",
    "            sum += A[row * K + k] * B[k * N + col];\n",
    "        }\n",
    "        \n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int M = 1024, K = 1024, N = 1024;\n",
    "    size_t size_A = M * K * sizeof(float);\n",
    "    size_t size_B = K * N * sizeof(float);\n",
    "    size_t size_C = M * N * sizeof(float);\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float *h_A = (float*)malloc(size_A);\n",
    "    float *h_B = (float*)malloc(size_B);\n",
    "    float *h_C = (float*)malloc(size_C);\n",
    "    \n",
    "    // Initialize matrices\n",
    "    for (int i = 0; i < M * K; i++) h_A[i] = rand() / (float)RAND_MAX;\n",
    "    for (int i = 0; i < K * N; i++) h_B[i] = rand() / (float)RAND_MAX;\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc(&d_A, size_A);\n",
    "    cudaMalloc(&d_B, size_B);\n",
    "    cudaMalloc(&d_C, size_C);\n",
    "    \n",
    "    // Copy to device\n",
    "    cudaMemcpy(d_A, h_A, size_A, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, size_B, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch kernel\n",
    "    dim3 block(BLOCK_SIZE, BLOCK_SIZE);\n",
    "    dim3 grid((N + BLOCK_SIZE - 1) / BLOCK_SIZE,\n",
    "              (M + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
    "    \n",
    "    // Warmup\n",
    "    matmul_naive<<<grid, block>>>(d_A, d_B, d_C, M, N, K);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Benchmark\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        matmul_naive<<<grid, block>>>(d_A, d_B, d_C, M, N, K);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    ms /= 10;  // Average\n",
    "    \n",
    "    // Calculate GFLOPS\n",
    "    double flops = 2.0 * M * N * K;  // multiply + add\n",
    "    double gflops = flops / (ms * 1e6);\n",
    "    \n",
    "    printf(\"Matrix size: %d x %d x %d\\n\", M, K, N);\n",
    "    printf(\"Time: %.3f ms\\n\", ms);\n",
    "    printf(\"Performance: %.2f GFLOPS\\n\", gflops);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
    "    free(h_A); free(h_B); free(h_C);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08533a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o naive_matmul naive_matmul.cu\n",
    "!./naive_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6747bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul_naive(A, B, C, M, N, K):\n",
    "    \"\"\"Naive matrix multiplication: C = A @ B\"\"\"\n",
    "    row = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    col = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    \n",
    "    if row < M and col < N:\n",
    "        total = 0.0\n",
    "        for k in range(K):\n",
    "            total += A[row, k] * B[k, col]\n",
    "        C[row, col] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test naive matrix multiplication\n",
    "M, K, N = 512, 512, 512\n",
    "\n",
    "A = np.random.rand(M, K).astype(np.float32)\n",
    "B = np.random.rand(K, N).astype(np.float32)\n",
    "C = np.zeros((M, N), dtype=np.float32)\n",
    "\n",
    "d_A = cuda.to_device(A)\n",
    "d_B = cuda.to_device(B)\n",
    "d_C = cuda.to_device(C)\n",
    "\n",
    "BLOCK_SIZE = 16\n",
    "grid = ((N + BLOCK_SIZE - 1) // BLOCK_SIZE,\n",
    "        (M + BLOCK_SIZE - 1) // BLOCK_SIZE)\n",
    "block = (BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "matmul_naive[grid, block](d_A, d_B, d_C, M, N, K)\n",
    "result = d_C.copy_to_host()\n",
    "\n",
    "# Verify\n",
    "expected = A @ B\n",
    "print(f\"Matrix sizes: A({M}×{K}) @ B({K}×{N}) = C({M}×{N})\")\n",
    "print(f\"Correct: {'✓' if np.allclose(result, expected, rtol=1e-4) else '✗'}\")\n",
    "print(f\"Max error: {np.max(np.abs(result - expected)):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d76a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Memory Access Analysis\n",
    "\n",
    "### Access Pattern Visualization\n",
    "\n",
    "```\n",
    "For C[row, col], thread reads:\n",
    "\n",
    "From A:                    From B:\n",
    "Row 'row' of A             Column 'col' of B\n",
    "┌─────────────┐            ┌──┬──┬──┐\n",
    "│             │            │  │  │  │\n",
    "├─────────────┤ ← row      │  │col│  │\n",
    "│ * * * * * * │            │  │ ↓│  │\n",
    "├─────────────┤            │  │ * │  │\n",
    "│             │            │  │ * │  │\n",
    "└─────────────┘            │  │ * │  │\n",
    "                           └──┴──┴──┘\n",
    "```\n",
    "\n",
    "### Memory Coalescing\n",
    "\n",
    "```\n",
    "Adjacent threads in a warp (same row, consecutive cols):\n",
    "\n",
    "Thread 0: C[row, 0]  → reads A[row, 0:K], B[0:K, 0]\n",
    "Thread 1: C[row, 1]  → reads A[row, 0:K], B[0:K, 1]\n",
    "Thread 2: C[row, 2]  → reads A[row, 0:K], B[0:K, 2]\n",
    "...\n",
    "\n",
    "A access: All threads read SAME row → broadcast (efficient)\n",
    "B access: Threads read consecutive columns → COALESCED (efficient)\n",
    "\n",
    "But HUGE redundancy:\n",
    "• Each row of A read N times (once per column of C)\n",
    "• Each column of B read M times (once per row of C)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_memory_traffic(M, K, N):\n",
    "    \"\"\"Analyze memory traffic for naive matrix multiply.\"\"\"\n",
    "    \n",
    "    # Each C element reads entire row of A and column of B\n",
    "    reads_per_output = K + K  # K elements from A, K from B\n",
    "    total_reads = M * N * reads_per_output\n",
    "    \n",
    "    # Theoretical minimum (each A, B element read once)\n",
    "    min_reads = M * K + K * N\n",
    "    \n",
    "    # Output writes\n",
    "    writes = M * N\n",
    "    \n",
    "    # Bytes (float32)\n",
    "    bytes_read = total_reads * 4\n",
    "    bytes_min = min_reads * 4\n",
    "    bytes_write = writes * 4\n",
    "    \n",
    "    print(f\"Matrix multiply: ({M}×{K}) @ ({K}×{N}) = ({M}×{N})\")\n",
    "    print(f\"\\nMemory reads:\")\n",
    "    print(f\"  Naive:    {bytes_read / 1e9:.2f} GB\")\n",
    "    print(f\"  Minimum:  {bytes_min / 1e6:.2f} MB\")\n",
    "    print(f\"  Overhead: {bytes_read / bytes_min:.0f}x\")\n",
    "    print(f\"\\nOperations: {2 * M * N * K / 1e9:.2f} GFLOP\")\n",
    "    print(f\"Arithmetic intensity (naive): {2 * M * N * K / bytes_read:.2f} FLOP/byte\")\n",
    "\n",
    "analyze_memory_traffic(1024, 1024, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02eb53f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_matmul(M, K, N, iterations=20):\n",
    "    \"\"\"Benchmark naive matrix multiplication.\"\"\"\n",
    "    A = np.random.rand(M, K).astype(np.float32)\n",
    "    B = np.random.rand(K, N).astype(np.float32)\n",
    "    C = np.zeros((M, N), dtype=np.float32)\n",
    "    \n",
    "    d_A = cuda.to_device(A)\n",
    "    d_B = cuda.to_device(B)\n",
    "    d_C = cuda.to_device(C)\n",
    "    \n",
    "    BLOCK_SIZE = 16\n",
    "    grid = ((N + BLOCK_SIZE - 1) // BLOCK_SIZE,\n",
    "            (M + BLOCK_SIZE - 1) // BLOCK_SIZE)\n",
    "    block = (BLOCK_SIZE, BLOCK_SIZE)\n",
    "    \n",
    "    # Warmup\n",
    "    matmul_naive[grid, block](d_A, d_B, d_C, M, N, K)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        matmul_naive[grid, block](d_A, d_B, d_C, M, N, K)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations * 1000  # ms\n",
    "    \n",
    "    # Calculate GFLOPS\n",
    "    flops = 2 * M * N * K\n",
    "    gflops = flops / (elapsed * 1e6)\n",
    "    \n",
    "    return elapsed, gflops\n",
    "\n",
    "print(f\"{'Size':<15} {'Time (ms)':<12} {'GFLOPS':<12}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for size in [256, 512, 1024, 2048]:\n",
    "    try:\n",
    "        ms, gflops = benchmark_matmul(size, size, size)\n",
    "        print(f\"{size}×{size}×{size:<8} {ms:<12.3f} {gflops:<12.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{size}×{size}×{size:<8} Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3f80c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Why Naive is Slow\n",
    "\n",
    "### The Problem\n",
    "\n",
    "```\n",
    "For 1024×1024 matrices:\n",
    "\n",
    "Operations:     2 × 1024³ = 2.1 billion FLOPS\n",
    "Naive reads:    1024² × 2K = 2.1 billion reads\n",
    "Arithmetic intensity: 1 FLOP per read = TERRIBLE\n",
    "\n",
    "GPU peak: ~10 TFLOPS, Memory BW: ~500 GB/s\n",
    "Required BW for 10 TFLOPS: 10 TB/s (20x more than available!)\n",
    "\n",
    "Result: Memory-bound at ~10% of peak\n",
    "```\n",
    "\n",
    "### The Solution Preview\n",
    "\n",
    "```\n",
    "TILING with shared memory:\n",
    "\n",
    "1. Load tiles of A and B into shared memory\n",
    "2. Compute partial products using fast shared memory\n",
    "3. Repeat for all tiles\n",
    "\n",
    "With 32×32 tiles:\n",
    "  Each element loaded once per tile, reused 32 times\n",
    "  32x reduction in global memory traffic!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0df0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with NumPy (uses optimized BLAS)\n",
    "def compare_with_numpy(sizes):\n",
    "    print(f\"{'Size':<12} {'Naive (ms)':<12} {'NumPy (ms)':<12} {'Ratio':<10}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for size in sizes:\n",
    "        A = np.random.rand(size, size).astype(np.float32)\n",
    "        B = np.random.rand(size, size).astype(np.float32)\n",
    "        \n",
    "        # NumPy\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(5):\n",
    "            _ = A @ B\n",
    "        numpy_ms = (time.perf_counter() - start) / 5 * 1000\n",
    "        \n",
    "        # CUDA naive\n",
    "        cuda_ms, _ = benchmark_matmul(size, size, size, iterations=5)\n",
    "        \n",
    "        print(f\"{size}×{size:<8} {cuda_ms:<12.3f} {numpy_ms:<12.3f} {cuda_ms/numpy_ms:.1f}x\")\n",
    "\n",
    "compare_with_numpy([256, 512, 1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b005eb3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Rectangular Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test with non-square matrices\n",
    "# Verify that the kernel handles M != K != N correctly\n",
    "\n",
    "test_cases = [\n",
    "    (100, 200, 150),  # M × K × N\n",
    "    (500, 100, 300),\n",
    "    (64, 1024, 64),\n",
    "]\n",
    "\n",
    "for M, K, N in test_cases:\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39305301",
   "metadata": {},
   "source": [
    "### Exercise 2: Block Size Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try different block sizes and measure performance\n",
    "# Try: 8×8, 16×16, 32×32\n",
    "\n",
    "block_sizes = [8, 16, 32]\n",
    "\n",
    "# Your benchmarking code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842ae842",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Naive Matrix Multiplication\n",
    "\n",
    "| Aspect | Value |\n",
    "|--------|-------|\n",
    "| Parallelization | One thread per output element |\n",
    "| Memory access | Huge redundancy (each element read N or M times) |\n",
    "| Arithmetic intensity | ~1 FLOP/byte (very low) |\n",
    "| Performance | ~10% of peak (memory-bound) |\n",
    "\n",
    "### CUDA C++ Key Pattern\n",
    "\n",
    "```cpp\n",
    "__global__ void matmul_naive(float* A, float* B, float* C, int M, int N, int K) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (row < M && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < K; k++) {\n",
    "            sum += A[row * K + k] * B[k * N + col];\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Next: Tiled Matrix Multiplication\n",
    "Tomorrow we'll use shared memory tiling to dramatically improve performance!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
