{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4d96d9",
   "metadata": {},
   "source": [
    "# ğŸš€ Day 1: Memory Coalescing - The Key to GPU Performance\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapati3/cuda-lab/blob/main/learning-path/week-02/day-1-memory-coalescing.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ£ The Hook: Why is My GPU Code So Slow?\n",
    "\n",
    "> *You bought a Ferrari, but you're stuck in traffic.*\n",
    "\n",
    "You've written a GPU kernel. It should be 100x faster than CPU. But it's only 3x fasterâ€”or worse. What's going on?\n",
    "\n",
    "**The answer is almost always: memory access patterns.**\n",
    "\n",
    "Your GPU has incredible compute power (the Ferrari), but if you're accessing memory inefficiently, you're creating a traffic jam at the memory controller. Today, we'll learn how to clear that traffic jam with **memory coalescing**.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- ğŸ¯ **Why** memory bandwidth is the #1 GPU bottleneck\n",
    "- ğŸ”§ **How** the GPU memory system actually works (transactions, bursts)\n",
    "- âœ… **What** makes an access pattern coalesced vs. non-coalesced  \n",
    "- ğŸ“Š **How much** performance you gain (hint: often 10-30x!)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Philosophy\n",
    "\n",
    "> **CUDA C++ First, Python/Numba as Optional Backup**\n",
    "\n",
    "This notebook shows:\n",
    "1. **CUDA C++ code** - The PRIMARY implementation you should learn\n",
    "2. **Python/Numba code** - OPTIONAL for quick interactive testing in Colab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Colab/Local Setup - Run this first!\n",
    "# Python/Numba is OPTIONAL - for quick interactive testing only\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"ğŸ”§ Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"âœ… Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’» Running locally - make sure you have: pip install numba numpy\")\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(\"\\nâš ï¸  Remember: CUDA C++ code is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115054e",
   "metadata": {},
   "source": [
    "## 1. How GPU Memory Access Works\n",
    "\n",
    "<details open>\n",
    "<summary>ğŸ’¡ <b>Concept Card: The Delivery Truck Analogy</b></summary>\n",
    "\n",
    "### ğŸ¯ The Problem\n",
    "When your GPU kernel reads data from global memory, it doesn't fetch individual bytes. Understanding this is the key to 10-30x performance gains.\n",
    "\n",
    "### ğŸšš The Delivery Truck Analogy\n",
    "Think of the GPU memory controller like a **delivery truck with a minimum package size**.\n",
    "\n",
    "- The truck (memory controller) can only deliver packages of **32, 64, or 128 bytes**\n",
    "- Even if you only want **4 bytes** (one `float`), the truck delivers a full **128-byte package**\n",
    "- If 32 threads in a warp request **adjacent addresses** (0, 1, 2, ... 31), the truck makes **ONE trip** with one 128-byte package\n",
    "- If 32 threads request **scattered addresses** (0, 32, 64, ... 992), the truck must make **32 separate trips**!\n",
    "\n",
    "**Same data. Same computation. 32x more memory traffic.**\n",
    "\n",
    "### ğŸ”§ Hardware Reality\n",
    "When a warp (32 threads) accesses global memory, the hardware:\n",
    "1. Collects all memory addresses from all 32 threads\n",
    "2. Groups addresses that fall within the same **128-byte aligned segment**\n",
    "3. Issues one **memory transaction** per segment needed\n",
    "4. Threads receive their data when the transaction completes\n",
    "\n",
    "**Best case:** All 32 threads access one 128-byte segment â†’ **1 transaction**  \n",
    "**Worst case:** All 32 threads access different segments â†’ **32 transactions**\n",
    "\n",
    "### âœ… The Pattern\n",
    "```\n",
    "COALESCED (Good) - 1 transaction:\n",
    "Thread:    0    1    2    3   ...  31\n",
    "Address:  [0]  [1]  [2]  [3] ... [31]\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 All in same 128-byte segment\n",
    "\n",
    "NON-COALESCED (Bad) - up to 32 transactions:\n",
    "Thread:    0    1    2    3   ...  31  \n",
    "Address:  [0] [32] [64] [96] ...[992]\n",
    "           â”‚    â”‚    â”‚    â”‚       â”‚\n",
    "           Different segments â†’ separate transactions\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "Let's see this in action with a benchmark comparing coalesced vs. strided access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad20a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile coalescing_demo.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// GOOD: Coalesced access - adjacent threads access adjacent memory\n",
    "__global__ void coalescedCopy(const float* src, float* dst, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        dst[idx] = src[idx];  // Thread 0â†’addr 0, Thread 1â†’addr 1, ...\n",
    "    }\n",
    "}\n",
    "\n",
    "// BAD: Strided access - adjacent threads access scattered memory\n",
    "__global__ void stridedCopy(const float* src, float* dst, int n, int stride) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int strided_idx = idx * stride;  // Thread 0â†’addr 0, Thread 1â†’addr 32, ...\n",
    "    if (strided_idx < n) {\n",
    "        dst[strided_idx] = src[strided_idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;  // 1M elements\n",
    "    const int bytes = N * sizeof(float);\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float *h_src = (float*)malloc(bytes);\n",
    "    float *h_dst = (float*)malloc(bytes);\n",
    "    \n",
    "    // Initialize source data\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_src[i] = (float)i;\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_src, *d_dst;\n",
    "    cudaMalloc(&d_src, bytes);\n",
    "    cudaMalloc(&d_dst, bytes);\n",
    "    \n",
    "    // Copy to device\n",
    "    cudaMemcpy(d_src, h_src, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch coalesced kernel\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    \n",
    "    printf(\"Testing coalesced vs strided access patterns:\\n\");\n",
    "    printf(\"Array size: %d elements\\n\\n\", N);\n",
    "    \n",
    "    // Time coalesced access\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        coalescedCopy<<<blocks, threads>>>(d_src, d_dst, N);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float coalesced_ms;\n",
    "    cudaEventElapsedTime(&coalesced_ms, start, stop);\n",
    "    printf(\"Coalesced access (stride=1): %.3f ms (avg per iteration)\\n\", coalesced_ms / 100);\n",
    "    \n",
    "    // Time strided access with different strides\n",
    "    for (int stride = 2; stride <= 32; stride *= 2) {\n",
    "        cudaMemset(d_dst, 0, bytes);\n",
    "        \n",
    "        cudaEventRecord(start);\n",
    "        for (int i = 0; i < 100; i++) {\n",
    "            stridedCopy<<<blocks, threads>>>(d_src, d_dst, N, stride);\n",
    "        }\n",
    "        cudaEventRecord(stop);\n",
    "        cudaEventSynchronize(stop);\n",
    "        \n",
    "        float strided_ms;\n",
    "        cudaEventElapsedTime(&strided_ms, start, stop);\n",
    "        printf(\"Strided access (stride=%d): %.3f ms (%.1fx slower)\\n\", \n",
    "               stride, strided_ms / 100, strided_ms / coalesced_ms);\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_src);\n",
    "    cudaFree(d_dst);\n",
    "    free(h_src);\n",
    "    free(h_dst);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o coalescing_demo coalescing_demo.cu\n",
    "!./coalescing_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0423966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Visualization: Memory Access Patterns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Left: Coalesced Access\n",
    "ax1 = axes[0]\n",
    "ax1.set_title(\"âœ… Coalesced Access\\n(1 Memory Transaction)\", fontsize=12, fontweight='bold', color='green')\n",
    "\n",
    "# Draw memory segment\n",
    "ax1.add_patch(plt.Rectangle((0, 0), 32, 1, fill=True, color='lightgreen', edgecolor='green', linewidth=2))\n",
    "ax1.text(16, 0.5, \"128-byte Memory Segment\", ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Draw threads\n",
    "for i in range(8):\n",
    "    ax1.annotate('', xy=(i*4 + 2, 0), xytext=(i*4 + 2, -0.8),\n",
    "                arrowprops=dict(arrowstyle='->', color='blue', lw=1.5))\n",
    "    ax1.text(i*4 + 2, -1, f'T{i}', ha='center', fontsize=8)\n",
    "\n",
    "ax1.text(16, -1.5, \"Threads 0-31 access addresses 0-31\", ha='center', fontsize=9, style='italic')\n",
    "ax1.set_xlim(-1, 33)\n",
    "ax1.set_ylim(-2, 1.5)\n",
    "ax1.axis('off')\n",
    "\n",
    "# Right: Strided Access\n",
    "ax2 = axes[1]\n",
    "ax2.set_title(\"âŒ Strided Access (stride=32)\\n(32 Memory Transactions!)\", fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "# Draw multiple memory segments\n",
    "for seg in range(4):\n",
    "    ax2.add_patch(plt.Rectangle((seg*8, seg*0.3), 6, 0.8, fill=True, \n",
    "                                 color='lightsalmon', edgecolor='red', linewidth=1.5))\n",
    "    ax2.annotate('', xy=(seg*8 + 3, seg*0.3), xytext=(seg*8 + 3, -0.8),\n",
    "                arrowprops=dict(arrowstyle='->', color='blue', lw=1.5))\n",
    "    ax2.text(seg*8 + 3, -1, f'T{seg}', ha='center', fontsize=8)\n",
    "    ax2.text(seg*8 + 3, seg*0.3 + 0.4, f'Seg {seg}', ha='center', fontsize=8)\n",
    "\n",
    "ax2.text(14, 2.2, \"...\", fontsize=16, ha='center')\n",
    "ax2.text(14, -1.5, \"Each thread hits a different 128-byte segment!\", ha='center', fontsize=9, style='italic')\n",
    "ax2.set_xlim(-1, 33)\n",
    "ax2.set_ylim(-2, 2.5)\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('coalescing_diagram.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"ğŸ’¾ Diagram saved as coalescing_diagram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8613536",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba (Optional - Quick Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bfa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(\"CUDA device:\", cuda.get_current_device().name.decode())\n",
    "\n",
    "# Get memory bandwidth info\n",
    "device = cuda.get_current_device()\n",
    "print(f\"Warp size: {device.WARP_SIZE}\")\n",
    "print(f\"Max threads per block: {device.MAX_THREADS_PER_BLOCK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcea3d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. The Coalescing Rules\n",
    "\n",
    "<details open>\n",
    "<summary>ğŸ’¡ <b>Concept Card: The Golden Rule of GPU Memory</b></summary>\n",
    "\n",
    "### ğŸ¯ The Golden Rule\n",
    "> **Adjacent threads (within a warp) should access adjacent memory locations.**\n",
    "\n",
    "If you remember only one thing from this notebook, remember this. It applies to:\n",
    "- 1D arrays: `arr[threadIdx.x]` âœ… vs `arr[threadIdx.x * stride]` âŒ\n",
    "- 2D arrays: iterate over columns (fast dimension) with `threadIdx.x`\n",
    "- Structs: prefer Structure of Arrays (SoA) over Array of Structures (AoS)\n",
    "\n",
    "### ğŸ”§ Transaction Sizes\n",
    "The memory controller issues transactions in fixed sizes:\n",
    "| Transaction Size | Elements (`float32`) | When Used |\n",
    "|-----------------|---------------------|-----------|\n",
    "| 32 bytes | 8 floats | Partial warp access |\n",
    "| 64 bytes | 16 floats | Half warp aligned |\n",
    "| **128 bytes** | **32 floats** | **Full warp aligned** â† ideal! |\n",
    "\n",
    "A perfectly coalesced warp access loads 32 floats in a single 128-byte transaction.\n",
    "\n",
    "### âš ï¸ Common Gotchas\n",
    "1. **Stride > 1**: `arr[tid * 2]` doubles transactions\n",
    "2. **Column-major access**: Reading down columns in a row-major array\n",
    "3. **Misaligned base**: Starting address not 128-byte aligned\n",
    "4. **Random access**: Hash tables, gather operations\n",
    "\n",
    "</details>\n",
    "\n",
    "### Quick Reference: Access Pattern Cheat Sheet\n",
    "\n",
    "| Pattern | Example | Coalesced? | Why? |\n",
    "|---------|---------|------------|------|\n",
    "| Sequential | `arr[threadIdx.x]` | âœ… Yes | Adjacent threads â†’ adjacent addresses |\n",
    "| Strided | `arr[threadIdx.x * stride]` | âŒ No | Threads skip addresses |\n",
    "| Random | `arr[hash(threadIdx.x)]` | âŒ No | Unpredictable addresses |\n",
    "| Row-major 2D | `arr[row][col]` where `col = threadIdx.x` | âœ… Yes | Threads vary fast dimension |\n",
    "| Column-major 2D | `arr[row][col]` where `row = threadIdx.x` | âŒ No | Threads vary slow dimension |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88867bfe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ”· CUDA C++ 2D Access Patterns (Primary)\n",
    "\n",
    "<details open>\n",
    "<summary>ğŸ’¡ <b>Concept Card: Row-Major Layout and Thread Mapping</b></summary>\n",
    "\n",
    "### ğŸ¯ The Problem\n",
    "2D arrays in C/C++/NumPy are stored in **row-major order**. This means:\n",
    "- Elements in the same row are contiguous in memory\n",
    "- Moving to the next row jumps by `num_columns` elements\n",
    "\n",
    "### ğŸ”§ Memory Layout Visualization\n",
    "```\n",
    "Logical 2D View:           Physical 1D Memory:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         \n",
    "â”‚ [0,0][0,1][0,2] â”‚ Row 0   â†’ [0,0][0,1][0,2][1,0][1,1][1,2][2,0]...\n",
    "â”‚ [1,0][1,1][1,2] â”‚ Row 1         â†‘         â†‘\n",
    "â”‚ [2,0][2,1][2,2] â”‚ Row 2     Contiguous  Row boundary (jump!)\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### âœ… The Pattern\n",
    "```cuda\n",
    "// âœ… COALESCED: threadIdx.x varies the column (fast dimension)\n",
    "int col = blockIdx.x * blockDim.x + threadIdx.x;  // threadIdx.x â†’ column\n",
    "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "int idx = row * num_cols + col;  // Adjacent threads â†’ adjacent addresses\n",
    "\n",
    "// âŒ NON-COALESCED: threadIdx.x varies the row (slow dimension)  \n",
    "int row = blockIdx.x * blockDim.x + threadIdx.x;  // threadIdx.x â†’ row (WRONG!)\n",
    "int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "int idx = row * num_cols + col;  // Adjacent threads â†’ addresses num_cols apart\n",
    "```\n",
    "\n",
    "### âš ï¸ Key Insight\n",
    "The first dimension of your CUDA grid (`blockIdx.x`, `threadIdx.x`) should map to the **last dimension** of your array (columns in row-major).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb07075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile coalescing_2d.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// GOOD: Row-major access - threads in a warp access adjacent columns\n",
    "__global__ void rowMajorAccess(float* matrix, float* output, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // Fast dimension\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;  // Row-major indexing\n",
    "        output[idx] = matrix[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// BAD: Column-major access - threads in a warp access scattered rows\n",
    "__global__ void colMajorAccess(float* matrix, float* output, int rows, int cols) {\n",
    "    int row = blockIdx.x * blockDim.x + threadIdx.x;  // Wrong! Fast dimension on rows\n",
    "    int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;\n",
    "        output[idx] = matrix[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int ROWS = 4096;\n",
    "    const int COLS = 4096;\n",
    "    const int SIZE = ROWS * COLS;\n",
    "    const size_t bytes = SIZE * sizeof(float);\n",
    "    \n",
    "    float *d_matrix, *d_output;\n",
    "    cudaMalloc(&d_matrix, bytes);\n",
    "    cudaMalloc(&d_output, bytes);\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_matrix = (float*)malloc(bytes);\n",
    "    for (int i = 0; i < SIZE; i++) h_matrix[i] = 1.0f;\n",
    "    cudaMemcpy(d_matrix, h_matrix, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks_row((COLS + 15) / 16, (ROWS + 15) / 16);\n",
    "    dim3 blocks_col((ROWS + 15) / 16, (COLS + 15) / 16);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    printf(\"=== 2D Access Pattern Benchmark ===\\n\");\n",
    "    printf(\"Matrix: %d x %d (%.1f MB)\\n\\n\", ROWS, COLS, bytes / 1e6);\n",
    "    \n",
    "    // Benchmark row-major (coalesced)\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        rowMajorAccess<<<blocks_row, threads>>>(d_matrix, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float row_ms;\n",
    "    cudaEventElapsedTime(&row_ms, start, stop);\n",
    "    float row_bw = (2 * bytes * 100) / (row_ms / 1000) / 1e9;\n",
    "    \n",
    "    // Benchmark column-major (non-coalesced)\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        colMajorAccess<<<blocks_col, threads>>>(d_matrix, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float col_ms;\n",
    "    cudaEventElapsedTime(&col_ms, start, stop);\n",
    "    float col_bw = (2 * bytes * 100) / (col_ms / 1000) / 1e9;\n",
    "    \n",
    "    printf(\"Row-major (coalesced):    %.2f ms, %.1f GB/s\\n\", row_ms / 100, row_bw);\n",
    "    printf(\"Column-major (strided):   %.2f ms, %.1f GB/s\\n\", col_ms / 100, col_bw);\n",
    "    printf(\"Speedup from coalescing:  %.2fx\\n\", col_ms / row_ms);\n",
    "    \n",
    "    cudaFree(d_matrix);\n",
    "    cudaFree(d_output);\n",
    "    free(h_matrix);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f790170",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o coalescing_2d coalescing_2d.cu && ./coalescing_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73d4a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. See the Impact: Coalesced vs Non-Coalesced Benchmarks\n",
    "\n",
    "*Now that we understand the theory, let's **prove it with numbers**.*\n",
    "\n",
    "The following Python/Numba code demonstrates the same principles for quick interactive testing.\n",
    "Run both cells to see the dramatic performance difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd534d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def coalesced_copy(src, dst, n):\n",
    "    \"\"\"\n",
    "    COALESCED: Adjacent threads access adjacent elements.\n",
    "    Thread 0 â†’ src[0], Thread 1 â†’ src[1], ...\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        dst[idx] = src[idx]\n",
    "\n",
    "@cuda.jit\n",
    "def strided_copy(src, dst, n, stride):\n",
    "    \"\"\"\n",
    "    NON-COALESCED: Threads access memory with stride.\n",
    "    Thread 0 â†’ src[0], Thread 1 â†’ src[stride], Thread 2 â†’ src[2*stride]...\n",
    "    \"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n // stride:\n",
    "        # Calculate strided index\n",
    "        idx = tid * stride\n",
    "        if idx < n:\n",
    "            dst[idx] = src[idx]\n",
    "\n",
    "def benchmark_access_pattern(n, stride=1, iterations=100):\n",
    "    \"\"\"Benchmark different access patterns\"\"\"\n",
    "    src = cuda.to_device(np.random.randn(n).astype(np.float32))\n",
    "    dst = cuda.device_array(n, dtype=np.float32)\n",
    "    \n",
    "    threads = 256\n",
    "    blocks = math.ceil(n / threads)\n",
    "    \n",
    "    # Warmup\n",
    "    if stride == 1:\n",
    "        coalesced_copy[blocks, threads](src, dst, n)\n",
    "    else:\n",
    "        strided_copy[blocks, threads](src, dst, n, stride)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        if stride == 1:\n",
    "            coalesced_copy[blocks, threads](src, dst, n)\n",
    "        else:\n",
    "            strided_copy[blocks, threads](src, dst, n, stride)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    # Calculate bandwidth\n",
    "    bytes_transferred = 2 * n * 4  # Read + write, float32\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Compare patterns\n",
    "n = 100_000_000  # 100M elements\n",
    "\n",
    "print(f\"Array size: {n:,} elements ({n * 4 / 1e9:.2f} GB)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Pattern':<25} | {'Time (ms)':<12} | {'Bandwidth (GB/s)'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "time_coal, bw_coal = benchmark_access_pattern(n, stride=1)\n",
    "print(f\"{'Coalesced (stride=1)':<25} | {time_coal:<12.3f} | {bw_coal:.1f}\")\n",
    "\n",
    "for stride in [2, 4, 8, 16, 32]:\n",
    "    time_s, bw_s = benchmark_access_pattern(n, stride=stride)\n",
    "    slowdown = time_s / time_coal\n",
    "    print(f\"{'Strided (stride=' + str(stride) + ')':<25} | {time_s:<12.3f} | {bw_s:.1f} ({slowdown:.1f}x slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464b4ef",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Version (Optional)\n",
    "\n",
    "The following demonstrates the same concept using Numba for quick interactive testing.\n",
    "Note how the thread-to-index mapping determines whether access is coalesced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6486bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def row_major_read(matrix, output, rows, cols):\n",
    "    \"\"\"\n",
    "    COALESCED: Each warp reads along a row.\n",
    "    threadIdx.x corresponds to column (fast-changing dimension)\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Reading matrix[row][col] - threads in a warp read adjacent columns\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def col_major_read(matrix, output, rows, cols):\n",
    "    \"\"\"\n",
    "    NON-COALESCED: Each warp reads down a column.\n",
    "    threadIdx.x corresponds to row (slow-changing dimension)\n",
    "    \"\"\"\n",
    "    row, col = cuda.grid(2)  # Note: swapped!\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Same operation, but different thread mapping\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "def benchmark_2d_pattern(rows, cols, pattern='row', iterations=100):\n",
    "    \"\"\"Benchmark 2D access patterns\"\"\"\n",
    "    matrix = cuda.to_device(np.random.randn(rows, cols).astype(np.float32))\n",
    "    output = cuda.device_array((rows, cols), dtype=np.float32)\n",
    "    \n",
    "    threads = (16, 16)  # 256 threads per block\n",
    "    \n",
    "    if pattern == 'row':\n",
    "        blocks = (math.ceil(cols / 16), math.ceil(rows / 16))\n",
    "        kernel = row_major_read\n",
    "    else:\n",
    "        blocks = (math.ceil(rows / 16), math.ceil(cols / 16))\n",
    "        kernel = col_major_read\n",
    "    \n",
    "    # Warmup\n",
    "    kernel[blocks, threads](matrix, output, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        kernel[blocks, threads](matrix, output, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    bytes_transferred = 2 * rows * cols * 4\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Benchmark 2D patterns\n",
    "rows, cols = 4096, 4096  # 64MB matrix\n",
    "\n",
    "print(f\"Matrix size: {rows} Ã— {cols} ({rows * cols * 4 / 1e6:.1f} MB)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "time_row, bw_row = benchmark_2d_pattern(rows, cols, 'row')\n",
    "time_col, bw_col = benchmark_2d_pattern(rows, cols, 'col')\n",
    "\n",
    "print(f\"Row-major (coalesced):     {time_row:.3f} ms, {bw_row:.1f} GB/s\")\n",
    "print(f\"Column-major (strided):    {time_col:.3f} ms, {bw_col:.1f} GB/s\")\n",
    "print(f\"\\nSpeedup from coalescing: {time_col/time_row:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aec9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Visualize the Performance Difference\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the results from the benchmark above (or example values if not run)\n",
    "try:\n",
    "    patterns = ['Row-Major\\n(Coalesced)', 'Column-Major\\n(Strided)']\n",
    "    times = [time_row, time_col]\n",
    "    bandwidths = [bw_row, bw_col]\n",
    "except NameError:\n",
    "    # Example values if benchmark wasn't run\n",
    "    patterns = ['Row-Major\\n(Coalesced)', 'Column-Major\\n(Strided)']\n",
    "    times = [0.15, 1.5]  # Example: 10x difference\n",
    "    bandwidths = [400, 40]\n",
    "    print(\"âš ï¸ Using example values. Run the benchmark above to see actual results.\\n\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Time comparison\n",
    "colors = ['#2ecc71', '#e74c3c']  # Green for good, red for bad\n",
    "bars1 = ax1.bar(patterns, times, color=colors)\n",
    "ax1.set_ylabel('Time (ms)', fontsize=11)\n",
    "ax1.set_title('â±ï¸ Execution Time\\n(Lower is Better)', fontsize=12, fontweight='bold')\n",
    "for bar, val in zip(bars1, times):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(times)*0.02,\n",
    "            f'{val:.2f} ms', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Bandwidth comparison  \n",
    "bars2 = ax2.bar(patterns, bandwidths, color=colors)\n",
    "ax2.set_ylabel('Bandwidth (GB/s)', fontsize=11)\n",
    "ax2.set_title('ğŸ“ˆ Memory Bandwidth Achieved\\n(Higher is Better)', fontsize=12, fontweight='bold')\n",
    "for bar, val in zip(bars2, bandwidths):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(bandwidths)*0.02,\n",
    "            f'{val:.0f} GB/s', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('coalescing_benchmark.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "speedup = times[1] / times[0] if times[0] > 0 else 10\n",
    "print(f\"\\nğŸ¯ Key Result: Coalesced access is {speedup:.1f}x faster!\")\n",
    "print(f\"   Same computation, same data sizeâ€”just a different memory access pattern.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8f93f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Matrix Transpose: A Classic Coalescing Challenge\n",
    "\n",
    "<details open>\n",
    "<summary>ğŸ’¡ <b>Concept Card: The Transpose Dilemma</b></summary>\n",
    "\n",
    "### ğŸ¯ The Problem\n",
    "Matrix transpose seems simple: swap `A[i][j]` with `A[j][i]`. But there's a fundamental conflict:\n",
    "\n",
    "- **Reading rows** (coalesced) â†’ **Writing columns** (non-coalesced)\n",
    "- **Reading columns** (non-coalesced) â†’ **Writing rows** (coalesced)\n",
    "\n",
    "**You can't have both coalesced reads AND writes with a naive approach!**\n",
    "\n",
    "### ğŸ”§ Why This Happens\n",
    "```\n",
    "Input Matrix (read):        Output Matrix (write):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ A B C D ... â”‚ â† Thread 0-3 read here     â”‚ A E I M ... â”‚ â† But must write scattered!\n",
    "â”‚ E F G H ... â”‚                            â”‚ B F J N ... â”‚\n",
    "â”‚ I J K L ... â”‚                            â”‚ C G K O ... â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "If we read row 0 (A,B,C,D) contiguously...\n",
    "We must write to column 0 (A,E,I,M) which is strided in memory!\n",
    "```\n",
    "\n",
    "### âœ… The Solution (Preview)\n",
    "In the next notebook (Day 2), we'll use **shared memory** to fix this:\n",
    "1. Threads read coalesced into shared memory\n",
    "2. Synchronize (shared memory has no coalescing requirement!)\n",
    "3. Threads write coalesced from shared memory\n",
    "\n",
    "This transforms a 10x slowdown into nearly optimal performance.\n",
    "\n",
    "### âš ï¸ Key Takeaway\n",
    "Matrix transpose is the canonical example of why coalescing matters. Naive code can be **10-32x slower** than optimized code doing the exact same computation.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d7ea1",
   "metadata": {},
   "source": [
    "### ğŸ”· CUDA C++ Matrix Transpose (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile transpose_naive.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Naive transpose: coalesced reads, non-coalesced writes\n",
    "__global__ void transposeReadCoalesced(float* input, float* output, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        // Read: input[row][col] - coalesced (threads read along row)\n",
    "        // Write: output[col][row] - non-coalesced (threads write to scattered cols)\n",
    "        output[col * rows + row] = input[row * cols + col];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Alternative: coalesced writes, non-coalesced reads\n",
    "__global__ void transposeWriteCoalesced(float* input, float* output, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        // Read: input[col][row] - non-coalesced (scattered reads)\n",
    "        // Write: output[row][col] - coalesced (threads write along row)\n",
    "        output[row * cols + col] = input[col * rows + row];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int ROWS = 4096;\n",
    "    const int COLS = 4096;\n",
    "    const size_t bytes = ROWS * COLS * sizeof(float);\n",
    "    \n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, bytes);\n",
    "    cudaMalloc(&d_output, bytes);\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_input = (float*)malloc(bytes);\n",
    "    for (int i = 0; i < ROWS * COLS; i++) h_input[i] = (float)i;\n",
    "    cudaMemcpy(d_input, h_input, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks((COLS + 15) / 16, (ROWS + 15) / 16);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    printf(\"=== Matrix Transpose Coalescing Demo ===\\n\");\n",
    "    printf(\"Matrix: %d x %d\\n\\n\", ROWS, COLS);\n",
    "    \n",
    "    // Benchmark read-coalesced\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        transposeReadCoalesced<<<blocks, threads>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float read_ms;\n",
    "    cudaEventElapsedTime(&read_ms, start, stop);\n",
    "    \n",
    "    // Benchmark write-coalesced\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        transposeWriteCoalesced<<<blocks, threads>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float write_ms;\n",
    "    cudaEventElapsedTime(&write_ms, start, stop);\n",
    "    \n",
    "    printf(\"Read-coalesced transpose:  %.2f ms\\n\", read_ms / 100);\n",
    "    printf(\"Write-coalesced transpose: %.2f ms\\n\", write_ms / 100);\n",
    "    printf(\"\\nNeither is optimal - shared memory fixes this (Day 2)!\\n\");\n",
    "    \n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    free(h_input);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd07a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o transpose_naive transpose_naive.cu && ./transpose_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67084cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def transpose_naive(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Naive transpose: coalesced reads, non-coalesced writes\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Read from input[row][col] (coalesced - threads read along row)\n",
    "        # Write to output[col][row] (non-coalesced - threads write to scattered locations)\n",
    "        output_matrix[col, row] = input_matrix[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def transpose_read_coalesced(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Same as naive - prioritize coalesced reads\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output_matrix[col, row] = input_matrix[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def transpose_write_coalesced(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Prioritize coalesced writes (non-coalesced reads)\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Read from input[col][row] (non-coalesced - scattered reads)\n",
    "        # Write to output[row][col] (coalesced - threads write along row)\n",
    "        output_matrix[row, col] = input_matrix[col, row]\n",
    "\n",
    "def benchmark_transpose(rows, cols, kernel, iterations=100):\n",
    "    \"\"\"Benchmark transpose kernel\"\"\"\n",
    "    input_mat = cuda.to_device(np.random.randn(rows, cols).astype(np.float32))\n",
    "    output_mat = cuda.device_array((cols, rows), dtype=np.float32)\n",
    "    \n",
    "    threads = (16, 16)\n",
    "    blocks = (math.ceil(cols / 16), math.ceil(rows / 16))\n",
    "    \n",
    "    # Warmup\n",
    "    kernel[blocks, threads](input_mat, output_mat, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        kernel[blocks, threads](input_mat, output_mat, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    bytes_transferred = 2 * rows * cols * 4\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Benchmark transpose patterns\n",
    "rows, cols = 4096, 4096\n",
    "\n",
    "print(f\"Matrix transpose: {rows} Ã— {cols}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "time_read, bw_read = benchmark_transpose(rows, cols, transpose_read_coalesced)\n",
    "time_write, bw_write = benchmark_transpose(rows, cols, transpose_write_coalesced)\n",
    "\n",
    "print(f\"Coalesced reads:   {time_read:.3f} ms, {bw_read:.1f} GB/s\")\n",
    "print(f\"Coalesced writes:  {time_write:.3f} ms, {bw_write:.1f} GB/s\")\n",
    "print(f\"\\nğŸ’¡ Neither is optimal! We need shared memory (Day 2) to fix this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde74aa",
   "metadata": {},
   "source": [
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Practice memory coalescing concepts with these hands-on exercises.\n",
    "\n",
    "### Exercise 1: Identify the Access Pattern\n",
    "\n",
    "For each kernel below, identify if the access is coalesced or not.\n",
    "\n",
    "### ğŸ”· CUDA C++ Version (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c853cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile exercise_patterns.cu\n",
    "// exercise_patterns.cu - Identify coalesced vs non-coalesced access\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Pattern A: Sequential access\n",
    "__global__ void patternA(int* arr, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        arr[idx] = idx;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern B: Reverse sequential access\n",
    "__global__ void patternB(int* arr, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        arr[n - 1 - idx] = idx;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern C: Strided access (every other element)\n",
    "__global__ void patternC(int* arr, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n / 2) {\n",
    "        arr[idx * 2] = idx;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern D: 2D access with correct mapping\n",
    "__global__ void patternD(int* matrix, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    if (row < rows && col < cols) {\n",
    "        matrix[row * cols + col] = row + col;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Exercise 1: Identify Access Patterns ===\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern A: arr[idx] = idx\\n\");\n",
    "    printf(\"  â†’ Threads 0,1,2,3,... write to indices 0,1,2,3,...\\n\");\n",
    "    printf(\"  â†’ ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern B: arr[n - 1 - idx] = idx\\n\");\n",
    "    printf(\"  â†’ Threads 0,1,2,3,... write to indices n-1,n-2,n-3,...\\n\");\n",
    "    printf(\"  â†’ ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern C: arr[idx * 2] = idx\\n\");\n",
    "    printf(\"  â†’ Threads 0,1,2,3,... write to indices 0,2,4,6,...\\n\");\n",
    "    printf(\"  â†’ ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern D: matrix[row * cols + col] with threadIdx.x â†’ col\\n\");\n",
    "    printf(\"  â†’ Adjacent threads access adjacent columns\\n\");\n",
    "    printf(\"  â†’ ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"-------------------------------------------\\n\");\n",
    "    printf(\"ANSWERS:\\n\");\n",
    "    printf(\"A: COALESCED (sequential access)\\n\");\n",
    "    printf(\"B: COALESCED (reverse is still contiguous within warp)\\n\");\n",
    "    printf(\"C: NON-COALESCED (stride of 2, 50%% efficiency)\\n\");\n",
    "    printf(\"D: COALESCED (threadIdx.x maps to fast dimension)\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o exercise_patterns exercise_patterns.cu && ./exercise_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d20e1",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Version (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f422329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Identify coalesced vs non-coalesced\n",
    "\n",
    "# Pattern A\n",
    "@cuda.jit\n",
    "def pattern_a(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        arr[idx] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern B\n",
    "@cuda.jit\n",
    "def pattern_b(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        arr[n - 1 - idx] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern C\n",
    "@cuda.jit\n",
    "def pattern_c(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n // 2:\n",
    "        arr[idx * 2] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern D\n",
    "@cuda.jit\n",
    "def pattern_d(matrix, rows, cols):\n",
    "    col, row = cuda.grid(2)\n",
    "    if row < rows and col < cols:\n",
    "        matrix[row, col] = row + col  # TODO: Coalesced or not?\n",
    "\n",
    "print(\"Analyze each pattern and answer:\")\n",
    "print(\"Pattern A: ?\")\n",
    "print(\"Pattern B: ?\")\n",
    "print(\"Pattern C: ?\")\n",
    "print(\"Pattern D: ?\")\n",
    "\n",
    "# Answers:\n",
    "# A: Coalesced (sequential access)\n",
    "# B: Coalesced (reverse sequential is still contiguous within warp)\n",
    "# C: Non-coalesced (stride of 2)\n",
    "# D: Coalesced (threadIdx.x maps to col, which is the fast dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019a64d",
   "metadata": {},
   "source": [
    "### Exercise 2: Fix the Non-Coalesced Access\n",
    "\n",
    "The kernel below processes a 2D array but has non-coalesced access. Fix it!\n",
    "\n",
    "### ğŸ”· CUDA C++ Version (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2638c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fix_coalescing.cu\n",
    "// fix_coalescing.cu - Fix the non-coalesced access pattern\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define ROWS 2048\n",
    "#define COLS 2048\n",
    "\n",
    "// BAD: Non-coalesced access\n",
    "// Problem: threadIdx.x maps to row, causing strided column access\n",
    "__global__ void processMatrixBad(const float* input, float* output, int rows, int cols) {\n",
    "    // This mapping is WRONG for row-major memory!\n",
    "    int row = blockIdx.x * blockDim.x + threadIdx.x;  // threadIdx.x â†’ row\n",
    "    int col = blockIdx.y * blockDim.y + threadIdx.y;  // threadIdx.y â†’ col\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;\n",
    "        output[idx] = input[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// GOOD: Coalesced access\n",
    "// TODO: Fix the thread-to-index mapping so adjacent threads access adjacent memory\n",
    "__global__ void processMatrixGood(const float* input, float* output, int rows, int cols) {\n",
    "    // FIX: threadIdx.x should map to the COLUMN (fast dimension in row-major)\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // threadIdx.x â†’ col\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;  // threadIdx.y â†’ row\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;\n",
    "        output[idx] = input[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t bytes = ROWS * COLS * sizeof(float);\n",
    "    \n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, bytes);\n",
    "    cudaMalloc(&d_output, bytes);\n",
    "    \n",
    "    // Initialize with dummy data\n",
    "    cudaMemset(d_input, 0, bytes);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    printf(\"=== Exercise 2: Fix Non-Coalesced Access ===\\n\\n\");\n",
    "    printf(\"Matrix size: %d x %d\\n\\n\", ROWS, COLS);\n",
    "    \n",
    "    // BAD version: threadIdx.x â†’ row (WRONG for row-major!)\n",
    "    dim3 blocksBad(ROWS / 16, COLS / 16);\n",
    "    dim3 threadsBad(16, 16);  // x=16 threads for rows\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        processMatrixBad<<<blocksBad, threadsBad>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float badTime;\n",
    "    cudaEventElapsedTime(&badTime, start, stop);\n",
    "    float badBW = (2 * bytes * 100) / (badTime / 1000) / 1e9;\n",
    "    \n",
    "    // GOOD version: threadIdx.x â†’ col (CORRECT for row-major!)\n",
    "    dim3 blocksGood(COLS / 16, ROWS / 16);\n",
    "    dim3 threadsGood(16, 16);  // x=16 threads for cols\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        processMatrixGood<<<blocksGood, threadsGood>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float goodTime;\n",
    "    cudaEventElapsedTime(&goodTime, start, stop);\n",
    "    float goodBW = (2 * bytes * 100) / (goodTime / 1000) / 1e9;\n",
    "    \n",
    "    printf(\"BAD  (threadIdx.x â†’ row): %.2f ms, %.1f GB/s\\n\", badTime / 100, badBW);\n",
    "    printf(\"GOOD (threadIdx.x â†’ col): %.2f ms, %.1f GB/s\\n\", goodTime / 100, goodBW);\n",
    "    printf(\"\\nSpeedup: %.1fx\\n\", badTime / goodTime);\n",
    "    \n",
    "    printf(\"\\n-------------------------------------------\\n\");\n",
    "    printf(\"KEY INSIGHT:\\n\");\n",
    "    printf(\"In row-major layout, adjacent columns are adjacent in memory.\\n\");\n",
    "    printf(\"threadIdx.x should map to the COLUMN index for coalescing!\\n\");\n",
    "    \n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o fix_coalescing fix_coalescing.cu && ./fix_coalescing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a703b",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Version (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Fix the access pattern\n",
    "\n",
    "@cuda.jit\n",
    "def process_matrix_bad(matrix, output, rows, cols):\n",
    "    \"\"\"BAD: Non-coalesced access\"\"\"\n",
    "    # Problem: threadIdx.x maps to row, causing non-coalesced column access\n",
    "    row, col = cuda.grid(2)  # This mapping is wrong!\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def process_matrix_good(matrix, output, rows, cols):\n",
    "    \"\"\"TODO: Fix to be coalesced\"\"\"\n",
    "    # TODO: Change the thread-to-index mapping\n",
    "    row, col = cuda.grid(2)  # FIX THIS LINE\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "# Test your fix\n",
    "# rows, cols = 2048, 2048\n",
    "# ... benchmark both versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e948211",
   "metadata": {},
   "source": [
    "### Exercise 3: Advanced Coalescing Challenges\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Complete these coalescing exercises to solidify your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dcb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile coalescing_exercises.cu\n",
    "// coalescing_exercises.cu - Advanced Memory Coalescing Exercises\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define CHECK_CUDA(call) { \\\n",
    "    cudaError_t err = call; \\\n",
    "    if (err != cudaSuccess) { \\\n",
    "        printf(\"CUDA Error: %s at line %d\\n\", cudaGetErrorString(err), __LINE__); \\\n",
    "        exit(1); \\\n",
    "    } \\\n",
    "}\n",
    "\n",
    "//=============================================================================\n",
    "// EXERCISE 1: Analyze Access Patterns\n",
    "// Determine if each kernel has coalesced memory access\n",
    "//=============================================================================\n",
    "\n",
    "// Pattern A: Direct indexing\n",
    "__global__ void patternDirect(float* out, const float* in, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        out[idx] = in[idx] * 2.0f;  // Coalesced? _____\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern B: Offset indexing\n",
    "__global__ void patternOffset(float* out, const float* in, int n, int offset) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int offsetIdx = idx + offset;\n",
    "    if (offsetIdx < n) {\n",
    "        out[offsetIdx] = in[offsetIdx] * 2.0f;  // Coalesced? _____\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern C: Warp-strided indexing\n",
    "__global__ void patternWarpStrided(float* out, const float* in, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stridedIdx = (idx / 32) * 64 + (idx % 32);  // Skip every other warp-sized chunk\n",
    "    if (stridedIdx < n) {\n",
    "        out[stridedIdx] = in[stridedIdx] * 2.0f;  // Coalesced? _____\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern D: Interleaved access\n",
    "__global__ void patternInterleaved(float* out, const float* in, int n, int numArrays) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    // Access pattern: thread 0->arr0[0], thread 1->arr1[0], thread 2->arr2[0]...\n",
    "    int arrayIdx = idx % numArrays;\n",
    "    int elemIdx = idx / numArrays;\n",
    "    int actualIdx = arrayIdx * (n / numArrays) + elemIdx;\n",
    "    if (actualIdx < n) {\n",
    "        out[actualIdx] = in[actualIdx] * 2.0f;  // Coalesced? _____\n",
    "    }\n",
    "}\n",
    "\n",
    "//=============================================================================\n",
    "// EXERCISE 2: Fix Non-Coalesced Access\n",
    "// Rewrite these kernels to achieve coalesced memory access\n",
    "//=============================================================================\n",
    "\n",
    "// BAD: Column-major access in row-major array\n",
    "__global__ void copyColumnMajorBad(float* dst, const float* src, int rows, int cols) {\n",
    "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        // Adjacent threads (in x) access rows -> non-coalesced!\n",
    "        dst[row * cols + col] = src[row * cols + col];\n",
    "    }\n",
    "}\n",
    "\n",
    "// TODO: Fix this kernel for coalesced access\n",
    "__global__ void copyColumnMajorFixed(float* dst, const float* src, int rows, int cols) {\n",
    "    // HINT: Map threadIdx.x to columns instead of rows\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // Fixed: x -> columns\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;  // Fixed: y -> rows\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        dst[row * cols + col] = src[row * cols + col];\n",
    "    }\n",
    "}\n",
    "\n",
    "//=============================================================================\n",
    "// EXERCISE 3: Structure of Arrays (SoA) vs Array of Structures (AoS)\n",
    "// Compare memory access patterns\n",
    "//=============================================================================\n",
    "\n",
    "// Array of Structures (AoS) - Poor coalescing\n",
    "struct ParticleAoS {\n",
    "    float x, y, z;\n",
    "    float vx, vy, vz;\n",
    "    float mass;\n",
    "    int id;  // 8 floats = 32 bytes per particle\n",
    "};\n",
    "\n",
    "// Structure of Arrays (SoA) - Better coalescing\n",
    "struct ParticlesSoA {\n",
    "    float* x;\n",
    "    float* y;\n",
    "    float* z;\n",
    "    float* vx;\n",
    "    float* vy;\n",
    "    float* vz;\n",
    "    float* mass;\n",
    "    int* id;\n",
    "};\n",
    "\n",
    "// BAD: AoS access pattern\n",
    "__global__ void updateParticlesAoS(ParticleAoS* particles, int n, float dt) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        // Each thread accesses 32-byte struct, stride = 32 bytes between threads\n",
    "        particles[idx].x += particles[idx].vx * dt;\n",
    "        particles[idx].y += particles[idx].vy * dt;\n",
    "        particles[idx].z += particles[idx].vz * dt;\n",
    "    }\n",
    "}\n",
    "\n",
    "// GOOD: SoA access pattern\n",
    "__global__ void updateParticlesSoA(float* x, float* y, float* z,\n",
    "                                    float* vx, float* vy, float* vz,\n",
    "                                    int n, float dt) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        // Adjacent threads access adjacent memory locations\n",
    "        x[idx] += vx[idx] * dt;\n",
    "        y[idx] += vy[idx] * dt;\n",
    "        z[idx] += vz[idx] * dt;\n",
    "    }\n",
    "}\n",
    "\n",
    "//=============================================================================\n",
    "// EXERCISE 4: Benchmark Coalesced vs Non-Coalesced\n",
    "//=============================================================================\n",
    "\n",
    "__global__ void coalescedSum(float* output, const float* input, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        output[idx] = input[idx] + 1.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void nonCoalescedSum(float* output, const float* input, int n, int stride) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stridedIdx = idx * stride;\n",
    "    if (stridedIdx < n) {\n",
    "        output[stridedIdx] = input[stridedIdx] + 1.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Memory Coalescing Exercises ===\\n\\n\");\n",
    "    \n",
    "    //-------------------------------------------------------------------------\n",
    "    // Exercise 1: Access Pattern Analysis\n",
    "    //-------------------------------------------------------------------------\n",
    "    printf(\"EXERCISE 1: Access Pattern Analysis\\n\");\n",
    "    printf(\"===================================\\n\");\n",
    "    printf(\"Analyze each pattern and determine if it's coalesced:\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern A (Direct): out[idx] = in[idx]\\n\");\n",
    "    printf(\"  â†’ Adjacent threads access adjacent memory\\n\");\n",
    "    printf(\"  â†’ ANSWER: COALESCED âœ“\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern B (Offset): out[idx + offset] = in[idx + offset]\\n\");\n",
    "    printf(\"  â†’ All threads offset by same amount, still contiguous\\n\");\n",
    "    printf(\"  â†’ ANSWER: COALESCED âœ“ (if offset is aligned)\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern C (Warp-strided): Skips every other 32-element chunk\\n\");\n",
    "    printf(\"  â†’ Within a warp, threads still access contiguous memory\\n\");\n",
    "    printf(\"  â†’ ANSWER: COALESCED âœ“ (per warp)\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern D (Interleaved): Threads scattered across arrays\\n\");\n",
    "    printf(\"  â†’ Adjacent threads access non-adjacent memory\\n\");\n",
    "    printf(\"  â†’ ANSWER: NON-COALESCED âœ—\\n\\n\");\n",
    "    \n",
    "    //-------------------------------------------------------------------------\n",
    "    // Exercise 2 & 4: Benchmark\n",
    "    //-------------------------------------------------------------------------\n",
    "    printf(\"EXERCISE 2 & 4: Performance Benchmark\\n\");\n",
    "    printf(\"=====================================\\n\");\n",
    "    \n",
    "    const int N = 1 << 22;  // 4M elements\n",
    "    const int bytes = N * sizeof(float);\n",
    "    \n",
    "    float *d_input, *d_output;\n",
    "    CHECK_CUDA(cudaMalloc(&d_input, bytes));\n",
    "    CHECK_CUDA(cudaMalloc(&d_output, bytes));\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_input = (float*)malloc(bytes);\n",
    "    for (int i = 0; i < N; i++) h_input[i] = 1.0f;\n",
    "    CHECK_CUDA(cudaMemcpy(d_input, h_input, bytes, cudaMemcpyHostToDevice));\n",
    "    \n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CHECK_CUDA(cudaEventCreate(&start));\n",
    "    CHECK_CUDA(cudaEventCreate(&stop));\n",
    "    \n",
    "    // Benchmark coalesced access\n",
    "    CHECK_CUDA(cudaEventRecord(start));\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        coalescedSum<<<numBlocks, blockSize>>>(d_output, d_input, N);\n",
    "    }\n",
    "    CHECK_CUDA(cudaEventRecord(stop));\n",
    "    CHECK_CUDA(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float coalescedTime;\n",
    "    CHECK_CUDA(cudaEventElapsedTime(&coalescedTime, start, stop));\n",
    "    \n",
    "    // Benchmark non-coalesced (stride = 2)\n",
    "    CHECK_CUDA(cudaEventRecord(start));\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        nonCoalescedSum<<<numBlocks, blockSize>>>(d_output, d_input, N, 2);\n",
    "    }\n",
    "    CHECK_CUDA(cudaEventRecord(stop));\n",
    "    CHECK_CUDA(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float stride2Time;\n",
    "    CHECK_CUDA(cudaEventElapsedTime(&stride2Time, start, stop));\n",
    "    \n",
    "    // Benchmark non-coalesced (stride = 32)\n",
    "    CHECK_CUDA(cudaEventRecord(start));\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        nonCoalescedSum<<<numBlocks/32, blockSize>>>(d_output, d_input, N, 32);\n",
    "    }\n",
    "    CHECK_CUDA(cudaEventRecord(stop));\n",
    "    CHECK_CUDA(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float stride32Time;\n",
    "    CHECK_CUDA(cudaEventElapsedTime(&stride32Time, start, stop));\n",
    "    \n",
    "    printf(\"\\nPerformance Results (100 iterations):\\n\");\n",
    "    printf(\"  Coalesced (stride=1):     %.2f ms\\n\", coalescedTime);\n",
    "    printf(\"  Non-coalesced (stride=2): %.2f ms (%.1fx slower)\\n\", \n",
    "           stride2Time, stride2Time / coalescedTime);\n",
    "    printf(\"  Non-coalesced (stride=32):%.2f ms (%.1fx slower)\\n\", \n",
    "           stride32Time, stride32Time / coalescedTime);\n",
    "    \n",
    "    // Calculate bandwidth\n",
    "    float coalescedBW = (2.0f * bytes * 100) / (coalescedTime / 1000.0f) / 1e9;\n",
    "    printf(\"\\nEffective Bandwidth:\\n\");\n",
    "    printf(\"  Coalesced: %.1f GB/s\\n\", coalescedBW);\n",
    "    \n",
    "    //-------------------------------------------------------------------------\n",
    "    // Exercise 3: SoA vs AoS\n",
    "    //-------------------------------------------------------------------------\n",
    "    printf(\"\\nEXERCISE 3: SoA vs AoS Memory Layout\\n\");\n",
    "    printf(\"====================================\\n\");\n",
    "    printf(\"Array of Structures (AoS):\\n\");\n",
    "    printf(\"  Memory: [x0,y0,z0,vx0,vy0,vz0,m0,id0][x1,y1,z1,...]\\n\");\n",
    "    printf(\"  Thread 0 accesses byte 0, Thread 1 accesses byte 32\\n\");\n",
    "    printf(\"  â†’ NON-COALESCED (32-byte stride)\\n\\n\");\n",
    "    \n",
    "    printf(\"Structure of Arrays (SoA):\\n\");\n",
    "    printf(\"  Memory: [x0,x1,x2,...][y0,y1,y2,...][z0,z1,z2,...]\\n\");\n",
    "    printf(\"  Thread 0 accesses x[0], Thread 1 accesses x[1]\\n\");\n",
    "    printf(\"  â†’ COALESCED (4-byte stride for floats)\\n\\n\");\n",
    "    \n",
    "    printf(\"Recommendation: Use SoA layout for GPU-intensive code!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    CHECK_CUDA(cudaFree(d_input));\n",
    "    CHECK_CUDA(cudaFree(d_output));\n",
    "    CHECK_CUDA(cudaEventDestroy(start));\n",
    "    CHECK_CUDA(cudaEventDestroy(stop));\n",
    "    free(h_input);\n",
    "    \n",
    "    printf(\"\\n=== Exercises Complete ===\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106af35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o coalescing_exercises coalescing_exercises.cu && ./coalescing_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119bfd20",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Version (Optional)\n",
    "\n",
    "The exercises above cover the key coalescing concepts. For quick validation, you can use the Python/Numba kernels from earlier exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db563c5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Summary: What You Learned Today\n",
    "\n",
    "<details open>\n",
    "<summary><b>ğŸ“‹ Quick Reference Card</b></summary>\n",
    "\n",
    "### The Golden Rule\n",
    "> **Adjacent threads should access adjacent memory addresses.**\n",
    "\n",
    "### The Delivery Truck Analogy\n",
    "- Memory controller delivers in 128-byte packages (like a truck with minimum box size)\n",
    "- Scattered requests = multiple trips = wasted bandwidth\n",
    "- Contiguous requests = one trip = maximum efficiency\n",
    "\n",
    "### Access Pattern Cheat Sheet\n",
    "| Do This âœ… | Not This âŒ |\n",
    "|-----------|------------|\n",
    "| `arr[threadIdx.x]` | `arr[threadIdx.x * stride]` |\n",
    "| `matrix[row][col]` with col = threadIdx.x | `matrix[row][col]` with row = threadIdx.x |\n",
    "| Structure of Arrays (SoA) | Array of Structures (AoS) |\n",
    "| Sequential access | Random/scattered access |\n",
    "\n",
    "### Performance Impact\n",
    "| Access Pattern | Typical Bandwidth | Efficiency |\n",
    "|---------------|-------------------|------------|\n",
    "| Perfectly coalesced | 200-400 GB/s | ~100% |\n",
    "| Stride of 2 | 100-200 GB/s | ~50% |\n",
    "| Stride of 32 | 10-30 GB/s | ~3-10% |\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”‘ Three Things to Remember\n",
    "\n",
    "1. **The WHY**: GPU memory is optimized for bulk transfers. Scattered access wastes bandwidth because each request still fetches 128 bytes.\n",
    "\n",
    "2. **The RULE**: Map `threadIdx.x` (the fast-changing dimension) to the last array index (columns in row-major C/NumPy arrays).\n",
    "\n",
    "3. **THE LIMITATION**: Some patterns (like transpose) can't be fixed with coalescing aloneâ€”that's why we need shared memory (Day 2).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š What's Next?\n",
    "\n",
    "**Day 2: Shared Memory** - You'll learn:\n",
    "- How to use shared memory as a fast \"scratch pad\"\n",
    "- The tiled algorithm pattern\n",
    "- How to fix the transpose problem (10x â†’ 1.1x overhead!)\n",
    "- Thread synchronization with `__syncthreads()`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”— Deep Dive Resources\n",
    "- [Device Memory Access](../../cuda-programming-guide/03-advanced/device-memory-access.md)\n",
    "- [Performance Optimization](../../cuda-programming-guide/03-advanced/performance-optimization.md)\n",
    "- [NVIDIA Memory Coalescing Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#coalesced-access-to-global-memory)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
