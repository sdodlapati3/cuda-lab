{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4d96d9",
   "metadata": {},
   "source": [
    "# üöÄ Day 1: Memory Coalescing - The Key to GPU Performance\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapati3/cuda-lab/blob/main/learning-path/week-02/day-1-memory-coalescing.ipynb)\n",
    "\n",
    "## Learning Philosophy\n",
    "\n",
    "> **CUDA C++ First, Python/Numba as Optional Backup**\n",
    "\n",
    "This notebook shows:\n",
    "1. **CUDA C++ code** - The PRIMARY implementation you should learn\n",
    "2. **Python/Numba code** - OPTIONAL for quick interactive testing in Colab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Colab/Local Setup - Run this first!\n",
    "# Python/Numba is OPTIONAL - for quick interactive testing only\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"üîß Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"‚úÖ Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"üíª Running locally - make sure you have: pip install numba numpy\")\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Remember: CUDA C++ code is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115054e",
   "metadata": {},
   "source": [
    "# Day 1: Memory Coalescing - The Key to GPU Performance\n",
    "\n",
    "Memory bandwidth is the #1 bottleneck in most GPU programs. Today you'll learn:\n",
    "- How GPUs access global memory\n",
    "- What memory coalescing means\n",
    "- How to write coalesced access patterns\n",
    "- Measuring the performance impact\n",
    "\n",
    "---\n",
    "\n",
    "## 1. How GPU Memory Access Works\n",
    "\n",
    "When a warp (32 threads) accesses global memory, the hardware:\n",
    "1. Collects all memory addresses from all threads\n",
    "2. Groups them into **memory transactions** (32, 64, or 128 bytes)\n",
    "3. Fetches data in as few transactions as possible\n",
    "\n",
    "### üî∑ CUDA C++ Implementation (Primary)\n",
    "\n",
    "```\n",
    "COALESCED ACCESS (Good):\n",
    "Thread:    0    1    2    3   ...  31\n",
    "Address:  [0]  [1]  [2]  [3] ... [31]\n",
    "           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                ONE 128-byte transaction!\n",
    "\n",
    "NON-COALESCED ACCESS (Bad):\n",
    "Thread:    0    1    2    3   ...  31\n",
    "Address:  [0] [32] [64] [96] ...[992]\n",
    "           ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ       ‚îÇ\n",
    "           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           32 separate transactions! (32x slower)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad20a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile coalescing_demo.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// GOOD: Coalesced access - adjacent threads access adjacent memory\n",
    "__global__ void coalescedCopy(const float* src, float* dst, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        dst[idx] = src[idx];  // Thread 0‚Üíaddr 0, Thread 1‚Üíaddr 1, ...\n",
    "    }\n",
    "}\n",
    "\n",
    "// BAD: Strided access - adjacent threads access scattered memory\n",
    "__global__ void stridedCopy(const float* src, float* dst, int n, int stride) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int strided_idx = idx * stride;  // Thread 0‚Üíaddr 0, Thread 1‚Üíaddr 32, ...\n",
    "    if (strided_idx < n) {\n",
    "        dst[strided_idx] = src[strided_idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;  // 1M elements\n",
    "    const int bytes = N * sizeof(float);\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float *h_src = (float*)malloc(bytes);\n",
    "    float *h_dst = (float*)malloc(bytes);\n",
    "    \n",
    "    // Initialize source data\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_src[i] = (float)i;\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_src, *d_dst;\n",
    "    cudaMalloc(&d_src, bytes);\n",
    "    cudaMalloc(&d_dst, bytes);\n",
    "    \n",
    "    // Copy to device\n",
    "    cudaMemcpy(d_src, h_src, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch coalesced kernel\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    \n",
    "    printf(\"Testing coalesced vs strided access patterns:\\n\");\n",
    "    printf(\"Array size: %d elements\\n\\n\", N);\n",
    "    \n",
    "    // Time coalesced access\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        coalescedCopy<<<blocks, threads>>>(d_src, d_dst, N);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float coalesced_ms;\n",
    "    cudaEventElapsedTime(&coalesced_ms, start, stop);\n",
    "    printf(\"Coalesced access (stride=1): %.3f ms (avg per iteration)\\n\", coalesced_ms / 100);\n",
    "    \n",
    "    // Time strided access with different strides\n",
    "    for (int stride = 2; stride <= 32; stride *= 2) {\n",
    "        cudaMemset(d_dst, 0, bytes);\n",
    "        \n",
    "        cudaEventRecord(start);\n",
    "        for (int i = 0; i < 100; i++) {\n",
    "            stridedCopy<<<blocks, threads>>>(d_src, d_dst, N, stride);\n",
    "        }\n",
    "        cudaEventRecord(stop);\n",
    "        cudaEventSynchronize(stop);\n",
    "        \n",
    "        float strided_ms;\n",
    "        cudaEventElapsedTime(&strided_ms, start, stop);\n",
    "        printf(\"Strided access (stride=%d): %.3f ms (%.1fx slower)\\n\", \n",
    "               stride, strided_ms / 100, strided_ms / coalesced_ms);\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_src);\n",
    "    cudaFree(d_dst);\n",
    "    free(h_src);\n",
    "    free(h_dst);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o coalescing_demo coalescing_demo.cu\n",
    "!./coalescing_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8613536",
   "metadata": {},
   "source": [
    "### üî∂ Python/Numba (Optional - Quick Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bfa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(\"CUDA device:\", cuda.get_current_device().name.decode())\n",
    "\n",
    "# Get memory bandwidth info\n",
    "device = cuda.get_current_device()\n",
    "print(f\"Warp size: {device.WARP_SIZE}\")\n",
    "print(f\"Max threads per block: {device.MAX_THREADS_PER_BLOCK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcea3d",
   "metadata": {},
   "source": [
    "## 2. The Coalescing Rule\n",
    "\n",
    "### The Golden Rule:\n",
    "**Adjacent threads (within a warp) should access adjacent memory locations.**\n",
    "\n",
    "### Transaction Sizes:\n",
    "- 32 bytes (8 √ó float32)\n",
    "- 64 bytes (16 √ó float32)\n",
    "- 128 bytes (32 √ó float32) ‚Üê ideal for a warp!\n",
    "\n",
    "### Good vs Bad Patterns:\n",
    "\n",
    "| Pattern | Example | Coalesced? |\n",
    "|---------|---------|------------|\n",
    "| Sequential | `arr[threadIdx.x]` | ‚úÖ Yes |\n",
    "| Strided | `arr[threadIdx.x * stride]` | ‚ùå No (if stride > 1) |\n",
    "| Random | `arr[random_index]` | ‚ùå No |\n",
    "| Row-major 2D | `arr[row][col]` with col = threadIdx.x | ‚úÖ Yes |\n",
    "| Column-major 2D | `arr[row][col]` with row = threadIdx.x | ‚ùå No |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88867bfe",
   "metadata": {},
   "source": [
    "### üî∑ CUDA C++ 2D Access Patterns (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb07075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile coalescing_2d.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// GOOD: Row-major access - threads in a warp access adjacent columns\n",
    "__global__ void rowMajorAccess(float* matrix, float* output, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // Fast dimension\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;  // Row-major indexing\n",
    "        output[idx] = matrix[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// BAD: Column-major access - threads in a warp access scattered rows\n",
    "__global__ void colMajorAccess(float* matrix, float* output, int rows, int cols) {\n",
    "    int row = blockIdx.x * blockDim.x + threadIdx.x;  // Wrong! Fast dimension on rows\n",
    "    int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;\n",
    "        output[idx] = matrix[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int ROWS = 4096;\n",
    "    const int COLS = 4096;\n",
    "    const int SIZE = ROWS * COLS;\n",
    "    const size_t bytes = SIZE * sizeof(float);\n",
    "    \n",
    "    float *d_matrix, *d_output;\n",
    "    cudaMalloc(&d_matrix, bytes);\n",
    "    cudaMalloc(&d_output, bytes);\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_matrix = (float*)malloc(bytes);\n",
    "    for (int i = 0; i < SIZE; i++) h_matrix[i] = 1.0f;\n",
    "    cudaMemcpy(d_matrix, h_matrix, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks_row((COLS + 15) / 16, (ROWS + 15) / 16);\n",
    "    dim3 blocks_col((ROWS + 15) / 16, (COLS + 15) / 16);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    printf(\"=== 2D Access Pattern Benchmark ===\\n\");\n",
    "    printf(\"Matrix: %d x %d (%.1f MB)\\n\\n\", ROWS, COLS, bytes / 1e6);\n",
    "    \n",
    "    // Benchmark row-major (coalesced)\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        rowMajorAccess<<<blocks_row, threads>>>(d_matrix, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float row_ms;\n",
    "    cudaEventElapsedTime(&row_ms, start, stop);\n",
    "    float row_bw = (2 * bytes * 100) / (row_ms / 1000) / 1e9;\n",
    "    \n",
    "    // Benchmark column-major (non-coalesced)\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        colMajorAccess<<<blocks_col, threads>>>(d_matrix, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float col_ms;\n",
    "    cudaEventElapsedTime(&col_ms, start, stop);\n",
    "    float col_bw = (2 * bytes * 100) / (col_ms / 1000) / 1e9;\n",
    "    \n",
    "    printf(\"Row-major (coalesced):    %.2f ms, %.1f GB/s\\n\", row_ms / 100, row_bw);\n",
    "    printf(\"Column-major (strided):   %.2f ms, %.1f GB/s\\n\", col_ms / 100, col_bw);\n",
    "    printf(\"Speedup from coalescing:  %.2fx\\n\", col_ms / row_ms);\n",
    "    \n",
    "    cudaFree(d_matrix);\n",
    "    cudaFree(d_output);\n",
    "    free(h_matrix);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f790170",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o coalescing_2d coalescing_2d.cu && ./coalescing_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73d4a8",
   "metadata": {},
   "source": [
    "## 3. Demonstrating Coalesced vs Non-Coalesced Access\n",
    "\n",
    "Let's create two kernels that do the same work but with different access patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd534d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def coalesced_copy(src, dst, n):\n",
    "    \"\"\"\n",
    "    COALESCED: Adjacent threads access adjacent elements.\n",
    "    Thread 0 ‚Üí src[0], Thread 1 ‚Üí src[1], ...\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        dst[idx] = src[idx]\n",
    "\n",
    "@cuda.jit\n",
    "def strided_copy(src, dst, n, stride):\n",
    "    \"\"\"\n",
    "    NON-COALESCED: Threads access memory with stride.\n",
    "    Thread 0 ‚Üí src[0], Thread 1 ‚Üí src[stride], Thread 2 ‚Üí src[2*stride]...\n",
    "    \"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n // stride:\n",
    "        # Calculate strided index\n",
    "        idx = tid * stride\n",
    "        if idx < n:\n",
    "            dst[idx] = src[idx]\n",
    "\n",
    "def benchmark_access_pattern(n, stride=1, iterations=100):\n",
    "    \"\"\"Benchmark different access patterns\"\"\"\n",
    "    src = cuda.to_device(np.random.randn(n).astype(np.float32))\n",
    "    dst = cuda.device_array(n, dtype=np.float32)\n",
    "    \n",
    "    threads = 256\n",
    "    blocks = math.ceil(n / threads)\n",
    "    \n",
    "    # Warmup\n",
    "    if stride == 1:\n",
    "        coalesced_copy[blocks, threads](src, dst, n)\n",
    "    else:\n",
    "        strided_copy[blocks, threads](src, dst, n, stride)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        if stride == 1:\n",
    "            coalesced_copy[blocks, threads](src, dst, n)\n",
    "        else:\n",
    "            strided_copy[blocks, threads](src, dst, n, stride)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    # Calculate bandwidth\n",
    "    bytes_transferred = 2 * n * 4  # Read + write, float32\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Compare patterns\n",
    "n = 100_000_000  # 100M elements\n",
    "\n",
    "print(f\"Array size: {n:,} elements ({n * 4 / 1e9:.2f} GB)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Pattern':<25} | {'Time (ms)':<12} | {'Bandwidth (GB/s)'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "time_coal, bw_coal = benchmark_access_pattern(n, stride=1)\n",
    "print(f\"{'Coalesced (stride=1)':<25} | {time_coal:<12.3f} | {bw_coal:.1f}\")\n",
    "\n",
    "for stride in [2, 4, 8, 16, 32]:\n",
    "    time_s, bw_s = benchmark_access_pattern(n, stride=stride)\n",
    "    slowdown = time_s / time_coal\n",
    "    print(f\"{'Strided (stride=' + str(stride) + ')':<25} | {time_s:<12.3f} | {bw_s:.1f} ({slowdown:.1f}x slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464b4ef",
   "metadata": {},
   "source": [
    "## 4. 2D Array Access Patterns\n",
    "\n",
    "For 2D arrays (matrices, images), access pattern matters even more!\n",
    "\n",
    "```\n",
    "Row-Major Layout (C/NumPy default):\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ (0,0) (0,1) (0,2) (0,3) ... ‚îÇ Row 0 (contiguous in memory)\n",
    "‚îÇ (1,0) (1,1) (1,2) (1,3) ... ‚îÇ Row 1\n",
    "‚îÇ (2,0) (2,1) (2,2) (2,3) ... ‚îÇ Row 2\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Memory: [0,0][0,1][0,2][0,3]...[1,0][1,1][1,2]...\n",
    "\n",
    "‚úÖ COALESCED: Threads read along a row (vary column)\n",
    "   Thread 0 ‚Üí (row, 0), Thread 1 ‚Üí (row, 1), ...\n",
    "\n",
    "‚ùå NON-COALESCED: Threads read down a column (vary row)\n",
    "   Thread 0 ‚Üí (0, col), Thread 1 ‚Üí (1, col), ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6486bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def row_major_read(matrix, output, rows, cols):\n",
    "    \"\"\"\n",
    "    COALESCED: Each warp reads along a row.\n",
    "    threadIdx.x corresponds to column (fast-changing dimension)\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Reading matrix[row][col] - threads in a warp read adjacent columns\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def col_major_read(matrix, output, rows, cols):\n",
    "    \"\"\"\n",
    "    NON-COALESCED: Each warp reads down a column.\n",
    "    threadIdx.x corresponds to row (slow-changing dimension)\n",
    "    \"\"\"\n",
    "    row, col = cuda.grid(2)  # Note: swapped!\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Same operation, but different thread mapping\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "def benchmark_2d_pattern(rows, cols, pattern='row', iterations=100):\n",
    "    \"\"\"Benchmark 2D access patterns\"\"\"\n",
    "    matrix = cuda.to_device(np.random.randn(rows, cols).astype(np.float32))\n",
    "    output = cuda.device_array((rows, cols), dtype=np.float32)\n",
    "    \n",
    "    threads = (16, 16)  # 256 threads per block\n",
    "    \n",
    "    if pattern == 'row':\n",
    "        blocks = (math.ceil(cols / 16), math.ceil(rows / 16))\n",
    "        kernel = row_major_read\n",
    "    else:\n",
    "        blocks = (math.ceil(rows / 16), math.ceil(cols / 16))\n",
    "        kernel = col_major_read\n",
    "    \n",
    "    # Warmup\n",
    "    kernel[blocks, threads](matrix, output, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        kernel[blocks, threads](matrix, output, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    bytes_transferred = 2 * rows * cols * 4\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Benchmark 2D patterns\n",
    "rows, cols = 4096, 4096  # 64MB matrix\n",
    "\n",
    "print(f\"Matrix size: {rows} √ó {cols} ({rows * cols * 4 / 1e6:.1f} MB)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "time_row, bw_row = benchmark_2d_pattern(rows, cols, 'row')\n",
    "time_col, bw_col = benchmark_2d_pattern(rows, cols, 'col')\n",
    "\n",
    "print(f\"Row-major (coalesced):     {time_row:.3f} ms, {bw_row:.1f} GB/s\")\n",
    "print(f\"Column-major (strided):    {time_col:.3f} ms, {bw_col:.1f} GB/s\")\n",
    "print(f\"\\nSpeedup from coalescing: {time_col/time_row:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8f93f",
   "metadata": {},
   "source": [
    "## 5. Matrix Transpose: A Classic Coalescing Problem\n",
    "\n",
    "Matrix transpose is tricky because:\n",
    "- Reading rows (coalesced) means writing columns (non-coalesced)\n",
    "- Reading columns (non-coalesced) means writing rows (coalesced)\n",
    "\n",
    "You can't win with naive approach! (We'll fix this with shared memory in Day 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d7ea1",
   "metadata": {},
   "source": [
    "### üî∑ CUDA C++ Matrix Transpose (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile transpose_naive.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Naive transpose: coalesced reads, non-coalesced writes\n",
    "__global__ void transposeReadCoalesced(float* input, float* output, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        // Read: input[row][col] - coalesced (threads read along row)\n",
    "        // Write: output[col][row] - non-coalesced (threads write to scattered cols)\n",
    "        output[col * rows + row] = input[row * cols + col];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Alternative: coalesced writes, non-coalesced reads\n",
    "__global__ void transposeWriteCoalesced(float* input, float* output, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        // Read: input[col][row] - non-coalesced (scattered reads)\n",
    "        // Write: output[row][col] - coalesced (threads write along row)\n",
    "        output[row * cols + col] = input[col * rows + row];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int ROWS = 4096;\n",
    "    const int COLS = 4096;\n",
    "    const size_t bytes = ROWS * COLS * sizeof(float);\n",
    "    \n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, bytes);\n",
    "    cudaMalloc(&d_output, bytes);\n",
    "    \n",
    "    // Initialize\n",
    "    float* h_input = (float*)malloc(bytes);\n",
    "    for (int i = 0; i < ROWS * COLS; i++) h_input[i] = (float)i;\n",
    "    cudaMemcpy(d_input, h_input, bytes, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks((COLS + 15) / 16, (ROWS + 15) / 16);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    printf(\"=== Matrix Transpose Coalescing Demo ===\\n\");\n",
    "    printf(\"Matrix: %d x %d\\n\\n\", ROWS, COLS);\n",
    "    \n",
    "    // Benchmark read-coalesced\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        transposeReadCoalesced<<<blocks, threads>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float read_ms;\n",
    "    cudaEventElapsedTime(&read_ms, start, stop);\n",
    "    \n",
    "    // Benchmark write-coalesced\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        transposeWriteCoalesced<<<blocks, threads>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float write_ms;\n",
    "    cudaEventElapsedTime(&write_ms, start, stop);\n",
    "    \n",
    "    printf(\"Read-coalesced transpose:  %.2f ms\\n\", read_ms / 100);\n",
    "    printf(\"Write-coalesced transpose: %.2f ms\\n\", write_ms / 100);\n",
    "    printf(\"\\nNeither is optimal - shared memory fixes this (Day 2)!\\n\");\n",
    "    \n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    free(h_input);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd07a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o transpose_naive transpose_naive.cu && ./transpose_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67084cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def transpose_naive(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Naive transpose: coalesced reads, non-coalesced writes\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Read from input[row][col] (coalesced - threads read along row)\n",
    "        # Write to output[col][row] (non-coalesced - threads write to scattered locations)\n",
    "        output_matrix[col, row] = input_matrix[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def transpose_read_coalesced(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Same as naive - prioritize coalesced reads\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output_matrix[col, row] = input_matrix[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def transpose_write_coalesced(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Prioritize coalesced writes (non-coalesced reads)\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Read from input[col][row] (non-coalesced - scattered reads)\n",
    "        # Write to output[row][col] (coalesced - threads write along row)\n",
    "        output_matrix[row, col] = input_matrix[col, row]\n",
    "\n",
    "def benchmark_transpose(rows, cols, kernel, iterations=100):\n",
    "    \"\"\"Benchmark transpose kernel\"\"\"\n",
    "    input_mat = cuda.to_device(np.random.randn(rows, cols).astype(np.float32))\n",
    "    output_mat = cuda.device_array((cols, rows), dtype=np.float32)\n",
    "    \n",
    "    threads = (16, 16)\n",
    "    blocks = (math.ceil(cols / 16), math.ceil(rows / 16))\n",
    "    \n",
    "    # Warmup\n",
    "    kernel[blocks, threads](input_mat, output_mat, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        kernel[blocks, threads](input_mat, output_mat, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    bytes_transferred = 2 * rows * cols * 4\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Benchmark transpose patterns\n",
    "rows, cols = 4096, 4096\n",
    "\n",
    "print(f\"Matrix transpose: {rows} √ó {cols}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "time_read, bw_read = benchmark_transpose(rows, cols, transpose_read_coalesced)\n",
    "time_write, bw_write = benchmark_transpose(rows, cols, transpose_write_coalesced)\n",
    "\n",
    "print(f\"Coalesced reads:   {time_read:.3f} ms, {bw_read:.1f} GB/s\")\n",
    "print(f\"Coalesced writes:  {time_write:.3f} ms, {bw_write:.1f} GB/s\")\n",
    "print(f\"\\nüí° Neither is optimal! We need shared memory (Day 2) to fix this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde74aa",
   "metadata": {},
   "source": [
    "## üéØ Exercises\n",
    "\n",
    "### Exercise 1: Identify the Access Pattern\n",
    "\n",
    "For each kernel below, identify if the access is coalesced or not.\n",
    "\n",
    "### üî∑ CUDA C++ Version (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c853cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile exercise_patterns.cu\n",
    "// exercise_patterns.cu - Identify coalesced vs non-coalesced access\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Pattern A: Sequential access\n",
    "__global__ void patternA(int* arr, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        arr[idx] = idx;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern B: Reverse sequential access\n",
    "__global__ void patternB(int* arr, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        arr[n - 1 - idx] = idx;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern C: Strided access (every other element)\n",
    "__global__ void patternC(int* arr, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n / 2) {\n",
    "        arr[idx * 2] = idx;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "// Pattern D: 2D access with correct mapping\n",
    "__global__ void patternD(int* matrix, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    if (row < rows && col < cols) {\n",
    "        matrix[row * cols + col] = row + col;  // TODO: Coalesced or not?\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Exercise 1: Identify Access Patterns ===\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern A: arr[idx] = idx\\n\");\n",
    "    printf(\"  ‚Üí Threads 0,1,2,3,... write to indices 0,1,2,3,...\\n\");\n",
    "    printf(\"  ‚Üí ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern B: arr[n - 1 - idx] = idx\\n\");\n",
    "    printf(\"  ‚Üí Threads 0,1,2,3,... write to indices n-1,n-2,n-3,...\\n\");\n",
    "    printf(\"  ‚Üí ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern C: arr[idx * 2] = idx\\n\");\n",
    "    printf(\"  ‚Üí Threads 0,1,2,3,... write to indices 0,2,4,6,...\\n\");\n",
    "    printf(\"  ‚Üí ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"Pattern D: matrix[row * cols + col] with threadIdx.x ‚Üí col\\n\");\n",
    "    printf(\"  ‚Üí Adjacent threads access adjacent columns\\n\");\n",
    "    printf(\"  ‚Üí ANSWER: ?\\n\\n\");\n",
    "    \n",
    "    printf(\"-------------------------------------------\\n\");\n",
    "    printf(\"ANSWERS:\\n\");\n",
    "    printf(\"A: COALESCED (sequential access)\\n\");\n",
    "    printf(\"B: COALESCED (reverse is still contiguous within warp)\\n\");\n",
    "    printf(\"C: NON-COALESCED (stride of 2, 50%% efficiency)\\n\");\n",
    "    printf(\"D: COALESCED (threadIdx.x maps to fast dimension)\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o exercise_patterns exercise_patterns.cu && ./exercise_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d20e1",
   "metadata": {},
   "source": [
    "### üî∂ Python/Numba Version (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f422329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Identify coalesced vs non-coalesced\n",
    "\n",
    "# Pattern A\n",
    "@cuda.jit\n",
    "def pattern_a(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        arr[idx] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern B\n",
    "@cuda.jit\n",
    "def pattern_b(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        arr[n - 1 - idx] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern C\n",
    "@cuda.jit\n",
    "def pattern_c(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n // 2:\n",
    "        arr[idx * 2] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern D\n",
    "@cuda.jit\n",
    "def pattern_d(matrix, rows, cols):\n",
    "    col, row = cuda.grid(2)\n",
    "    if row < rows and col < cols:\n",
    "        matrix[row, col] = row + col  # TODO: Coalesced or not?\n",
    "\n",
    "print(\"Analyze each pattern and answer:\")\n",
    "print(\"Pattern A: ?\")\n",
    "print(\"Pattern B: ?\")\n",
    "print(\"Pattern C: ?\")\n",
    "print(\"Pattern D: ?\")\n",
    "\n",
    "# Answers:\n",
    "# A: Coalesced (sequential access)\n",
    "# B: Coalesced (reverse sequential is still contiguous within warp)\n",
    "# C: Non-coalesced (stride of 2)\n",
    "# D: Coalesced (threadIdx.x maps to col, which is the fast dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019a64d",
   "metadata": {},
   "source": [
    "### Exercise 2: Fix the Non-Coalesced Access\n",
    "\n",
    "The kernel below processes a 2D array but has non-coalesced access. Fix it!\n",
    "\n",
    "### üî∑ CUDA C++ Version (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2638c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fix_coalescing.cu\n",
    "// fix_coalescing.cu - Fix the non-coalesced access pattern\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define ROWS 2048\n",
    "#define COLS 2048\n",
    "\n",
    "// BAD: Non-coalesced access\n",
    "// Problem: threadIdx.x maps to row, causing strided column access\n",
    "__global__ void processMatrixBad(const float* input, float* output, int rows, int cols) {\n",
    "    // This mapping is WRONG for row-major memory!\n",
    "    int row = blockIdx.x * blockDim.x + threadIdx.x;  // threadIdx.x ‚Üí row\n",
    "    int col = blockIdx.y * blockDim.y + threadIdx.y;  // threadIdx.y ‚Üí col\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;\n",
    "        output[idx] = input[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// GOOD: Coalesced access\n",
    "// TODO: Fix the thread-to-index mapping so adjacent threads access adjacent memory\n",
    "__global__ void processMatrixGood(const float* input, float* output, int rows, int cols) {\n",
    "    // FIX: threadIdx.x should map to the COLUMN (fast dimension in row-major)\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // threadIdx.x ‚Üí col\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;  // threadIdx.y ‚Üí row\n",
    "    \n",
    "    if (row < rows && col < cols) {\n",
    "        int idx = row * cols + col;\n",
    "        output[idx] = input[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t bytes = ROWS * COLS * sizeof(float);\n",
    "    \n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, bytes);\n",
    "    cudaMalloc(&d_output, bytes);\n",
    "    \n",
    "    // Initialize with dummy data\n",
    "    cudaMemset(d_input, 0, bytes);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    printf(\"=== Exercise 2: Fix Non-Coalesced Access ===\\n\\n\");\n",
    "    printf(\"Matrix size: %d x %d\\n\\n\", ROWS, COLS);\n",
    "    \n",
    "    // BAD version: threadIdx.x ‚Üí row (WRONG for row-major!)\n",
    "    dim3 blocksBad(ROWS / 16, COLS / 16);\n",
    "    dim3 threadsBad(16, 16);  // x=16 threads for rows\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        processMatrixBad<<<blocksBad, threadsBad>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float badTime;\n",
    "    cudaEventElapsedTime(&badTime, start, stop);\n",
    "    float badBW = (2 * bytes * 100) / (badTime / 1000) / 1e9;\n",
    "    \n",
    "    // GOOD version: threadIdx.x ‚Üí col (CORRECT for row-major!)\n",
    "    dim3 blocksGood(COLS / 16, ROWS / 16);\n",
    "    dim3 threadsGood(16, 16);  // x=16 threads for cols\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        processMatrixGood<<<blocksGood, threadsGood>>>(d_input, d_output, ROWS, COLS);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float goodTime;\n",
    "    cudaEventElapsedTime(&goodTime, start, stop);\n",
    "    float goodBW = (2 * bytes * 100) / (goodTime / 1000) / 1e9;\n",
    "    \n",
    "    printf(\"BAD  (threadIdx.x ‚Üí row): %.2f ms, %.1f GB/s\\n\", badTime / 100, badBW);\n",
    "    printf(\"GOOD (threadIdx.x ‚Üí col): %.2f ms, %.1f GB/s\\n\", goodTime / 100, goodBW);\n",
    "    printf(\"\\nSpeedup: %.1fx\\n\", badTime / goodTime);\n",
    "    \n",
    "    printf(\"\\n-------------------------------------------\\n\");\n",
    "    printf(\"KEY INSIGHT:\\n\");\n",
    "    printf(\"In row-major layout, adjacent columns are adjacent in memory.\\n\");\n",
    "    printf(\"threadIdx.x should map to the COLUMN index for coalescing!\\n\");\n",
    "    \n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o fix_coalescing fix_coalescing.cu && ./fix_coalescing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a703b",
   "metadata": {},
   "source": [
    "### üî∂ Python/Numba Version (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Fix the access pattern\n",
    "\n",
    "@cuda.jit\n",
    "def process_matrix_bad(matrix, output, rows, cols):\n",
    "    \"\"\"BAD: Non-coalesced access\"\"\"\n",
    "    # Problem: threadIdx.x maps to row, causing non-coalesced column access\n",
    "    row, col = cuda.grid(2)  # This mapping is wrong!\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def process_matrix_good(matrix, output, rows, cols):\n",
    "    \"\"\"TODO: Fix to be coalesced\"\"\"\n",
    "    # TODO: Change the thread-to-index mapping\n",
    "    row, col = cuda.grid(2)  # FIX THIS LINE\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "# Test your fix\n",
    "# rows, cols = 2048, 2048\n",
    "# ... benchmark both versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db563c5b",
   "metadata": {},
   "source": [
    "## üìù Key Takeaways\n",
    "\n",
    "### Memory Coalescing Rules:\n",
    "\n",
    "1. **Adjacent threads should access adjacent memory**\n",
    "   - Thread 0 ‚Üí mem[0], Thread 1 ‚Üí mem[1], etc.\n",
    "\n",
    "2. **For 2D arrays in row-major (C/NumPy):**\n",
    "   - `threadIdx.x` should map to the column index\n",
    "   - `col, row = cuda.grid(2)` is the correct order\n",
    "\n",
    "3. **Strided access kills performance**\n",
    "   - Stride of 2 ‚Üí ~50% efficiency\n",
    "   - Stride of 32 ‚Üí ~3% efficiency\n",
    "\n",
    "4. **Some patterns can't be fixed with coalescing alone**\n",
    "   - Matrix transpose needs shared memory\n",
    "   - We'll learn this tomorrow!\n",
    "\n",
    "### Performance Impact:\n",
    "- Coalesced: 200-400 GB/s on T4\n",
    "- Non-coalesced: 10-50 GB/s\n",
    "- **10-40x performance difference!**\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Next Up: Day 2 - Shared Memory\n",
    "- Using shared memory for tile-based algorithms\n",
    "- Fixing the transpose problem\n",
    "- Thread synchronization with `__syncthreads()`\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Resources\n",
    "- [Device Memory Access](../../cuda-programming-guide/03-advanced/device-memory-access.md)\n",
    "- [Performance Optimization](../../cuda-programming-guide/03-advanced/performance-optimization.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
