{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4d96d9",
   "metadata": {},
   "source": [
    "# üöÄ Day 1: Memory Coalescing - The Key to GPU Performance\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapati3/cuda-lab/blob/main/learning-path/week-02/day-1-memory-coalescing.ipynb)\n",
    "\n",
    "## Learning Philosophy\n",
    "\n",
    "> **CUDA C++ First, Python/Numba as Optional Backup**\n",
    "\n",
    "This notebook shows:\n",
    "1. **CUDA C++ code** - The PRIMARY implementation you should learn\n",
    "2. **Python/Numba code** - OPTIONAL for quick interactive testing in Colab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Colab/Local Setup - Run this first!\n",
    "# Python/Numba is OPTIONAL - for quick interactive testing only\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"üîß Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"‚úÖ Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"üíª Running locally - make sure you have: pip install numba numpy\")\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Remember: CUDA C++ code is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115054e",
   "metadata": {},
   "source": [
    "# Day 1: Memory Coalescing - The Key to GPU Performance\n",
    "\n",
    "Memory bandwidth is the #1 bottleneck in most GPU programs. Today you'll learn:\n",
    "- How GPUs access global memory\n",
    "- What memory coalescing means\n",
    "- How to write coalesced access patterns\n",
    "- Measuring the performance impact\n",
    "\n",
    "---\n",
    "\n",
    "## 1. How GPU Memory Access Works\n",
    "\n",
    "When a warp (32 threads) accesses global memory, the hardware:\n",
    "1. Collects all memory addresses from all threads\n",
    "2. Groups them into **memory transactions** (32, 64, or 128 bytes)\n",
    "3. Fetches data in as few transactions as possible\n",
    "\n",
    "### CUDA C++ Example: Coalesced vs Non-Coalesced\n",
    "\n",
    "```cpp\n",
    "// coalescing_demo.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// GOOD: Coalesced access - adjacent threads access adjacent memory\n",
    "__global__ void coalescedCopy(const float* src, float* dst, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        dst[idx] = src[idx];  // Thread 0‚Üíaddr 0, Thread 1‚Üíaddr 1, ...\n",
    "    }\n",
    "}\n",
    "\n",
    "// BAD: Strided access - adjacent threads access scattered memory\n",
    "__global__ void stridedCopy(const float* src, float* dst, int n, int stride) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int strided_idx = idx * stride;  // Thread 0‚Üíaddr 0, Thread 1‚Üíaddr 32, ...\n",
    "    if (strided_idx < n) {\n",
    "        dst[strided_idx] = src[strided_idx];\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "```\n",
    "COALESCED ACCESS (Good):\n",
    "Thread:    0    1    2    3   ...  31\n",
    "Address:  [0]  [1]  [2]  [3] ... [31]\n",
    "           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                ONE 128-byte transaction!\n",
    "\n",
    "NON-COALESCED ACCESS (Bad):\n",
    "Thread:    0    1    2    3   ...  31\n",
    "Address:  [0] [32] [64] [96] ...[992]\n",
    "           ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ       ‚îÇ\n",
    "           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           32 separate transactions! (32x slower)\n",
    "```\n",
    "\n",
    "### Python/Numba (Optional - Interactive Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bfa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "print(\"CUDA device:\", cuda.get_current_device().name.decode())\n",
    "\n",
    "# Get memory bandwidth info\n",
    "device = cuda.get_current_device()\n",
    "print(f\"Warp size: {device.WARP_SIZE}\")\n",
    "print(f\"Max threads per block: {device.MAX_THREADS_PER_BLOCK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcea3d",
   "metadata": {},
   "source": [
    "## 2. The Coalescing Rule\n",
    "\n",
    "### The Golden Rule:\n",
    "**Adjacent threads (within a warp) should access adjacent memory locations.**\n",
    "\n",
    "### Transaction Sizes:\n",
    "- 32 bytes (8 √ó float32)\n",
    "- 64 bytes (16 √ó float32)\n",
    "- 128 bytes (32 √ó float32) ‚Üê ideal for a warp!\n",
    "\n",
    "### Good vs Bad Patterns:\n",
    "\n",
    "| Pattern | Example | Coalesced? |\n",
    "|---------|---------|------------|\n",
    "| Sequential | `arr[threadIdx.x]` | ‚úÖ Yes |\n",
    "| Strided | `arr[threadIdx.x * stride]` | ‚ùå No (if stride > 1) |\n",
    "| Random | `arr[random_index]` | ‚ùå No |\n",
    "| Row-major 2D | `arr[row][col]` with col = threadIdx.x | ‚úÖ Yes |\n",
    "| Column-major 2D | `arr[row][col]` with row = threadIdx.x | ‚ùå No |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73d4a8",
   "metadata": {},
   "source": [
    "## 3. Demonstrating Coalesced vs Non-Coalesced Access\n",
    "\n",
    "Let's create two kernels that do the same work but with different access patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd534d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def coalesced_copy(src, dst, n):\n",
    "    \"\"\"\n",
    "    COALESCED: Adjacent threads access adjacent elements.\n",
    "    Thread 0 ‚Üí src[0], Thread 1 ‚Üí src[1], ...\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        dst[idx] = src[idx]\n",
    "\n",
    "@cuda.jit\n",
    "def strided_copy(src, dst, n, stride):\n",
    "    \"\"\"\n",
    "    NON-COALESCED: Threads access memory with stride.\n",
    "    Thread 0 ‚Üí src[0], Thread 1 ‚Üí src[stride], Thread 2 ‚Üí src[2*stride]...\n",
    "    \"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < n // stride:\n",
    "        # Calculate strided index\n",
    "        idx = tid * stride\n",
    "        if idx < n:\n",
    "            dst[idx] = src[idx]\n",
    "\n",
    "def benchmark_access_pattern(n, stride=1, iterations=100):\n",
    "    \"\"\"Benchmark different access patterns\"\"\"\n",
    "    src = cuda.to_device(np.random.randn(n).astype(np.float32))\n",
    "    dst = cuda.device_array(n, dtype=np.float32)\n",
    "    \n",
    "    threads = 256\n",
    "    blocks = math.ceil(n / threads)\n",
    "    \n",
    "    # Warmup\n",
    "    if stride == 1:\n",
    "        coalesced_copy[blocks, threads](src, dst, n)\n",
    "    else:\n",
    "        strided_copy[blocks, threads](src, dst, n, stride)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        if stride == 1:\n",
    "            coalesced_copy[blocks, threads](src, dst, n)\n",
    "        else:\n",
    "            strided_copy[blocks, threads](src, dst, n, stride)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    # Calculate bandwidth\n",
    "    bytes_transferred = 2 * n * 4  # Read + write, float32\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Compare patterns\n",
    "n = 100_000_000  # 100M elements\n",
    "\n",
    "print(f\"Array size: {n:,} elements ({n * 4 / 1e9:.2f} GB)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Pattern':<25} | {'Time (ms)':<12} | {'Bandwidth (GB/s)'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "time_coal, bw_coal = benchmark_access_pattern(n, stride=1)\n",
    "print(f\"{'Coalesced (stride=1)':<25} | {time_coal:<12.3f} | {bw_coal:.1f}\")\n",
    "\n",
    "for stride in [2, 4, 8, 16, 32]:\n",
    "    time_s, bw_s = benchmark_access_pattern(n, stride=stride)\n",
    "    slowdown = time_s / time_coal\n",
    "    print(f\"{'Strided (stride=' + str(stride) + ')':<25} | {time_s:<12.3f} | {bw_s:.1f} ({slowdown:.1f}x slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464b4ef",
   "metadata": {},
   "source": [
    "## 4. 2D Array Access Patterns\n",
    "\n",
    "For 2D arrays (matrices, images), access pattern matters even more!\n",
    "\n",
    "```\n",
    "Row-Major Layout (C/NumPy default):\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ (0,0) (0,1) (0,2) (0,3) ... ‚îÇ Row 0 (contiguous in memory)\n",
    "‚îÇ (1,0) (1,1) (1,2) (1,3) ... ‚îÇ Row 1\n",
    "‚îÇ (2,0) (2,1) (2,2) (2,3) ... ‚îÇ Row 2\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Memory: [0,0][0,1][0,2][0,3]...[1,0][1,1][1,2]...\n",
    "\n",
    "‚úÖ COALESCED: Threads read along a row (vary column)\n",
    "   Thread 0 ‚Üí (row, 0), Thread 1 ‚Üí (row, 1), ...\n",
    "\n",
    "‚ùå NON-COALESCED: Threads read down a column (vary row)\n",
    "   Thread 0 ‚Üí (0, col), Thread 1 ‚Üí (1, col), ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6486bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def row_major_read(matrix, output, rows, cols):\n",
    "    \"\"\"\n",
    "    COALESCED: Each warp reads along a row.\n",
    "    threadIdx.x corresponds to column (fast-changing dimension)\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Reading matrix[row][col] - threads in a warp read adjacent columns\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def col_major_read(matrix, output, rows, cols):\n",
    "    \"\"\"\n",
    "    NON-COALESCED: Each warp reads down a column.\n",
    "    threadIdx.x corresponds to row (slow-changing dimension)\n",
    "    \"\"\"\n",
    "    row, col = cuda.grid(2)  # Note: swapped!\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Same operation, but different thread mapping\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "def benchmark_2d_pattern(rows, cols, pattern='row', iterations=100):\n",
    "    \"\"\"Benchmark 2D access patterns\"\"\"\n",
    "    matrix = cuda.to_device(np.random.randn(rows, cols).astype(np.float32))\n",
    "    output = cuda.device_array((rows, cols), dtype=np.float32)\n",
    "    \n",
    "    threads = (16, 16)  # 256 threads per block\n",
    "    \n",
    "    if pattern == 'row':\n",
    "        blocks = (math.ceil(cols / 16), math.ceil(rows / 16))\n",
    "        kernel = row_major_read\n",
    "    else:\n",
    "        blocks = (math.ceil(rows / 16), math.ceil(cols / 16))\n",
    "        kernel = col_major_read\n",
    "    \n",
    "    # Warmup\n",
    "    kernel[blocks, threads](matrix, output, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        kernel[blocks, threads](matrix, output, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    bytes_transferred = 2 * rows * cols * 4\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Benchmark 2D patterns\n",
    "rows, cols = 4096, 4096  # 64MB matrix\n",
    "\n",
    "print(f\"Matrix size: {rows} √ó {cols} ({rows * cols * 4 / 1e6:.1f} MB)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "time_row, bw_row = benchmark_2d_pattern(rows, cols, 'row')\n",
    "time_col, bw_col = benchmark_2d_pattern(rows, cols, 'col')\n",
    "\n",
    "print(f\"Row-major (coalesced):     {time_row:.3f} ms, {bw_row:.1f} GB/s\")\n",
    "print(f\"Column-major (strided):    {time_col:.3f} ms, {bw_col:.1f} GB/s\")\n",
    "print(f\"\\nSpeedup from coalescing: {time_col/time_row:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8f93f",
   "metadata": {},
   "source": [
    "## 5. Matrix Transpose: A Classic Coalescing Problem\n",
    "\n",
    "Matrix transpose is tricky because:\n",
    "- Reading rows (coalesced) means writing columns (non-coalesced)\n",
    "- Reading columns (non-coalesced) means writing rows (coalesced)\n",
    "\n",
    "You can't win with naive approach! (We'll fix this with shared memory in Day 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67084cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def transpose_naive(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Naive transpose: coalesced reads, non-coalesced writes\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Read from input[row][col] (coalesced - threads read along row)\n",
    "        # Write to output[col][row] (non-coalesced - threads write to scattered locations)\n",
    "        output_matrix[col, row] = input_matrix[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def transpose_read_coalesced(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Same as naive - prioritize coalesced reads\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output_matrix[col, row] = input_matrix[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def transpose_write_coalesced(input_matrix, output_matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Prioritize coalesced writes (non-coalesced reads)\n",
    "    \"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        # Read from input[col][row] (non-coalesced - scattered reads)\n",
    "        # Write to output[row][col] (coalesced - threads write along row)\n",
    "        output_matrix[row, col] = input_matrix[col, row]\n",
    "\n",
    "def benchmark_transpose(rows, cols, kernel, iterations=100):\n",
    "    \"\"\"Benchmark transpose kernel\"\"\"\n",
    "    input_mat = cuda.to_device(np.random.randn(rows, cols).astype(np.float32))\n",
    "    output_mat = cuda.device_array((cols, rows), dtype=np.float32)\n",
    "    \n",
    "    threads = (16, 16)\n",
    "    blocks = (math.ceil(cols / 16), math.ceil(rows / 16))\n",
    "    \n",
    "    # Warmup\n",
    "    kernel[blocks, threads](input_mat, output_mat, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        kernel[blocks, threads](input_mat, output_mat, rows, cols)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / iterations\n",
    "    \n",
    "    bytes_transferred = 2 * rows * cols * 4\n",
    "    bandwidth = bytes_transferred / elapsed / 1e9\n",
    "    \n",
    "    return elapsed * 1000, bandwidth\n",
    "\n",
    "# Benchmark transpose patterns\n",
    "rows, cols = 4096, 4096\n",
    "\n",
    "print(f\"Matrix transpose: {rows} √ó {cols}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "time_read, bw_read = benchmark_transpose(rows, cols, transpose_read_coalesced)\n",
    "time_write, bw_write = benchmark_transpose(rows, cols, transpose_write_coalesced)\n",
    "\n",
    "print(f\"Coalesced reads:   {time_read:.3f} ms, {bw_read:.1f} GB/s\")\n",
    "print(f\"Coalesced writes:  {time_write:.3f} ms, {bw_write:.1f} GB/s\")\n",
    "print(f\"\\nüí° Neither is optimal! We need shared memory (Day 2) to fix this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde74aa",
   "metadata": {},
   "source": [
    "## üéØ Exercises\n",
    "\n",
    "### Exercise 1: Identify the Access Pattern\n",
    "\n",
    "For each kernel below, identify if the access is coalesced or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f422329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Identify coalesced vs non-coalesced\n",
    "\n",
    "# Pattern A\n",
    "@cuda.jit\n",
    "def pattern_a(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        arr[idx] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern B\n",
    "@cuda.jit\n",
    "def pattern_b(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n:\n",
    "        arr[n - 1 - idx] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern C\n",
    "@cuda.jit\n",
    "def pattern_c(arr, n):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n // 2:\n",
    "        arr[idx * 2] = idx  # TODO: Coalesced or not?\n",
    "\n",
    "# Pattern D\n",
    "@cuda.jit\n",
    "def pattern_d(matrix, rows, cols):\n",
    "    col, row = cuda.grid(2)\n",
    "    if row < rows and col < cols:\n",
    "        matrix[row, col] = row + col  # TODO: Coalesced or not?\n",
    "\n",
    "print(\"Analyze each pattern and answer:\")\n",
    "print(\"Pattern A: ?\")\n",
    "print(\"Pattern B: ?\")\n",
    "print(\"Pattern C: ?\")\n",
    "print(\"Pattern D: ?\")\n",
    "\n",
    "# Answers:\n",
    "# A: Coalesced (sequential access)\n",
    "# B: Coalesced (reverse sequential is still contiguous within warp)\n",
    "# C: Non-coalesced (stride of 2)\n",
    "# D: Coalesced (threadIdx.x maps to col, which is the fast dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019a64d",
   "metadata": {},
   "source": [
    "### Exercise 2: Fix the Non-Coalesced Access\n",
    "\n",
    "The kernel below processes a 2D array but has non-coalesced access. Fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Fix the access pattern\n",
    "\n",
    "@cuda.jit\n",
    "def process_matrix_bad(matrix, output, rows, cols):\n",
    "    \"\"\"BAD: Non-coalesced access\"\"\"\n",
    "    # Problem: threadIdx.x maps to row, causing non-coalesced column access\n",
    "    row, col = cuda.grid(2)  # This mapping is wrong!\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def process_matrix_good(matrix, output, rows, cols):\n",
    "    \"\"\"TODO: Fix to be coalesced\"\"\"\n",
    "    # TODO: Change the thread-to-index mapping\n",
    "    row, col = cuda.grid(2)  # FIX THIS LINE\n",
    "    \n",
    "    if row < rows and col < cols:\n",
    "        output[row, col] = matrix[row, col] * 2.0\n",
    "\n",
    "# Test your fix\n",
    "# rows, cols = 2048, 2048\n",
    "# ... benchmark both versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db563c5b",
   "metadata": {},
   "source": [
    "## üìù Key Takeaways\n",
    "\n",
    "### Memory Coalescing Rules:\n",
    "\n",
    "1. **Adjacent threads should access adjacent memory**\n",
    "   - Thread 0 ‚Üí mem[0], Thread 1 ‚Üí mem[1], etc.\n",
    "\n",
    "2. **For 2D arrays in row-major (C/NumPy):**\n",
    "   - `threadIdx.x` should map to the column index\n",
    "   - `col, row = cuda.grid(2)` is the correct order\n",
    "\n",
    "3. **Strided access kills performance**\n",
    "   - Stride of 2 ‚Üí ~50% efficiency\n",
    "   - Stride of 32 ‚Üí ~3% efficiency\n",
    "\n",
    "4. **Some patterns can't be fixed with coalescing alone**\n",
    "   - Matrix transpose needs shared memory\n",
    "   - We'll learn this tomorrow!\n",
    "\n",
    "### Performance Impact:\n",
    "- Coalesced: 200-400 GB/s on T4\n",
    "- Non-coalesced: 10-50 GB/s\n",
    "- **10-40x performance difference!**\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Next Up: Day 2 - Shared Memory\n",
    "- Using shared memory for tile-based algorithms\n",
    "- Fixing the transpose problem\n",
    "- Thread synchronization with `__syncthreads()`\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Resources\n",
    "- [Device Memory Access](../../cuda-programming-guide/03-advanced/device-memory-access.md)\n",
    "- [Performance Optimization](../../cuda-programming-guide/03-advanced/performance-optimization.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
