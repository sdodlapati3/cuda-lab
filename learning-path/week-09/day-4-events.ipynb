{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81856651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"âš ï¸  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c3a5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: CUDA Events Basics\n",
    "\n",
    "### What are CUDA Events?\n",
    "\n",
    "```\n",
    "EVENT = A marker in a stream that can be:\n",
    "        â€¢ Recorded (placed at a point in stream)\n",
    "        â€¢ Queried (check if reached)\n",
    "        â€¢ Waited on (block until reached)\n",
    "        â€¢ Used for timing\n",
    "\n",
    "Stream Timeline:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "[H2D Copy] â†’ [event1] â†’ [Kernel] â†’ [event2] â†’ [D2H Copy]\n",
    "              â†‘                      â†‘\n",
    "        record start           record stop\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 elapsed time!\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "This example demonstrates event creation, recording, synchronization, and timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile event_basics.cu\n",
    "// event_basics.cu - Event creation, recording, and synchronization\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void computeKernel(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        for (int i = 0; i < 100; i++) {\n",
    "            data[tid] = sqrtf(data[tid] + 1.0f);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 22;\n",
    "    \n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    // ============================================\n",
    "    // Event Creation\n",
    "    // ============================================\n",
    "    cudaEvent_t start, stop;\n",
    "    \n",
    "    // Default events (for timing and sync)\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Event with flags:\n",
    "    // cudaEventDefault      - Default behavior\n",
    "    // cudaEventBlockingSync - CPU blocks instead of spinning\n",
    "    // cudaEventDisableTiming- Faster, but can't time\n",
    "    // cudaEventInterprocess - For IPC\n",
    "    \n",
    "    cudaEvent_t fastEvent;\n",
    "    cudaEventCreateWithFlags(&fastEvent, cudaEventDisableTiming);\n",
    "    \n",
    "    // ============================================\n",
    "    // Event Recording (place marker in stream)\n",
    "    // ============================================\n",
    "    cudaEventRecord(start);  // Default stream\n",
    "    // OR: cudaEventRecord(start, stream);  // Specific stream\n",
    "    \n",
    "    computeKernel<<<256, 256>>>(d_data, N);\n",
    "    computeKernel<<<256, 256>>>(d_data, N);\n",
    "    computeKernel<<<256, 256>>>(d_data, N);\n",
    "    \n",
    "    cudaEventRecord(stop);\n",
    "    \n",
    "    // ============================================\n",
    "    // Event Synchronization\n",
    "    // ============================================\n",
    "    \n",
    "    // Method 1: Block until event completes\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    // Method 2: Query (non-blocking)\n",
    "    cudaError_t status = cudaEventQuery(stop);\n",
    "    if (status == cudaSuccess) {\n",
    "        printf(\"Event completed!\\n\");\n",
    "    } else if (status == cudaErrorNotReady) {\n",
    "        printf(\"Event not yet reached\\n\");\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Event Timing\n",
    "    // ============================================\n",
    "    float milliseconds = 0;\n",
    "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "    printf(\"Kernel time: %.3f ms\\n\", milliseconds);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaEventDestroy(fastEvent);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o event_basics event_basics.cu\n",
    "!./event_basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976151dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Accurate GPU Timing\n",
    "\n",
    "### Why Events for Timing?\n",
    "\n",
    "```\n",
    "CPU Timing (WRONG for GPU):\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "auto start = clock();\n",
    "kernel<<<>>>(...);        // Returns immediately!\n",
    "auto end = clock();       // Measures launch overhead only\n",
    "// WRONG: Measures ~0.001ms instead of actual kernel time\n",
    "\n",
    "GPU Event Timing (CORRECT):\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "cudaEventRecord(start);\n",
    "kernel<<<>>>(...);        // Runs asynchronously\n",
    "cudaEventRecord(stop);\n",
    "cudaEventSynchronize(stop);\n",
    "cudaEventElapsedTime(&ms, start, stop);\n",
    "// CORRECT: Measures actual GPU execution time\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "This example demonstrates proper GPU timing techniques including warmup, single kernel timing, averaging over multiple iterations, and timing individual sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1179504",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile accurate_timing.cu\n",
    "// accurate_timing.cu - Proper GPU timing\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void kernel(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        for (int i = 0; i < 1000; i++) {\n",
    "            data[tid] = sinf(data[tid]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // ============================================\n",
    "    // Warmup (IMPORTANT!)\n",
    "    // ============================================\n",
    "    // First kernel launch has overhead (JIT, caching, etc.)\n",
    "    kernel<<<256, 256>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // ============================================\n",
    "    // Time Single Kernel\n",
    "    // ============================================\n",
    "    cudaEventRecord(start);\n",
    "    kernel<<<256, 256>>>(d_data, N);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float singleTime;\n",
    "    cudaEventElapsedTime(&singleTime, start, stop);\n",
    "    printf(\"Single kernel: %.3f ms\\n\", singleTime);\n",
    "    \n",
    "    // ============================================\n",
    "    // Time Multiple Iterations (more accurate)\n",
    "    // ============================================\n",
    "    const int ITERATIONS = 100;\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        kernel<<<256, 256>>>(d_data, N);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float totalTime;\n",
    "    cudaEventElapsedTime(&totalTime, start, stop);\n",
    "    printf(\"Average over %d runs: %.3f ms\\n\", \n",
    "           ITERATIONS, totalTime / ITERATIONS);\n",
    "    \n",
    "    // ============================================\n",
    "    // Time Individual Sections\n",
    "    // ============================================\n",
    "    cudaEvent_t e1, e2, e3;\n",
    "    cudaEventCreate(&e1);\n",
    "    cudaEventCreate(&e2);\n",
    "    cudaEventCreate(&e3);\n",
    "    \n",
    "    float *h_data;\n",
    "    cudaMallocHost(&h_data, N * sizeof(float));\n",
    "    \n",
    "    cudaEventRecord(e1);\n",
    "    cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaEventRecord(e2);\n",
    "    kernel<<<256, 256>>>(d_data, N);\n",
    "    cudaEventRecord(e3);\n",
    "    cudaEventSynchronize(e3);\n",
    "    \n",
    "    float h2dTime, kernelTime;\n",
    "    cudaEventElapsedTime(&h2dTime, e1, e2);\n",
    "    cudaEventElapsedTime(&kernelTime, e2, e3);\n",
    "    \n",
    "    printf(\"H2D transfer: %.3f ms\\n\", h2dTime);\n",
    "    printf(\"Kernel exec:  %.3f ms\\n\", kernelTime);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaEventDestroy(e1);\n",
    "    cudaEventDestroy(e2);\n",
    "    cudaEventDestroy(e3);\n",
    "    cudaFree(d_data);\n",
    "    cudaFreeHost(h_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27a53b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Inter-Stream Synchronization\n",
    "\n",
    "### cudaStreamWaitEvent\n",
    "\n",
    "```\n",
    "Without Event Sync:            With Event Sync:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”           â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Stream A: [Produce Data]       Stream A: [Produce]â”€â”€â”\n",
    "Stream B: [Use Data] â† RACE!   Stream B:            â””â”€â†’[Wait][Use]\n",
    "                                                    â†‘\n",
    "                                              cudaStreamWaitEvent\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "```cpp\n",
    "// inter_stream_sync.cu - Synchronizing between streams\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void produce(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = (float)tid * 2.0f;  // Produce data\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void consume(const float* input, float* output, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        output[tid] = input[tid] + 1.0f;  // Use produced data\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    \n",
    "    float *d_produced, *d_consumed;\n",
    "    cudaMalloc(&d_produced, N * sizeof(float));\n",
    "    cudaMalloc(&d_consumed, N * sizeof(float));\n",
    "    \n",
    "    cudaStream_t streamA, streamB;\n",
    "    cudaStreamCreate(&streamA);\n",
    "    cudaStreamCreate(&streamB);\n",
    "    \n",
    "    // Event for synchronization\n",
    "    cudaEvent_t dataReady;\n",
    "    cudaEventCreate(&dataReady);\n",
    "    \n",
    "    // ============================================\n",
    "    // Stream A: Produce data\n",
    "    // ============================================\n",
    "    produce<<<256, 256, 0, streamA>>>(d_produced, N);\n",
    "    \n",
    "    // Record event when production is done\n",
    "    cudaEventRecord(dataReady, streamA);\n",
    "    \n",
    "    // ============================================\n",
    "    // Stream B: Wait for data, then consume\n",
    "    // ============================================\n",
    "    // This makes streamB wait until streamA reaches dataReady\n",
    "    cudaStreamWaitEvent(streamB, dataReady);\n",
    "    \n",
    "    consume<<<256, 256, 0, streamB>>>(d_produced, d_consumed, N);\n",
    "    \n",
    "    // Both streams can do other independent work before/after\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Producer-consumer with event sync complete!\\n\");\n",
    "    \n",
    "    // ============================================\n",
    "    // Complex Dependency Graph\n",
    "    // ============================================\n",
    "    //       A1\n",
    "    //      /  \\\n",
    "    //     B1  B2\n",
    "    //      \\  /\n",
    "    //       C1\n",
    "    \n",
    "    cudaStream_t sA, sB1, sB2, sC;\n",
    "    cudaStreamCreate(&sA);\n",
    "    cudaStreamCreate(&sB1);\n",
    "    cudaStreamCreate(&sB2);\n",
    "    cudaStreamCreate(&sC);\n",
    "    \n",
    "    cudaEvent_t afterA, afterB1, afterB2;\n",
    "    cudaEventCreate(&afterA);\n",
    "    cudaEventCreate(&afterB1);\n",
    "    cudaEventCreate(&afterB2);\n",
    "    \n",
    "    // A1: Initial work\n",
    "    produce<<<256, 256, 0, sA>>>(d_produced, N);\n",
    "    cudaEventRecord(afterA, sA);\n",
    "    \n",
    "    // B1 and B2: Parallel work after A\n",
    "    cudaStreamWaitEvent(sB1, afterA);\n",
    "    cudaStreamWaitEvent(sB2, afterA);\n",
    "    consume<<<256, 256, 0, sB1>>>(d_produced, d_consumed, N/2);\n",
    "    consume<<<256, 256, 0, sB2>>>(d_produced + N/2, d_consumed + N/2, N/2);\n",
    "    cudaEventRecord(afterB1, sB1);\n",
    "    cudaEventRecord(afterB2, sB2);\n",
    "    \n",
    "    // C1: After both B1 and B2 complete\n",
    "    cudaStreamWaitEvent(sC, afterB1);\n",
    "    cudaStreamWaitEvent(sC, afterB2);\n",
    "    produce<<<256, 256, 0, sC>>>(d_consumed, N);  // Final processing\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Complex dependency graph complete!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaEventDestroy(dataReady);\n",
    "    cudaEventDestroy(afterA);\n",
    "    cudaEventDestroy(afterB1);\n",
    "    cudaEventDestroy(afterB2);\n",
    "    cudaStreamDestroy(streamA);\n",
    "    cudaStreamDestroy(streamB);\n",
    "    cudaStreamDestroy(sA);\n",
    "    cudaStreamDestroy(sB1);\n",
    "    cudaStreamDestroy(sB2);\n",
    "    cudaStreamDestroy(sC);\n",
    "    cudaFree(d_produced);\n",
    "    cudaFree(d_consumed);\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce6acbe",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba (Optional - Quick Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ff98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python/Numba Event Timing Demo (OPTIONAL)\n",
    "\n",
    "@cuda.jit\n",
    "def heavy_kernel(data):\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < data.shape[0]:\n",
    "        val = data[tid]\n",
    "        for _ in range(1000):\n",
    "            val = val * 1.0001 + 0.0001\n",
    "        data[tid] = val\n",
    "\n",
    "n = 1 << 20\n",
    "\n",
    "# Create device array\n",
    "d_data = cuda.device_array(n, dtype=np.float32)\n",
    "\n",
    "# Warmup\n",
    "heavy_kernel[(n+255)//256, 256](d_data)\n",
    "cuda.synchronize()\n",
    "\n",
    "# Time with events\n",
    "stream = cuda.stream()\n",
    "start_event = stream.record()\n",
    "\n",
    "for _ in range(10):\n",
    "    heavy_kernel[(n+255)//256, 256, stream](d_data)\n",
    "\n",
    "end_event = stream.record()\n",
    "stream.synchronize()\n",
    "\n",
    "elapsed = cuda.event_elapsed_time(start_event, end_event)\n",
    "print(f\"10 kernels: {elapsed:.2f} ms\")\n",
    "print(f\"Per kernel: {elapsed/10:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c52178",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Event Flags & Advanced Usage\n",
    "\n",
    "### Event Flags\n",
    "\n",
    "```cpp\n",
    "// event_flags.cu - Different event types\n",
    "\n",
    "// cudaEventDefault - Standard event for timing and sync\n",
    "cudaEvent_t defaultEvent;\n",
    "cudaEventCreate(&defaultEvent);\n",
    "\n",
    "// cudaEventBlockingSync - CPU thread yields instead of spinning\n",
    "// Better for power efficiency, slightly higher latency\n",
    "cudaEvent_t blockingEvent;\n",
    "cudaEventCreateWithFlags(&blockingEvent, cudaEventBlockingSync);\n",
    "\n",
    "// cudaEventDisableTiming - Can't use for timing, but faster\n",
    "// Good for pure synchronization\n",
    "cudaEvent_t syncOnlyEvent;\n",
    "cudaEventCreateWithFlags(&syncOnlyEvent, cudaEventDisableTiming);\n",
    "\n",
    "// Combine flags\n",
    "cudaEvent_t fastSyncEvent;\n",
    "cudaEventCreateWithFlags(&fastSyncEvent, \n",
    "                          cudaEventBlockingSync | cudaEventDisableTiming);\n",
    "```\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    EVENT FLAGS                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Flag                 â”‚ Use Case                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Default              â”‚ Timing + sync, general use       â”‚\n",
    "â”‚ BlockingSync         â”‚ Long waits, power-sensitive      â”‚\n",
    "â”‚ DisableTiming        â”‚ Pure sync, maximum performance   â”‚\n",
    "â”‚ Both combined        â”‚ Sync-only, power-efficient       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61579d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Benchmark Kernel\n",
    "Create a timing utility that:\n",
    "- Warms up the kernel\n",
    "- Runs multiple iterations\n",
    "- Reports min/max/avg times\n",
    "\n",
    "### Exercise 2: DAG Executor\n",
    "```cpp\n",
    "// Implement a simple DAG (Directed Acyclic Graph) of kernels:\n",
    "//     A\n",
    "//    /|\\\n",
    "//   B C D\n",
    "//    \\|/\n",
    "//     E\n",
    "```\n",
    "\n",
    "### Exercise 3: Event Pool\n",
    "Implement an event pool that reuses events to avoid creation overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db6feb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 CUDA EVENTS                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Event Lifecycle:                                       â”‚\n",
    "â”‚  â€¢ cudaEventCreate(&event)                              â”‚\n",
    "â”‚  â€¢ cudaEventRecord(event, stream)                       â”‚\n",
    "â”‚  â€¢ cudaEventSynchronize(event)                          â”‚\n",
    "â”‚  â€¢ cudaEventElapsedTime(&ms, start, stop)               â”‚\n",
    "â”‚  â€¢ cudaEventDestroy(event)                              â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Inter-Stream Sync:                                     â”‚\n",
    "â”‚  â€¢ cudaStreamWaitEvent(stream, event)                   â”‚\n",
    "â”‚  â€¢ Creates dependency: stream waits for event           â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Timing Best Practices:                                 â”‚\n",
    "â”‚  â€¢ Warmup before timing                                 â”‚\n",
    "â”‚  â€¢ Multiple iterations for accuracy                     â”‚\n",
    "â”‚  â€¢ Use events, not CPU timers                           â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Week 9 Complete!\n",
    "\n",
    "**Day 5:** Practice exercises and checkpoint quiz.\n",
    "\n",
    "**Next Week:** CUDA Graphs - compile entire workflows for minimal overhead!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
