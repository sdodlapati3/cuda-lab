{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aba9538",
   "metadata": {},
   "source": [
    "## Why CUDA Graphs?\n",
    "\n",
    "**Problem**: Each kernel launch has CPU overhead (~5-10μs per launch)\n",
    "\n",
    "**Solution**: CUDA Graphs capture entire workflows and replay them with minimal overhead\n",
    "\n",
    "| Approach | Launch Overhead per Kernel |\n",
    "|----------|---------------------------|\n",
    "| Regular launches | ~5-10 μs |\n",
    "| CUDA Graph launch | ~10 μs total (for entire graph) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cuda_graphs_basics.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void kernel1(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = data[idx] + 1.0f;\n",
    "}\n",
    "\n",
    "__global__ void kernel2(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = data[idx] * 2.0f;\n",
    "}\n",
    "\n",
    "__global__ void kernel3(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = data[idx] - 1.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    const int blocks = (N + 255) / 256;\n",
    "    \n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    cudaMemset(d_data, 0, N * sizeof(float));\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // === METHOD 1: Stream Capture ===\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    // Begin capture\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    // These are captured, NOT executed yet\n",
    "    kernel1<<<blocks, 256, 0, stream>>>(d_data, N);\n",
    "    kernel2<<<blocks, 256, 0, stream>>>(d_data, N);\n",
    "    kernel3<<<blocks, 256, 0, stream>>>(d_data, N);\n",
    "    \n",
    "    // End capture\n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    // Create executable graph\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // Launch graph multiple times\n",
    "    printf(\"Launching graph 10 times...\\n\");\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "    }\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    // Verify result: ((0+1)*2-1) = 1, applied 10 times\n",
    "    float h_result;\n",
    "    cudaMemcpy(&h_result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Result after 10 graph launches: %.0f\\n\", h_result);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cuda_graphs_basics.cu -o cuda_graphs_basics && ./cuda_graphs_basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b64dab",
   "metadata": {},
   "source": [
    "## Manual Graph Construction\n",
    "\n",
    "Build graphs programmatically with full control over node dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47633aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cuda_graphs_manual.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void initKernel(float* data, int n, float val) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = val;\n",
    "}\n",
    "\n",
    "__global__ void squareKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = data[idx] * data[idx];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1024;\n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    // Create empty graph\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphCreate(&graph, 0);\n",
    "    \n",
    "    // Add kernel nodes manually\n",
    "    cudaGraphNode_t initNode, squareNode;\n",
    "    \n",
    "    // Kernel parameters for initKernel\n",
    "    cudaKernelNodeParams initParams = {};\n",
    "    void* initArgs[] = {&d_data, (void*)&N, nullptr};\n",
    "    float initVal = 3.0f;\n",
    "    initArgs[2] = &initVal;\n",
    "    initParams.func = (void*)initKernel;\n",
    "    initParams.gridDim = dim3((N + 255) / 256);\n",
    "    initParams.blockDim = dim3(256);\n",
    "    initParams.sharedMemBytes = 0;\n",
    "    initParams.kernelParams = initArgs;\n",
    "    initParams.extra = nullptr;\n",
    "    \n",
    "    // Add init node (no dependencies)\n",
    "    cudaGraphAddKernelNode(&initNode, graph, nullptr, 0, &initParams);\n",
    "    \n",
    "    // Kernel parameters for squareKernel\n",
    "    cudaKernelNodeParams squareParams = {};\n",
    "    void* squareArgs[] = {&d_data, (void*)&N};\n",
    "    squareParams.func = (void*)squareKernel;\n",
    "    squareParams.gridDim = dim3((N + 255) / 256);\n",
    "    squareParams.blockDim = dim3(256);\n",
    "    squareParams.sharedMemBytes = 0;\n",
    "    squareParams.kernelParams = squareArgs;\n",
    "    squareParams.extra = nullptr;\n",
    "    \n",
    "    // Add square node (depends on init)\n",
    "    cudaGraphNode_t deps[] = {initNode};\n",
    "    cudaGraphAddKernelNode(&squareNode, graph, deps, 1, &squareParams);\n",
    "    \n",
    "    // Instantiate and launch\n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    float h_result;\n",
    "    cudaMemcpy(&h_result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Result: init(3.0) then square = %.0f (expected 9)\\n\", h_result);\n",
    "    \n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cuda_graphs_manual.cu -o cuda_graphs_manual && ./cuda_graphs_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bfe623",
   "metadata": {},
   "source": [
    "## Graph Update (Parameter Changes)\n",
    "\n",
    "Update graph parameters without rebuilding the entire graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0911e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cuda_graphs_update.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void scaleKernel(float* data, int n, float scale) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = data[idx] * scale;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1024;\n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    float h_data[N];\n",
    "    for (int i = 0; i < N; i++) h_data[i] = 1.0f;\n",
    "    cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // Capture initial graph with scale = 2.0\n",
    "    float scale = 2.0f;\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    scaleKernel<<<(N+255)/256, 256, 0, stream>>>(d_data, N, scale);\n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // Launch with scale = 2.0\n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    float h_result;\n",
    "    cudaMemcpy(&h_result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    printf(\"After scale=2.0: %.1f\\n\", h_result);\n",
    "    \n",
    "    // Update graph with new scale = 3.0\n",
    "    cudaGraph_t newGraph;\n",
    "    scale = 3.0f;\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    scaleKernel<<<(N+255)/256, 256, 0, stream>>>(d_data, N, scale);\n",
    "    cudaStreamEndCapture(stream, &newGraph);\n",
    "    \n",
    "    // Update existing executable with new graph\n",
    "    cudaGraphExecUpdateResultInfo updateResult;\n",
    "    cudaGraphExecUpdate(graphExec, newGraph, &updateResult);\n",
    "    \n",
    "    if (updateResult.result == cudaGraphExecUpdateSuccess) {\n",
    "        printf(\"Graph updated successfully!\\n\");\n",
    "    }\n",
    "    \n",
    "    // Launch updated graph\n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    cudaMemcpy(&h_result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    printf(\"After scale=3.0: %.1f\\n\", h_result);\n",
    "    \n",
    "    cudaGraphDestroy(newGraph);\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cuda_graphs_update.cu -o cuda_graphs_update && ./cuda_graphs_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb839e",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cuda_graphs_benchmark.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void tinyKernel(float* data) {\n",
    "    data[threadIdx.x] += 1.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, 256 * sizeof(float));\n",
    "    cudaMemset(d_data, 0, 256 * sizeof(float));\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    const int KERNELS = 100;\n",
    "    const int ITERATIONS = 1000;\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Benchmark regular launches\n",
    "    cudaEventRecord(start);\n",
    "    for (int iter = 0; iter < ITERATIONS; iter++) {\n",
    "        for (int k = 0; k < KERNELS; k++) {\n",
    "            tinyKernel<<<1, 256>>>(d_data);\n",
    "        }\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float regularMs;\n",
    "    cudaEventElapsedTime(&regularMs, start, stop);\n",
    "    \n",
    "    // Capture graph\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    for (int k = 0; k < KERNELS; k++) {\n",
    "        tinyKernel<<<1, 256, 0, stream>>>(d_data);\n",
    "    }\n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // Benchmark graph launches\n",
    "    cudaEventRecord(start);\n",
    "    for (int iter = 0; iter < ITERATIONS; iter++) {\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "    }\n",
    "    cudaStreamSynchronize(stream);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float graphMs;\n",
    "    cudaEventElapsedTime(&graphMs, start, stop);\n",
    "    \n",
    "    printf(\"Launching %d tiny kernels x %d iterations:\\n\", KERNELS, ITERATIONS);\n",
    "    printf(\"Regular launches: %.2f ms\\n\", regularMs);\n",
    "    printf(\"Graph launches:   %.2f ms\\n\", graphMs);\n",
    "    printf(\"Speedup: %.1fx\\n\", regularMs / graphMs);\n",
    "    \n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cuda_graphs_benchmark.cu -o cuda_graphs_benchmark && ./cuda_graphs_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4375b3cb",
   "metadata": {},
   "source": [
    "## CUDA Graph Node Types\n",
    "\n",
    "| Node Type | Purpose |\n",
    "|-----------|--------|\n",
    "| `cudaGraphAddKernelNode` | Kernel execution |\n",
    "| `cudaGraphAddMemcpyNode` | Memory copy |\n",
    "| `cudaGraphAddMemsetNode` | Memory set |\n",
    "| `cudaGraphAddHostNode` | CPU callback |\n",
    "| `cudaGraphAddChildGraphNode` | Nested graph |\n",
    "| `cudaGraphAddEventRecordNode` | Record event |\n",
    "| `cudaGraphAddEventWaitNode` | Wait for event |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36667002",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Stream Capture** - Easiest way to create graphs from existing code\n",
    "2. **Manual Construction** - Full control over dependencies\n",
    "3. **Graph Update** - Change parameters without rebuilding\n",
    "4. **Best for** - Repetitive workflows with many small kernels\n",
    "5. **Overhead reduction** - 10-100x for launch-bound workloads"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
