{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"‚ö†Ô∏è  CUDA C++ is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857c088",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Traditional vs Unified Memory\n",
    "\n",
    "Let's compare explicit memory management with unified memory to understand the tradeoffs.\n",
    "\n",
    "### Traditional Memory (Explicit Transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a801a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile traditional_memory.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error: %s at line %d\\n\", \\\n",
    "                    cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void saxpy(float *y, const float *x, float a, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        y[i] = a * x[i] + y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;  // 1M elements\n",
    "    const float a = 2.0f;\n",
    "    size_t bytes = N * sizeof(float);\n",
    "    \n",
    "    // Host memory\n",
    "    float *h_x = (float*)malloc(bytes);\n",
    "    float *h_y = (float*)malloc(bytes);\n",
    "    \n",
    "    // Initialize on host\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_x[i] = 1.0f;\n",
    "        h_y[i] = 2.0f;\n",
    "    }\n",
    "    \n",
    "    // Device memory\n",
    "    float *d_x, *d_y;\n",
    "    CUDA_CHECK(cudaMalloc(&d_x, bytes));\n",
    "    CUDA_CHECK(cudaMalloc(&d_y, bytes));\n",
    "    \n",
    "    // Timing events\n",
    "    cudaEvent_t start, stop;\n",
    "    CUDA_CHECK(cudaEventCreate(&start));\n",
    "    CUDA_CHECK(cudaEventCreate(&stop));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(start));\n",
    "    \n",
    "    // Step 1: Copy H2D\n",
    "    CUDA_CHECK(cudaMemcpy(d_x, h_x, bytes, cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_y, h_y, bytes, cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // Step 2: Kernel\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    saxpy<<<blocks, threads>>>(d_y, d_x, a, N);\n",
    "    \n",
    "    // Step 3: Copy D2H\n",
    "    CUDA_CHECK(cudaMemcpy(h_y, d_y, bytes, cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(stop));\n",
    "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float ms;\n",
    "    CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
    "    \n",
    "    // Verify\n",
    "    float expected = a * 1.0f + 2.0f;  // 4.0\n",
    "    int errors = 0;\n",
    "    for (int i = 0; i < N && errors < 5; i++) {\n",
    "        if (fabsf(h_y[i] - expected) > 1e-5) errors++;\n",
    "    }\n",
    "    \n",
    "    printf(\"=== Traditional Memory (Explicit Transfers) ===\\n\");\n",
    "    printf(\"Total time: %.3f ms\\n\", ms);\n",
    "    printf(\"Errors: %d\\n\", errors);\n",
    "    \n",
    "    // Cleanup\n",
    "    CUDA_CHECK(cudaEventDestroy(start));\n",
    "    CUDA_CHECK(cudaEventDestroy(stop));\n",
    "    CUDA_CHECK(cudaFree(d_x));\n",
    "    CUDA_CHECK(cudaFree(d_y));\n",
    "    free(h_x);\n",
    "    free(h_y);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o traditional_memory traditional_memory.cu && ./traditional_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a703b50",
   "metadata": {},
   "source": [
    "### Unified Memory (Automatic Migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05794b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile unified_memory.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error: %s at line %d\\n\", \\\n",
    "                    cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void saxpy(float *y, const float *x, float a, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        y[i] = a * x[i] + y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;  // 1M elements\n",
    "    const float a = 2.0f;\n",
    "    size_t bytes = N * sizeof(float);\n",
    "    \n",
    "    // Unified memory - accessible from both CPU and GPU\n",
    "    float *x, *y;\n",
    "    CUDA_CHECK(cudaMallocManaged(&x, bytes));\n",
    "    CUDA_CHECK(cudaMallocManaged(&y, bytes));\n",
    "    \n",
    "    // Initialize on host - data will migrate to GPU on first kernel access\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        x[i] = 1.0f;\n",
    "        y[i] = 2.0f;\n",
    "    }\n",
    "    \n",
    "    // Timing events\n",
    "    cudaEvent_t start, stop;\n",
    "    CUDA_CHECK(cudaEventCreate(&start));\n",
    "    CUDA_CHECK(cudaEventCreate(&stop));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(start));\n",
    "    \n",
    "    // Kernel - data migrates automatically\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    saxpy<<<blocks, threads>>>(y, x, a, N);\n",
    "    \n",
    "    // Synchronize before host access\n",
    "    CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(stop));\n",
    "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float ms;\n",
    "    CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
    "    \n",
    "    // Verify - data migrates back to host\n",
    "    float expected = a * 1.0f + 2.0f;  // 4.0\n",
    "    int errors = 0;\n",
    "    for (int i = 0; i < N && errors < 5; i++) {\n",
    "        if (fabsf(y[i] - expected) > 1e-5) errors++;\n",
    "    }\n",
    "    \n",
    "    printf(\"=== Unified Memory (Automatic Migration) ===\\n\");\n",
    "    printf(\"Total time: %.3f ms\\n\", ms);\n",
    "    printf(\"Errors: %d\\n\", errors);\n",
    "    printf(\"\\nNOTE: First run may be slower due to page faults.\\n\");\n",
    "    printf(\"      Use prefetching for better performance!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    CUDA_CHECK(cudaEventDestroy(start));\n",
    "    CUDA_CHECK(cudaEventDestroy(stop));\n",
    "    CUDA_CHECK(cudaFree(x));\n",
    "    CUDA_CHECK(cudaFree(y));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o unified_memory unified_memory.cu && ./unified_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966f791",
   "metadata": {},
   "source": [
    "### Key Differences\n",
    "\n",
    "| Aspect | Traditional | Unified |\n",
    "|--------|-------------|----------|\n",
    "| Allocation | `cudaMalloc` + `malloc` | `cudaMallocManaged` |\n",
    "| Transfers | Explicit `cudaMemcpy` | Automatic on-demand |\n",
    "| Code simplicity | More complex | Simpler |\n",
    "| Performance | Predictable | May have page faults |\n",
    "| Control | Full control | Driver-managed |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11cd7ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prefetching for Performance\n",
    "\n",
    "Unified memory can suffer from page faults on first access. **Prefetching** moves data proactively to avoid this overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile prefetch_demo.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error: %s at line %d\\n\", \\\n",
    "                    cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void square(float *data, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        data[i] = data[i] * data[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "float benchmark_no_prefetch(float *data, int N, int device) {\n",
    "    // Reset data on CPU\n",
    "    for (int i = 0; i < N; i++) data[i] = 2.0f;\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    \n",
    "    // No prefetch - page faults on GPU access\n",
    "    square<<<(N + 255) / 256, 256>>>(data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Access on CPU - more page faults\n",
    "    volatile float sum = 0;\n",
    "    for (int i = 0; i < 1000; i++) sum += data[i];\n",
    "    \n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return ms;\n",
    "}\n",
    "\n",
    "float benchmark_with_prefetch(float *data, int N, int device) {\n",
    "    // Reset data on CPU\n",
    "    for (int i = 0; i < N; i++) data[i] = 2.0f;\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    \n",
    "    // Prefetch to GPU BEFORE kernel\n",
    "    cudaMemPrefetchAsync(data, N * sizeof(float), device);\n",
    "    \n",
    "    square<<<(N + 255) / 256, 256>>>(data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Prefetch back to CPU BEFORE host access\n",
    "    cudaMemPrefetchAsync(data, N * sizeof(float), cudaCpuDeviceId);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    volatile float sum = 0;\n",
    "    for (int i = 0; i < 1000; i++) sum += data[i];\n",
    "    \n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return ms;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 22;  // 4M elements\n",
    "    \n",
    "    int device;\n",
    "    CUDA_CHECK(cudaGetDevice(&device));\n",
    "    \n",
    "    float *data;\n",
    "    CUDA_CHECK(cudaMallocManaged(&data, N * sizeof(float)));\n",
    "    \n",
    "    printf(\"=== Prefetching Benchmark ===\\n\");\n",
    "    printf(\"Array size: %d elements (%.1f MB)\\n\\n\", N, N * sizeof(float) / 1e6);\n",
    "    \n",
    "    // Warm up\n",
    "    benchmark_no_prefetch(data, N, device);\n",
    "    \n",
    "    // Run benchmarks\n",
    "    float time_no_prefetch = benchmark_no_prefetch(data, N, device);\n",
    "    float time_with_prefetch = benchmark_with_prefetch(data, N, device);\n",
    "    \n",
    "    printf(\"Without prefetch: %.3f ms\\n\", time_no_prefetch);\n",
    "    printf(\"With prefetch:    %.3f ms\\n\", time_with_prefetch);\n",
    "    printf(\"Speedup:          %.2fx\\n\", time_no_prefetch / time_with_prefetch);\n",
    "    \n",
    "    CUDA_CHECK(cudaFree(data));\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o prefetch_demo prefetch_demo.cu && ./prefetch_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf2bec",
   "metadata": {},
   "source": [
    "### Key Prefetch APIs\n",
    "\n",
    "```cpp\n",
    "// Prefetch to GPU\n",
    "cudaMemPrefetchAsync(ptr, size, deviceId, stream);\n",
    "\n",
    "// Prefetch to CPU\n",
    "cudaMemPrefetchAsync(ptr, size, cudaCpuDeviceId, stream);\n",
    "```\n",
    "\n",
    "**Best Practice**: Always prefetch data to where it will be accessed next!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f52c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Memory Hints with cudaMemAdvise\n",
    "\n",
    "Beyond prefetching, you can provide **hints** to the driver about expected access patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile memory_advise.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error: %s at line %d\\n\", \\\n",
    "                    cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void read_only_kernel(const float* __restrict__ input, \n",
    "                                  float* output, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        // Read multiple times - benefits from read-mostly hint\n",
    "        output[i] = input[i] * 2.0f + input[i] * 3.0f + input[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    size_t bytes = N * sizeof(float);\n",
    "    \n",
    "    int device;\n",
    "    CUDA_CHECK(cudaGetDevice(&device));\n",
    "    \n",
    "    float *input, *output;\n",
    "    CUDA_CHECK(cudaMallocManaged(&input, bytes));\n",
    "    CUDA_CHECK(cudaMallocManaged(&output, bytes));\n",
    "    \n",
    "    // Initialize input (read-only data)\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        input[i] = (float)i;\n",
    "    }\n",
    "    \n",
    "    printf(\"=== Memory Advise Demo ===\\n\\n\");\n",
    "    \n",
    "    // Hint 1: ReadMostly - data will be primarily read, not written\n",
    "    // Creates read-only copies on GPU, original stays on CPU\n",
    "    CUDA_CHECK(cudaMemAdvise(input, bytes, cudaMemAdviseSetReadMostly, device));\n",
    "    printf(\"Applied cudaMemAdviseSetReadMostly to input array\\n\");\n",
    "    printf(\"  -> Driver may create read-only replicas on GPU\\n\\n\");\n",
    "    \n",
    "    // Hint 2: PreferredLocation - suggest where data should reside\n",
    "    CUDA_CHECK(cudaMemAdvise(output, bytes, cudaMemAdviseSetPreferredLocation, device));\n",
    "    printf(\"Applied cudaMemAdviseSetPreferredLocation(GPU) to output array\\n\");\n",
    "    printf(\"  -> Output will preferentially reside on GPU\\n\\n\");\n",
    "    \n",
    "    // Prefetch for best performance\n",
    "    CUDA_CHECK(cudaMemPrefetchAsync(input, bytes, device));\n",
    "    CUDA_CHECK(cudaMemPrefetchAsync(output, bytes, device));\n",
    "    \n",
    "    // Timing\n",
    "    cudaEvent_t start, stop;\n",
    "    CUDA_CHECK(cudaEventCreate(&start));\n",
    "    CUDA_CHECK(cudaEventCreate(&stop));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(start));\n",
    "    \n",
    "    read_only_kernel<<<(N + 255) / 256, 256>>>(input, output, N);\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(stop));\n",
    "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float ms;\n",
    "    CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
    "    \n",
    "    // Verify first few results\n",
    "    CUDA_CHECK(cudaMemPrefetchAsync(output, bytes, cudaCpuDeviceId));\n",
    "    CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    \n",
    "    printf(\"Kernel time: %.3f ms\\n\\n\", ms);\n",
    "    printf(\"Verification (first 5 elements):\\n\");\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        float expected = input[i] * 2.0f + input[i] * 3.0f + input[i];  // 6 * input[i]\n",
    "        printf(\"  output[%d] = %.1f (expected: %.1f)\\n\", i, output[i], expected);\n",
    "    }\n",
    "    \n",
    "    // Cleanup - clear hints before freeing\n",
    "    CUDA_CHECK(cudaMemAdvise(input, bytes, cudaMemAdviseUnsetReadMostly, device));\n",
    "    CUDA_CHECK(cudaMemAdvise(output, bytes, cudaMemAdviseUnsetPreferredLocation, device));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventDestroy(start));\n",
    "    CUDA_CHECK(cudaEventDestroy(stop));\n",
    "    CUDA_CHECK(cudaFree(input));\n",
    "    CUDA_CHECK(cudaFree(output));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e362062",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o memory_advise memory_advise.cu && ./memory_advise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbba69e",
   "metadata": {},
   "source": [
    "### Available Memory Hints\n",
    "\n",
    "| Hint | Description | Use Case |\n",
    "|------|-------------|----------|\n",
    "| `cudaMemAdviseSetReadMostly` | Data is read frequently, rarely written | Lookup tables, constants |\n",
    "| `cudaMemAdviseSetPreferredLocation` | Prefer specific device/CPU | Control where data resides |\n",
    "| `cudaMemAdviseSetAccessedBy` | Device will access this memory | Enable direct access mapping |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20b58d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Oversubscription - Using More Memory Than GPU Has\n",
    "\n",
    "Unified memory enables **oversubscription**: allocating more memory than physically available on GPU. The driver pages data in and out as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f112ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile oversubscription.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error: %s at line %d\\n\", \\\n",
    "                    cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void process_chunk(float* data, size_t offset, size_t count) {\n",
    "    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < count) {\n",
    "        data[offset + i] = data[offset + i] * 2.0f + 1.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Query GPU memory\n",
    "    int device;\n",
    "    CUDA_CHECK(cudaGetDevice(&device));\n",
    "    \n",
    "    size_t free_mem, total_mem;\n",
    "    CUDA_CHECK(cudaMemGetInfo(&free_mem, &total_mem));\n",
    "    \n",
    "    printf(\"=== Oversubscription Demo ===\\n\\n\");\n",
    "    printf(\"GPU Memory: %.2f GB total, %.2f GB free\\n\\n\",\n",
    "           total_mem / 1e9, free_mem / 1e9);\n",
    "    \n",
    "    // Allocate 25% of GPU memory (safe for demo)\n",
    "    // In real oversubscription, you'd allocate MORE than total_mem\n",
    "    size_t alloc_size = total_mem / 4;\n",
    "    size_t n_elements = alloc_size / sizeof(float);\n",
    "    \n",
    "    printf(\"Allocating %.2f GB (%.0f million floats)\\n\",\n",
    "           alloc_size / 1e9, n_elements / 1e6);\n",
    "    \n",
    "    float* data;\n",
    "    CUDA_CHECK(cudaMallocManaged(&data, alloc_size));\n",
    "    \n",
    "    // Initialize on CPU (data starts on CPU)\n",
    "    printf(\"Initializing data on CPU...\\n\");\n",
    "    for (size_t i = 0; i < n_elements; i++) {\n",
    "        data[i] = 1.0f;\n",
    "    }\n",
    "    \n",
    "    // Process in chunks - simulate streaming access pattern\n",
    "    // This is how oversubscription works: process chunks that fit in GPU memory\n",
    "    size_t chunk_size = n_elements / 4;\n",
    "    int threads = 256;\n",
    "    int blocks = (chunk_size + threads - 1) / threads;\n",
    "    \n",
    "    printf(\"\\nProcessing in 4 chunks...\\n\");\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CUDA_CHECK(cudaEventCreate(&start));\n",
    "    CUDA_CHECK(cudaEventCreate(&stop));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(start));\n",
    "    \n",
    "    for (int chunk = 0; chunk < 4; chunk++) {\n",
    "        size_t offset = chunk * chunk_size;\n",
    "        \n",
    "        // Prefetch this chunk to GPU\n",
    "        CUDA_CHECK(cudaMemPrefetchAsync(data + offset, \n",
    "                                         chunk_size * sizeof(float), \n",
    "                                         device));\n",
    "        \n",
    "        // Process chunk\n",
    "        process_chunk<<<blocks, threads>>>(data, offset, chunk_size);\n",
    "        \n",
    "        // Prefetch back to CPU (for next iteration or final access)\n",
    "        CUDA_CHECK(cudaMemPrefetchAsync(data + offset,\n",
    "                                         chunk_size * sizeof(float),\n",
    "                                         cudaCpuDeviceId));\n",
    "    }\n",
    "    \n",
    "    CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(stop));\n",
    "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float ms;\n",
    "    CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
    "    \n",
    "    // Verify\n",
    "    float expected = 1.0f * 2.0f + 1.0f;  // 3.0\n",
    "    int errors = 0;\n",
    "    for (size_t i = 0; i < n_elements && errors < 5; i++) {\n",
    "        if (fabsf(data[i] - expected) > 1e-5) errors++;\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nTotal time: %.1f ms\\n\", ms);\n",
    "    printf(\"Throughput: %.2f GB/s\\n\", (alloc_size * 2) / (ms / 1000) / 1e9);\n",
    "    printf(\"Errors: %d\\n\", errors);\n",
    "    \n",
    "    printf(\"\\n--- Oversubscription Key Points ---\\n\");\n",
    "    printf(\"1. cudaMallocManaged can exceed GPU memory\\n\");\n",
    "    printf(\"2. Driver pages data in/out automatically\\n\");\n",
    "    printf(\"3. Streaming access patterns work best\\n\");\n",
    "    printf(\"4. Use prefetching to control paging\\n\");\n",
    "    \n",
    "    CUDA_CHECK(cudaEventDestroy(start));\n",
    "    CUDA_CHECK(cudaEventDestroy(stop));\n",
    "    CUDA_CHECK(cudaFree(data));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4da46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o oversubscription oversubscription.cu && ./oversubscription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901232c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Comprehensive Example: Optimized Unified Memory Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8143ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile um_pipeline.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error: %s at line %d\\n\", \\\n",
    "                    cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// Kernel 1: Normalize data\n",
    "__global__ void normalize(float* data, float max_val, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        data[i] = data[i] / max_val;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Kernel 2: Apply ReLU\n",
    "__global__ void relu(float* data, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        data[i] = data[i] > 0.0f ? data[i] : 0.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Kernel 3: Scale and offset\n",
    "__global__ void scale_offset(float* data, float scale, float offset, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        data[i] = data[i] * scale + offset;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 22;  // 4M elements\n",
    "    size_t bytes = N * sizeof(float);\n",
    "    \n",
    "    int device;\n",
    "    CUDA_CHECK(cudaGetDevice(&device));\n",
    "    \n",
    "    float* data;\n",
    "    CUDA_CHECK(cudaMallocManaged(&data, bytes));\n",
    "    \n",
    "    printf(\"=== Optimized Unified Memory Pipeline ===\\n\\n\");\n",
    "    \n",
    "    // Initialize with random-ish data (some negative)\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        data[i] = (float)(i % 1000) - 500.0f;  // Range: -500 to 499\n",
    "    }\n",
    "    \n",
    "    // Step 1: Set memory hints\n",
    "    // Data will be accessed primarily by GPU\n",
    "    CUDA_CHECK(cudaMemAdvise(data, bytes, \n",
    "                              cudaMemAdviseSetPreferredLocation, device));\n",
    "    printf(\"1. Set preferred location to GPU\\n\");\n",
    "    \n",
    "    // Step 2: Prefetch before kernel launch\n",
    "    CUDA_CHECK(cudaMemPrefetchAsync(data, bytes, device));\n",
    "    printf(\"2. Prefetched data to GPU\\n\");\n",
    "    \n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    \n",
    "    // Timing\n",
    "    cudaEvent_t start, stop;\n",
    "    CUDA_CHECK(cudaEventCreate(&start));\n",
    "    CUDA_CHECK(cudaEventCreate(&stop));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(start));\n",
    "    \n",
    "    // Step 3: Execute kernel pipeline\n",
    "    // All kernels run on GPU - no data migration between kernels!\n",
    "    normalize<<<blocks, threads>>>(data, 500.0f, N);  // -> [-1, 1)\n",
    "    relu<<<blocks, threads>>>(data, N);              // -> [0, 1)\n",
    "    scale_offset<<<blocks, threads>>>(data, 2.0f, -1.0f, N);  // -> [-1, 1)\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(stop));\n",
    "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float kernel_ms;\n",
    "    CUDA_CHECK(cudaEventElapsedTime(&kernel_ms, start, stop));\n",
    "    \n",
    "    printf(\"3. Executed 3-kernel pipeline\\n\");\n",
    "    printf(\"   Kernel time: %.3f ms\\n\\n\", kernel_ms);\n",
    "    \n",
    "    // Step 4: Prefetch back to CPU for verification\n",
    "    CUDA_CHECK(cudaMemPrefetchAsync(data, bytes, cudaCpuDeviceId));\n",
    "    CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    printf(\"4. Prefetched results back to CPU\\n\\n\");\n",
    "    \n",
    "    // Verify sample values\n",
    "    printf(\"Sample results:\\n\");\n",
    "    int samples[] = {0, 100, 250, 500, 750};\n",
    "    for (int j = 0; j < 5; j++) {\n",
    "        int i = samples[j];\n",
    "        float original = (float)(i % 1000) - 500.0f;\n",
    "        float after_norm = original / 500.0f;\n",
    "        float after_relu = after_norm > 0 ? after_norm : 0;\n",
    "        float expected = after_relu * 2.0f - 1.0f;\n",
    "        printf(\"  data[%d]: original=%.1f -> result=%.4f (expected=%.4f)\\n\",\n",
    "               i, original, data[i], expected);\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    CUDA_CHECK(cudaMemAdvise(data, bytes,\n",
    "                              cudaMemAdviseUnsetPreferredLocation, device));\n",
    "    CUDA_CHECK(cudaEventDestroy(start));\n",
    "    CUDA_CHECK(cudaEventDestroy(stop));\n",
    "    CUDA_CHECK(cudaFree(data));\n",
    "    \n",
    "    printf(\"\\n=== Pipeline Complete ===\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff16643",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o um_pipeline um_pipeline.cu && ./um_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6843884a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Unified Memory Best Practices\n",
    "\n",
    "### 1. Use Prefetching\n",
    "```cpp\n",
    "cudaMemPrefetchAsync(ptr, size, device);      // Before GPU kernel\n",
    "cudaMemPrefetchAsync(ptr, size, cudaCpuDeviceId);  // Before CPU access\n",
    "```\n",
    "\n",
    "### 2. Provide Memory Hints\n",
    "```cpp\n",
    "cudaMemAdvise(ptr, size, cudaMemAdviseSetReadMostly, device);  // Read-only data\n",
    "cudaMemAdvise(ptr, size, cudaMemAdviseSetPreferredLocation, device);  // GPU-resident\n",
    "```\n",
    "\n",
    "### 3. Choose Wisely\n",
    "\n",
    "| Scenario | Recommendation |\n",
    "|----------|----------------|\n",
    "| Simple prototyping | Basic unified memory |\n",
    "| Performance critical | Prefetching + hints |\n",
    "| Maximum control | Traditional explicit transfers |\n",
    "| Large datasets | Oversubscription with chunked access |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206f627",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Prefetch Optimization\n",
    "Modify the unified memory example to add prefetching and measure the improvement.\n",
    "\n",
    "### Exercise 2: Read-Mostly Pattern\n",
    "Create an example with lookup table data using `cudaMemAdviseSetReadMostly`.\n",
    "\n",
    "### Exercise 3: Multi-Kernel Pipeline\n",
    "Build a 5-stage processing pipeline and optimize with proper prefetching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77117bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup generated files\n",
    "!rm -f traditional_memory unified_memory prefetch_demo memory_advise oversubscription um_pipeline *.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065b477",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Unified Memory Basics\n",
    "\n",
    "### What is Unified Memory?\n",
    "\n",
    "```\n",
    "Traditional CUDA:             Unified Memory:\n",
    "\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   CPU        ‚îÇ              ‚îÇ   CPU        ‚îÇ\n",
    "‚îÇ   Memory     ‚îÇ              ‚îÇ              ‚îÇ\n",
    "‚îÇ   h_data     ‚îÇ              ‚îÇ              ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ              ‚îÇ\n",
    "       ‚îÇ cudaMemcpy()         ‚îÇ   Unified    ‚îÇ\n",
    "       ‚Üì                      ‚îÇ   Address    ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ   Space      ‚îÇ\n",
    "‚îÇ   GPU        ‚îÇ              ‚îÇ              ‚îÇ\n",
    "‚îÇ   Memory     ‚îÇ              ‚îÇ   data       ‚îÇ ‚Üê One pointer!\n",
    "‚îÇ   d_data     ‚îÇ              ‚îÇ              ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Two pointers,                 One pointer,\n",
    "explicit copies               automatic migration\n",
    "```\n",
    "\n",
    "### üî∑ CUDA C++ Implementation (Primary)\n",
    "\n",
    "```cpp\n",
    "// unified_memory.cu - Unified memory basics\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void addKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] += 1.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n = 1 << 20;  // 1M elements\n",
    "    size_t size = n * sizeof(float);\n",
    "    \n",
    "    // ========== TRADITIONAL APPROACH ==========\n",
    "    {\n",
    "        float *h_data = (float*)malloc(size);\n",
    "        float *d_data;\n",
    "        cudaMalloc(&d_data, size);\n",
    "        \n",
    "        // Initialize on host\n",
    "        for (int i = 0; i < n; i++) h_data[i] = i;\n",
    "        \n",
    "        // Copy to device\n",
    "        cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);\n",
    "        \n",
    "        // Launch kernel\n",
    "        addKernel<<<(n+255)/256, 256>>>(d_data, n);\n",
    "        \n",
    "        // Copy back\n",
    "        cudaMemcpy(h_data, d_data, size, cudaMemcpyDeviceToHost);\n",
    "        \n",
    "        printf(\"Traditional: h_data[0] = %f\\n\", h_data[0]);\n",
    "        \n",
    "        free(h_data);\n",
    "        cudaFree(d_data);\n",
    "    }\n",
    "    \n",
    "    // ========== UNIFIED MEMORY APPROACH ==========\n",
    "    {\n",
    "        float *data;\n",
    "        cudaMallocManaged(&data, size);  // One allocation!\n",
    "        \n",
    "        // Initialize on host (no copy needed!)\n",
    "        for (int i = 0; i < n; i++) data[i] = i;\n",
    "        \n",
    "        // Launch kernel (no copy needed!)\n",
    "        addKernel<<<(n+255)/256, 256>>>(data, n);\n",
    "        cudaDeviceSynchronize();\n",
    "        \n",
    "        // Use on host (no copy needed!)\n",
    "        printf(\"Unified: data[0] = %f\\n\", data[0]);\n",
    "        \n",
    "        cudaFree(data);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe4894",
   "metadata": {},
   "source": [
    "### üî∂ Python/Numba (Optional - Quick Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python/Numba - Managed memory example\n",
    "\n",
    "@cuda.jit\n",
    "def add_one(data):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < data.size:\n",
    "        data[idx] += 1.0\n",
    "\n",
    "# Using managed memory (simplified API)\n",
    "def unified_memory_demo():\n",
    "    n = 1_000_000\n",
    "    \n",
    "    # Create managed array\n",
    "    # Note: Numba handles this through cuda.to_device or \n",
    "    # cuda.managed_array (if available)\n",
    "    \n",
    "    # Standard approach (for comparison)\n",
    "    host_data = np.arange(n, dtype=np.float32)\n",
    "    device_data = cuda.to_device(host_data)\n",
    "    \n",
    "    block = 256\n",
    "    grid = (n + block - 1) // block\n",
    "    \n",
    "    add_one[grid, block](device_data)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    result = device_data.copy_to_host()\n",
    "    print(f\"First elements: {result[:5]}\")\n",
    "    print(f\"Expected: [1. 2. 3. 4. 5.]\")\n",
    "\n",
    "unified_memory_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c95c2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Page Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75fe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_page_migration():\n",
    "    \"\"\"Explain how unified memory page migration works.\"\"\"\n",
    "    print(\"Unified Memory Page Migration\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"How it works:\")\n",
    "    print(\"  1. Memory allocated as 'managed' pages\")\n",
    "    print(\"  2. Pages migrate on demand (page fault)\")\n",
    "    print(\"  3. OS/driver handles migration transparently\")\n",
    "    print()\n",
    "    print(\"Page fault flow:\")\n",
    "    print(\"  GPU kernel accesses page ‚Üí Page not on GPU\")\n",
    "    print(\"  ‚Üí Page fault triggered ‚Üí Migration from CPU to GPU\")\n",
    "    print(\"  ‚Üí Kernel resumes with page now on GPU\")\n",
    "    print()\n",
    "    print(\"Page sizes:\")\n",
    "    print(\"  CPU: 4 KB (standard) or 2 MB (huge pages)\")\n",
    "    print(\"  GPU: 64 KB (Pascal+) or 2 MB (large page mode)\")\n",
    "    print()\n",
    "    print(\"Migration overhead:\")\n",
    "    print(\"  - Page fault handling: ~20-50 ¬µs\")\n",
    "    print(\"  - Data transfer: depends on page size and PCIe/NVLink\")\n",
    "    print(\"  - Can be significant for random access patterns!\")\n",
    "\n",
    "explain_page_migration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d0d2a",
   "metadata": {},
   "source": [
    "### üî∑ Prefetching to Avoid Page Faults\n",
    "\n",
    "```cpp\n",
    "// prefetch.cu - Prefetching for better performance\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = sqrtf(data[idx]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n = 1 << 24;  // 16M elements\n",
    "    size_t size = n * sizeof(float);\n",
    "    \n",
    "    float *data;\n",
    "    cudaMallocManaged(&data, size);\n",
    "    \n",
    "    // Initialize on CPU\n",
    "    for (int i = 0; i < n; i++) data[i] = (float)i;\n",
    "    \n",
    "    int device;\n",
    "    cudaGetDevice(&device);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // ===== WITHOUT PREFETCH =====\n",
    "    cudaEventRecord(start);\n",
    "    processKernel<<<(n+255)/256, 256>>>(data, n);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms_no_prefetch;\n",
    "    cudaEventElapsedTime(&ms_no_prefetch, start, stop);\n",
    "    printf(\"Without prefetch: %.2f ms\\n\", ms_no_prefetch);\n",
    "    \n",
    "    // Reset data to CPU\n",
    "    cudaMemPrefetchAsync(data, size, cudaCpuDeviceId);\n",
    "    cudaDeviceSynchronize();\n",
    "    for (int i = 0; i < n; i++) data[i] = (float)i;\n",
    "    \n",
    "    // ===== WITH PREFETCH =====\n",
    "    cudaEventRecord(start);\n",
    "    cudaMemPrefetchAsync(data, size, device);  // Prefetch to GPU\n",
    "    processKernel<<<(n+255)/256, 256>>>(data, n);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms_with_prefetch;\n",
    "    cudaEventElapsedTime(&ms_with_prefetch, start, stop);\n",
    "    printf(\"With prefetch: %.2f ms\\n\", ms_with_prefetch);\n",
    "    \n",
    "    printf(\"Speedup: %.2fx\\n\", ms_no_prefetch / ms_with_prefetch);\n",
    "    \n",
    "    cudaFree(data);\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a190c4c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Memory Hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_hints():\n",
    "    \"\"\"Explain CUDA memory advise hints.\"\"\"\n",
    "    print(\"cudaMemAdvise Hints\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"cudaMemAdviseSetReadMostly\")\n",
    "    print(\"  - Hint: Data will be read, rarely written\")\n",
    "    print(\"  - Effect: May duplicate to avoid migration\")\n",
    "    print(\"  - Use: Lookup tables, constant data\")\n",
    "    print()\n",
    "    print(\"cudaMemAdviseSetPreferredLocation\")\n",
    "    print(\"  - Hint: Preferred location for data\")\n",
    "    print(\"  - Effect: Tries to keep data at specified location\")\n",
    "    print(\"  - Use: Data primarily used by one processor\")\n",
    "    print()\n",
    "    print(\"cudaMemAdviseSetAccessedBy\")\n",
    "    print(\"  - Hint: Which devices will access data\")\n",
    "    print(\"  - Effect: Creates direct mapping if possible\")\n",
    "    print(\"  - Use: Multi-GPU scenarios\")\n",
    "    print()\n",
    "    print(\"Example usage:\")\n",
    "    print(\"  cudaMemAdvise(ptr, size, cudaMemAdviseSetReadMostly, 0);\")\n",
    "    print(\"  cudaMemAdvise(ptr, size, cudaMemAdviseSetPreferredLocation, device);\")\n",
    "    print(\"  cudaMemAdvise(ptr, size, cudaMemAdviseSetAccessedBy, device);\")\n",
    "\n",
    "memory_hints()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4fdf39",
   "metadata": {},
   "source": [
    "### üî∑ CUDA C++ Memory Advise\n",
    "\n",
    "```cpp\n",
    "// advise.cu - Using memory hints\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void lookupKernel(const float* table, const int* indices,\n",
    "                              float* output, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        output[idx] = table[indices[idx]];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int tableSize = 1 << 20;   // 1M lookup table\n",
    "    int n = 1 << 24;           // 16M lookups\n",
    "    \n",
    "    float *table;\n",
    "    int *indices;\n",
    "    float *output;\n",
    "    \n",
    "    cudaMallocManaged(&table, tableSize * sizeof(float));\n",
    "    cudaMallocManaged(&indices, n * sizeof(int));\n",
    "    cudaMallocManaged(&output, n * sizeof(float));\n",
    "    \n",
    "    // Initialize\n",
    "    for (int i = 0; i < tableSize; i++) table[i] = sqrtf(i);\n",
    "    for (int i = 0; i < n; i++) indices[i] = rand() % tableSize;\n",
    "    \n",
    "    int device;\n",
    "    cudaGetDevice(&device);\n",
    "    \n",
    "    // ===== APPLY HINTS =====\n",
    "    \n",
    "    // Table is read-only - can be duplicated\n",
    "    cudaMemAdvise(table, tableSize * sizeof(float),\n",
    "                  cudaMemAdviseSetReadMostly, 0);\n",
    "    \n",
    "    // Indices and output should prefer GPU\n",
    "    cudaMemAdvise(indices, n * sizeof(int),\n",
    "                  cudaMemAdviseSetPreferredLocation, device);\n",
    "    cudaMemAdvise(output, n * sizeof(float),\n",
    "                  cudaMemAdviseSetPreferredLocation, device);\n",
    "    \n",
    "    // Prefetch to GPU\n",
    "    cudaMemPrefetchAsync(table, tableSize * sizeof(float), device);\n",
    "    cudaMemPrefetchAsync(indices, n * sizeof(int), device);\n",
    "    \n",
    "    // Launch kernel\n",
    "    lookupKernel<<<(n+255)/256, 256>>>(table, indices, output, n);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Prefetch output back to CPU for verification\n",
    "    cudaMemPrefetchAsync(output, n * sizeof(float), cudaCpuDeviceId);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    printf(\"output[0] = %f (expected: %f)\\n\", \n",
    "           output[0], table[indices[0]]);\n",
    "    \n",
    "    cudaFree(table);\n",
    "    cudaFree(indices);\n",
    "    cudaFree(output);\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ab1d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: When to Use Unified Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unified_vs_explicit():\n",
    "    \"\"\"Compare unified vs explicit memory management.\"\"\"\n",
    "    print(\"Unified vs Explicit Memory\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"USE UNIFIED MEMORY WHEN:\")\n",
    "    print(\"  ‚úì Prototyping and development\")\n",
    "    print(\"  ‚úì Complex data structures (linked lists, trees)\")\n",
    "    print(\"  ‚úì Oversubscription (data larger than GPU memory)\")\n",
    "    print(\"  ‚úì Unclear access patterns\")\n",
    "    print(\"  ‚úì Porting CPU code quickly\")\n",
    "    print()\n",
    "    print(\"USE EXPLICIT MEMORY WHEN:\")\n",
    "    print(\"  ‚úì Maximum performance critical\")\n",
    "    print(\"  ‚úì Predictable access patterns\")\n",
    "    print(\"  ‚úì Frequent CPU-GPU ping-pong\")\n",
    "    print(\"  ‚úì Fine-grained control needed\")\n",
    "    print(\"  ‚úì Overlapping compute and transfer\")\n",
    "    print()\n",
    "    print(\"PERFORMANCE CONSIDERATIONS:\")\n",
    "    print(\"  - Page faults have ~20-50 ¬µs overhead each\")\n",
    "    print(\"  - First access triggers migration\")\n",
    "    print(\"  - Random access patterns = many page faults\")\n",
    "    print(\"  - Prefetching mitigates most overhead\")\n",
    "    print(\"  - With proper hints, ~95%+ of explicit performance\")\n",
    "\n",
    "unified_vs_explicit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e4396",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Oversubscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6277713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_oversubscription():\n",
    "    \"\"\"Explain memory oversubscription with unified memory.\"\"\"\n",
    "    print(\"Memory Oversubscription\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"Traditional CUDA:\")\n",
    "    print(\"  GPU memory = hard limit\")\n",
    "    print(\"  cudaMalloc fails if not enough memory\")\n",
    "    print()\n",
    "    print(\"Unified Memory (Pascal+):\")\n",
    "    print(\"  Can allocate more than GPU memory!\")\n",
    "    print(\"  Pages migrate as needed\")\n",
    "    print(\"  Works like virtual memory\")\n",
    "    print()\n",
    "    print(\"Example:\")\n",
    "    print(\"  GPU has 8 GB memory\")\n",
    "    print(\"  Allocate 32 GB with cudaMallocManaged\")\n",
    "    print(\"  Process 8 GB at a time on GPU\")\n",
    "    print(\"  Pages swap automatically\")\n",
    "    print()\n",
    "    print(\"Caveats:\")\n",
    "    print(\"  - Performance degrades with thrashing\")\n",
    "    print(\"  - Need good access locality\")\n",
    "    print(\"  - Consider prefetch hints\")\n",
    "\n",
    "explain_oversubscription()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3daed0",
   "metadata": {},
   "source": [
    "### üî∑ CUDA C++ Oversubscription Example\n",
    "\n",
    "```cpp\n",
    "// oversubscription.cu - Using more memory than GPU has\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processChunk(float* data, int start, int chunk_size) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < chunk_size) {\n",
    "        data[start + idx] = sqrtf(data[start + idx]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Query GPU memory\n",
    "    size_t free_mem, total_mem;\n",
    "    cudaMemGetInfo(&free_mem, &total_mem);\n",
    "    printf(\"GPU Memory: %.1f GB free, %.1f GB total\\n\",\n",
    "           free_mem / 1e9, total_mem / 1e9);\n",
    "    \n",
    "    // Allocate MORE than GPU memory\n",
    "    size_t n = total_mem / sizeof(float) * 2;  // 2x GPU memory\n",
    "    size_t size = n * sizeof(float);\n",
    "    printf(\"Allocating %.1f GB (2x GPU memory)\\n\", size / 1e9);\n",
    "    \n",
    "    float *data;\n",
    "    cudaError_t err = cudaMallocManaged(&data, size);\n",
    "    if (err != cudaSuccess) {\n",
    "        printf(\"Allocation failed: %s\\n\", cudaGetErrorString(err));\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    // Initialize on CPU (pages stay on CPU)\n",
    "    for (size_t i = 0; i < n; i++) {\n",
    "        data[i] = (float)(i % 1000);\n",
    "    }\n",
    "    \n",
    "    // Process in chunks to demonstrate oversubscription\n",
    "    int device;\n",
    "    cudaGetDevice(&device);\n",
    "    \n",
    "    size_t chunk_size = n / 4;  // Process 1/4 at a time\n",
    "    \n",
    "    for (int chunk = 0; chunk < 4; chunk++) {\n",
    "        size_t start = chunk * chunk_size;\n",
    "        \n",
    "        // Prefetch this chunk to GPU\n",
    "        cudaMemPrefetchAsync(&data[start], chunk_size * sizeof(float), device);\n",
    "        \n",
    "        // Process chunk\n",
    "        processChunk<<<(chunk_size+255)/256, 256>>>(data, start, chunk_size);\n",
    "        \n",
    "        printf(\"Processed chunk %d\\n\", chunk);\n",
    "    }\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Prefetch result back to CPU\n",
    "    cudaMemPrefetchAsync(data, size, cudaCpuDeviceId);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    printf(\"data[0] = %f (expected sqrt(0) = 0)\\n\", data[0]);\n",
    "    printf(\"data[1] = %f (expected sqrt(1) = 1)\\n\", data[1]);\n",
    "    \n",
    "    cudaFree(data);\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8eb2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Compare Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f638f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare unified memory (with/without prefetch) vs explicit memory\n",
    "\n",
    "@cuda.jit\n",
    "def compute_kernel(data, result):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < result.size:\n",
    "        x = data[idx]\n",
    "        result[idx] = x * x + x\n",
    "\n",
    "def benchmark_memory_approaches(n=10_000_000):\n",
    "    \"\"\"Compare different memory management approaches.\"\"\"\n",
    "    # TODO: Implement benchmarks for:\n",
    "    # 1. Explicit memory with cudaMemcpy\n",
    "    # 2. Unified memory without prefetch\n",
    "    # 3. Unified memory with prefetch\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800eeb28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Unified Memory API\n",
    "\n",
    "```cpp\n",
    "// Allocation\n",
    "cudaMallocManaged(&ptr, size);\n",
    "\n",
    "// Prefetching\n",
    "cudaMemPrefetchAsync(ptr, size, device);     // To GPU\n",
    "cudaMemPrefetchAsync(ptr, size, cudaCpuDeviceId); // To CPU\n",
    "\n",
    "// Hints\n",
    "cudaMemAdvise(ptr, size, cudaMemAdviseSetReadMostly, device);\n",
    "cudaMemAdvise(ptr, size, cudaMemAdviseSetPreferredLocation, device);\n",
    "cudaMemAdvise(ptr, size, cudaMemAdviseSetAccessedBy, device);\n",
    "```\n",
    "\n",
    "### Decision Guide\n",
    "\n",
    "| Scenario | Recommendation |\n",
    "|----------|----------------|\n",
    "| Prototyping | Unified memory |\n",
    "| Complex data structures | Unified memory |\n",
    "| Maximum performance | Explicit + overlapping |\n",
    "| Data > GPU memory | Unified + prefetch |\n",
    "| Production code | Unified + hints (or explicit) |\n",
    "\n",
    "### Week 7 Complete!\n",
    "Next week: Profiling & Analysis with Nsight tools."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
