{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9dd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "print(\"⚠️  CUDA C++ is the PRIMARY learning material!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64bd3b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: What is Occupancy?\n",
    "\n",
    "### Definition\n",
    "\n",
    "```\n",
    "                    Active Warps per SM\n",
    "Occupancy (%) = ─────────────────────────── × 100\n",
    "                 Maximum Warps per SM\n",
    "\n",
    "Example: 32 active warps / 64 max warps = 50% occupancy\n",
    "```\n",
    "\n",
    "### Why Occupancy Matters\n",
    "\n",
    "```\n",
    "GPU hides memory latency through parallelism:\n",
    "\n",
    "Low Occupancy (25%):\n",
    "  Warp 0: [COMPUTE]──[WAIT FOR MEMORY]────────────────[COMPUTE]\n",
    "  Warp 1: ──[COMPUTE]──[WAIT FOR MEMORY]────────────────[COMPUTE]\n",
    "  Warp 2: ────[COMPUTE]──[WAIT FOR MEMORY]────────────────[COMPUTE]\n",
    "  Warp 3: ──────[COMPUTE]──[WAIT FOR MEMORY]────────────────[COMPUTE]\n",
    "  SM:     ████░░░░░░░░░░░░░░░░░░░░░████░░░░░░░░░░░░░░░░░░░░░░\n",
    "                          ^^ SM idle, waiting for memory\n",
    "\n",
    "High Occupancy (100%):\n",
    "  Warp 0:  [COMP][WAIT....][COMP]\n",
    "  Warp 1:  [COMP][WAIT....][COMP]\n",
    "  ...many more warps...\n",
    "  Warp 63: [COMP][WAIT....][COMP]\n",
    "  SM:      ██████████████████████████████████████████████████\n",
    "                    ^^ SM always has work to do\n",
    "```\n",
    "\n",
    "### CUDA C++ Occupancy Query (Primary)\n",
    "\n",
    "```cpp\n",
    "// occupancy.cu - Query and optimize occupancy\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void sampleKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        float x = data[idx];\n",
    "        data[idx] = x * x + x;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Get device properties\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    \n",
    "    printf(\"Device: %s\\n\", prop.name);\n",
    "    printf(\"Max threads per SM: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
    "    printf(\"Max threads per block: %d\\n\", prop.maxThreadsPerBlock);\n",
    "    printf(\"Registers per SM: %d\\n\", prop.regsPerMultiprocessor);\n",
    "    printf(\"Shared memory per SM: %zu KB\\n\", prop.sharedMemPerMultiprocessor / 1024);\n",
    "    printf(\"Number of SMs: %d\\n\", prop.multiProcessorCount);\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    // Calculate occupancy for different block sizes\n",
    "    printf(\"Block Size | Active Blocks/SM | Occupancy\\n\");\n",
    "    printf(\"----------------------------------------\\n\");\n",
    "    \n",
    "    for (int blockSize = 64; blockSize <= 1024; blockSize *= 2) {\n",
    "        int minGridSize, optBlockSize;\n",
    "        \n",
    "        // Query occupancy\n",
    "        cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "            &minGridSize, sampleKernel, blockSize, 0);\n",
    "        \n",
    "        int maxWarpsPerSM = prop.maxThreadsPerMultiProcessor / 32;\n",
    "        int activeWarps = minGridSize * (blockSize / 32);\n",
    "        float occupancy = 100.0f * activeWarps / maxWarpsPerSM;\n",
    "        \n",
    "        printf(\"%10d | %16d | %6.1f%%\\n\", blockSize, minGridSize, occupancy);\n",
    "    }\n",
    "    \n",
    "    // Get optimal block size\n",
    "    int minGridSize, optBlockSize;\n",
    "    cudaOccupancyMaxPotentialBlockSize(&minGridSize, &optBlockSize, \n",
    "                                        sampleKernel, 0, 0);\n",
    "    printf(\"\\nOptimal block size: %d\\n\", optBlockSize);\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "### Python/Numba (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query device properties\n",
    "device = cuda.get_current_device()\n",
    "\n",
    "print(\"=== GPU Occupancy Properties ===\")\n",
    "print(f\"Device: {device.name}\")\n",
    "print(f\"Compute Capability: {device.compute_capability}\")\n",
    "print(f\"Max threads per block: {device.MAX_THREADS_PER_BLOCK}\")\n",
    "print(f\"Max block dimensions: {device.MAX_BLOCK_DIM_X} x {device.MAX_BLOCK_DIM_Y} x {device.MAX_BLOCK_DIM_Z}\")\n",
    "print(f\"Max grid dimensions: {device.MAX_GRID_DIM_X} x {device.MAX_GRID_DIM_Y} x {device.MAX_GRID_DIM_Z}\")\n",
    "print(f\"Max shared memory per block: {device.MAX_SHARED_MEMORY_PER_BLOCK / 1024:.0f} KB\")\n",
    "print(f\"Multiprocessor count: {device.MULTIPROCESSOR_COUNT}\")\n",
    "print(f\"Warp size: {device.WARP_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719482e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Occupancy Limiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_occupancy_limiters():\n",
    "    \"\"\"Explain the three occupancy limiters.\"\"\"\n",
    "    print(\"The Three Occupancy Limiters\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"1. THREADS (Block Size)\")\n",
    "    print(\"   Max threads per SM: typically 1536-2048\")\n",
    "    print(\"   Max threads per block: 1024\")\n",
    "    print(\"   Issue: Too small block → not enough threads\")\n",
    "    print(\"          Too large block → can't fit enough blocks\")\n",
    "    print()\n",
    "    print(\"2. REGISTERS\")\n",
    "    print(\"   Registers per SM: 65536 (typical)\")\n",
    "    print(\"   Max per thread: 255\")\n",
    "    print(\"   Issue: High register usage → fewer concurrent threads\")\n",
    "    print(\"   Formula: max_threads = regs_per_SM / regs_per_thread\")\n",
    "    print()\n",
    "    print(\"3. SHARED MEMORY\")\n",
    "    print(\"   Shared memory per SM: 48-164 KB\")\n",
    "    print(\"   Configurable with L1 cache\")\n",
    "    print(\"   Issue: Large shared blocks → fewer concurrent blocks\")\n",
    "    print(\"   Formula: max_blocks = smem_per_SM / smem_per_block\")\n",
    "\n",
    "explain_occupancy_limiters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173579fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_occupancy(threads_per_block, regs_per_thread, shared_per_block,\n",
    "                        max_threads_per_sm=2048, max_regs_per_sm=65536,\n",
    "                        max_shared_per_sm=49152, max_blocks_per_sm=32):\n",
    "    \"\"\"Calculate theoretical occupancy.\"\"\"\n",
    "    \n",
    "    # Threads limit\n",
    "    blocks_by_threads = max_threads_per_sm // threads_per_block\n",
    "    \n",
    "    # Registers limit\n",
    "    regs_per_block = threads_per_block * regs_per_thread\n",
    "    if regs_per_block > 0:\n",
    "        blocks_by_regs = max_regs_per_sm // regs_per_block\n",
    "    else:\n",
    "        blocks_by_regs = max_blocks_per_sm\n",
    "    \n",
    "    # Shared memory limit\n",
    "    if shared_per_block > 0:\n",
    "        blocks_by_shared = max_shared_per_sm // shared_per_block\n",
    "    else:\n",
    "        blocks_by_shared = max_blocks_per_sm\n",
    "    \n",
    "    # Block limit\n",
    "    max_blocks = min(blocks_by_threads, blocks_by_regs, blocks_by_shared, max_blocks_per_sm)\n",
    "    \n",
    "    # Calculate occupancy\n",
    "    warps_per_block = threads_per_block // 32\n",
    "    active_warps = max_blocks * warps_per_block\n",
    "    max_warps = max_threads_per_sm // 32\n",
    "    occupancy = 100 * active_warps / max_warps\n",
    "    \n",
    "    print(f\"Occupancy Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Input: {threads_per_block} threads/block, {regs_per_thread} regs/thread, {shared_per_block} bytes shared\")\n",
    "    print(f\"\\nLimiters:\")\n",
    "    print(f\"  By threads:      {blocks_by_threads} blocks\")\n",
    "    print(f\"  By registers:    {blocks_by_regs} blocks\")\n",
    "    print(f\"  By shared mem:   {blocks_by_shared} blocks\")\n",
    "    print(f\"  By block limit:  {max_blocks_per_sm} blocks\")\n",
    "    print(f\"\\nResult:\")\n",
    "    print(f\"  Active blocks:   {max_blocks}\")\n",
    "    print(f\"  Active warps:    {active_warps}/{max_warps}\")\n",
    "    print(f\"  Occupancy:       {occupancy:.1f}%\")\n",
    "    \n",
    "    # Identify limiter\n",
    "    limiter = \"blocks\"\n",
    "    if max_blocks == blocks_by_threads:\n",
    "        limiter = \"threads\"\n",
    "    elif max_blocks == blocks_by_regs:\n",
    "        limiter = \"registers\"\n",
    "    elif max_blocks == blocks_by_shared:\n",
    "        limiter = \"shared memory\"\n",
    "    print(f\"  Limiter:         {limiter}\")\n",
    "    \n",
    "    return occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: High occupancy kernel\n",
    "print(\"Example 1: Simple kernel\")\n",
    "calculate_occupancy(threads_per_block=256, regs_per_thread=32, shared_per_block=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a33b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Register-limited kernel\n",
    "print(\"\\nExample 2: Register-heavy kernel\")\n",
    "calculate_occupancy(threads_per_block=256, regs_per_thread=128, shared_per_block=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Shared-memory limited kernel\n",
    "print(\"\\nExample 3: Shared memory heavy kernel\")\n",
    "calculate_occupancy(threads_per_block=256, regs_per_thread=32, shared_per_block=16384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b130c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Occupancy vs Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb088983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occupancy_performance_relationship():\n",
    "    \"\"\"Explain when high occupancy matters.\"\"\"\n",
    "    print(\"Occupancy vs Performance\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"Key Insight: Higher occupancy ≠ always better performance\")\n",
    "    print()\n",
    "    print(\"When HIGH OCCUPANCY helps:\")\n",
    "    print(\"  ✓ Memory-bound kernels (need to hide latency)\")\n",
    "    print(\"  ✓ Simple arithmetic operations\")\n",
    "    print(\"  ✓ Irregular memory access patterns\")\n",
    "    print()\n",
    "    print(\"When HIGH OCCUPANCY may NOT help:\")\n",
    "    print(\"  ✗ Compute-bound kernels (already saturated)\")\n",
    "    print(\"  ✗ High instruction-level parallelism (ILP)\")\n",
    "    print(\"  ✗ When reducing occupancy enables better optimizations\")\n",
    "    print()\n",
    "    print(\"Rule of Thumb:\")\n",
    "    print(\"  - Start with ~50% occupancy\")\n",
    "    print(\"  - Profile to determine if occupancy is the bottleneck\")\n",
    "    print(\"  - Memory-bound: aim for higher occupancy\")\n",
    "    print(\"  - Compute-bound: focus on instruction throughput\")\n",
    "\n",
    "occupancy_performance_relationship()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c51124",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Practical Occupancy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test different block sizes\n",
    "@cuda.jit\n",
    "def simple_kernel(data, result):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < data.size:\n",
    "        x = data[idx]\n",
    "        result[idx] = x * x + x\n",
    "\n",
    "def benchmark_block_sizes(n=10_000_000):\n",
    "    \"\"\"Benchmark different block sizes.\"\"\"\n",
    "    data = np.random.rand(n).astype(np.float32)\n",
    "    result = np.zeros(n, dtype=np.float32)\n",
    "    \n",
    "    d_data = cuda.to_device(data)\n",
    "    d_result = cuda.to_device(result)\n",
    "    \n",
    "    print(f\"Benchmarking with {n:,} elements\")\n",
    "    print(f\"{'Block Size':<12} {'Grid Size':<12} {'Time (ms)':<12} {'Throughput':<15}\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    for block_size in [32, 64, 128, 256, 512, 1024]:\n",
    "        grid_size = (n + block_size - 1) // block_size\n",
    "        \n",
    "        # Warmup\n",
    "        simple_kernel[grid_size, block_size](d_data, d_result)\n",
    "        cuda.synchronize()\n",
    "        \n",
    "        # Benchmark\n",
    "        iterations = 50\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(iterations):\n",
    "            simple_kernel[grid_size, block_size](d_data, d_result)\n",
    "        cuda.synchronize()\n",
    "        elapsed = (time.perf_counter() - start) / iterations * 1000\n",
    "        \n",
    "        throughput = n / (elapsed / 1000) / 1e9  # billion elements/sec\n",
    "        print(f\"{block_size:<12} {grid_size:<12} {elapsed:<12.3f} {throughput:.2f} B elem/s\")\n",
    "\n",
    "benchmark_block_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161be117",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Occupancy Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an interactive occupancy calculator\n",
    "# that takes kernel properties and outputs:\n",
    "# 1. Theoretical occupancy\n",
    "# 2. The limiting factor\n",
    "# 3. Suggestions for improvement\n",
    "\n",
    "def occupancy_advisor(threads, regs, shared):\n",
    "    \"\"\"Provide occupancy advice for given kernel parameters.\"\"\"\n",
    "    pass  # Your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae213ba",
   "metadata": {},
   "source": [
    "### Exercise 2: Occupancy Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create two kernels:\n",
    "# 1. Memory-bound kernel (should benefit from high occupancy)\n",
    "# 2. Compute-bound kernel (may not benefit as much)\n",
    "# Compare performance at different block sizes\n",
    "\n",
    "@cuda.jit\n",
    "def memory_bound_kernel(data, result):\n",
    "    \"\"\"Memory-bound: simple read-modify-write.\"\"\"\n",
    "    pass  # Your implementation\n",
    "\n",
    "@cuda.jit\n",
    "def compute_bound_kernel(data, result):\n",
    "    \"\"\"Compute-bound: heavy arithmetic.\"\"\"\n",
    "    pass  # Your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de60f35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Occupancy Formula\n",
    "\n",
    "```\n",
    "Occupancy = Active Warps / Max Warps per SM\n",
    "```\n",
    "\n",
    "### Three Limiters\n",
    "\n",
    "| Limiter | Resource | Typical Limit |\n",
    "|---------|----------|---------------|\n",
    "| Threads | Threads per SM | 1536-2048 |\n",
    "| Registers | Registers per SM | 65536 |\n",
    "| Shared Memory | Bytes per SM | 48-164 KB |\n",
    "\n",
    "### CUDA C++ APIs\n",
    "\n",
    "```cpp\n",
    "// Query occupancy\n",
    "cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
    "    &numBlocks, kernel, blockSize, sharedMem);\n",
    "\n",
    "// Get optimal block size\n",
    "cudaOccupancyMaxPotentialBlockSize(\n",
    "    &minGridSize, &blockSize, kernel, 0, 0);\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **50% occupancy is often sufficient** for good performance\n",
    "2. **Memory-bound kernels** benefit most from high occupancy\n",
    "3. **Profile first** - don't blindly maximize occupancy\n",
    "4. **Balance resources** - sometimes less is more\n",
    "\n",
    "### Tomorrow: Register Optimization\n",
    "We'll dive into register pressure and launch bounds."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
