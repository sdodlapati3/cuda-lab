{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_basics.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Child kernel - launched from GPU\n",
    "__global__ void childKernel(int* data, int offset, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[offset + idx] *= 2;  // Double the value\n",
    "    }\n",
    "}\n",
    "\n",
    "// Parent kernel - launches child kernels\n",
    "__global__ void parentKernel(int* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Only thread 0 launches children\n",
    "    if (tid == 0) {\n",
    "        printf(\"Parent: Launching child kernels from GPU!\\n\");\n",
    "        \n",
    "        int chunkSize = n / 4;\n",
    "        int threadsPerBlock = 64;\n",
    "        int blocks = (chunkSize + threadsPerBlock - 1) / threadsPerBlock;\n",
    "        \n",
    "        // Launch 4 child kernels, each processing a chunk\n",
    "        for (int i = 0; i < 4; i++) {\n",
    "            childKernel<<<blocks, threadsPerBlock>>>(data, i * chunkSize, chunkSize);\n",
    "        }\n",
    "        \n",
    "        // Wait for all children to complete\n",
    "        cudaDeviceSynchronize();\n",
    "        printf(\"Parent: All children completed!\\n\");\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 256;\n",
    "    int *h_data, *d_data;\n",
    "    \n",
    "    h_data = (int*)malloc(N * sizeof(int));\n",
    "    cudaMalloc(&d_data, N * sizeof(int));\n",
    "    \n",
    "    // Initialize data\n",
    "    for (int i = 0; i < N; i++) h_data[i] = i;\n",
    "    cudaMemcpy(d_data, h_data, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    printf(\"Before: data[0]=%d, data[100]=%d\\n\", h_data[0], h_data[100]);\n",
    "    \n",
    "    // Launch parent kernel (which launches children)\n",
    "    parentKernel<<<1, 1>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_data, d_data, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"After:  data[0]=%d, data[100]=%d\\n\", h_data[0], h_data[100]);\n",
    "    \n",
    "    cudaFree(d_data);\n",
    "    free(h_data);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with relocatable device code and device runtime\n",
    "!nvcc -rdc=true -lcudadevrt cdp_basics.cu -o cdp_basics && ./cdp_basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2005b",
   "metadata": {},
   "source": [
    "## Key Compilation Flags\n",
    "\n",
    "- `-rdc=true`: Enable relocatable device code (required for CDP)\n",
    "- `-lcudadevrt`: Link device runtime library\n",
    "\n",
    "## Memory Visibility Rules\n",
    "\n",
    "1. **Global Memory**: Visible to all grids (parent and children)\n",
    "2. **Shared Memory**: NOT visible across grids\n",
    "3. **Local Memory**: Private to each thread\n",
    "4. **Unified Memory**: Preferred for CDP (automatic coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_memory.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void childModify(int* globalData, int parentValue) {\n",
    "    int tid = threadIdx.x;\n",
    "    \n",
    "    // Child can READ parent's local variable (passed by value)\n",
    "    printf(\"Child[%d]: Received parentValue = %d\\n\", tid, parentValue);\n",
    "    \n",
    "    // Child can MODIFY global memory\n",
    "    globalData[tid] = parentValue + tid;\n",
    "}\n",
    "\n",
    "__global__ void parentKernel(int* globalData) {\n",
    "    __shared__ int sharedData[32];\n",
    "    int localVar = 42;\n",
    "    \n",
    "    sharedData[threadIdx.x] = threadIdx.x * 10;\n",
    "    __syncthreads();\n",
    "    \n",
    "    if (threadIdx.x == 0) {\n",
    "        // Pass value to child (NOT pointer to shared/local!)\n",
    "        childModify<<<1, 4>>>(globalData, localVar);\n",
    "        cudaDeviceSynchronize();\n",
    "        \n",
    "        // Check child's modifications\n",
    "        printf(\"Parent: globalData = [%d, %d, %d, %d]\\n\",\n",
    "               globalData[0], globalData[1], globalData[2], globalData[3]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int *d_data;\n",
    "    cudaMalloc(&d_data, 32 * sizeof(int));\n",
    "    cudaMemset(d_data, 0, 32 * sizeof(int));\n",
    "    \n",
    "    parentKernel<<<1, 32>>>(d_data);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaFree(d_data);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_memory.cu -o cdp_memory && ./cdp_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071ff5f",
   "metadata": {},
   "source": [
    "## Device-Side Synchronization\n",
    "\n",
    "| Function | Scope | Use Case |\n",
    "|----------|-------|----------|\n",
    "| `cudaDeviceSynchronize()` | Wait for ALL children | Most common |\n",
    "| `cudaStreamSynchronize(stream)` | Wait for stream | Ordered execution |\n",
    "| Implicit sync at parent exit | Automatic | Default behavior |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8124b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_streams.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void worker(int id, int* result) {\n",
    "    printf(\"Worker %d running on GPU\\n\", id);\n",
    "    result[id] = id * 100;\n",
    "}\n",
    "\n",
    "__global__ void coordinator(int* results) {\n",
    "    cudaStream_t streams[4];\n",
    "    \n",
    "    // Create device-side streams\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        cudaStreamCreateWithFlags(&streams[i], cudaStreamNonBlocking);\n",
    "    }\n",
    "    \n",
    "    // Launch workers into different streams (concurrent execution)\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        worker<<<1, 1, 0, streams[i]>>>(i, results);\n",
    "    }\n",
    "    \n",
    "    // Wait for all streams\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Cleanup streams\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        cudaStreamDestroy(streams[i]);\n",
    "    }\n",
    "    \n",
    "    printf(\"Results: [%d, %d, %d, %d]\\n\",\n",
    "           results[0], results[1], results[2], results[3]);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int *d_results;\n",
    "    cudaMalloc(&d_results, 4 * sizeof(int));\n",
    "    \n",
    "    coordinator<<<1, 1>>>(d_results);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaFree(d_results);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_streams.cu -o cdp_streams && ./cdp_streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7cb13",
   "metadata": {},
   "source": [
    "## Exercise: Parallel Sum with CDP\n",
    "\n",
    "Implement a parallel sum using dynamic parallelism:\n",
    "1. Parent divides array into chunks\n",
    "2. Each child computes partial sum\n",
    "3. Parent combines partial sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a57201",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_sum_exercise.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// TODO: Implement child kernel that sums a chunk\n",
    "__global__ void sumChunk(float* data, int start, int end, float* partialSum) {\n",
    "    // Your code here\n",
    "}\n",
    "\n",
    "// TODO: Implement parent kernel that coordinates the work\n",
    "__global__ void parallelSum(float* data, int n, int numChunks, float* result) {\n",
    "    // Your code here\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Test your implementation\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d55d",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **CDP enables GPU-side kernel launches** - no CPU roundtrip needed\n",
    "2. **Compilation flags required**: `-rdc=true -lcudadevrt`\n",
    "3. **Memory visibility**: Only global/unified memory shared across grids\n",
    "4. **Synchronization**: Use `cudaDeviceSynchronize()` to wait for children\n",
    "5. **Device streams**: Enable concurrent child execution\n",
    "\n",
    "## Next: Day 2 - Recursive Algorithms with CDP"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
