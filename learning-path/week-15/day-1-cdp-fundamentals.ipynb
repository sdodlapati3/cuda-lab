{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f75eea",
   "metadata": {},
   "source": [
    "# Day 1: CUDA Dynamic Parallelism Fundamentals\n",
    "\n",
    "## ğŸ¯ The Manager Who Spawns Sub-Teams On-the-Fly\n",
    "\n",
    "> **Hook:** Imagine a construction site manager who, upon seeing the actual terrain, can instantly hire specialized sub-teams without calling headquarters. Need extra plumbers for unexpected pipes? Spawn them on-site. Found bedrock? Summon the drilling crew immediately. Traditional CUDA is like calling the office (CPU) every time you need more workers. **Dynamic Parallelism lets the GPU manager spawn new teams directly from the job site!**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this session, you will:\n",
    "1. **Understand CDP architecture** - How parent kernels launch child kernels directly on GPU\n",
    "2. **Master compilation requirements** - Use `-rdc=true` and `-lcudadevrt` flags correctly\n",
    "3. **Apply memory visibility rules** - Know what's shared between parent and children\n",
    "4. **Implement device-side synchronization** - Use `cudaDeviceSynchronize()` effectively\n",
    "5. **Create device streams** - Enable concurrent child kernel execution\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Prerequisites\n",
    "- Week 14: PyTorch CUDA Extensions (understanding GPU kernel workflows)\n",
    "- Understanding of CUDA streams and synchronization\n",
    "- Familiarity with basic kernel launching from host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_basics.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Child kernel - launched from GPU\n",
    "__global__ void childKernel(int* data, int offset, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[offset + idx] *= 2;  // Double the value\n",
    "    }\n",
    "}\n",
    "\n",
    "// Parent kernel - launches child kernels\n",
    "__global__ void parentKernel(int* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Only thread 0 launches children\n",
    "    if (tid == 0) {\n",
    "        printf(\"Parent: Launching child kernels from GPU!\\n\");\n",
    "        \n",
    "        int chunkSize = n / 4;\n",
    "        int threadsPerBlock = 64;\n",
    "        int blocks = (chunkSize + threadsPerBlock - 1) / threadsPerBlock;\n",
    "        \n",
    "        // Launch 4 child kernels, each processing a chunk\n",
    "        for (int i = 0; i < 4; i++) {\n",
    "            childKernel<<<blocks, threadsPerBlock>>>(data, i * chunkSize, chunkSize);\n",
    "        }\n",
    "        \n",
    "        // Wait for all children to complete\n",
    "        cudaDeviceSynchronize();\n",
    "        printf(\"Parent: All children completed!\\n\");\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 256;\n",
    "    int *h_data, *d_data;\n",
    "    \n",
    "    h_data = (int*)malloc(N * sizeof(int));\n",
    "    cudaMalloc(&d_data, N * sizeof(int));\n",
    "    \n",
    "    // Initialize data\n",
    "    for (int i = 0; i < N; i++) h_data[i] = i;\n",
    "    cudaMemcpy(d_data, h_data, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    printf(\"Before: data[0]=%d, data[100]=%d\\n\", h_data[0], h_data[100]);\n",
    "    \n",
    "    // Launch parent kernel (which launches children)\n",
    "    parentKernel<<<1, 1>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_data, d_data, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"After:  data[0]=%d, data[100]=%d\\n\", h_data[0], h_data[100]);\n",
    "    \n",
    "    cudaFree(d_data);\n",
    "    free(h_data);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be70578",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Concept Card: CDP as Manager Delegation\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ğŸ—ï¸ THE ON-SITE MANAGER ANALOGY                                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  TRADITIONAL CUDA (Calling Headquarters)        CDP (On-Site Authority)    â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  GPU Thread: \"Found 4 problem areas!\"          GPU Thread: \"Found 4 areas!\"â”‚\n",
    "â”‚       â”‚                                              â”‚                      â”‚\n",
    "â”‚       â–¼                                              â–¼                      â”‚\n",
    "â”‚  Return to CPU â”€â”€â”€â”€â–º \"Send 4 teams\"            Spawn 4 child kernels â—„â”€â”€â”€â”€â”€â”‚\n",
    "â”‚       â”‚                                              â”‚         directly     â”‚\n",
    "â”‚       â–¼                                              â–¼                      â”‚\n",
    "â”‚  CPU launches 4 kernels                        Children work immediately   â”‚\n",
    "â”‚       â”‚                                              â”‚                      â”‚\n",
    "â”‚       â–¼ (latency!)                                   â–¼ (no latency!)       â”‚\n",
    "â”‚  Wait for completion                           Parent waits on GPU         â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  ğŸ”‘ KEY INSIGHT:                                                            â”‚\n",
    "â”‚  â€¢ Parent kernel = Site Manager with hiring authority                       â”‚\n",
    "â”‚  â€¢ Child kernels = Sub-teams spawned for specific tasks                     â”‚\n",
    "â”‚  â€¢ cudaDeviceSynchronize() = Manager waiting for sub-teams to finish        â”‚\n",
    "â”‚  â€¢ Device streams = Multiple sub-teams working in parallel                  â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  ğŸ“‹ When to Use CDP:                                                        â”‚\n",
    "â”‚  â€¢ Work discovered AT RUNTIME (irregular workloads)                         â”‚\n",
    "â”‚  â€¢ Recursive algorithms (divide and conquer)                                â”‚\n",
    "â”‚  â€¢ Adaptive mesh refinement                                                 â”‚\n",
    "â”‚  â€¢ Tree/graph traversals                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Section 1: Basic CDP - Parent Launching Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with relocatable device code and device runtime\n",
    "!nvcc -rdc=true -lcudadevrt cdp_basics.cu -o cdp_basics && ./cdp_basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2005b",
   "metadata": {},
   "source": [
    "## Key Compilation Flags\n",
    "\n",
    "- `-rdc=true`: Enable relocatable device code (required for CDP)\n",
    "- `-lcudadevrt`: Link device runtime library\n",
    "\n",
    "## Memory Visibility Rules\n",
    "\n",
    "1. **Global Memory**: Visible to all grids (parent and children)\n",
    "2. **Shared Memory**: NOT visible across grids\n",
    "3. **Local Memory**: Private to each thread\n",
    "4. **Unified Memory**: Preferred for CDP (automatic coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_memory.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void childModify(int* globalData, int parentValue) {\n",
    "    int tid = threadIdx.x;\n",
    "    \n",
    "    // Child can READ parent's local variable (passed by value)\n",
    "    printf(\"Child[%d]: Received parentValue = %d\\n\", tid, parentValue);\n",
    "    \n",
    "    // Child can MODIFY global memory\n",
    "    globalData[tid] = parentValue + tid;\n",
    "}\n",
    "\n",
    "__global__ void parentKernel(int* globalData) {\n",
    "    __shared__ int sharedData[32];\n",
    "    int localVar = 42;\n",
    "    \n",
    "    sharedData[threadIdx.x] = threadIdx.x * 10;\n",
    "    __syncthreads();\n",
    "    \n",
    "    if (threadIdx.x == 0) {\n",
    "        // Pass value to child (NOT pointer to shared/local!)\n",
    "        childModify<<<1, 4>>>(globalData, localVar);\n",
    "        cudaDeviceSynchronize();\n",
    "        \n",
    "        // Check child's modifications\n",
    "        printf(\"Parent: globalData = [%d, %d, %d, %d]\\n\",\n",
    "               globalData[0], globalData[1], globalData[2], globalData[3]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int *d_data;\n",
    "    cudaMalloc(&d_data, 32 * sizeof(int));\n",
    "    cudaMemset(d_data, 0, 32 * sizeof(int));\n",
    "    \n",
    "    parentKernel<<<1, 32>>>(d_data);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaFree(d_data);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_memory.cu -o cdp_memory && ./cdp_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071ff5f",
   "metadata": {},
   "source": [
    "## Device-Side Synchronization\n",
    "\n",
    "| Function | Scope | Use Case |\n",
    "|----------|-------|----------|\n",
    "| `cudaDeviceSynchronize()` | Wait for ALL children | Most common |\n",
    "| `cudaStreamSynchronize(stream)` | Wait for stream | Ordered execution |\n",
    "| Implicit sync at parent exit | Automatic | Default behavior |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8124b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_streams.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void worker(int id, int* result) {\n",
    "    printf(\"Worker %d running on GPU\\n\", id);\n",
    "    result[id] = id * 100;\n",
    "}\n",
    "\n",
    "__global__ void coordinator(int* results) {\n",
    "    cudaStream_t streams[4];\n",
    "    \n",
    "    // Create device-side streams\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        cudaStreamCreateWithFlags(&streams[i], cudaStreamNonBlocking);\n",
    "    }\n",
    "    \n",
    "    // Launch workers into different streams (concurrent execution)\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        worker<<<1, 1, 0, streams[i]>>>(i, results);\n",
    "    }\n",
    "    \n",
    "    // Wait for all streams\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Cleanup streams\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        cudaStreamDestroy(streams[i]);\n",
    "    }\n",
    "    \n",
    "    printf(\"Results: [%d, %d, %d, %d]\\n\",\n",
    "           results[0], results[1], results[2], results[3]);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int *d_results;\n",
    "    cudaMalloc(&d_results, 4 * sizeof(int));\n",
    "    \n",
    "    coordinator<<<1, 1>>>(d_results);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaFree(d_results);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_streams.cu -o cdp_streams && ./cdp_streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7cb13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Implement a parallel sum using dynamic parallelism:\n",
    "1. Parent divides array into chunks\n",
    "2. Each child computes partial sum\n",
    "3. Parent combines partial sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a57201",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_fundamentals_exercises.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "/*\n",
    " * CDP Fundamentals Exercises\n",
    " * Compile: nvcc -arch=sm_75 -rdc=true -lcudadevrt -o cdp_fundamentals_exercises cdp_fundamentals_exercises.cu\n",
    " * \n",
    " * Exercise 1: Parallel Sum with CDP\n",
    " * - Parent kernel divides array into chunks\n",
    " * - Child kernels compute partial sums\n",
    " * - Parent combines results\n",
    " * \n",
    " * Exercise 2: Hierarchical Reduction\n",
    " * - Implement multi-level reduction using CDP\n",
    " * - Each level reduces by factor of 4\n",
    " * \n",
    " * Exercise 3: Dynamic Work Distribution\n",
    " * - Parent kernel discovers work items\n",
    " * - Launch child kernels based on runtime conditions\n",
    " */\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA error at %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
    "                   cudaGetErrorString(err)); \\\n",
    "            exit(EXIT_FAILURE); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 1: Parallel Sum with CDP\n",
    "// =============================================================================\n",
    "\n",
    "// Child kernel: sum a chunk of the array\n",
    "__global__ void sumChunkKernel(float* data, int start, int count, float* partialSum) {\n",
    "    // TODO: Implement chunk summation\n",
    "    // Use shared memory for reduction within block\n",
    "    // Write result to partialSum[blockIdx.x]\n",
    "    \n",
    "    extern __shared__ float sdata[];\n",
    "    int tid = threadIdx.x;\n",
    "    int idx = start + blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Load into shared memory\n",
    "    sdata[tid] = (idx < start + count) ? data[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Reduction in shared memory\n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        partialSum[blockIdx.x] = sdata[0];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Parent kernel: coordinate parallel sum\n",
    "__global__ void parallelSumKernel(float* data, int n, int numChunks, float* result) {\n",
    "    // TODO: Implement parent kernel\n",
    "    // 1. Allocate device memory for partial sums\n",
    "    // 2. Launch child kernels for each chunk\n",
    "    // 3. Synchronize and combine results\n",
    "    \n",
    "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
    "        int chunkSize = (n + numChunks - 1) / numChunks;\n",
    "        \n",
    "        // Allocate partial sums (device-side allocation)\n",
    "        float* partialSums;\n",
    "        cudaMalloc(&partialSums, numChunks * sizeof(float));\n",
    "        \n",
    "        int threadsPerBlock = 256;\n",
    "        \n",
    "        // Launch child kernels for each chunk\n",
    "        for (int i = 0; i < numChunks; i++) {\n",
    "            int start = i * chunkSize;\n",
    "            int count = min(chunkSize, n - start);\n",
    "            int blocks = (count + threadsPerBlock - 1) / threadsPerBlock;\n",
    "            \n",
    "            sumChunkKernel<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(\n",
    "                data, start, count, partialSums + i);\n",
    "        }\n",
    "        \n",
    "        cudaDeviceSynchronize();\n",
    "        \n",
    "        // Combine partial sums\n",
    "        float total = 0.0f;\n",
    "        for (int i = 0; i < numChunks; i++) {\n",
    "            float ps;\n",
    "            // Read partial sum (this is simplified - in practice use another kernel)\n",
    "            total += partialSums[i];\n",
    "        }\n",
    "        \n",
    "        *result = total;\n",
    "        cudaFree(partialSums);\n",
    "        \n",
    "        printf(\"CDP Sum Result: %f\\n\", total);\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise1_parallel_sum() {\n",
    "    printf(\"\\n=== Exercise 1: Parallel Sum with CDP ===\\n\");\n",
    "    \n",
    "    const int N = 1024;\n",
    "    const int NUM_CHUNKS = 4;\n",
    "    \n",
    "    float *h_data = new float[N];\n",
    "    float h_result = 0.0f;\n",
    "    \n",
    "    // Initialize data\n",
    "    float expected = 0.0f;\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_data[i] = 1.0f;  // Simple case: all ones\n",
    "        expected += h_data[i];\n",
    "    }\n",
    "    \n",
    "    float *d_data, *d_result;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_result, sizeof(float)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    parallelSumKernel<<<1, 1>>>(d_data, N, NUM_CHUNKS, d_result);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(&h_result, d_result, sizeof(float), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    printf(\"Expected: %f, Got: %f\\n\", expected, h_result);\n",
    "    \n",
    "    delete[] h_data;\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_result);\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 2: Hierarchical Reduction with CDP\n",
    "// =============================================================================\n",
    "\n",
    "__global__ void hierarchicalReduceKernel(float* data, int n, int depth) {\n",
    "    // TODO: Implement hierarchical reduction\n",
    "    // Base case: n <= threshold, do simple sum\n",
    "    // Recursive case: reduce by factor of 4, launch child\n",
    "    \n",
    "    if (n <= 4 || depth >= 4) {\n",
    "        // Base case: simple sum\n",
    "        if (threadIdx.x == 0) {\n",
    "            float sum = 0.0f;\n",
    "            for (int i = 0; i < n; i++) {\n",
    "                sum += data[i];\n",
    "            }\n",
    "            data[0] = sum;\n",
    "            printf(\"Depth %d: Base case reduction of %d elements = %f\\n\", depth, n, sum);\n",
    "        }\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Reduce by factor of 4\n",
    "    int newN = (n + 3) / 4;\n",
    "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    \n",
    "    if (tid < newN) {\n",
    "        float sum = 0.0f;\n",
    "        for (int i = 0; i < 4 && tid * 4 + i < n; i++) {\n",
    "            sum += data[tid * 4 + i];\n",
    "        }\n",
    "        data[tid] = sum;\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        hierarchicalReduceKernel<<<1, min(newN, 256)>>>(data, newN, depth + 1);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise2_hierarchical_reduction() {\n",
    "    printf(\"\\n=== Exercise 2: Hierarchical Reduction ===\\n\");\n",
    "    \n",
    "    const int N = 256;\n",
    "    float *h_data = new float[N];\n",
    "    \n",
    "    float expected = 0.0f;\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_data[i] = 1.0f;\n",
    "        expected += h_data[i];\n",
    "    }\n",
    "    \n",
    "    float *d_data;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    hierarchicalReduceKernel<<<1, 256>>>(d_data, N, 0);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    float result;\n",
    "    CHECK_CUDA(cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    printf(\"Expected: %f, Got: %f\\n\", expected, result);\n",
    "    \n",
    "    delete[] h_data;\n",
    "    cudaFree(d_data);\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 3: Dynamic Work Distribution\n",
    "// =============================================================================\n",
    "\n",
    "__global__ void processWorkItem(int* data, int workId, int size) {\n",
    "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    if (tid < size) {\n",
    "        data[tid] = data[tid] * 2 + workId;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void dynamicWorkDistribution(int* data, int* workSizes, int numItems) {\n",
    "    // TODO: Discover work at runtime and launch children\n",
    "    // Only process items with size > threshold\n",
    "    \n",
    "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
    "        int offset = 0;\n",
    "        int processed = 0;\n",
    "        \n",
    "        for (int i = 0; i < numItems; i++) {\n",
    "            int size = workSizes[i];\n",
    "            \n",
    "            // Runtime decision: only process if size > 10\n",
    "            if (size > 10) {\n",
    "                int blocks = (size + 127) / 128;\n",
    "                processWorkItem<<<blocks, 128>>>(data + offset, i, size);\n",
    "                processed++;\n",
    "                printf(\"Processing work item %d with size %d\\n\", i, size);\n",
    "            } else {\n",
    "                printf(\"Skipping work item %d (size %d too small)\\n\", i, size);\n",
    "            }\n",
    "            \n",
    "            offset += size;\n",
    "        }\n",
    "        \n",
    "        cudaDeviceSynchronize();\n",
    "        printf(\"Processed %d of %d work items\\n\", processed, numItems);\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise3_dynamic_work() {\n",
    "    printf(\"\\n=== Exercise 3: Dynamic Work Distribution ===\\n\");\n",
    "    \n",
    "    int h_workSizes[] = {5, 50, 8, 100, 3, 200};\n",
    "    int numItems = 6;\n",
    "    int totalSize = 0;\n",
    "    for (int i = 0; i < numItems; i++) totalSize += h_workSizes[i];\n",
    "    \n",
    "    int *h_data = new int[totalSize];\n",
    "    for (int i = 0; i < totalSize; i++) h_data[i] = 1;\n",
    "    \n",
    "    int *d_data, *d_workSizes;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, totalSize * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_workSizes, numItems * sizeof(int)));\n",
    "    CHECK_CUDA(cudaMemcpy(d_data, h_data, totalSize * sizeof(int), cudaMemcpyHostToDevice));\n",
    "    CHECK_CUDA(cudaMemcpy(d_workSizes, h_workSizes, numItems * sizeof(int), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    dynamicWorkDistribution<<<1, 1>>>(d_data, d_workSizes, numItems);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    CHECK_CUDA(cudaMemcpy(h_data, d_data, totalSize * sizeof(int), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    printf(\"Sample results: data[0]=%d, data[10]=%d, data[100]=%d\\n\",\n",
    "           h_data[0], h_data[10], h_data[100]);\n",
    "    \n",
    "    delete[] h_data;\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_workSizes);\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Main\n",
    "// =============================================================================\n",
    "\n",
    "int main() {\n",
    "    printf(\"CDP Fundamentals Exercises\\n\");\n",
    "    printf(\"==========================\\n\");\n",
    "    \n",
    "    exercise1_parallel_sum();\n",
    "    exercise2_hierarchical_reduction();\n",
    "    exercise3_dynamic_work();\n",
    "    \n",
    "    printf(\"\\nâœ… All CDP exercises completed!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -rdc=true -lcudadevrt -o cdp_fundamentals_exercises cdp_fundamentals_exercises.cu && ./cdp_fundamentals_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a254678",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d55d",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaways\n",
    "\n",
    "### The Manager Delegation Pattern Mastered!\n",
    "\n",
    "| Concept | Manager Analogy | CUDA Implementation |\n",
    "|---------|-----------------|---------------------|\n",
    "| **Parent Kernel** | Site manager with authority | Kernel that calls `<<<>>>` |\n",
    "| **Child Kernels** | Specialized sub-teams | Kernels launched from device |\n",
    "| **Memory Sharing** | Shared blueprints (global) | Only global/unified memory visible |\n",
    "| **Sync Point** | \"Wait for all sub-teams\" | `cudaDeviceSynchronize()` |\n",
    "| **Device Streams** | Parallel work crews | `cudaStreamCreateWithFlags()` |\n",
    "\n",
    "### CDP Decision Checklist\n",
    "\n",
    "```\n",
    "âœ… Use CDP when:\n",
    "   â–¡ Work is discovered at runtime (data-dependent)\n",
    "   â–¡ CPU roundtrip latency would hurt performance\n",
    "   â–¡ Recursive algorithms (divide-and-conquer)\n",
    "   â–¡ Irregular/adaptive workloads\n",
    "\n",
    "âŒ Avoid CDP when:\n",
    "   â–¡ Fixed, known workload (just launch from CPU)\n",
    "   â–¡ Shallow recursion (overhead not worth it)\n",
    "   â–¡ Memory-bound kernels (launch overhead adds up)\n",
    "```\n",
    "\n",
    "### Essential Commands\n",
    "\n",
    "```bash\n",
    "# Compilation (REQUIRED for CDP)\n",
    "nvcc -rdc=true -lcudadevrt my_cdp_code.cu -o my_cdp_code\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Next: Day 2 - Recursive Algorithms with CDP\n",
    "\n",
    "Tomorrow we'll apply the manager delegation pattern to recursive algorithms like quicksort and tree traversals!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
