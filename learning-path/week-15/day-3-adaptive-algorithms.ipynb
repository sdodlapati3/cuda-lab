{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea062eb",
   "metadata": {},
   "source": [
    "## Adaptive Grid Sizing\n",
    "\n",
    "CDP allows kernels to decide at runtime how much parallelism to spawn based on actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile adaptive_grid.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Worker kernel - processes items in range\n",
    "__global__ void processRange(int* data, int start, int end, int* output) {\n",
    "    int idx = start + blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < end) {\n",
    "        output[idx] = data[idx] * data[idx];  // Square each element\n",
    "    }\n",
    "}\n",
    "\n",
    "// Coordinator kernel - adapts parallelism to workload\n",
    "__global__ void adaptiveProcess(int* data, int* counts, int numRegions, int* output) {\n",
    "    int region = blockIdx.x;\n",
    "    if (region >= numRegions) return;\n",
    "    \n",
    "    int count = counts[region];\n",
    "    int start = 0;\n",
    "    for (int i = 0; i < region; i++) start += counts[i];\n",
    "    int end = start + count;\n",
    "    \n",
    "    // Adapt grid size to actual workload\n",
    "    if (count > 0) {\n",
    "        int threadsPerBlock = 128;\n",
    "        int blocks = (count + threadsPerBlock - 1) / threadsPerBlock;\n",
    "        \n",
    "        printf(\"Region %d: %d items -> launching %d blocks\\n\", region, count, blocks);\n",
    "        processRange<<<blocks, threadsPerBlock>>>(data, start, end, output);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Variable-sized regions (simulating irregular workload)\n",
    "    int h_counts[] = {100, 5, 500, 20, 1000};\n",
    "    int numRegions = 5;\n",
    "    int totalItems = 0;\n",
    "    for (int i = 0; i < numRegions; i++) totalItems += h_counts[i];\n",
    "    \n",
    "    printf(\"Total items: %d across %d regions\\n\", totalItems, numRegions);\n",
    "    \n",
    "    int *d_data, *d_counts, *d_output;\n",
    "    cudaMalloc(&d_data, totalItems * sizeof(int));\n",
    "    cudaMalloc(&d_counts, numRegions * sizeof(int));\n",
    "    cudaMalloc(&d_output, totalItems * sizeof(int));\n",
    "    \n",
    "    // Initialize data\n",
    "    int* h_data = new int[totalItems];\n",
    "    for (int i = 0; i < totalItems; i++) h_data[i] = i;\n",
    "    cudaMemcpy(d_data, h_data, totalItems * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_counts, h_counts, numRegions * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch adaptive coordinator\n",
    "    adaptiveProcess<<<numRegions, 1>>>(d_data, d_counts, numRegions, d_output);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Verify results\n",
    "    int* h_output = new int[totalItems];\n",
    "    cudaMemcpy(h_output, d_output, totalItems * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"\\nSample results: output[0]=%d, output[100]=%d, output[600]=%d\\n\",\n",
    "           h_output[0], h_output[100], h_output[600]);\n",
    "    \n",
    "    delete[] h_data;\n",
    "    delete[] h_output;\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_counts);\n",
    "    cudaFree(d_output);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt adaptive_grid.cu -o adaptive_grid && ./adaptive_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fd9f9",
   "metadata": {},
   "source": [
    "## Quadtree Construction with CDP\n",
    "\n",
    "Quadtrees adaptively subdivide 2D space based on point density - perfect for CDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_quadtree.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define MAX_POINTS_PER_NODE 4\n",
    "#define MAX_DEPTH 8\n",
    "\n",
    "struct Point {\n",
    "    float x, y;\n",
    "};\n",
    "\n",
    "struct BoundingBox {\n",
    "    float minX, minY, maxX, maxY;\n",
    "    \n",
    "    __device__ bool contains(Point p) {\n",
    "        return p.x >= minX && p.x <= maxX && p.y >= minY && p.y <= maxY;\n",
    "    }\n",
    "    \n",
    "    __device__ BoundingBox quadrant(int q) {\n",
    "        float midX = (minX + maxX) / 2;\n",
    "        float midY = (minY + maxY) / 2;\n",
    "        switch (q) {\n",
    "            case 0: return {minX, midY, midX, maxY};  // NW\n",
    "            case 1: return {midX, midY, maxX, maxY};  // NE\n",
    "            case 2: return {minX, minY, midX, midY};  // SW\n",
    "            case 3: return {midX, minY, maxX, midY};  // SE\n",
    "        }\n",
    "        return *this;\n",
    "    }\n",
    "};\n",
    "\n",
    "// Count points in bounding box\n",
    "__device__ int countPointsInBox(Point* points, int n, BoundingBox box) {\n",
    "    int count = 0;\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        if (box.contains(points[i])) count++;\n",
    "    }\n",
    "    return count;\n",
    "}\n",
    "\n",
    "// Recursive quadtree construction\n",
    "__global__ void buildQuadtree(Point* points, int n, BoundingBox box, int depth, int* nodeCount) {\n",
    "    int count = countPointsInBox(points, n, box);\n",
    "    \n",
    "    if (count == 0 || depth >= MAX_DEPTH) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Count this node\n",
    "    int nodeId = atomicAdd(nodeCount, 1);\n",
    "    \n",
    "    if (count <= MAX_POINTS_PER_NODE) {\n",
    "        // Leaf node - no further subdivision\n",
    "        printf(\"Leaf node %d at depth %d: %d points\\n\", nodeId, depth, count);\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Internal node - subdivide\n",
    "    printf(\"Internal node %d at depth %d: %d points -> subdividing\\n\", nodeId, depth, count);\n",
    "    \n",
    "    // Launch children for each quadrant\n",
    "    for (int q = 0; q < 4; q++) {\n",
    "        BoundingBox childBox = box.quadrant(q);\n",
    "        buildQuadtree<<<1, 1>>>(points, n, childBox, depth + 1, nodeCount);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 100;\n",
    "    Point h_points[N];\n",
    "    \n",
    "    // Generate clustered points\n",
    "    srand(42);\n",
    "    for (int i = 0; i < N/2; i++) {\n",
    "        // Cluster 1: upper-right\n",
    "        h_points[i] = {0.7f + 0.3f * rand() / RAND_MAX, 0.7f + 0.3f * rand() / RAND_MAX};\n",
    "    }\n",
    "    for (int i = N/2; i < N; i++) {\n",
    "        // Cluster 2: lower-left\n",
    "        h_points[i] = {0.0f + 0.3f * rand() / RAND_MAX, 0.0f + 0.3f * rand() / RAND_MAX};\n",
    "    }\n",
    "    \n",
    "    Point* d_points;\n",
    "    int* d_nodeCount;\n",
    "    cudaMalloc(&d_points, N * sizeof(Point));\n",
    "    cudaMalloc(&d_nodeCount, sizeof(int));\n",
    "    \n",
    "    cudaMemcpy(d_points, h_points, N * sizeof(Point), cudaMemcpyHostToDevice);\n",
    "    cudaMemset(d_nodeCount, 0, sizeof(int));\n",
    "    \n",
    "    BoundingBox rootBox = {0, 0, 1, 1};\n",
    "    buildQuadtree<<<1, 1>>>(d_points, N, rootBox, 0, d_nodeCount);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    int h_nodeCount;\n",
    "    cudaMemcpy(&h_nodeCount, d_nodeCount, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"\\nTotal nodes created: %d\\n\", h_nodeCount);\n",
    "    \n",
    "    cudaFree(d_points);\n",
    "    cudaFree(d_nodeCount);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_quadtree.cu -o cdp_quadtree && ./cdp_quadtree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddead560",
   "metadata": {},
   "source": [
    "## When CDP Shines vs. When to Avoid\n",
    "\n",
    "### Good Use Cases ✅\n",
    "- Recursive divide-and-conquer\n",
    "- Irregular/adaptive workloads\n",
    "- Tree/graph traversal\n",
    "- Workload discovered at runtime\n",
    "\n",
    "### Avoid When ❌\n",
    "- Regular, predictable parallelism\n",
    "- Very deep recursion (>16 levels)\n",
    "- Launching many tiny kernels\n",
    "- CPU coordination is acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f10c3",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Adaptive parallelism** - spawn work based on actual data\n",
    "2. **Hierarchical structures** - quadtree/octree natural fit\n",
    "3. **Irregular workloads** - regions with variable sizes\n",
    "4. **Trade-offs** - launch overhead vs. CPU roundtrip\n",
    "\n",
    "## Next: Day 4 - CDP Optimization & Best Practices"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
