{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf42d044",
   "metadata": {},
   "source": [
    "## GPU Quicksort with Dynamic Parallelism\n",
    "\n",
    "Quicksort is a classic recursive algorithm that benefits from CDP:\n",
    "1. Partition array around pivot\n",
    "2. Recursively sort left and right subarrays\n",
    "3. Base case: small arrays sorted with simple algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d59633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_quicksort.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <thrust/device_vector.h>\n",
    "#include <thrust/host_vector.h>\n",
    "\n",
    "#define INSERTION_SORT_THRESHOLD 32\n",
    "#define MAX_DEPTH 16\n",
    "\n",
    "// Simple insertion sort for small arrays\n",
    "__device__ void insertionSort(int* arr, int left, int right) {\n",
    "    for (int i = left + 1; i <= right; i++) {\n",
    "        int key = arr[i];\n",
    "        int j = i - 1;\n",
    "        while (j >= left && arr[j] > key) {\n",
    "            arr[j + 1] = arr[j];\n",
    "            j--;\n",
    "        }\n",
    "        arr[j + 1] = key;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Partition using Lomuto scheme\n",
    "__device__ int partition(int* arr, int left, int right) {\n",
    "    int pivot = arr[right];\n",
    "    int i = left - 1;\n",
    "    \n",
    "    for (int j = left; j < right; j++) {\n",
    "        if (arr[j] <= pivot) {\n",
    "            i++;\n",
    "            int temp = arr[i];\n",
    "            arr[i] = arr[j];\n",
    "            arr[j] = temp;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    int temp = arr[i + 1];\n",
    "    arr[i + 1] = arr[right];\n",
    "    arr[right] = temp;\n",
    "    \n",
    "    return i + 1;\n",
    "}\n",
    "\n",
    "// Recursive quicksort kernel\n",
    "__global__ void quicksortKernel(int* arr, int left, int right, int depth) {\n",
    "    // Base case: small array or max depth reached\n",
    "    if (right - left < INSERTION_SORT_THRESHOLD || depth >= MAX_DEPTH) {\n",
    "        if (left < right) {\n",
    "            insertionSort(arr, left, right);\n",
    "        }\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Partition the array\n",
    "    int pivotIdx = partition(arr, left, right);\n",
    "    \n",
    "    // Launch child kernels for subarrays\n",
    "    cudaStream_t leftStream, rightStream;\n",
    "    cudaStreamCreateWithFlags(&leftStream, cudaStreamNonBlocking);\n",
    "    cudaStreamCreateWithFlags(&rightStream, cudaStreamNonBlocking);\n",
    "    \n",
    "    if (pivotIdx - 1 > left) {\n",
    "        quicksortKernel<<<1, 1, 0, leftStream>>>(arr, left, pivotIdx - 1, depth + 1);\n",
    "    }\n",
    "    if (pivotIdx + 1 < right) {\n",
    "        quicksortKernel<<<1, 1, 0, rightStream>>>(arr, pivotIdx + 1, right, depth + 1);\n",
    "    }\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "    cudaStreamDestroy(leftStream);\n",
    "    cudaStreamDestroy(rightStream);\n",
    "}\n",
    "\n",
    "void gpuQuicksort(int* d_arr, int n) {\n",
    "    quicksortKernel<<<1, 1>>>(d_arr, 0, n - 1, 0);\n",
    "    cudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1024;\n",
    "    thrust::host_vector<int> h_arr(N);\n",
    "    \n",
    "    // Initialize with random values\n",
    "    srand(42);\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_arr[i] = rand() % 10000;\n",
    "    }\n",
    "    \n",
    "    printf(\"Before sort: [%d, %d, %d, ... , %d]\\n\",\n",
    "           h_arr[0], h_arr[1], h_arr[2], h_arr[N-1]);\n",
    "    \n",
    "    thrust::device_vector<int> d_arr = h_arr;\n",
    "    gpuQuicksort(thrust::raw_pointer_cast(d_arr.data()), N);\n",
    "    h_arr = d_arr;\n",
    "    \n",
    "    printf(\"After sort:  [%d, %d, %d, ... , %d]\\n\",\n",
    "           h_arr[0], h_arr[1], h_arr[2], h_arr[N-1]);\n",
    "    \n",
    "    // Verify sorted\n",
    "    bool sorted = true;\n",
    "    for (int i = 1; i < N; i++) {\n",
    "        if (h_arr[i] < h_arr[i-1]) sorted = false;\n",
    "    }\n",
    "    printf(\"Array is %s\\n\", sorted ? \"SORTED\" : \"NOT SORTED\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66741ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_quicksort.cu -o cdp_quicksort && ./cdp_quicksort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595623c8",
   "metadata": {},
   "source": [
    "## Recursion Depth Limits\n",
    "\n",
    "CDP has practical limits:\n",
    "- **Default nesting depth**: 24 levels\n",
    "- **Pending kernel limit**: 2048 by default\n",
    "- **Device memory for sync**: ~150KB per level\n",
    "\n",
    "Configure with `cudaDeviceSetLimit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a81d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_limits.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "int main() {\n",
    "    size_t syncDepth, pendingLaunchCount, stackSize;\n",
    "    \n",
    "    cudaDeviceGetLimit(&syncDepth, cudaLimitDevRuntimeSyncDepth);\n",
    "    cudaDeviceGetLimit(&pendingLaunchCount, cudaLimitDevRuntimePendingLaunchCount);\n",
    "    cudaDeviceGetLimit(&stackSize, cudaLimitStackSize);\n",
    "    \n",
    "    printf(\"CDP Limits:\\n\");\n",
    "    printf(\"  Max sync depth: %zu\\n\", syncDepth);\n",
    "    printf(\"  Max pending launches: %zu\\n\", pendingLaunchCount);\n",
    "    printf(\"  Stack size per thread: %zu bytes\\n\", stackSize);\n",
    "    \n",
    "    // Increase limits if needed\n",
    "    cudaDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, 32);\n",
    "    cudaDeviceSetLimit(cudaLimitDevRuntimePendingLaunchCount, 4096);\n",
    "    \n",
    "    cudaDeviceGetLimit(&syncDepth, cudaLimitDevRuntimeSyncDepth);\n",
    "    cudaDeviceGetLimit(&pendingLaunchCount, cudaLimitDevRuntimePendingLaunchCount);\n",
    "    \n",
    "    printf(\"\\nAfter increasing:\\n\");\n",
    "    printf(\"  Max sync depth: %zu\\n\", syncDepth);\n",
    "    printf(\"  Max pending launches: %zu\\n\", pendingLaunchCount);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78774f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cdp_limits.cu -o cdp_limits && ./cdp_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f57b82",
   "metadata": {},
   "source": [
    "## Binary Tree Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_tree.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "struct TreeNode {\n",
    "    int value;\n",
    "    int left;   // Index of left child (-1 if none)\n",
    "    int right;  // Index of right child (-1 if none)\n",
    "};\n",
    "\n",
    "__global__ void processNode(TreeNode* tree, int nodeIdx, int* result, int* resultIdx) {\n",
    "    if (nodeIdx < 0) return;\n",
    "    \n",
    "    TreeNode node = tree[nodeIdx];\n",
    "    \n",
    "    // Process left subtree first (in-order)\n",
    "    if (node.left >= 0) {\n",
    "        processNode<<<1, 1>>>(tree, node.left, result, resultIdx);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "    \n",
    "    // Process current node\n",
    "    int idx = atomicAdd(resultIdx, 1);\n",
    "    result[idx] = node.value;\n",
    "    \n",
    "    // Process right subtree\n",
    "    if (node.right >= 0) {\n",
    "        processNode<<<1, 1>>>(tree, node.right, result, resultIdx);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    //       4\n",
    "    //      / \\\\\n",
    "    //     2   6\n",
    "    //    / \\\\ / \\\\\n",
    "    //   1  3 5  7\n",
    "    \n",
    "    TreeNode h_tree[7] = {\n",
    "        {4, 1, 2},   // 0: root\n",
    "        {2, 3, 4},   // 1: left of root\n",
    "        {6, 5, 6},   // 2: right of root\n",
    "        {1, -1, -1}, // 3: leaf\n",
    "        {3, -1, -1}, // 4: leaf\n",
    "        {5, -1, -1}, // 5: leaf\n",
    "        {7, -1, -1}  // 6: leaf\n",
    "    };\n",
    "    \n",
    "    TreeNode* d_tree;\n",
    "    int *d_result, *d_resultIdx;\n",
    "    int h_result[7];\n",
    "    \n",
    "    cudaMalloc(&d_tree, 7 * sizeof(TreeNode));\n",
    "    cudaMalloc(&d_result, 7 * sizeof(int));\n",
    "    cudaMalloc(&d_resultIdx, sizeof(int));\n",
    "    \n",
    "    cudaMemcpy(d_tree, h_tree, 7 * sizeof(TreeNode), cudaMemcpyHostToDevice);\n",
    "    cudaMemset(d_resultIdx, 0, sizeof(int));\n",
    "    \n",
    "    processNode<<<1, 1>>>(d_tree, 0, d_result, d_resultIdx);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_result, d_result, 7 * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"In-order traversal: \");\n",
    "    for (int i = 0; i < 7; i++) printf(\"%d \", h_result[i]);\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    cudaFree(d_tree);\n",
    "    cudaFree(d_result);\n",
    "    cudaFree(d_resultIdx);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_tree.cu -o cdp_tree && ./cdp_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a72dd4",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Recursive algorithms** map naturally to CDP\n",
    "2. **Use base cases** to limit recursion depth and switch to iterative\n",
    "3. **Streams enable concurrent** left/right processing\n",
    "4. **Monitor limits** with `cudaDeviceGetLimit`\n",
    "5. **Consider hybrid**: CDP for structure, parallel kernels for data\n",
    "\n",
    "## Next: Day 3 - Adaptive Algorithms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
