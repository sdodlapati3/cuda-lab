{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf42d044",
   "metadata": {},
   "source": [
    "## GPU Quicksort with Dynamic Parallelism\n",
    "\n",
    "Quicksort is a classic recursive algorithm that benefits from CDP:\n",
    "1. Partition array around pivot\n",
    "2. Recursively sort left and right subarrays\n",
    "3. Base case: small arrays sorted with simple algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d59633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_quicksort.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <thrust/device_vector.h>\n",
    "#include <thrust/host_vector.h>\n",
    "\n",
    "#define INSERTION_SORT_THRESHOLD 32\n",
    "#define MAX_DEPTH 16\n",
    "\n",
    "// Simple insertion sort for small arrays\n",
    "__device__ void insertionSort(int* arr, int left, int right) {\n",
    "    for (int i = left + 1; i <= right; i++) {\n",
    "        int key = arr[i];\n",
    "        int j = i - 1;\n",
    "        while (j >= left && arr[j] > key) {\n",
    "            arr[j + 1] = arr[j];\n",
    "            j--;\n",
    "        }\n",
    "        arr[j + 1] = key;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Partition using Lomuto scheme\n",
    "__device__ int partition(int* arr, int left, int right) {\n",
    "    int pivot = arr[right];\n",
    "    int i = left - 1;\n",
    "    \n",
    "    for (int j = left; j < right; j++) {\n",
    "        if (arr[j] <= pivot) {\n",
    "            i++;\n",
    "            int temp = arr[i];\n",
    "            arr[i] = arr[j];\n",
    "            arr[j] = temp;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    int temp = arr[i + 1];\n",
    "    arr[i + 1] = arr[right];\n",
    "    arr[right] = temp;\n",
    "    \n",
    "    return i + 1;\n",
    "}\n",
    "\n",
    "// Recursive quicksort kernel\n",
    "__global__ void quicksortKernel(int* arr, int left, int right, int depth) {\n",
    "    // Base case: small array or max depth reached\n",
    "    if (right - left < INSERTION_SORT_THRESHOLD || depth >= MAX_DEPTH) {\n",
    "        if (left < right) {\n",
    "            insertionSort(arr, left, right);\n",
    "        }\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Partition the array\n",
    "    int pivotIdx = partition(arr, left, right);\n",
    "    \n",
    "    // Launch child kernels for subarrays\n",
    "    cudaStream_t leftStream, rightStream;\n",
    "    cudaStreamCreateWithFlags(&leftStream, cudaStreamNonBlocking);\n",
    "    cudaStreamCreateWithFlags(&rightStream, cudaStreamNonBlocking);\n",
    "    \n",
    "    if (pivotIdx - 1 > left) {\n",
    "        quicksortKernel<<<1, 1, 0, leftStream>>>(arr, left, pivotIdx - 1, depth + 1);\n",
    "    }\n",
    "    if (pivotIdx + 1 < right) {\n",
    "        quicksortKernel<<<1, 1, 0, rightStream>>>(arr, pivotIdx + 1, right, depth + 1);\n",
    "    }\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "    cudaStreamDestroy(leftStream);\n",
    "    cudaStreamDestroy(rightStream);\n",
    "}\n",
    "\n",
    "void gpuQuicksort(int* d_arr, int n) {\n",
    "    quicksortKernel<<<1, 1>>>(d_arr, 0, n - 1, 0);\n",
    "    cudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1024;\n",
    "    thrust::host_vector<int> h_arr(N);\n",
    "    \n",
    "    // Initialize with random values\n",
    "    srand(42);\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_arr[i] = rand() % 10000;\n",
    "    }\n",
    "    \n",
    "    printf(\"Before sort: [%d, %d, %d, ... , %d]\\n\",\n",
    "           h_arr[0], h_arr[1], h_arr[2], h_arr[N-1]);\n",
    "    \n",
    "    thrust::device_vector<int> d_arr = h_arr;\n",
    "    gpuQuicksort(thrust::raw_pointer_cast(d_arr.data()), N);\n",
    "    h_arr = d_arr;\n",
    "    \n",
    "    printf(\"After sort:  [%d, %d, %d, ... , %d]\\n\",\n",
    "           h_arr[0], h_arr[1], h_arr[2], h_arr[N-1]);\n",
    "    \n",
    "    // Verify sorted\n",
    "    bool sorted = true;\n",
    "    for (int i = 1; i < N; i++) {\n",
    "        if (h_arr[i] < h_arr[i-1]) sorted = false;\n",
    "    }\n",
    "    printf(\"Array is %s\\n\", sorted ? \"SORTED\" : \"NOT SORTED\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66741ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_quicksort.cu -o cdp_quicksort && ./cdp_quicksort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595623c8",
   "metadata": {},
   "source": [
    "## Recursion Depth Limits\n",
    "\n",
    "CDP has practical limits:\n",
    "- **Default nesting depth**: 24 levels\n",
    "- **Pending kernel limit**: 2048 by default\n",
    "- **Device memory for sync**: ~150KB per level\n",
    "\n",
    "Configure with `cudaDeviceSetLimit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a81d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_limits.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "int main() {\n",
    "    size_t syncDepth, pendingLaunchCount, stackSize;\n",
    "    \n",
    "    cudaDeviceGetLimit(&syncDepth, cudaLimitDevRuntimeSyncDepth);\n",
    "    cudaDeviceGetLimit(&pendingLaunchCount, cudaLimitDevRuntimePendingLaunchCount);\n",
    "    cudaDeviceGetLimit(&stackSize, cudaLimitStackSize);\n",
    "    \n",
    "    printf(\"CDP Limits:\\n\");\n",
    "    printf(\"  Max sync depth: %zu\\n\", syncDepth);\n",
    "    printf(\"  Max pending launches: %zu\\n\", pendingLaunchCount);\n",
    "    printf(\"  Stack size per thread: %zu bytes\\n\", stackSize);\n",
    "    \n",
    "    // Increase limits if needed\n",
    "    cudaDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, 32);\n",
    "    cudaDeviceSetLimit(cudaLimitDevRuntimePendingLaunchCount, 4096);\n",
    "    \n",
    "    cudaDeviceGetLimit(&syncDepth, cudaLimitDevRuntimeSyncDepth);\n",
    "    cudaDeviceGetLimit(&pendingLaunchCount, cudaLimitDevRuntimePendingLaunchCount);\n",
    "    \n",
    "    printf(\"\\nAfter increasing:\\n\");\n",
    "    printf(\"  Max sync depth: %zu\\n\", syncDepth);\n",
    "    printf(\"  Max pending launches: %zu\\n\", pendingLaunchCount);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78774f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cdp_limits.cu -o cdp_limits && ./cdp_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f57b82",
   "metadata": {},
   "source": [
    "## Binary Tree Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cdp_tree.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "struct TreeNode {\n",
    "    int value;\n",
    "    int left;   // Index of left child (-1 if none)\n",
    "    int right;  // Index of right child (-1 if none)\n",
    "};\n",
    "\n",
    "__global__ void processNode(TreeNode* tree, int nodeIdx, int* result, int* resultIdx) {\n",
    "    if (nodeIdx < 0) return;\n",
    "    \n",
    "    TreeNode node = tree[nodeIdx];\n",
    "    \n",
    "    // Process left subtree first (in-order)\n",
    "    if (node.left >= 0) {\n",
    "        processNode<<<1, 1>>>(tree, node.left, result, resultIdx);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "    \n",
    "    // Process current node\n",
    "    int idx = atomicAdd(resultIdx, 1);\n",
    "    result[idx] = node.value;\n",
    "    \n",
    "    // Process right subtree\n",
    "    if (node.right >= 0) {\n",
    "        processNode<<<1, 1>>>(tree, node.right, result, resultIdx);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    //       4\n",
    "    //      / \\\\\n",
    "    //     2   6\n",
    "    //    / \\\\ / \\\\\n",
    "    //   1  3 5  7\n",
    "    \n",
    "    TreeNode h_tree[7] = {\n",
    "        {4, 1, 2},   // 0: root\n",
    "        {2, 3, 4},   // 1: left of root\n",
    "        {6, 5, 6},   // 2: right of root\n",
    "        {1, -1, -1}, // 3: leaf\n",
    "        {3, -1, -1}, // 4: leaf\n",
    "        {5, -1, -1}, // 5: leaf\n",
    "        {7, -1, -1}  // 6: leaf\n",
    "    };\n",
    "    \n",
    "    TreeNode* d_tree;\n",
    "    int *d_result, *d_resultIdx;\n",
    "    int h_result[7];\n",
    "    \n",
    "    cudaMalloc(&d_tree, 7 * sizeof(TreeNode));\n",
    "    cudaMalloc(&d_result, 7 * sizeof(int));\n",
    "    cudaMalloc(&d_resultIdx, sizeof(int));\n",
    "    \n",
    "    cudaMemcpy(d_tree, h_tree, 7 * sizeof(TreeNode), cudaMemcpyHostToDevice);\n",
    "    cudaMemset(d_resultIdx, 0, sizeof(int));\n",
    "    \n",
    "    processNode<<<1, 1>>>(d_tree, 0, d_result, d_resultIdx);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_result, d_result, 7 * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"In-order traversal: \");\n",
    "    for (int i = 0; i < 7; i++) printf(\"%d \", h_result[i]);\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    cudaFree(d_tree);\n",
    "    cudaFree(d_result);\n",
    "    cudaFree(d_resultIdx);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -rdc=true -lcudadevrt cdp_tree.cu -o cdp_tree && ./cdp_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb0eafa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Exercises\n",
    "\n",
    "### ðŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Complete these exercises to reinforce your understanding of recursive algorithms with CDP:\n",
    "\n",
    "**Exercise 1: Binary Search Tree Traversal**\n",
    "Implement an in-order traversal of a binary search tree using CDP. Each node should spawn child kernels to process left and right subtrees.\n",
    "\n",
    "**Exercise 2: Merge Sort with CDP**\n",
    "Implement parallel merge sort using dynamic parallelism. The kernel should recursively divide the array and merge sorted subarrays.\n",
    "\n",
    "**Exercise 3: Recursive Tree Height**\n",
    "Calculate the height of a binary tree using CDP. Each node spawns children to find the max depth of subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile recursive_exercises.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 1: Binary Search Tree In-Order Traversal with CDP\n",
    "// ============================================================\n",
    "\n",
    "struct TreeNode {\n",
    "    int value;\n",
    "    int left;   // Index of left child (-1 if none)\n",
    "    int right;  // Index of right child (-1 if none)\n",
    "};\n",
    "\n",
    "__device__ int traversalIndex = 0;\n",
    "\n",
    "__global__ void inorderTraversal(TreeNode* tree, int nodeIdx, int* result) {\n",
    "    if (nodeIdx == -1) return;\n",
    "    \n",
    "    // Process left subtree\n",
    "    if (tree[nodeIdx].left != -1) {\n",
    "        inorderTraversal<<<1, 1>>>(tree, tree[nodeIdx].left, result);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "    \n",
    "    // Visit current node\n",
    "    int pos = atomicAdd(&traversalIndex, 1);\n",
    "    result[pos] = tree[nodeIdx].value;\n",
    "    \n",
    "    // Process right subtree\n",
    "    if (tree[nodeIdx].right != -1) {\n",
    "        inorderTraversal<<<1, 1>>>(tree, tree[nodeIdx].right, result);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise1_bst_traversal() {\n",
    "    printf(\"=== Exercise 1: BST In-Order Traversal ===\\n\");\n",
    "    \n",
    "    // Build a simple BST:\n",
    "    //        4\n",
    "    //       / \\\n",
    "    //      2   6\n",
    "    //     / \\ / \\\n",
    "    //    1  3 5  7\n",
    "    \n",
    "    TreeNode h_tree[7] = {\n",
    "        {4, 1, 2},   // Node 0: root=4, left->1, right->2\n",
    "        {2, 3, 4},   // Node 1: value=2, left->3, right->4\n",
    "        {6, 5, 6},   // Node 2: value=6, left->5, right->6\n",
    "        {1, -1, -1}, // Node 3: value=1 (leaf)\n",
    "        {3, -1, -1}, // Node 4: value=3 (leaf)\n",
    "        {5, -1, -1}, // Node 5: value=5 (leaf)\n",
    "        {7, -1, -1}  // Node 6: value=7 (leaf)\n",
    "    };\n",
    "    \n",
    "    TreeNode* d_tree;\n",
    "    int* d_result;\n",
    "    int h_result[7];\n",
    "    \n",
    "    cudaMalloc(&d_tree, 7 * sizeof(TreeNode));\n",
    "    cudaMalloc(&d_result, 7 * sizeof(int));\n",
    "    cudaMemcpy(d_tree, h_tree, 7 * sizeof(TreeNode), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Reset traversal index\n",
    "    int zero = 0;\n",
    "    cudaMemcpyToSymbol(traversalIndex, &zero, sizeof(int));\n",
    "    \n",
    "    inorderTraversal<<<1, 1>>>(d_tree, 0, d_result);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_result, d_result, 7 * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"In-order traversal: \");\n",
    "    for (int i = 0; i < 7; i++) printf(\"%d \", h_result[i]);\n",
    "    printf(\"\\nExpected: 1 2 3 4 5 6 7\\n\\n\");\n",
    "    \n",
    "    cudaFree(d_tree);\n",
    "    cudaFree(d_result);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 2: Parallel Merge Sort with CDP\n",
    "// ============================================================\n",
    "\n",
    "__device__ void merge(int* arr, int left, int mid, int right, int* temp) {\n",
    "    int i = left, j = mid + 1, k = left;\n",
    "    \n",
    "    while (i <= mid && j <= right) {\n",
    "        if (arr[i] <= arr[j]) {\n",
    "            temp[k++] = arr[i++];\n",
    "        } else {\n",
    "            temp[k++] = arr[j++];\n",
    "        }\n",
    "    }\n",
    "    while (i <= mid) temp[k++] = arr[i++];\n",
    "    while (j <= right) temp[k++] = arr[j++];\n",
    "    \n",
    "    for (int i = left; i <= right; i++) {\n",
    "        arr[i] = temp[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void mergeSort(int* arr, int left, int right, int* temp, int depth) {\n",
    "    if (left >= right) return;\n",
    "    \n",
    "    int mid = left + (right - left) / 2;\n",
    "    \n",
    "    if (depth < 4) {  // Limit recursion depth\n",
    "        cudaStream_t s1, s2;\n",
    "        cudaStreamCreateWithFlags(&s1, cudaStreamNonBlocking);\n",
    "        cudaStreamCreateWithFlags(&s2, cudaStreamNonBlocking);\n",
    "        \n",
    "        mergeSort<<<1, 1, 0, s1>>>(arr, left, mid, temp, depth + 1);\n",
    "        mergeSort<<<1, 1, 0, s2>>>(arr, mid + 1, right, temp, depth + 1);\n",
    "        \n",
    "        cudaDeviceSynchronize();\n",
    "        cudaStreamDestroy(s1);\n",
    "        cudaStreamDestroy(s2);\n",
    "    } else {\n",
    "        // Base case: sequential sort for small subarrays\n",
    "        for (int i = left + 1; i <= right; i++) {\n",
    "            int key = arr[i];\n",
    "            int j = i - 1;\n",
    "            while (j >= left && arr[j] > key) {\n",
    "                arr[j + 1] = arr[j];\n",
    "                j--;\n",
    "            }\n",
    "            arr[j + 1] = key;\n",
    "        }\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    merge(arr, left, mid, right, temp);\n",
    "}\n",
    "\n",
    "void exercise2_merge_sort() {\n",
    "    printf(\"=== Exercise 2: Parallel Merge Sort ===\\n\");\n",
    "    \n",
    "    const int N = 16;\n",
    "    int h_arr[] = {64, 34, 25, 12, 22, 11, 90, 45, 33, 21, 88, 15, 44, 72, 19, 56};\n",
    "    int* d_arr;\n",
    "    int* d_temp;\n",
    "    \n",
    "    cudaMalloc(&d_arr, N * sizeof(int));\n",
    "    cudaMalloc(&d_temp, N * sizeof(int));\n",
    "    cudaMemcpy(d_arr, h_arr, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    printf(\"Before: \");\n",
    "    for (int i = 0; i < N; i++) printf(\"%d \", h_arr[i]);\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    mergeSort<<<1, 1>>>(d_arr, 0, N - 1, d_temp, 0);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_arr, d_arr, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"After:  \");\n",
    "    for (int i = 0; i < N; i++) printf(\"%d \", h_arr[i]);\n",
    "    printf(\"\\n\\n\");\n",
    "    \n",
    "    cudaFree(d_arr);\n",
    "    cudaFree(d_temp);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 3: Recursive Tree Height with CDP\n",
    "// ============================================================\n",
    "\n",
    "__global__ void treeHeight(TreeNode* tree, int nodeIdx, int* heights) {\n",
    "    if (nodeIdx == -1) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    int leftHeight = 0, rightHeight = 0;\n",
    "    \n",
    "    // Get heights from children using CDP\n",
    "    if (tree[nodeIdx].left != -1 || tree[nodeIdx].right != -1) {\n",
    "        int* d_leftH;\n",
    "        int* d_rightH;\n",
    "        cudaMalloc(&d_leftH, sizeof(int));\n",
    "        cudaMalloc(&d_rightH, sizeof(int));\n",
    "        cudaMemset(d_leftH, 0, sizeof(int));\n",
    "        cudaMemset(d_rightH, 0, sizeof(int));\n",
    "        \n",
    "        cudaStream_t s1, s2;\n",
    "        cudaStreamCreateWithFlags(&s1, cudaStreamNonBlocking);\n",
    "        cudaStreamCreateWithFlags(&s2, cudaStreamNonBlocking);\n",
    "        \n",
    "        if (tree[nodeIdx].left != -1) {\n",
    "            treeHeight<<<1, 1, 0, s1>>>(tree, tree[nodeIdx].left, d_leftH);\n",
    "        }\n",
    "        if (tree[nodeIdx].right != -1) {\n",
    "            treeHeight<<<1, 1, 0, s2>>>(tree, tree[nodeIdx].right, d_rightH);\n",
    "        }\n",
    "        \n",
    "        cudaDeviceSynchronize();\n",
    "        \n",
    "        cudaMemcpy(&leftHeight, d_leftH, sizeof(int), cudaMemcpyDeviceToDevice);\n",
    "        cudaMemcpy(&rightHeight, d_rightH, sizeof(int), cudaMemcpyDeviceToDevice);\n",
    "        \n",
    "        // Read values directly\n",
    "        int* h_left = (int*)malloc(sizeof(int));\n",
    "        int* h_right = (int*)malloc(sizeof(int));\n",
    "        cudaMemcpy(h_left, d_leftH, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "        cudaMemcpy(h_right, d_rightH, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "        leftHeight = *h_left;\n",
    "        rightHeight = *h_right;\n",
    "        free(h_left);\n",
    "        free(h_right);\n",
    "        \n",
    "        cudaFree(d_leftH);\n",
    "        cudaFree(d_rightH);\n",
    "        cudaStreamDestroy(s1);\n",
    "        cudaStreamDestroy(s2);\n",
    "    }\n",
    "    \n",
    "    heights[0] = 1 + max(leftHeight, rightHeight);\n",
    "}\n",
    "\n",
    "void exercise3_tree_height() {\n",
    "    printf(\"=== Exercise 3: Recursive Tree Height ===\\n\");\n",
    "    \n",
    "    // Same BST as Exercise 1 (height = 3)\n",
    "    TreeNode h_tree[7] = {\n",
    "        {4, 1, 2},\n",
    "        {2, 3, 4},\n",
    "        {6, 5, 6},\n",
    "        {1, -1, -1},\n",
    "        {3, -1, -1},\n",
    "        {5, -1, -1},\n",
    "        {7, -1, -1}\n",
    "    };\n",
    "    \n",
    "    TreeNode* d_tree;\n",
    "    int* d_height;\n",
    "    int h_height;\n",
    "    \n",
    "    cudaMalloc(&d_tree, 7 * sizeof(TreeNode));\n",
    "    cudaMalloc(&d_height, sizeof(int));\n",
    "    cudaMemcpy(d_tree, h_tree, 7 * sizeof(TreeNode), cudaMemcpyHostToDevice);\n",
    "    cudaMemset(d_height, 0, sizeof(int));\n",
    "    \n",
    "    treeHeight<<<1, 1>>>(d_tree, 0, d_height);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(&h_height, d_height, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"Tree height: %d\\n\", h_height);\n",
    "    printf(\"Expected: 3\\n\\n\");\n",
    "    \n",
    "    cudaFree(d_tree);\n",
    "    cudaFree(d_height);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"CDP Recursive Algorithms Exercises\\n\");\n",
    "    printf(\"===================================\\n\\n\");\n",
    "    \n",
    "    exercise1_bst_traversal();\n",
    "    exercise2_merge_sort();\n",
    "    exercise3_tree_height();\n",
    "    \n",
    "    printf(\"All exercises completed!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd122696",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -rdc=true -lcudadevrt -o recursive_exercises recursive_exercises.cu && ./recursive_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10db2f1",
   "metadata": {},
   "source": [
    "### ðŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "The following exercises explore similar recursive concepts using Python. Note that Numba CUDA does not support dynamic parallelism directly, so these focus on alternative approaches.\n",
    "\n",
    "**Exercise A:** Implement an iterative quicksort using a stack-based approach with Numba CUDA kernels.\n",
    "\n",
    "**Exercise B:** Compare the performance of CPU recursive merge sort vs. GPU parallel reduction-based sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a72dd4",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Recursive algorithms** map naturally to CDP\n",
    "2. **Use base cases** to limit recursion depth and switch to iterative\n",
    "3. **Streams enable concurrent** left/right processing\n",
    "4. **Monitor limits** with `cudaDeviceGetLimit`\n",
    "5. **Consider hybrid**: CDP for structure, parallel kernels for data\n",
    "\n",
    "## Next: Day 3 - Adaptive Algorithms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
