{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc608c4",
   "metadata": {},
   "source": [
    "## What is MIG?\n",
    "\n",
    "Multi-Instance GPU (MIG) partitions a single GPU into multiple isolated instances:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────┐\n",
    "│                 Full H100 GPU                   │\n",
    "│  80GB HBM3  |  132 SMs  |  Full Memory BW       │\n",
    "└─────────────────────────────────────────────────┘\n",
    "                      │\n",
    "            MIG Partitioning\n",
    "                      │\n",
    "          ┌───────────┴───────────┐\n",
    "          ▼                       ▼\n",
    "┌─────────────────┐     ┌─────────────────┐\n",
    "│   MIG 3g.40gb   │     │   MIG 3g.40gb   │\n",
    "│   40GB | 66 SMs │     │   40GB | 66 SMs │\n",
    "└─────────────────┘     └─────────────────┘\n",
    "     Instance 0              Instance 1\n",
    "```\n",
    "\n",
    "**Key benefits:**\n",
    "- Hardware-level isolation (memory, SMs, cache)\n",
    "- Quality of Service (QoS) guarantees\n",
    "- Multi-tenant GPU sharing\n",
    "- Right-sizing GPU for workloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecdeb31",
   "metadata": {},
   "source": [
    "## Querying MIG Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722729cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mig_query.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <nvml.h>\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA error: %s\\n\", cudaGetErrorString(err)); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "#define CHECK_NVML(call) \\\n",
    "    do { \\\n",
    "        nvmlReturn_t result = call; \\\n",
    "        if (result != NVML_SUCCESS) { \\\n",
    "            printf(\"NVML error: %s\\n\", nvmlErrorString(result)); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "void printMIGCapabilities(int device) {\n",
    "    cudaDeviceProp prop;\n",
    "    CHECK_CUDA(cudaGetDeviceProperties(&prop, device));\n",
    "    \n",
    "    printf(\"\\n=== MIG Capabilities for %s ===\\n\", prop.name);\n",
    "    \n",
    "    // Check architecture\n",
    "    int major = prop.major, minor = prop.minor;\n",
    "    printf(\"Compute Capability: %d.%d\\n\", major, minor);\n",
    "    \n",
    "    // MIG requires Ampere (8.0) or newer\n",
    "    if (major < 8) {\n",
    "        printf(\"MIG NOT SUPPORTED - Requires Ampere (8.0) or newer\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Check specific GPU models\n",
    "    const char* name = prop.name;\n",
    "    bool isMIGCapable = false;\n",
    "    \n",
    "    // Known MIG-capable GPUs\n",
    "    if (strstr(name, \"A100\") || strstr(name, \"H100\") || \n",
    "        strstr(name, \"H200\") || strstr(name, \"B100\") ||\n",
    "        strstr(name, \"B200\") || strstr(name, \"A30\")) {\n",
    "        isMIGCapable = true;\n",
    "    }\n",
    "    \n",
    "    printf(\"GPU: %s\\n\", name);\n",
    "    printf(\"MIG Capable: %s\\n\", isMIGCapable ? \"YES\" : \"NO (consumer GPU)\");\n",
    "    \n",
    "    if (!isMIGCapable) {\n",
    "        printf(\"  Note: Only datacenter GPUs (A100, H100, etc.) support MIG\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Query MIG mode via NVML\n",
    "    nvmlInit();\n",
    "    nvmlDevice_t nvmlDevice;\n",
    "    CHECK_NVML(nvmlDeviceGetHandleByIndex(device, &nvmlDevice));\n",
    "    \n",
    "    unsigned int currentMode, pendingMode;\n",
    "    nvmlReturn_t migResult = nvmlDeviceGetMigMode(nvmlDevice, &currentMode, &pendingMode);\n",
    "    \n",
    "    if (migResult == NVML_SUCCESS) {\n",
    "        printf(\"\\nMIG Mode:\\n\");\n",
    "        printf(\"  Current: %s\\n\", currentMode ? \"ENABLED\" : \"DISABLED\");\n",
    "        printf(\"  Pending: %s\\n\", pendingMode ? \"ENABLED\" : \"DISABLED\");\n",
    "        \n",
    "        if (currentMode) {\n",
    "            // List GPU instances\n",
    "            unsigned int count;\n",
    "            nvmlGpuInstance_t gpuInstances[8];\n",
    "            nvmlReturn_t giResult = nvmlDeviceGetGpuInstances(nvmlDevice, \n",
    "                                                               NVML_GPU_INSTANCE_PROFILE_1_SLICE,\n",
    "                                                               gpuInstances, &count);\n",
    "            printf(\"  GPU Instances found: %u\\n\", count);\n",
    "        }\n",
    "    } else if (migResult == NVML_ERROR_NOT_SUPPORTED) {\n",
    "        printf(\"\\nMIG query not supported on this configuration\\n\");\n",
    "    }\n",
    "    \n",
    "    // Memory info\n",
    "    printf(\"\\nGPU Resources:\\n\");\n",
    "    printf(\"  Total Memory: %.2f GB\\n\", prop.totalGlobalMem / (1024.0 * 1024.0 * 1024.0));\n",
    "    printf(\"  SMs: %d\\n\", prop.multiProcessorCount);\n",
    "    printf(\"  Memory Bus Width: %d bits\\n\", prop.memoryBusWidth);\n",
    "    \n",
    "    nvmlShutdown();\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== MIG Query Tool ===\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));\n",
    "    printf(\"Found %d CUDA device(s)\\n\", deviceCount);\n",
    "    \n",
    "    for (int i = 0; i < deviceCount; i++) {\n",
    "        printMIGCapabilities(i);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ba708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with NVML library\n",
    "!nvcc -O3 -arch=sm_80 mig_query.cu -o mig_query -lnvidia-ml && ./mig_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7452cb",
   "metadata": {},
   "source": [
    "## nvidia-smi MIG Commands\n",
    "\n",
    "Check MIG status using command line (typically requires admin access to modify):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adea654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query GPU info including MIG mode\n",
    "!nvidia-smi --query-gpu=name,mig.mode.current,mig.mode.pending --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99845051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available MIG profiles (if on MIG-capable GPU)\n",
    "!nvidia-smi mig -lgip 2>/dev/null || echo \"MIG not available or not enabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List existing GPU instances\n",
    "!nvidia-smi mig -lgi 2>/dev/null || echo \"No GPU instances or MIG not enabled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6b822",
   "metadata": {},
   "source": [
    "## MIG Instance Profiles\n",
    "\n",
    "H100 SXM (80GB) supports these profiles:\n",
    "\n",
    "| Profile | GPCs | Memory | Use Case |\n",
    "|---------|------|--------|----------|\n",
    "| 1g.10gb | 1/7 | 10GB | Small inference |\n",
    "| 2g.20gb | 2/7 | 20GB | Medium workloads |\n",
    "| 3g.40gb | 3/7 | 40GB | Training |\n",
    "| 4g.40gb | 4/7 | 40GB | Large training |\n",
    "| 7g.80gb | 7/7 | 80GB | Full GPU (no isolation) |\n",
    "\n",
    "A100 (80GB) profiles:\n",
    "\n",
    "| Profile | GPCs | Memory |\n",
    "|---------|------|--------|\n",
    "| 1g.10gb | 1/7 | 10GB |\n",
    "| 2g.20gb | 2/7 | 20GB |\n",
    "| 3g.40gb | 3/7 | 40GB |\n",
    "| 7g.80gb | 7/7 | 80GB |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6841068",
   "metadata": {},
   "source": [
    "## Detecting MIG Instance in Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a92220",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile detect_mig_instance.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA error: %s\\n\", cudaGetErrorString(err)); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== MIG Instance Detection ===\\n\\n\");\n",
    "    \n",
    "    // Check CUDA_VISIBLE_DEVICES\n",
    "    const char* visibleDevices = getenv(\"CUDA_VISIBLE_DEVICES\");\n",
    "    printf(\"CUDA_VISIBLE_DEVICES: %s\\n\", visibleDevices ? visibleDevices : \"(not set)\");\n",
    "    \n",
    "    // Check for MIG UUID format\n",
    "    if (visibleDevices && strstr(visibleDevices, \"MIG-\")) {\n",
    "        printf(\"Running on MIG instance!\\n\");\n",
    "        printf(\"MIG UUID: %s\\n\", visibleDevices);\n",
    "    }\n",
    "    \n",
    "    int deviceCount;\n",
    "    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));\n",
    "    printf(\"\\nVisible devices: %d\\n\", deviceCount);\n",
    "    \n",
    "    for (int i = 0; i < deviceCount; i++) {\n",
    "        cudaDeviceProp prop;\n",
    "        CHECK_CUDA(cudaGetDeviceProperties(&prop, i));\n",
    "        \n",
    "        printf(\"\\nDevice %d: %s\\n\", i, prop.name);\n",
    "        printf(\"  UUID: \");\n",
    "        for (int j = 0; j < 16; j++) {\n",
    "            printf(\"%02x\", (unsigned char)prop.uuid.bytes[j]);\n",
    "            if (j == 3 || j == 5 || j == 7 || j == 9) printf(\"-\");\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "        \n",
    "        printf(\"  Total Memory: %.2f GB\\n\", \n",
    "               prop.totalGlobalMem / (1024.0 * 1024.0 * 1024.0));\n",
    "        printf(\"  SMs: %d\\n\", prop.multiProcessorCount);\n",
    "        printf(\"  Compute: %d.%d\\n\", prop.major, prop.minor);\n",
    "        \n",
    "        // Detect if this looks like a MIG partition\n",
    "        // MIG instances have fewer SMs than the full GPU\n",
    "        // H100: 132 SMs full, A100: 108 SMs full\n",
    "        bool likelyMIG = false;\n",
    "        if (strstr(prop.name, \"H100\") && prop.multiProcessorCount < 100) {\n",
    "            likelyMIG = true;\n",
    "        } else if (strstr(prop.name, \"A100\") && prop.multiProcessorCount < 100) {\n",
    "            likelyMIG = true;\n",
    "        }\n",
    "        \n",
    "        if (likelyMIG) {\n",
    "            printf(\"  >>> Appears to be a MIG partition (reduced SM count)\\n\");\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Run a simple kernel to verify\n",
    "    printf(\"\\nRunning verification kernel...\\n\");\n",
    "    int* d_data;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, sizeof(int)));\n",
    "    CHECK_CUDA(cudaMemset(d_data, 0, sizeof(int)));\n",
    "    CHECK_CUDA(cudaFree(d_data));\n",
    "    printf(\"Kernel execution successful!\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 detect_mig_instance.cu -o detect_mig_instance && ./detect_mig_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480f20e",
   "metadata": {},
   "source": [
    "## MIG Architecture Deep Dive\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│                          H100 Full GPU                           │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│  GPC 0  │  GPC 1  │  GPC 2  │  GPC 3  │  GPC 4  │  GPC 5  │ GPC 6│\n",
    "│ (16 SM) │ (16 SM) │ (16 SM) │ (16 SM) │ (16 SM) │ (16 SM) │(20SM)│\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│                    L2 Cache (50 MB)                              │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│  HBM3 Stack 0  │  Stack 1  │  Stack 2  │  Stack 3  │  Stack 4   │\n",
    "│    (16 GB)     │  (16 GB)  │  (16 GB)  │  (16 GB)  │  (16 GB)   │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "MIG creates isolated \"slices\" with:\n",
    "- Dedicated GPCs (Graphics Processing Clusters)\n",
    "- Dedicated memory bandwidth\n",
    "- Isolated L2 cache partition\n",
    "- Separate error isolation domain\n",
    "```\n",
    "\n",
    "**Key isolation properties:**\n",
    "1. **Memory isolation** - Each instance has private memory\n",
    "2. **SM isolation** - Dedicated compute resources\n",
    "3. **Bandwidth isolation** - QoS guaranteed memory BW\n",
    "4. **Error isolation** - Faults don't affect other instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec489e52",
   "metadata": {},
   "source": [
    "## Benchmark on MIG Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mig_benchmark.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA error: %s\\n\", cudaGetErrorString(err)); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void computeKernel(float* data, int n, int iterations) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        float val = data[idx];\n",
    "        for (int i = 0; i < iterations; i++) {\n",
    "            val = sinf(val) * cosf(val) + 0.1f;\n",
    "        }\n",
    "        data[idx] = val;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== MIG Instance Benchmark ===\\n\\n\");\n",
    "    \n",
    "    cudaDeviceProp prop;\n",
    "    CHECK_CUDA(cudaGetDeviceProperties(&prop, 0));\n",
    "    \n",
    "    printf(\"GPU: %s\\n\", prop.name);\n",
    "    printf(\"SMs: %d\\n\", prop.multiProcessorCount);\n",
    "    printf(\"Memory: %.2f GB\\n\\n\", prop.totalGlobalMem / (1024.0*1024.0*1024.0));\n",
    "    \n",
    "    // Use available memory (scale to instance size)\n",
    "    size_t freeMemory, totalMemory;\n",
    "    CHECK_CUDA(cudaMemGetInfo(&freeMemory, &totalMemory));\n",
    "    \n",
    "    // Use 50% of available memory\n",
    "    size_t dataSize = freeMemory / 2;\n",
    "    int n = dataSize / sizeof(float);\n",
    "    \n",
    "    printf(\"Allocating %.2f GB (%.2f GB available)\\n\", \n",
    "           dataSize / (1024.0*1024.0*1024.0),\n",
    "           freeMemory / (1024.0*1024.0*1024.0));\n",
    "    \n",
    "    float* d_data;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, dataSize));\n",
    "    CHECK_CUDA(cudaMemset(d_data, 0, dataSize));\n",
    "    \n",
    "    // Benchmark compute throughput\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (n + blockSize - 1) / blockSize;\n",
    "    int iterations = 100;\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CHECK_CUDA(cudaEventCreate(&start));\n",
    "    CHECK_CUDA(cudaEventCreate(&stop));\n",
    "    \n",
    "    // Warmup\n",
    "    computeKernel<<<numBlocks, blockSize>>>(d_data, n, iterations);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    \n",
    "    // Benchmark\n",
    "    CHECK_CUDA(cudaEventRecord(start));\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        computeKernel<<<numBlocks, blockSize>>>(d_data, n, iterations);\n",
    "    }\n",
    "    CHECK_CUDA(cudaEventRecord(stop));\n",
    "    CHECK_CUDA(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float ms;\n",
    "    CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));\n",
    "    \n",
    "    double throughput = (double)n * 10 * iterations / (ms / 1000.0) / 1e9;\n",
    "    printf(\"\\nCompute: %.2f ms for 10 iterations\\n\", ms);\n",
    "    printf(\"Throughput: %.2f billion ops/sec\\n\", throughput);\n",
    "    printf(\"Per-SM throughput: %.2f billion ops/sec/SM\\n\", \n",
    "           throughput / prop.multiProcessorCount);\n",
    "    \n",
    "    // Memory bandwidth test\n",
    "    CHECK_CUDA(cudaEventRecord(start));\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        CHECK_CUDA(cudaMemset(d_data, i, dataSize));\n",
    "    }\n",
    "    CHECK_CUDA(cudaEventRecord(stop));\n",
    "    CHECK_CUDA(cudaEventSynchronize(stop));\n",
    "    \n",
    "    CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));\n",
    "    double bw = (double)dataSize * 10 / (ms / 1000.0) / 1e9;\n",
    "    printf(\"\\nMemory Bandwidth: %.2f GB/s\\n\", bw);\n",
    "    \n",
    "    CHECK_CUDA(cudaFree(d_data));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 mig_benchmark.cu -o mig_benchmark && ./mig_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0291a82",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **MIG provides hardware isolation** - Not just time-slicing\n",
    "2. **Available on datacenter GPUs** - A100, H100, B100, B200\n",
    "3. **Check CUDA_VISIBLE_DEVICES** - MIG instances have MIG-UUID format\n",
    "4. **SM count indicates partition size** - Fewer SMs = smaller MIG instance\n",
    "5. **Memory is proportionally allocated** - 1g.10gb gets ~10GB"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
