{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18cec834",
   "metadata": {},
   "source": [
    "# Day 4: Production Patterns - Managing Hotel Reservations at Scale\n",
    "\n",
    "**Week 18 - Enterprise GPU Management**\n",
    "\n",
    "> *\"A 5-star hotel doesn't just have roomsâ€”it has health monitoring, failover procedures, resource management, and a staff trained for any situation.\"*\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "1. **Implement** GPU health monitoring systems\n",
    "2. **Design** failover mechanisms for GPU failures\n",
    "3. **Apply** RAII patterns for automatic resource cleanup\n",
    "4. **Build** production-ready GPU management frameworks\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¨ Concept Card: Managing Hotel Reservations\n",
    "\n",
    "**Production MIG is like running a professional hotel chain:**\n",
    "\n",
    "```\n",
    "Hotel Management Dashboard:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           ğŸ¨ GPU Hotel Chain Management System              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  ğŸ“Š Health Monitor (NVML)          ğŸ”„ Failover System       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚ GPU 0: ğŸŸ¢ 45Â°C 4.2GB/40  â”‚       â”‚ Primary: GPU 0       â”‚ â”‚\n",
    "â”‚  â”‚ GPU 1: ğŸŸ¢ 48Â°C 8.1GB/40  â”‚       â”‚ Backup:  GPU 1       â”‚ â”‚\n",
    "â”‚  â”‚ GPU 2: ğŸŸ¡ 72Â°C 38GB/40   â”‚       â”‚ Status: Ready        â”‚ â”‚\n",
    "â”‚  â”‚ GPU 3: ğŸ”´ OFFLINE        â”‚       â”‚ Last switch: Never   â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  ğŸ“‹ Resource Manager                ğŸ« Reservation System   â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚ Contexts: 12 active     â”‚       â”‚ Queue: 5 pending     â”‚ â”‚\n",
    "â”‚  â”‚ Streams: 48 created     â”‚       â”‚ Active: 12 workloads â”‚ â”‚\n",
    "â”‚  â”‚ Memory: 156GB allocated â”‚       â”‚ SLA: 99.9% uptime    â”‚ â”‚\n",
    "â”‚  â”‚ Auto-cleanup: ENABLED   â”‚       â”‚ Priority: ML > Viz   â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**The Hotel Management Mapping:**\n",
    "| Hotel Concept | Production GPU | Implementation |\n",
    "|---------------|----------------|----------------|\n",
    "| ğŸŒ¡ï¸ Room sensors | Health monitoring | NVML temperature/power/ECC |\n",
    "| ğŸ”„ Backup generator | GPU failover | Multi-GPU redundancy |\n",
    "| ğŸ§¹ Housekeeping | RAII cleanup | Automatic resource release |\n",
    "| ğŸ“ Guest registry | Logging system | Timestamps, metrics, errors |\n",
    "| ğŸƒ Fire drills | Error path testing | Verify recovery works |\n",
    "| ğŸ“Š Occupancy tracking | Resource monitoring | Memory/SM utilization |\n",
    "\n",
    "---\n",
    "\n",
    "## Pattern 1: GPU Health Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fab485",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gpu_health_check.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <nvml.h>\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA error: %s\\n\", cudaGetErrorString(err)); \\\n",
    "            return false; \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "struct GPUHealth {\n",
    "    int deviceId;\n",
    "    bool cudaAccessible;\n",
    "    bool memoryOk;\n",
    "    bool computeOk;\n",
    "    bool temperatureOk;\n",
    "    bool eccOk;\n",
    "    \n",
    "    // Metrics\n",
    "    size_t freeMemory;\n",
    "    size_t totalMemory;\n",
    "    unsigned int temperature;\n",
    "    unsigned int powerUsage;\n",
    "    unsigned int gpuUtilization;\n",
    "};\n",
    "\n",
    "__global__ void healthCheckKernel(int* result) {\n",
    "    // Simple compute test\n",
    "    int val = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    val = val * 2 + 1;\n",
    "    if (threadIdx.x == 0) {\n",
    "        *result = val;\n",
    "    }\n",
    "}\n",
    "\n",
    "bool checkGPUHealth(int deviceId, GPUHealth& health) {\n",
    "    health.deviceId = deviceId;\n",
    "    health.cudaAccessible = false;\n",
    "    health.memoryOk = false;\n",
    "    health.computeOk = false;\n",
    "    health.temperatureOk = false;\n",
    "    health.eccOk = true;  // Assume OK unless detected otherwise\n",
    "    \n",
    "    // Test CUDA accessibility\n",
    "    CHECK_CUDA(cudaSetDevice(deviceId));\n",
    "    health.cudaAccessible = true;\n",
    "    \n",
    "    // Memory check\n",
    "    CHECK_CUDA(cudaMemGetInfo(&health.freeMemory, &health.totalMemory));\n",
    "    health.memoryOk = (health.freeMemory > 0.1 * health.totalMemory);  // >10% free\n",
    "    \n",
    "    // Compute check\n",
    "    int* d_result;\n",
    "    int h_result = -1;\n",
    "    CHECK_CUDA(cudaMalloc(&d_result, sizeof(int)));\n",
    "    \n",
    "    healthCheckKernel<<<1, 32>>>(d_result);\n",
    "    CHECK_CUDA(cudaDeviceSynchronize());\n",
    "    CHECK_CUDA(cudaMemcpy(&h_result, d_result, sizeof(int), cudaMemcpyDeviceToHost));\n",
    "    CHECK_CUDA(cudaFree(d_result));\n",
    "    \n",
    "    health.computeOk = (h_result == 1);  // Expected: 0 * 2 + 1 = 1\n",
    "    \n",
    "    // NVML checks\n",
    "    nvmlDevice_t nvmlDevice;\n",
    "    if (nvmlDeviceGetHandleByIndex(deviceId, &nvmlDevice) == NVML_SUCCESS) {\n",
    "        // Temperature\n",
    "        if (nvmlDeviceGetTemperature(nvmlDevice, NVML_TEMPERATURE_GPU, \n",
    "                                      &health.temperature) == NVML_SUCCESS) {\n",
    "            health.temperatureOk = (health.temperature < 85);  // <85Â°C\n",
    "        }\n",
    "        \n",
    "        // Power\n",
    "        nvmlDeviceGetPowerUsage(nvmlDevice, &health.powerUsage);\n",
    "        health.powerUsage /= 1000;  // Convert to watts\n",
    "        \n",
    "        // Utilization\n",
    "        nvmlUtilization_t util;\n",
    "        if (nvmlDeviceGetUtilizationRates(nvmlDevice, &util) == NVML_SUCCESS) {\n",
    "            health.gpuUtilization = util.gpu;\n",
    "        }\n",
    "        \n",
    "        // ECC errors\n",
    "        unsigned long long eccErrors;\n",
    "        if (nvmlDeviceGetTotalEccErrors(nvmlDevice, NVML_MEMORY_ERROR_TYPE_UNCORRECTED,\n",
    "                                         NVML_VOLATILE_ECC, &eccErrors) == NVML_SUCCESS) {\n",
    "            health.eccOk = (eccErrors == 0);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return health.cudaAccessible && health.memoryOk && \n",
    "           health.computeOk && health.temperatureOk && health.eccOk;\n",
    "}\n",
    "\n",
    "void printHealth(const GPUHealth& h) {\n",
    "    printf(\"GPU %d Health:\\n\", h.deviceId);\n",
    "    printf(\"  CUDA Accessible: %s\\n\", h.cudaAccessible ? \"OK\" : \"FAIL\");\n",
    "    printf(\"  Memory: %s (%.1f/%.1f GB free)\\n\", \n",
    "           h.memoryOk ? \"OK\" : \"LOW\",\n",
    "           h.freeMemory / (1024.0*1024.0*1024.0),\n",
    "           h.totalMemory / (1024.0*1024.0*1024.0));\n",
    "    printf(\"  Compute: %s\\n\", h.computeOk ? \"OK\" : \"FAIL\");\n",
    "    printf(\"  Temperature: %s (%uÂ°C)\\n\", \n",
    "           h.temperatureOk ? \"OK\" : \"HIGH\", h.temperature);\n",
    "    printf(\"  ECC: %s\\n\", h.eccOk ? \"OK\" : \"ERRORS DETECTED\");\n",
    "    printf(\"  Power: %u W, Utilization: %u%%\\n\", \n",
    "           h.powerUsage, h.gpuUtilization);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== GPU Health Check ===\\n\\n\");\n",
    "    \n",
    "    nvmlInit();\n",
    "    \n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    \n",
    "    int healthyGPUs = 0;\n",
    "    for (int i = 0; i < deviceCount; i++) {\n",
    "        GPUHealth health;\n",
    "        bool isHealthy = checkGPUHealth(i, health);\n",
    "        \n",
    "        printHealth(health);\n",
    "        printf(\"  Overall: %s\\n\\n\", isHealthy ? \"HEALTHY\" : \"UNHEALTHY\");\n",
    "        \n",
    "        if (isHealthy) healthyGPUs++;\n",
    "    }\n",
    "    \n",
    "    printf(\"=== Summary: %d/%d GPUs healthy ===\\n\", healthyGPUs, deviceCount);\n",
    "    \n",
    "    nvmlShutdown();\n",
    "    return (healthyGPUs == deviceCount) ? 0 : 1;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 gpu_health_check.cu -o gpu_health_check -lnvidia-ml && ./gpu_health_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9bb91",
   "metadata": {},
   "source": [
    "## Pattern 2: Graceful GPU Failover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35379441",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gpu_failover.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <vector>\n",
    "\n",
    "class GPUManager {\n",
    "public:\n",
    "    struct GPUInfo {\n",
    "        int id;\n",
    "        bool available;\n",
    "        size_t memory;\n",
    "        int smCount;\n",
    "    };\n",
    "    \n",
    "private:\n",
    "    std::vector<GPUInfo> gpus_;\n",
    "    int currentDevice_ = -1;\n",
    "    \n",
    "public:\n",
    "    bool initialize() {\n",
    "        int count;\n",
    "        if (cudaGetDeviceCount(&count) != cudaSuccess) return false;\n",
    "        \n",
    "        for (int i = 0; i < count; i++) {\n",
    "            GPUInfo info;\n",
    "            info.id = i;\n",
    "            info.available = true;\n",
    "            \n",
    "            cudaDeviceProp prop;\n",
    "            if (cudaGetDeviceProperties(&prop, i) == cudaSuccess) {\n",
    "                info.memory = prop.totalGlobalMem;\n",
    "                info.smCount = prop.multiProcessorCount;\n",
    "            }\n",
    "            \n",
    "            gpus_.push_back(info);\n",
    "        }\n",
    "        \n",
    "        return !gpus_.empty();\n",
    "    }\n",
    "    \n",
    "    int selectBestGPU() {\n",
    "        int best = -1;\n",
    "        size_t bestMemory = 0;\n",
    "        \n",
    "        for (auto& gpu : gpus_) {\n",
    "            if (!gpu.available) continue;\n",
    "            \n",
    "            // Check actual free memory\n",
    "            cudaSetDevice(gpu.id);\n",
    "            size_t free, total;\n",
    "            if (cudaMemGetInfo(&free, &total) == cudaSuccess) {\n",
    "                if (free > bestMemory) {\n",
    "                    bestMemory = free;\n",
    "                    best = gpu.id;\n",
    "                }\n",
    "            } else {\n",
    "                gpu.available = false;  // Mark as unavailable\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return best;\n",
    "    }\n",
    "    \n",
    "    bool setDevice(int deviceId) {\n",
    "        if (cudaSetDevice(deviceId) != cudaSuccess) {\n",
    "            markUnavailable(deviceId);\n",
    "            return false;\n",
    "        }\n",
    "        currentDevice_ = deviceId;\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    void markUnavailable(int deviceId) {\n",
    "        for (auto& gpu : gpus_) {\n",
    "            if (gpu.id == deviceId) {\n",
    "                gpu.available = false;\n",
    "                printf(\"[FAILOVER] GPU %d marked unavailable\\n\", deviceId);\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    int failover() {\n",
    "        printf(\"[FAILOVER] Attempting failover from GPU %d\\n\", currentDevice_);\n",
    "        \n",
    "        // Mark current as unavailable\n",
    "        if (currentDevice_ >= 0) {\n",
    "            markUnavailable(currentDevice_);\n",
    "        }\n",
    "        \n",
    "        // Reset device to clear any errors\n",
    "        cudaDeviceReset();\n",
    "        \n",
    "        // Find next best GPU\n",
    "        int next = selectBestGPU();\n",
    "        if (next >= 0) {\n",
    "            if (setDevice(next)) {\n",
    "                printf(\"[FAILOVER] Switched to GPU %d\\n\", next);\n",
    "                return next;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        printf(\"[FAILOVER] No available GPUs!\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "    \n",
    "    void printStatus() {\n",
    "        printf(\"\\n=== GPU Status ===\\n\");\n",
    "        for (const auto& gpu : gpus_) {\n",
    "            printf(\"GPU %d: %s (%.1f GB, %d SMs)\\n\",\n",
    "                   gpu.id, \n",
    "                   gpu.available ? \"Available\" : \"Unavailable\",\n",
    "                   gpu.memory / (1024.0*1024.0*1024.0),\n",
    "                   gpu.smCount);\n",
    "        }\n",
    "        printf(\"Current: GPU %d\\n\\n\", currentDevice_);\n",
    "    }\n",
    "};\n",
    "\n",
    "__global__ void workloadKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = sqrtf((float)idx);\n",
    "    }\n",
    "}\n",
    "\n",
    "bool executeWithFailover(GPUManager& mgr, float* d_data, int n) {\n",
    "    const int maxRetries = 3;\n",
    "    \n",
    "    for (int retry = 0; retry < maxRetries; retry++) {\n",
    "        int blockSize = 256;\n",
    "        int numBlocks = (n + blockSize - 1) / blockSize;\n",
    "        \n",
    "        workloadKernel<<<numBlocks, blockSize>>>(d_data, n);\n",
    "        \n",
    "        cudaError_t err = cudaDeviceSynchronize();\n",
    "        if (err == cudaSuccess) {\n",
    "            return true;  // Success!\n",
    "        }\n",
    "        \n",
    "        printf(\"[ERROR] Kernel failed: %s\\n\", cudaGetErrorString(err));\n",
    "        \n",
    "        // Attempt failover\n",
    "        int newDevice = mgr.failover();\n",
    "        if (newDevice < 0) {\n",
    "            return false;  // No GPUs left\n",
    "        }\n",
    "        \n",
    "        // Reallocate on new device\n",
    "        cudaMalloc(&d_data, n * sizeof(float));\n",
    "        printf(\"[RECOVERY] Retrying on GPU %d (attempt %d/%d)\\n\", \n",
    "               newDevice, retry + 2, maxRetries);\n",
    "    }\n",
    "    \n",
    "    return false;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== GPU Failover Demo ===\\n\\n\");\n",
    "    \n",
    "    GPUManager mgr;\n",
    "    if (!mgr.initialize()) {\n",
    "        printf(\"No GPUs found!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    mgr.printStatus();\n",
    "    \n",
    "    // Select best GPU\n",
    "    int device = mgr.selectBestGPU();\n",
    "    if (device < 0) {\n",
    "        printf(\"No available GPUs!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    mgr.setDevice(device);\n",
    "    printf(\"Selected GPU %d\\n\\n\", device);\n",
    "    \n",
    "    // Allocate and run\n",
    "    const int N = 1024 * 1024;\n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    printf(\"Executing workload...\\n\");\n",
    "    if (executeWithFailover(mgr, d_data, N)) {\n",
    "        printf(\"Workload completed successfully!\\n\");\n",
    "    } else {\n",
    "        printf(\"Workload failed after all retries!\\n\");\n",
    "    }\n",
    "    \n",
    "    mgr.printStatus();\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 -std=c++14 gpu_failover.cu -o gpu_failover && ./gpu_failover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af932298",
   "metadata": {},
   "source": [
    "## Pattern 3: Resource RAII Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cuda_raii.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <memory>\n",
    "#include <stdexcept>\n",
    "\n",
    "// RAII wrapper for device memory\n",
    "template<typename T>\n",
    "class DeviceBuffer {\n",
    "private:\n",
    "    T* ptr_ = nullptr;\n",
    "    size_t size_ = 0;\n",
    "    \n",
    "public:\n",
    "    DeviceBuffer() = default;\n",
    "    \n",
    "    explicit DeviceBuffer(size_t count) : size_(count) {\n",
    "        if (cudaMalloc(&ptr_, count * sizeof(T)) != cudaSuccess) {\n",
    "            throw std::runtime_error(\"cudaMalloc failed\");\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ~DeviceBuffer() {\n",
    "        if (ptr_) cudaFree(ptr_);\n",
    "    }\n",
    "    \n",
    "    // Move only\n",
    "    DeviceBuffer(DeviceBuffer&& other) : ptr_(other.ptr_), size_(other.size_) {\n",
    "        other.ptr_ = nullptr;\n",
    "        other.size_ = 0;\n",
    "    }\n",
    "    \n",
    "    DeviceBuffer& operator=(DeviceBuffer&& other) {\n",
    "        if (this != &other) {\n",
    "            if (ptr_) cudaFree(ptr_);\n",
    "            ptr_ = other.ptr_;\n",
    "            size_ = other.size_;\n",
    "            other.ptr_ = nullptr;\n",
    "            other.size_ = 0;\n",
    "        }\n",
    "        return *this;\n",
    "    }\n",
    "    \n",
    "    // No copy\n",
    "    DeviceBuffer(const DeviceBuffer&) = delete;\n",
    "    DeviceBuffer& operator=(const DeviceBuffer&) = delete;\n",
    "    \n",
    "    T* get() { return ptr_; }\n",
    "    const T* get() const { return ptr_; }\n",
    "    size_t size() const { return size_; }\n",
    "    size_t bytes() const { return size_ * sizeof(T); }\n",
    "    \n",
    "    void copyFrom(const T* host) {\n",
    "        cudaMemcpy(ptr_, host, bytes(), cudaMemcpyHostToDevice);\n",
    "    }\n",
    "    \n",
    "    void copyTo(T* host) const {\n",
    "        cudaMemcpy(host, ptr_, bytes(), cudaMemcpyDeviceToHost);\n",
    "    }\n",
    "};\n",
    "\n",
    "// RAII wrapper for streams\n",
    "class CudaStream {\n",
    "private:\n",
    "    cudaStream_t stream_ = nullptr;\n",
    "    \n",
    "public:\n",
    "    CudaStream() {\n",
    "        cudaStreamCreate(&stream_);\n",
    "    }\n",
    "    \n",
    "    explicit CudaStream(unsigned int flags) {\n",
    "        cudaStreamCreateWithFlags(&stream_, flags);\n",
    "    }\n",
    "    \n",
    "    ~CudaStream() {\n",
    "        if (stream_) cudaStreamDestroy(stream_);\n",
    "    }\n",
    "    \n",
    "    CudaStream(CudaStream&& other) : stream_(other.stream_) {\n",
    "        other.stream_ = nullptr;\n",
    "    }\n",
    "    \n",
    "    cudaStream_t get() { return stream_; }\n",
    "    operator cudaStream_t() { return stream_; }\n",
    "    \n",
    "    void synchronize() { cudaStreamSynchronize(stream_); }\n",
    "    bool query() { return cudaStreamQuery(stream_) == cudaSuccess; }\n",
    "};\n",
    "\n",
    "// RAII wrapper for events\n",
    "class CudaEvent {\n",
    "private:\n",
    "    cudaEvent_t event_ = nullptr;\n",
    "    \n",
    "public:\n",
    "    CudaEvent() {\n",
    "        cudaEventCreate(&event_);\n",
    "    }\n",
    "    \n",
    "    explicit CudaEvent(unsigned int flags) {\n",
    "        cudaEventCreateWithFlags(&event_, flags);\n",
    "    }\n",
    "    \n",
    "    ~CudaEvent() {\n",
    "        if (event_) cudaEventDestroy(event_);\n",
    "    }\n",
    "    \n",
    "    cudaEvent_t get() { return event_; }\n",
    "    operator cudaEvent_t() { return event_; }\n",
    "    \n",
    "    void record(cudaStream_t stream = 0) {\n",
    "        cudaEventRecord(event_, stream);\n",
    "    }\n",
    "    \n",
    "    void synchronize() { cudaEventSynchronize(event_); }\n",
    "    \n",
    "    float elapsedMs(const CudaEvent& start) const {\n",
    "        float ms;\n",
    "        cudaEventElapsedTime(&ms, start.event_, event_);\n",
    "        return ms;\n",
    "    }\n",
    "};\n",
    "\n",
    "// Demo kernel\n",
    "__global__ void addKernel(float* c, const float* a, const float* b, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) c[idx] = a[idx] + b[idx];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== CUDA RAII Wrappers Demo ===\\n\\n\");\n",
    "    \n",
    "    const int N = 1024 * 1024;\n",
    "    \n",
    "    try {\n",
    "        // Automatic cleanup on scope exit!\n",
    "        DeviceBuffer<float> d_a(N);\n",
    "        DeviceBuffer<float> d_b(N);\n",
    "        DeviceBuffer<float> d_c(N);\n",
    "        \n",
    "        printf(\"Allocated 3 buffers: %.2f MB each\\n\", \n",
    "               d_a.bytes() / (1024.0*1024.0));\n",
    "        \n",
    "        // Prepare host data\n",
    "        std::unique_ptr<float[]> h_a(new float[N]);\n",
    "        std::unique_ptr<float[]> h_b(new float[N]);\n",
    "        std::unique_ptr<float[]> h_c(new float[N]);\n",
    "        \n",
    "        for (int i = 0; i < N; i++) {\n",
    "            h_a[i] = 1.0f;\n",
    "            h_b[i] = 2.0f;\n",
    "        }\n",
    "        \n",
    "        d_a.copyFrom(h_a.get());\n",
    "        d_b.copyFrom(h_b.get());\n",
    "        \n",
    "        // Timing with RAII events\n",
    "        CudaEvent start, stop;\n",
    "        CudaStream stream;\n",
    "        \n",
    "        start.record(stream);\n",
    "        \n",
    "        int blockSize = 256;\n",
    "        int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "        addKernel<<<numBlocks, blockSize, 0, stream>>>(d_c.get(), d_a.get(), d_b.get(), N);\n",
    "        \n",
    "        stop.record(stream);\n",
    "        stream.synchronize();\n",
    "        \n",
    "        printf(\"Kernel time: %.3f ms\\n\", stop.elapsedMs(start));\n",
    "        \n",
    "        // Verify\n",
    "        d_c.copyTo(h_c.get());\n",
    "        bool correct = (h_c[0] == 3.0f && h_c[N-1] == 3.0f);\n",
    "        printf(\"Result: %s\\n\", correct ? \"CORRECT\" : \"INCORRECT\");\n",
    "        \n",
    "    } catch (const std::exception& e) {\n",
    "        printf(\"Error: %s\\n\", e.what());\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    // All resources automatically freed here!\n",
    "    printf(\"\\nResources automatically cleaned up.\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbafc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 -std=c++14 cuda_raii.cu -o cuda_raii && ./cuda_raii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39687ab1",
   "metadata": {},
   "source": [
    "## Production Deployment Checklist\n",
    "\n",
    "### Pre-Deployment\n",
    "- [ ] All error checks in place\n",
    "- [ ] Memory leak testing complete\n",
    "- [ ] Stress testing passed\n",
    "- [ ] Logging configured\n",
    "- [ ] Metrics collection ready\n",
    "\n",
    "### Runtime\n",
    "- [ ] GPU health monitoring\n",
    "- [ ] Memory usage alerts\n",
    "- [ ] Temperature thresholds\n",
    "- [ ] ECC error tracking\n",
    "- [ ] Failover procedures\n",
    "\n",
    "### Recovery\n",
    "- [ ] Sticky error handling\n",
    "- [ ] Device reset procedures\n",
    "- [ ] State checkpointing\n",
    "- [ ] Graceful degradation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe6d9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Complete these exercises to practice production deployment patterns:\n",
    "\n",
    "1. **Exercise 1: GPU Health Monitor** - Build a comprehensive GPU health monitoring system\n",
    "2. **Exercise 2: RAII Resource Manager** - Implement automatic resource cleanup with RAII\n",
    "3. **Exercise 3: Failover Handler** - Design graceful GPU failure detection and recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e42bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile production_patterns_exercises.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <string.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t error = call; \\\n",
    "        if (error != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", \\\n",
    "                    cudaGetErrorString(error), __FILE__, __LINE__); \\\n",
    "            exit(EXIT_FAILURE); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 1: GPU Health Monitor\n",
    "// Build a comprehensive GPU health monitoring system\n",
    "// =============================================================================\n",
    "\n",
    "struct GPUHealthMetrics {\n",
    "    int deviceId;\n",
    "    char name[256];\n",
    "    size_t totalMemory;\n",
    "    size_t freeMemory;\n",
    "    size_t usedMemory;\n",
    "    float memoryUsagePercent;\n",
    "    int smCount;\n",
    "    int temperature;  // Would need NVML for real temp\n",
    "    bool isHealthy;\n",
    "    char healthStatus[64];\n",
    "};\n",
    "\n",
    "class GPUHealthMonitor {\n",
    "private:\n",
    "    int deviceCount;\n",
    "    GPUHealthMetrics* metrics;\n",
    "    \n",
    "    void updateMetrics(int deviceId) {\n",
    "        CUDA_CHECK(cudaSetDevice(deviceId));\n",
    "        \n",
    "        cudaDeviceProp prop;\n",
    "        CUDA_CHECK(cudaGetDeviceProperties(&prop, deviceId));\n",
    "        \n",
    "        metrics[deviceId].deviceId = deviceId;\n",
    "        strncpy(metrics[deviceId].name, prop.name, 255);\n",
    "        metrics[deviceId].smCount = prop.multiProcessorCount;\n",
    "        \n",
    "        CUDA_CHECK(cudaMemGetInfo(&metrics[deviceId].freeMemory, \n",
    "                                   &metrics[deviceId].totalMemory));\n",
    "        \n",
    "        metrics[deviceId].usedMemory = metrics[deviceId].totalMemory - \n",
    "                                       metrics[deviceId].freeMemory;\n",
    "        metrics[deviceId].memoryUsagePercent = \n",
    "            100.0f * metrics[deviceId].usedMemory / metrics[deviceId].totalMemory;\n",
    "        \n",
    "        // Simulated temperature (would use NVML in production)\n",
    "        metrics[deviceId].temperature = 45 + (rand() % 20);\n",
    "        \n",
    "        // Determine health status\n",
    "        if (metrics[deviceId].memoryUsagePercent > 95.0f) {\n",
    "            metrics[deviceId].isHealthy = false;\n",
    "            strcpy(metrics[deviceId].healthStatus, \"CRITICAL: Memory exhausted\");\n",
    "        } else if (metrics[deviceId].memoryUsagePercent > 85.0f) {\n",
    "            metrics[deviceId].isHealthy = true;\n",
    "            strcpy(metrics[deviceId].healthStatus, \"WARNING: High memory usage\");\n",
    "        } else if (metrics[deviceId].temperature > 80) {\n",
    "            metrics[deviceId].isHealthy = false;\n",
    "            strcpy(metrics[deviceId].healthStatus, \"CRITICAL: High temperature\");\n",
    "        } else {\n",
    "            metrics[deviceId].isHealthy = true;\n",
    "            strcpy(metrics[deviceId].healthStatus, \"HEALTHY\");\n",
    "        }\n",
    "    }\n",
    "\n",
    "public:\n",
    "    GPUHealthMonitor() {\n",
    "        CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
    "        metrics = new GPUHealthMetrics[deviceCount];\n",
    "        srand(time(NULL));\n",
    "    }\n",
    "    \n",
    "    ~GPUHealthMonitor() {\n",
    "        delete[] metrics;\n",
    "    }\n",
    "    \n",
    "    void collectMetrics() {\n",
    "        for (int i = 0; i < deviceCount; i++) {\n",
    "            updateMetrics(i);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    void printHealthReport() {\n",
    "        printf(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\");\n",
    "        printf(\"â•‘                      GPU HEALTH REPORT                            â•‘\\n\");\n",
    "        printf(\"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\\n\");\n",
    "        \n",
    "        time_t now = time(NULL);\n",
    "        printf(\"â•‘ Timestamp: %-56s â•‘\\n\", ctime(&now));\n",
    "        \n",
    "        for (int i = 0; i < deviceCount; i++) {\n",
    "            GPUHealthMetrics& m = metrics[i];\n",
    "            \n",
    "            printf(\"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\\n\");\n",
    "            printf(\"â•‘ GPU %d: %-59s â•‘\\n\", i, m.name);\n",
    "            printf(\"â•‘   Memory: %.2f / %.2f GB (%.1f%% used)                            \\n\",\n",
    "                   m.usedMemory / (1024.0 * 1024.0 * 1024.0),\n",
    "                   m.totalMemory / (1024.0 * 1024.0 * 1024.0),\n",
    "                   m.memoryUsagePercent);\n",
    "            printf(\"â•‘   SMs: %-3d  Temperature: %dÂ°C (simulated)                        \\n\",\n",
    "                   m.smCount, m.temperature);\n",
    "            printf(\"â•‘   Status: %-57s â•‘\\n\", m.healthStatus);\n",
    "        }\n",
    "        printf(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    }\n",
    "    \n",
    "    bool allDevicesHealthy() {\n",
    "        for (int i = 0; i < deviceCount; i++) {\n",
    "            if (!metrics[i].isHealthy) return false;\n",
    "        }\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    int getHealthyDeviceCount() {\n",
    "        int count = 0;\n",
    "        for (int i = 0; i < deviceCount; i++) {\n",
    "            if (metrics[i].isHealthy) count++;\n",
    "        }\n",
    "        return count;\n",
    "    }\n",
    "};\n",
    "\n",
    "void exercise1_health_monitor() {\n",
    "    printf(\"=== Exercise 1: GPU Health Monitor ===\\n\\n\");\n",
    "    \n",
    "    GPUHealthMonitor monitor;\n",
    "    \n",
    "    // Collect and display metrics\n",
    "    monitor.collectMetrics();\n",
    "    monitor.printHealthReport();\n",
    "    \n",
    "    printf(\"\\nHealth Summary:\\n\");\n",
    "    printf(\"  All devices healthy: %s\\n\", monitor.allDevicesHealthy() ? \"YES\" : \"NO\");\n",
    "    printf(\"  Healthy device count: %d\\n\\n\", monitor.getHealthyDeviceCount());\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 2: RAII Resource Manager\n",
    "// Implement automatic resource cleanup with RAII\n",
    "// =============================================================================\n",
    "\n",
    "template<typename T>\n",
    "class CudaBuffer {\n",
    "private:\n",
    "    T* ptr;\n",
    "    size_t count;\n",
    "    bool ownsMemory;\n",
    "    \n",
    "public:\n",
    "    CudaBuffer() : ptr(nullptr), count(0), ownsMemory(false) {}\n",
    "    \n",
    "    explicit CudaBuffer(size_t n) : count(n), ownsMemory(true) {\n",
    "        cudaError_t err = cudaMalloc(&ptr, n * sizeof(T));\n",
    "        if (err != cudaSuccess) {\n",
    "            ptr = nullptr;\n",
    "            count = 0;\n",
    "            ownsMemory = false;\n",
    "            fprintf(stderr, \"CudaBuffer allocation failed: %s\\n\", \n",
    "                    cudaGetErrorString(err));\n",
    "        } else {\n",
    "            printf(\"  [RAII] Allocated %zu bytes at %p\\n\", n * sizeof(T), ptr);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ~CudaBuffer() {\n",
    "        if (ownsMemory && ptr != nullptr) {\n",
    "            printf(\"  [RAII] Freeing buffer at %p\\n\", ptr);\n",
    "            cudaFree(ptr);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Disable copy\n",
    "    CudaBuffer(const CudaBuffer&) = delete;\n",
    "    CudaBuffer& operator=(const CudaBuffer&) = delete;\n",
    "    \n",
    "    // Enable move\n",
    "    CudaBuffer(CudaBuffer&& other) noexcept \n",
    "        : ptr(other.ptr), count(other.count), ownsMemory(other.ownsMemory) {\n",
    "        other.ptr = nullptr;\n",
    "        other.count = 0;\n",
    "        other.ownsMemory = false;\n",
    "    }\n",
    "    \n",
    "    CudaBuffer& operator=(CudaBuffer&& other) noexcept {\n",
    "        if (this != &other) {\n",
    "            if (ownsMemory && ptr) cudaFree(ptr);\n",
    "            ptr = other.ptr;\n",
    "            count = other.count;\n",
    "            ownsMemory = other.ownsMemory;\n",
    "            other.ptr = nullptr;\n",
    "            other.count = 0;\n",
    "            other.ownsMemory = false;\n",
    "        }\n",
    "        return *this;\n",
    "    }\n",
    "    \n",
    "    T* get() { return ptr; }\n",
    "    const T* get() const { return ptr; }\n",
    "    size_t size() const { return count; }\n",
    "    bool valid() const { return ptr != nullptr; }\n",
    "    \n",
    "    cudaError_t copyFromHost(const T* hostData, size_t n) {\n",
    "        if (!valid() || n > count) return cudaErrorInvalidValue;\n",
    "        return cudaMemcpy(ptr, hostData, n * sizeof(T), cudaMemcpyHostToDevice);\n",
    "    }\n",
    "    \n",
    "    cudaError_t copyToHost(T* hostData, size_t n) const {\n",
    "        if (!valid() || n > count) return cudaErrorInvalidValue;\n",
    "        return cudaMemcpy(hostData, ptr, n * sizeof(T), cudaMemcpyDeviceToHost);\n",
    "    }\n",
    "};\n",
    "\n",
    "class CudaStream {\n",
    "private:\n",
    "    cudaStream_t stream;\n",
    "    bool ownsStream;\n",
    "    \n",
    "public:\n",
    "    CudaStream() : ownsStream(true) {\n",
    "        cudaError_t err = cudaStreamCreate(&stream);\n",
    "        if (err == cudaSuccess) {\n",
    "            printf(\"  [RAII] Created stream %p\\n\", stream);\n",
    "        } else {\n",
    "            stream = nullptr;\n",
    "            ownsStream = false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ~CudaStream() {\n",
    "        if (ownsStream && stream) {\n",
    "            printf(\"  [RAII] Destroying stream %p\\n\", stream);\n",
    "            cudaStreamDestroy(stream);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    CudaStream(const CudaStream&) = delete;\n",
    "    CudaStream& operator=(const CudaStream&) = delete;\n",
    "    \n",
    "    cudaStream_t get() { return stream; }\n",
    "    bool valid() const { return stream != nullptr; }\n",
    "    \n",
    "    cudaError_t synchronize() { \n",
    "        return valid() ? cudaStreamSynchronize(stream) : cudaErrorInvalidValue; \n",
    "    }\n",
    "};\n",
    "\n",
    "__global__ void raiiTestKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = sqrtf((float)idx);\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise2_raii_resource_manager() {\n",
    "    printf(\"=== Exercise 2: RAII Resource Manager ===\\n\\n\");\n",
    "    \n",
    "    printf(\"Creating RAII-managed resources in a scope...\\n\\n\");\n",
    "    \n",
    "    {\n",
    "        // All resources will be automatically cleaned up when leaving scope\n",
    "        CudaBuffer<float> buffer(1024);\n",
    "        CudaStream stream;\n",
    "        \n",
    "        if (buffer.valid() && stream.valid()) {\n",
    "            printf(\"\\nLaunching kernel with RAII resources...\\n\");\n",
    "            raiiTestKernel<<<4, 256, 0, stream.get()>>>(buffer.get(), buffer.size());\n",
    "            stream.synchronize();\n",
    "            printf(\"Kernel completed!\\n\\n\");\n",
    "            \n",
    "            // Copy result back\n",
    "            float hostData[10];\n",
    "            buffer.copyToHost(hostData, 10);\n",
    "            printf(\"First 10 results: \");\n",
    "            for (int i = 0; i < 10; i++) {\n",
    "                printf(\"%.2f \", hostData[i]);\n",
    "            }\n",
    "            printf(\"\\n\\n\");\n",
    "        }\n",
    "        \n",
    "        printf(\"Leaving scope - resources will be automatically freed:\\n\");\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nAll RAII resources cleaned up automatically!\\n\\n\");\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 3: Failover Handler\n",
    "// Design graceful GPU failure detection and recovery\n",
    "// =============================================================================\n",
    "\n",
    "class GPUFailoverManager {\n",
    "private:\n",
    "    int primaryDevice;\n",
    "    int backupDevice;\n",
    "    bool primaryFailed;\n",
    "    int currentDevice;\n",
    "    \n",
    "    bool testDevice(int device) {\n",
    "        cudaError_t err = cudaSetDevice(device);\n",
    "        if (err != cudaSuccess) return false;\n",
    "        \n",
    "        // Try a small allocation to verify device is working\n",
    "        void* testPtr;\n",
    "        err = cudaMalloc(&testPtr, 1024);\n",
    "        if (err != cudaSuccess) return false;\n",
    "        \n",
    "        cudaFree(testPtr);\n",
    "        return true;\n",
    "    }\n",
    "\n",
    "public:\n",
    "    GPUFailoverManager(int primary = 0, int backup = -1) \n",
    "        : primaryDevice(primary), backupDevice(backup), \n",
    "          primaryFailed(false), currentDevice(primary) {\n",
    "        \n",
    "        int deviceCount;\n",
    "        cudaGetDeviceCount(&deviceCount);\n",
    "        \n",
    "        if (backupDevice < 0 && deviceCount > 1) {\n",
    "            backupDevice = (primaryDevice + 1) % deviceCount;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    bool initialize() {\n",
    "        printf(\"  Initializing failover manager...\\n\");\n",
    "        printf(\"  Primary device: %d\\n\", primaryDevice);\n",
    "        printf(\"  Backup device: %d\\n\", backupDevice);\n",
    "        \n",
    "        if (!testDevice(primaryDevice)) {\n",
    "            printf(\"  WARNING: Primary device failed initial test!\\n\");\n",
    "            return failoverToBackup();\n",
    "        }\n",
    "        \n",
    "        printf(\"  Primary device operational\\n\");\n",
    "        currentDevice = primaryDevice;\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    bool failoverToBackup() {\n",
    "        if (backupDevice < 0) {\n",
    "            printf(\"  ERROR: No backup device configured!\\n\");\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        printf(\"  Attempting failover to backup device %d...\\n\", backupDevice);\n",
    "        \n",
    "        if (!testDevice(backupDevice)) {\n",
    "            printf(\"  ERROR: Backup device also failed!\\n\");\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        primaryFailed = true;\n",
    "        currentDevice = backupDevice;\n",
    "        printf(\"  SUCCESS: Failover to device %d complete\\n\", backupDevice);\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    bool executeWithFailover(void (*workFunc)(int)) {\n",
    "        printf(\"\\n  Executing work on device %d...\\n\", currentDevice);\n",
    "        \n",
    "        cudaError_t err = cudaSetDevice(currentDevice);\n",
    "        if (err != cudaSuccess) {\n",
    "            printf(\"  Device %d unavailable, attempting failover...\\n\", currentDevice);\n",
    "            if (!failoverToBackup()) {\n",
    "                return false;\n",
    "            }\n",
    "            cudaSetDevice(currentDevice);\n",
    "        }\n",
    "        \n",
    "        workFunc(currentDevice);\n",
    "        \n",
    "        // Check for execution errors\n",
    "        err = cudaDeviceSynchronize();\n",
    "        if (err != cudaSuccess) {\n",
    "            printf(\"  Execution error on device %d: %s\\n\", \n",
    "                   currentDevice, cudaGetErrorString(err));\n",
    "            \n",
    "            if (!primaryFailed && backupDevice >= 0) {\n",
    "                printf(\"  Retrying on backup device...\\n\");\n",
    "                if (failoverToBackup()) {\n",
    "                    cudaSetDevice(currentDevice);\n",
    "                    workFunc(currentDevice);\n",
    "                    err = cudaDeviceSynchronize();\n",
    "                    if (err == cudaSuccess) {\n",
    "                        printf(\"  Retry succeeded on backup device\\n\");\n",
    "                        return true;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    int getCurrentDevice() const { return currentDevice; }\n",
    "    bool isPrimaryFailed() const { return primaryFailed; }\n",
    "};\n",
    "\n",
    "__global__ void failoverTestKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = (float)idx * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "void testWorkload(int device) {\n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, 1024 * sizeof(float));\n",
    "    failoverTestKernel<<<4, 256>>>(d_data, 1024);\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaFree(d_data);\n",
    "    printf(\"  Workload completed on device %d\\n\", device);\n",
    "}\n",
    "\n",
    "void exercise3_failover_handler() {\n",
    "    printf(\"=== Exercise 3: Failover Handler ===\\n\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    printf(\"Available devices: %d\\n\\n\", deviceCount);\n",
    "    \n",
    "    GPUFailoverManager failover(0, deviceCount > 1 ? 1 : -1);\n",
    "    \n",
    "    if (!failover.initialize()) {\n",
    "        printf(\"Failed to initialize failover manager!\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nExecuting workload with failover protection:\\n\");\n",
    "    bool success = failover.executeWithFailover(testWorkload);\n",
    "    \n",
    "    printf(\"\\nExecution Result:\\n\");\n",
    "    printf(\"  Success: %s\\n\", success ? \"YES\" : \"NO\");\n",
    "    printf(\"  Final device: %d\\n\", failover.getCurrentDevice());\n",
    "    printf(\"  Primary failed: %s\\n\\n\", failover.isPrimaryFailed() ? \"YES\" : \"NO\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\");\n",
    "    printf(\"â•‘   Week 18 Day 4: Production Patterns - CUDA C++ Exercises    â•‘\\n\");\n",
    "    printf(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\");\n",
    "    \n",
    "    exercise1_health_monitor();\n",
    "    exercise2_raii_resource_manager();\n",
    "    exercise3_failover_handler();\n",
    "    \n",
    "    printf(\"All exercises completed!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_75 -o production_patterns_exercises production_patterns_exercises.cu && ./production_patterns_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999ccdf",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "The following exercises use Python with PyCUDA/Numba for those who prefer Python-based GPU programming. Production patterns like health monitoring and failover are commonly implemented in Python orchestration layers.\n",
    "\n",
    "**Python Exercise Ideas:**\n",
    "1. Build a GPU health monitoring dashboard using `py3nvml` and Flask/Streamlit\n",
    "2. Implement a Python resource manager with automatic cleanup using context managers\n",
    "3. Create a production-ready GPU failover system with health checks and alerting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34412624",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaways\n",
    "\n",
    "### Production Patterns Mastered! ğŸ¨\n",
    "\n",
    "You've learned to run GPU operations like a 5-star hotel chain:\n",
    "\n",
    "| Pattern | Description | Hotel Analogy |\n",
    "|---------|-------------|---------------|\n",
    "| **Health Monitoring** | Temperature, memory, ECC | Room sensors dashboard |\n",
    "| **Failover Systems** | Handle GPU failures gracefully | Backup power/rooms |\n",
    "| **RAII Wrappers** | Automatic resource cleanup | Housekeeping protocols |\n",
    "| **Comprehensive Logging** | Errors, warnings, metrics | Guest registry & incidents |\n",
    "| **Error Path Testing** | Verify recovery procedures | Fire drills & training |\n",
    "\n",
    "### ğŸ¨ The Hotel Management Principle\n",
    "> \"A production GPU system needs the same care as a 5-star hotel: constant health monitoring, graceful failover, automatic cleanup, and staff ready for any emergency.\"\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Week 18 Complete: Enterprise GPU Management\n",
    "\n",
    "### ğŸ† Your MIG & Production Journey\n",
    "\n",
    "```\n",
    "Week 18 Achievement Unlocked! ğŸ…\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Day 1: MIG Fundamentals     ğŸ¨ Hotel partitioning\n",
    "Day 2: MIG Configuration    ğŸ”§ Creating private suites  \n",
    "Day 3: Error Management     ğŸš¨ Emergency protocols\n",
    "Day 4: Production Patterns  â­ 5-star operations\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "        ENTERPRISE GPU MASTER!\n",
    "```\n",
    "\n",
    "### ğŸŠ Congratulations on Completing the CUDA Curriculum!\n",
    "\n",
    "You've completed an incredible 18-week journey from GPU basics to enterprise-level GPU management:\n",
    "\n",
    "| Phase | Weeks | Key Skills |\n",
    "|-------|-------|------------|\n",
    "| **Foundations** | 1-4 | Threads, memory, optimization basics |\n",
    "| **Optimization** | 5-8 | Profiling, occupancy, performance tuning |\n",
    "| **Advanced** | 9-12 | Streams, graphs, cooperative groups, multi-GPU |\n",
    "| **Special Topics** | 13-16 | Libraries, deep learning, graphics interop |\n",
    "| **Enterprise** | 17-18 | Debugging, profiling, MIG, production |\n",
    "\n",
    "### ğŸš€ What's Next?\n",
    "- Deploy MIG-aware applications in production\n",
    "- Contribute to GPU-accelerated open source projects\n",
    "- Explore emerging NVIDIA technologies (Grace Hopper, Blackwell)\n",
    "- Share your knowledge with the community!\n",
    "\n",
    "**Thank you for learning with us! ğŸ™**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
