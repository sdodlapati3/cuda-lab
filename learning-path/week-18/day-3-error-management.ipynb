{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1ccba0",
   "metadata": {},
   "source": [
    "# Day 3: Error Management - Handling Suite Emergencies\n",
    "\n",
    "**Week 18 - Enterprise GPU Management**\n",
    "\n",
    "> *\"A great hotel doesn't just prevent problemsâ€”it has procedures for gracefully handling any emergency without disturbing other guests.\"*\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "1. **Implement** comprehensive CUDA error handling patterns\n",
    "2. **Distinguish** between sticky and non-sticky errors\n",
    "3. **Use** stream isolation for fault containment\n",
    "4. **Apply** production-grade logging and recovery strategies\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¨ Concept Card: Hotel Resource Isolation\n",
    "\n",
    "**MIG Error Isolation is like hotel emergency management:**\n",
    "\n",
    "```\n",
    "Without MIG (Shared Hotel Floor):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 ğŸ¨ Open Floor Plan                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”        â”‚\n",
    "â”‚  â”‚ App A â”‚  â”‚ App B â”‚  â”‚ App C â”‚  â”‚ App D â”‚        â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\n",
    "â”‚      â”‚          â”‚          â”‚          â”‚             â”‚\n",
    "â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚\n",
    "â”‚           Shared Memory Space                       â”‚\n",
    "â”‚  âš ï¸ App A crashes â†’ May corrupt B, C, D's memory!  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "With MIG (Isolated Suites):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            ğŸ¨ Private Suites (MIG Instances)        â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚\n",
    "â”‚  â”‚ ğŸšª Suite A  â”‚      â”‚ ğŸšª Suite B  â”‚              â”‚\n",
    "â”‚  â”‚   App A     â”‚      â”‚   App B     â”‚              â”‚\n",
    "â”‚  â”‚  40GB HBM   â”‚ ğŸ”’  â”‚  40GB HBM   â”‚              â”‚\n",
    "â”‚  â”‚  66 SMs     â”‚      â”‚  66 SMs     â”‚              â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\n",
    "â”‚  âš ï¸ App A crashes â†’ App B completely unaffected!   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**The Emergency Management Mapping:**\n",
    "| Hotel Concept | GPU Error Handling | Benefit |\n",
    "|---------------|-------------------|---------|\n",
    "| ğŸš¨ Fire in Suite A | Kernel crash | Only Suite A affected |\n",
    "| ğŸ”¥ Smoke containment | Memory isolation | Corruption can't spread |\n",
    "| ğŸš’ Local response | cudaDeviceReset() | Reset one instance only |\n",
    "| ğŸ“‹ Incident log | Error logging | Track and analyze issues |\n",
    "| ğŸ›¡ï¸ Suite firewall | Stream isolation | Further fault containment |\n",
    "\n",
    "---\n",
    "\n",
    "## Error Handling Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da11037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile error_handling.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdarg.h>\n",
    "#include <time.h>\n",
    "\n",
    "// =============================================================\n",
    "// Production Error Handling Framework\n",
    "// =============================================================\n",
    "\n",
    "enum LogLevel {\n",
    "    LOG_DEBUG = 0,\n",
    "    LOG_INFO = 1,\n",
    "    LOG_WARN = 2,\n",
    "    LOG_ERROR = 3,\n",
    "    LOG_FATAL = 4\n",
    "};\n",
    "\n",
    "const char* logLevelStr[] = {\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\", \"FATAL\"};\n",
    "\n",
    "// Thread-safe logging\n",
    "void logMessage(LogLevel level, const char* file, int line, const char* fmt, ...) {\n",
    "    time_t now = time(NULL);\n",
    "    struct tm* tm_info = localtime(&now);\n",
    "    char timestamp[26];\n",
    "    strftime(timestamp, 26, \"%Y-%m-%d %H:%M:%S\", tm_info);\n",
    "    \n",
    "    fprintf(stderr, \"[%s] [%s] %s:%d - \", timestamp, logLevelStr[level], file, line);\n",
    "    \n",
    "    va_list args;\n",
    "    va_start(args, fmt);\n",
    "    vfprintf(stderr, fmt, args);\n",
    "    va_end(args);\n",
    "    \n",
    "    fprintf(stderr, \"\\n\");\n",
    "}\n",
    "\n",
    "#define LOG_DEBUG(...) logMessage(LOG_DEBUG, __FILE__, __LINE__, __VA_ARGS__)\n",
    "#define LOG_INFO(...)  logMessage(LOG_INFO,  __FILE__, __LINE__, __VA_ARGS__)\n",
    "#define LOG_WARN(...)  logMessage(LOG_WARN,  __FILE__, __LINE__, __VA_ARGS__)\n",
    "#define LOG_ERROR(...) logMessage(LOG_ERROR, __FILE__, __LINE__, __VA_ARGS__)\n",
    "#define LOG_FATAL(...) logMessage(LOG_FATAL, __FILE__, __LINE__, __VA_ARGS__)\n",
    "\n",
    "// Enhanced CUDA error check with context\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = (call); \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            LOG_ERROR(\"CUDA error in %s: %s (code %d)\", \\\n",
    "                      #call, cudaGetErrorString(err), err); \\\n",
    "            return err; \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "#define CUDA_CHECK_FATAL(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = (call); \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            LOG_FATAL(\"CUDA error in %s: %s\", #call, cudaGetErrorString(err)); \\\n",
    "            exit(EXIT_FAILURE); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// Check for kernel launch errors (async)\n",
    "#define CUDA_KERNEL_CHECK() \\\n",
    "    do { \\\n",
    "        cudaError_t err = cudaGetLastError(); \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            LOG_ERROR(\"Kernel launch error: %s\", cudaGetErrorString(err)); \\\n",
    "            return err; \\\n",
    "        } \\\n",
    "        err = cudaDeviceSynchronize(); \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            LOG_ERROR(\"Kernel execution error: %s\", cudaGetErrorString(err)); \\\n",
    "            return err; \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// =============================================================\n",
    "// Example: Robust Memory Allocation\n",
    "// =============================================================\n",
    "\n",
    "cudaError_t safeDeviceMalloc(void** ptr, size_t size, const char* name) {\n",
    "    LOG_DEBUG(\"Allocating %zu bytes for '%s'\", size, name);\n",
    "    \n",
    "    // Check available memory first\n",
    "    size_t freeMemory, totalMemory;\n",
    "    CUDA_CHECK(cudaMemGetInfo(&freeMemory, &totalMemory));\n",
    "    \n",
    "    if (size > freeMemory) {\n",
    "        LOG_ERROR(\"Insufficient GPU memory for '%s': need %zu, have %zu\",\n",
    "                  name, size, freeMemory);\n",
    "        return cudaErrorMemoryAllocation;\n",
    "    }\n",
    "    \n",
    "    // Attempt allocation\n",
    "    CUDA_CHECK(cudaMalloc(ptr, size));\n",
    "    \n",
    "    LOG_INFO(\"Allocated %zu bytes for '%s' (%.1f%% of free memory)\",\n",
    "             size, name, 100.0 * size / freeMemory);\n",
    "    \n",
    "    return cudaSuccess;\n",
    "}\n",
    "\n",
    "// =============================================================\n",
    "// Example: Error Recovery\n",
    "// =============================================================\n",
    "\n",
    "__global__ void faultyKernel(int* data, int n, bool causeFault) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (causeFault && idx == 0) {\n",
    "        // Intentional out-of-bounds access\n",
    "        int* bad_ptr = (int*)0xDEADBEEF;\n",
    "        *bad_ptr = 42;\n",
    "    }\n",
    "    if (idx < n) {\n",
    "        data[idx] = idx * 2;\n",
    "    }\n",
    "}\n",
    "\n",
    "cudaError_t runWithRecovery(int* d_data, int n, bool causeFault) {\n",
    "    LOG_INFO(\"Launching kernel (causeFault=%d)\", causeFault);\n",
    "    \n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (n + blockSize - 1) / blockSize;\n",
    "    \n",
    "    faultyKernel<<<numBlocks, blockSize>>>(d_data, n, causeFault);\n",
    "    \n",
    "    cudaError_t launchErr = cudaGetLastError();\n",
    "    if (launchErr != cudaSuccess) {\n",
    "        LOG_ERROR(\"Kernel launch failed: %s\", cudaGetErrorString(launchErr));\n",
    "        return launchErr;\n",
    "    }\n",
    "    \n",
    "    cudaError_t syncErr = cudaDeviceSynchronize();\n",
    "    if (syncErr != cudaSuccess) {\n",
    "        LOG_ERROR(\"Kernel execution failed: %s\", cudaGetErrorString(syncErr));\n",
    "        \n",
    "        // Attempt recovery\n",
    "        LOG_WARN(\"Attempting device reset...\");\n",
    "        cudaError_t resetErr = cudaDeviceReset();\n",
    "        if (resetErr != cudaSuccess) {\n",
    "            LOG_FATAL(\"Device reset failed: %s\", cudaGetErrorString(resetErr));\n",
    "            return resetErr;\n",
    "        }\n",
    "        \n",
    "        LOG_INFO(\"Device reset successful\");\n",
    "        return syncErr;\n",
    "    }\n",
    "    \n",
    "    LOG_INFO(\"Kernel completed successfully\");\n",
    "    return cudaSuccess;\n",
    "}\n",
    "\n",
    "// =============================================================\n",
    "// Main Demo\n",
    "// =============================================================\n",
    "\n",
    "int main() {\n",
    "    LOG_INFO(\"=== Error Handling Demo ===\");\n",
    "    \n",
    "    const int N = 1024;\n",
    "    int* d_data = nullptr;\n",
    "    \n",
    "    // Safe allocation\n",
    "    cudaError_t err = safeDeviceMalloc((void**)&d_data, N * sizeof(int), \"test_data\");\n",
    "    if (err != cudaSuccess) {\n",
    "        LOG_FATAL(\"Allocation failed\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    // Test successful execution\n",
    "    LOG_INFO(\"--- Test 1: Normal execution ---\");\n",
    "    err = runWithRecovery(d_data, N, false);\n",
    "    if (err == cudaSuccess) {\n",
    "        LOG_INFO(\"Test 1 PASSED\");\n",
    "    }\n",
    "    \n",
    "    // Clean up\n",
    "    CUDA_CHECK_FATAL(cudaFree(d_data));\n",
    "    \n",
    "    LOG_INFO(\"=== Demo Complete ===\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 error_handling.cu -o error_handling && ./error_handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b0556",
   "metadata": {},
   "source": [
    "## Sticky Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sticky_errors.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Demonstrate sticky vs non-sticky errors\n",
    "// Sticky errors require device reset to clear\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Sticky Error Demonstration ===\\n\\n\");\n",
    "    \n",
    "    int deviceCount;\n",
    "    cudaError_t err = cudaGetDeviceCount(&deviceCount);\n",
    "    printf(\"Initial state: %s\\n\\n\", cudaGetErrorString(err));\n",
    "    \n",
    "    // Non-sticky error: Invalid configuration\n",
    "    printf(\"--- Non-Sticky Error Test ---\\n\");\n",
    "    int* dummy;\n",
    "    err = cudaMalloc(&dummy, (size_t)-1);  // Impossibly large allocation\n",
    "    printf(\"After bad malloc: %s\\n\", cudaGetErrorString(err));\n",
    "    \n",
    "    // Check last error (should be set)\n",
    "    err = cudaGetLastError();\n",
    "    printf(\"cudaGetLastError(): %s\\n\", cudaGetErrorString(err));\n",
    "    \n",
    "    // Check peek error (same but doesn't clear)\n",
    "    err = cudaPeekAtLastError();\n",
    "    printf(\"cudaPeekAtLastError(): %s\\n\", cudaGetErrorString(err));\n",
    "    \n",
    "    // After cudaGetLastError, error should be cleared\n",
    "    err = cudaGetLastError();\n",
    "    printf(\"After clearing: %s\\n\", cudaGetErrorString(err));\n",
    "    \n",
    "    // Try normal operation (should work)\n",
    "    int* d_ptr;\n",
    "    err = cudaMalloc(&d_ptr, sizeof(int));\n",
    "    printf(\"Normal allocation after non-sticky: %s\\n\", cudaGetErrorString(err));\n",
    "    \n",
    "    if (err == cudaSuccess) {\n",
    "        cudaFree(d_ptr);\n",
    "        printf(\"Device still functional!\\n\\n\");\n",
    "    }\n",
    "    \n",
    "    // Sticky errors (like illegal memory access) require device reset\n",
    "    printf(\"--- Sticky Error Categories ---\\n\");\n",
    "    printf(\"Non-sticky (recoverable):\\n\");\n",
    "    printf(\"  - cudaErrorInvalidValue\\n\");\n",
    "    printf(\"  - cudaErrorMemoryAllocation\\n\");\n",
    "    printf(\"  - cudaErrorInvalidDevicePointer\\n\");\n",
    "    printf(\"\\nSticky (require device reset):\\n\");\n",
    "    printf(\"  - cudaErrorIllegalAddress (illegal memory access)\\n\");\n",
    "    printf(\"  - cudaErrorHardwareStackError\\n\");\n",
    "    printf(\"  - cudaErrorAssert (device-side assert)\\n\");\n",
    "    printf(\"  - cudaErrorLaunchTimeout\\n\");\n",
    "    printf(\"  - ECC memory errors\\n\");\n",
    "    \n",
    "    printf(\"\\n--- Error Type Checking ---\\n\");\n",
    "    \n",
    "    // Example: Check if error is recoverable\n",
    "    auto isRecoverable = [](cudaError_t e) {\n",
    "        switch(e) {\n",
    "            case cudaErrorInvalidValue:\n",
    "            case cudaErrorMemoryAllocation:\n",
    "            case cudaErrorInvalidConfiguration:\n",
    "                return true;\n",
    "            default:\n",
    "                return false;\n",
    "        }\n",
    "    };\n",
    "    \n",
    "    cudaError_t testErrors[] = {\n",
    "        cudaErrorInvalidValue,\n",
    "        cudaErrorMemoryAllocation,\n",
    "        cudaErrorIllegalAddress,\n",
    "        cudaErrorAssert\n",
    "    };\n",
    "    \n",
    "    for (auto e : testErrors) {\n",
    "        printf(\"%s: %s\\n\", \n",
    "               cudaGetErrorName(e),\n",
    "               isRecoverable(e) ? \"Recoverable\" : \"Requires reset\");\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489443a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 sticky_errors.cu -o sticky_errors && ./sticky_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a9011",
   "metadata": {},
   "source": [
    "## Stream-Based Error Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ec8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stream_errors.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void simpleKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = sqrtf((float)idx);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Stream-Based Error Checking ===\\n\\n\");\n",
    "    \n",
    "    const int N = 1024 * 1024;\n",
    "    const int numStreams = 4;\n",
    "    \n",
    "    cudaStream_t streams[numStreams];\n",
    "    float* d_data[numStreams];\n",
    "    cudaError_t streamErrors[numStreams];\n",
    "    \n",
    "    // Create streams and allocate per-stream memory\n",
    "    for (int i = 0; i < numStreams; i++) {\n",
    "        cudaStreamCreate(&streams[i]);\n",
    "        cudaMalloc(&d_data[i], N * sizeof(float));\n",
    "        streamErrors[i] = cudaSuccess;\n",
    "    }\n",
    "    \n",
    "    // Launch kernels on different streams\n",
    "    printf(\"Launching kernels on %d streams...\\n\", numStreams);\n",
    "    \n",
    "    for (int i = 0; i < numStreams; i++) {\n",
    "        int blockSize = 256;\n",
    "        int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "        \n",
    "        simpleKernel<<<numBlocks, blockSize, 0, streams[i]>>>(d_data[i], N);\n",
    "        \n",
    "        // Check launch error immediately (doesn't wait for completion)\n",
    "        streamErrors[i] = cudaGetLastError();\n",
    "        if (streamErrors[i] != cudaSuccess) {\n",
    "            printf(\"Stream %d launch error: %s\\n\", i, \n",
    "                   cudaGetErrorString(streamErrors[i]));\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Query stream status (non-blocking)\n",
    "    printf(\"\\nQuerying stream status...\\n\");\n",
    "    for (int i = 0; i < numStreams; i++) {\n",
    "        cudaError_t status = cudaStreamQuery(streams[i]);\n",
    "        printf(\"Stream %d: %s\\n\", i, \n",
    "               status == cudaSuccess ? \"Complete\" :\n",
    "               status == cudaErrorNotReady ? \"Running\" :\n",
    "               cudaGetErrorString(status));\n",
    "    }\n",
    "    \n",
    "    // Synchronize each stream and check for errors\n",
    "    printf(\"\\nSynchronizing streams...\\n\");\n",
    "    for (int i = 0; i < numStreams; i++) {\n",
    "        cudaError_t err = cudaStreamSynchronize(streams[i]);\n",
    "        if (err != cudaSuccess) {\n",
    "            printf(\"Stream %d execution error: %s\\n\", i, \n",
    "                   cudaGetErrorString(err));\n",
    "            streamErrors[i] = err;\n",
    "        } else {\n",
    "            printf(\"Stream %d: Success\\n\", i);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Summary\n",
    "    printf(\"\\n--- Error Summary ---\\n\");\n",
    "    int errorCount = 0;\n",
    "    for (int i = 0; i < numStreams; i++) {\n",
    "        if (streamErrors[i] != cudaSuccess) {\n",
    "            errorCount++;\n",
    "            printf(\"Stream %d FAILED: %s\\n\", i, \n",
    "                   cudaGetErrorString(streamErrors[i]));\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if (errorCount == 0) {\n",
    "        printf(\"All %d streams completed successfully!\\n\", numStreams);\n",
    "    } else {\n",
    "        printf(\"%d/%d streams had errors\\n\", errorCount, numStreams);\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int i = 0; i < numStreams; i++) {\n",
    "        cudaFree(d_data[i]);\n",
    "        cudaStreamDestroy(streams[i]);\n",
    "    }\n",
    "    \n",
    "    return errorCount;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_80 stream_errors.cu -o stream_errors && ./stream_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566408e5",
   "metadata": {},
   "source": [
    "## CUDA Debugging Environment Variables\n",
    "\n",
    "```bash\n",
    "# Enable synchronous launches (helps locate errors)\n",
    "export CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "# Memory checking\n",
    "export CUDA_MEMCHECK_PATCH_MODULE=1\n",
    "\n",
    "# Device selection\n",
    "export CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "# Debug output\n",
    "export CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "\n",
    "# For compute-sanitizer\n",
    "compute-sanitizer --tool memcheck ./my_program\n",
    "compute-sanitizer --tool racecheck ./my_program\n",
    "compute-sanitizer --tool initcheck ./my_program\n",
    "compute-sanitizer --tool synccheck ./my_program\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf08e8a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)\n",
    "\n",
    "Complete these exercises to practice production error management concepts:\n",
    "\n",
    "1. **Exercise 1: Comprehensive Error Wrapper** - Build a robust CUDA error handling class\n",
    "2. **Exercise 2: Sticky Error Recovery** - Implement detection and recovery from sticky errors\n",
    "3. **Exercise 3: Stream Error Isolation** - Handle errors in isolated streams without affecting others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12080fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile error_management_exercises.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <time.h>\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 1: Comprehensive Error Wrapper\n",
    "// Build a robust CUDA error handling class\n",
    "// =============================================================================\n",
    "\n",
    "class CudaErrorHandler {\n",
    "private:\n",
    "    const char* filename;\n",
    "    int line;\n",
    "    bool throwOnError;\n",
    "    \n",
    "    static const char* errorSeverity(cudaError_t error) {\n",
    "        switch (error) {\n",
    "            case cudaSuccess:\n",
    "                return \"INFO\";\n",
    "            case cudaErrorMemoryAllocation:\n",
    "            case cudaErrorLaunchOutOfResources:\n",
    "                return \"CRITICAL\";\n",
    "            case cudaErrorInvalidValue:\n",
    "            case cudaErrorInvalidDevicePointer:\n",
    "                return \"ERROR\";\n",
    "            default:\n",
    "                return \"WARNING\";\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    static void logError(const char* severity, const char* file, int line, \n",
    "                        cudaError_t error, const char* context) {\n",
    "        time_t now = time(NULL);\n",
    "        char timeStr[26];\n",
    "        ctime_r(&now, timeStr);\n",
    "        timeStr[24] = '\\0';  // Remove newline\n",
    "        \n",
    "        fprintf(stderr, \"[%s] [%s] CUDA Error at %s:%d\\n\", \n",
    "                timeStr, severity, file, line);\n",
    "        fprintf(stderr, \"  Error Code: %d (%s)\\n\", \n",
    "                error, cudaGetErrorName(error));\n",
    "        fprintf(stderr, \"  Description: %s\\n\", cudaGetErrorString(error));\n",
    "        if (context) {\n",
    "            fprintf(stderr, \"  Context: %s\\n\", context);\n",
    "        }\n",
    "    }\n",
    "\n",
    "public:\n",
    "    CudaErrorHandler(const char* file, int ln, bool throwErr = false) \n",
    "        : filename(file), line(ln), throwOnError(throwErr) {}\n",
    "    \n",
    "    bool check(cudaError_t error, const char* context = nullptr) {\n",
    "        if (error != cudaSuccess) {\n",
    "            const char* severity = errorSeverity(error);\n",
    "            logError(severity, filename, line, error, context);\n",
    "            \n",
    "            if (throwOnError) {\n",
    "                exit(EXIT_FAILURE);\n",
    "            }\n",
    "            return false;\n",
    "        }\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    static void checkLastError(const char* context = nullptr) {\n",
    "        cudaError_t error = cudaGetLastError();\n",
    "        if (error != cudaSuccess) {\n",
    "            fprintf(stderr, \"[ERROR] Async CUDA Error: %s\\n\", \n",
    "                    cudaGetErrorString(error));\n",
    "            if (context) {\n",
    "                fprintf(stderr, \"  Context: %s\\n\", context);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "#define CUDA_SAFE_CALL(call) \\\n",
    "    CudaErrorHandler(__FILE__, __LINE__, true).check(call, #call)\n",
    "\n",
    "#define CUDA_CHECK_LAST(context) \\\n",
    "    CudaErrorHandler::checkLastError(context)\n",
    "\n",
    "__global__ void testKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = sqrtf((float)idx);\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise1_error_wrapper() {\n",
    "    printf(\"=== Exercise 1: Comprehensive Error Wrapper ===\\n\\n\");\n",
    "    \n",
    "    // Test successful operations\n",
    "    printf(\"Testing successful allocation...\\n\");\n",
    "    float* d_data;\n",
    "    CUDA_SAFE_CALL(cudaMalloc(&d_data, 1024 * sizeof(float)));\n",
    "    printf(\"  Allocation succeeded!\\n\\n\");\n",
    "    \n",
    "    // Test kernel launch with error checking\n",
    "    printf(\"Testing kernel launch...\\n\");\n",
    "    testKernel<<<4, 256>>>(d_data, 1024);\n",
    "    CUDA_CHECK_LAST(\"testKernel execution\");\n",
    "    CUDA_SAFE_CALL(cudaDeviceSynchronize());\n",
    "    printf(\"  Kernel completed successfully!\\n\\n\");\n",
    "    \n",
    "    // Test intentional error (trying to free already freed memory is UB, \n",
    "    // so we'll demonstrate with invalid operations safely)\n",
    "    printf(\"Testing error detection with invalid operation...\\n\");\n",
    "    CudaErrorHandler handler(__FILE__, __LINE__, false);  // Don't exit on error\n",
    "    \n",
    "    // Try to set an invalid device\n",
    "    bool success = handler.check(cudaSetDevice(999), \"Set invalid device\");\n",
    "    printf(\"  Error was %s detected and handled\\n\\n\", success ? \"NOT\" : \"correctly\");\n",
    "    \n",
    "    // Reset device state after error\n",
    "    cudaGetLastError();  // Clear the error\n",
    "    \n",
    "    CUDA_SAFE_CALL(cudaFree(d_data));\n",
    "    printf(\"Cleanup completed!\\n\\n\");\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 2: Sticky Error Recovery\n",
    "// Implement detection and recovery from sticky errors\n",
    "// =============================================================================\n",
    "\n",
    "class StickyErrorRecovery {\n",
    "private:\n",
    "    int deviceId;\n",
    "    bool hasError;\n",
    "    cudaError_t lastError;\n",
    "    \n",
    "public:\n",
    "    StickyErrorRecovery(int dev = 0) : deviceId(dev), hasError(false) {\n",
    "        cudaSetDevice(deviceId);\n",
    "    }\n",
    "    \n",
    "    bool checkForStickyError() {\n",
    "        cudaError_t error = cudaPeekAtLastError();\n",
    "        \n",
    "        if (error != cudaSuccess) {\n",
    "            hasError = true;\n",
    "            lastError = error;\n",
    "            \n",
    "            // Check if it's a sticky error\n",
    "            // Sticky errors persist until device reset\n",
    "            printf(\"  Detected error: %s\\n\", cudaGetErrorString(error));\n",
    "            \n",
    "            // Try to clear with cudaGetLastError\n",
    "            cudaGetLastError();\n",
    "            \n",
    "            // Check if error persists\n",
    "            if (cudaPeekAtLastError() != cudaSuccess) {\n",
    "                printf(\"  Error is STICKY - requires device reset\\n\");\n",
    "                return true;\n",
    "            } else {\n",
    "                printf(\"  Error was non-sticky - cleared successfully\\n\");\n",
    "                return false;\n",
    "            }\n",
    "        }\n",
    "        return false;\n",
    "    }\n",
    "    \n",
    "    bool attemptRecovery() {\n",
    "        printf(\"  Attempting device recovery...\\n\");\n",
    "        \n",
    "        // Reset the device\n",
    "        cudaError_t resetError = cudaDeviceReset();\n",
    "        \n",
    "        if (resetError != cudaSuccess) {\n",
    "            printf(\"  Device reset FAILED: %s\\n\", cudaGetErrorString(resetError));\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        // Re-select device\n",
    "        cudaError_t setError = cudaSetDevice(deviceId);\n",
    "        if (setError != cudaSuccess) {\n",
    "            printf(\"  Device selection FAILED: %s\\n\", cudaGetErrorString(setError));\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        // Verify recovery with a simple operation\n",
    "        void* testPtr;\n",
    "        cudaError_t allocError = cudaMalloc(&testPtr, 1024);\n",
    "        \n",
    "        if (allocError == cudaSuccess) {\n",
    "            cudaFree(testPtr);\n",
    "            printf(\"  Device recovery SUCCESSFUL\\n\");\n",
    "            hasError = false;\n",
    "            return true;\n",
    "        }\n",
    "        \n",
    "        printf(\"  Device recovery FAILED - device may require system reboot\\n\");\n",
    "        return false;\n",
    "    }\n",
    "    \n",
    "    void simulateWorkWithRecovery() {\n",
    "        float* d_data;\n",
    "        \n",
    "        // Attempt allocation\n",
    "        cudaError_t error = cudaMalloc(&d_data, 1024 * sizeof(float));\n",
    "        \n",
    "        if (error != cudaSuccess) {\n",
    "            printf(\"  Allocation failed, checking for sticky error...\\n\");\n",
    "            if (checkForStickyError()) {\n",
    "                if (attemptRecovery()) {\n",
    "                    // Retry operation after recovery\n",
    "                    error = cudaMalloc(&d_data, 1024 * sizeof(float));\n",
    "                    if (error == cudaSuccess) {\n",
    "                        printf(\"  Retry after recovery: SUCCESS\\n\");\n",
    "                        cudaFree(d_data);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        } else {\n",
    "            printf(\"  Allocation succeeded on first try\\n\");\n",
    "            cudaFree(d_data);\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "void exercise2_sticky_error_recovery() {\n",
    "    printf(\"=== Exercise 2: Sticky Error Recovery ===\\n\\n\");\n",
    "    \n",
    "    printf(\"Demonstrating sticky error recovery pattern...\\n\\n\");\n",
    "    \n",
    "    StickyErrorRecovery recovery(0);\n",
    "    \n",
    "    // Normal operation\n",
    "    printf(\"Test 1: Normal operation\\n\");\n",
    "    recovery.simulateWorkWithRecovery();\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    // Demonstrate error detection\n",
    "    printf(\"Test 2: Error detection after forced error\\n\");\n",
    "    \n",
    "    // Force a non-sticky error\n",
    "    cudaSetDevice(0);\n",
    "    cudaError_t err = cudaMalloc(nullptr, 0);  // Invalid operation\n",
    "    printf(\"  Forced error: %s\\n\", cudaGetErrorString(err));\n",
    "    \n",
    "    // Check and clear\n",
    "    recovery.checkForStickyError();\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    printf(\"Sticky error recovery pattern demonstrated!\\n\\n\");\n",
    "}\n",
    "\n",
    "// =============================================================================\n",
    "// Exercise 3: Stream Error Isolation\n",
    "// Handle errors in isolated streams without affecting others\n",
    "// =============================================================================\n",
    "\n",
    "class IsolatedStreamManager {\n",
    "private:\n",
    "    static const int MAX_STREAMS = 4;\n",
    "    cudaStream_t streams[MAX_STREAMS];\n",
    "    bool streamHasError[MAX_STREAMS];\n",
    "    \n",
    "public:\n",
    "    IsolatedStreamManager() {\n",
    "        for (int i = 0; i < MAX_STREAMS; i++) {\n",
    "            cudaStreamCreate(&streams[i]);\n",
    "            streamHasError[i] = false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ~IsolatedStreamManager() {\n",
    "        for (int i = 0; i < MAX_STREAMS; i++) {\n",
    "            cudaStreamDestroy(streams[i]);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    cudaStream_t getStream(int index) {\n",
    "        if (index >= 0 && index < MAX_STREAMS) {\n",
    "            return streams[index];\n",
    "        }\n",
    "        return nullptr;\n",
    "    }\n",
    "    \n",
    "    bool checkStreamStatus(int index) {\n",
    "        if (index < 0 || index >= MAX_STREAMS) return false;\n",
    "        \n",
    "        cudaError_t error = cudaStreamQuery(streams[index]);\n",
    "        \n",
    "        if (error == cudaSuccess) {\n",
    "            printf(\"  Stream %d: READY (completed)\\n\", index);\n",
    "            streamHasError[index] = false;\n",
    "            return true;\n",
    "        } else if (error == cudaErrorNotReady) {\n",
    "            printf(\"  Stream %d: BUSY (still executing)\\n\", index);\n",
    "            return true;\n",
    "        } else {\n",
    "            printf(\"  Stream %d: ERROR - %s\\n\", index, cudaGetErrorString(error));\n",
    "            streamHasError[index] = true;\n",
    "            return false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    void synchronizeHealthyStreams() {\n",
    "        printf(\"\\n  Synchronizing healthy streams:\\n\");\n",
    "        for (int i = 0; i < MAX_STREAMS; i++) {\n",
    "            if (!streamHasError[i]) {\n",
    "                cudaError_t error = cudaStreamSynchronize(streams[i]);\n",
    "                if (error == cudaSuccess) {\n",
    "                    printf(\"    Stream %d synchronized successfully\\n\", i);\n",
    "                } else {\n",
    "                    printf(\"    Stream %d sync failed: %s\\n\", i, cudaGetErrorString(error));\n",
    "                    streamHasError[i] = true;\n",
    "                }\n",
    "            } else {\n",
    "                printf(\"    Stream %d skipped (has error)\\n\", i);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    int getHealthyStreamCount() {\n",
    "        int count = 0;\n",
    "        for (int i = 0; i < MAX_STREAMS; i++) {\n",
    "            if (!streamHasError[i]) count++;\n",
    "        }\n",
    "        return count;\n",
    "    }\n",
    "};\n",
    "\n",
    "__global__ void streamWorkKernel(float* data, int n, int streamId) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = (float)(streamId * 1000 + idx);\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise3_stream_error_isolation() {\n",
    "    printf(\"=== Exercise 3: Stream Error Isolation ===\\n\\n\");\n",
    "    \n",
    "    IsolatedStreamManager manager;\n",
    "    \n",
    "    const int N = 1024;\n",
    "    float* d_data[4];\n",
    "    \n",
    "    // Allocate memory for each stream\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        cudaMalloc(&d_data[i], N * sizeof(float));\n",
    "    }\n",
    "    \n",
    "    printf(\"Launching kernels on isolated streams...\\n\\n\");\n",
    "    \n",
    "    // Launch work on each stream\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        streamWorkKernel<<<4, 256, 0, manager.getStream(i)>>>(d_data[i], N, i);\n",
    "        printf(\"  Launched kernel on stream %d\\n\", i);\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nChecking stream status:\\n\");\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        manager.checkStreamStatus(i);\n",
    "    }\n",
    "    \n",
    "    manager.synchronizeHealthyStreams();\n",
    "    \n",
    "    printf(\"\\n  Healthy streams remaining: %d/4\\n\\n\", manager.getHealthyStreamCount());\n",
    "    \n",
    "    // Cleanup\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        cudaFree(d_data[i]);\n",
    "    }\n",
    "    \n",
    "    printf(\"Stream isolation pattern demonstrated!\\n\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\");\n",
    "    printf(\"â•‘    Week 18 Day 3: Error Management - CUDA C++ Exercises      â•‘\\n\");\n",
    "    printf(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\");\n",
    "    \n",
    "    exercise1_error_wrapper();\n",
    "    exercise2_sticky_error_recovery();\n",
    "    exercise3_stream_error_isolation();\n",
    "    \n",
    "    printf(\"All exercises completed!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecdc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -arch=sm_75 -o error_management_exercises error_management_exercises.cu && ./error_management_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806e24b",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "The following exercises use Python with PyCUDA/Numba for those who prefer Python-based GPU programming. Error management is crucial in production Python GPU code as well.\n",
    "\n",
    "**Python Exercise Ideas:**\n",
    "1. Create a Python decorator for automatic CUDA error handling and logging\n",
    "2. Implement a context manager that handles CUDA errors and provides recovery\n",
    "3. Build a Python class for stream-isolated error handling with Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d98ab",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Takeaways\n",
    "\n",
    "### Error Management Mastered! ğŸ¨\n",
    "\n",
    "You've learned to handle GPU emergencies like a hotel's crisis management team:\n",
    "\n",
    "| Pattern | Description | Hotel Analogy |\n",
    "|---------|-------------|---------------|\n",
    "| **Always Check Errors** | Both launch and execution | Suite safety inspections |\n",
    "| **cudaGetLastError()** | Clears non-sticky errors | Clear false alarms |\n",
    "| **Sticky Error Reset** | cudaDeviceReset() required | Full suite renovation |\n",
    "| **Stream Isolation** | One stream's error doesn't spread | Suite firewall |\n",
    "| **Production Logging** | Timestamps and context | Incident reports |\n",
    "| **compute-sanitizer** | Memory and race detection | Building inspector |\n",
    "\n",
    "### ğŸ¨ The Emergency Isolation Principle\n",
    "> \"With MIG, a fire in Suite A triggers local sprinklers without flooding the entire buildingâ€”each partition handles its own errors independently.\"\n",
    "\n",
    "### âš¡ Quick Reference\n",
    "```cpp\n",
    "// Check and clear non-sticky error\n",
    "cudaError_t err = cudaGetLastError();\n",
    "if (err != cudaSuccess) {\n",
    "    log_error(\"Launch failed: %s\", cudaGetErrorString(err));\n",
    "}\n",
    "\n",
    "// For sticky errors, reset is required\n",
    "if (is_sticky_error(err)) {\n",
    "    cudaDeviceReset();  // Only affects current MIG instance\n",
    "}\n",
    "\n",
    "// Stream isolation for fault containment\n",
    "cudaStreamCreate(&isolated_stream);\n",
    "kernel<<<grid, block, 0, isolated_stream>>>(...);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Day 4 - Production Patterns â†’ Running a 5-star GPU operation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
