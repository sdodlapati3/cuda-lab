{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1970b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "print(\"âš ï¸  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46367fce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Update Graphs?\n",
    "\n",
    "### The Problem\n",
    "\n",
    "```\n",
    "Scenario: Training loop with changing data\n",
    "\n",
    "Without Updates (slow):\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "for epoch in range(100):\n",
    "    for batch in batches:\n",
    "        # Rebuild graph every time! (expensive)\n",
    "        capture_graph(batch)  # ~100ms\n",
    "        instantiate()         # ~10ms\n",
    "        launch()              # ~0.1ms\n",
    "\n",
    "With Updates (fast):\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# Build once\n",
    "capture_graph(first_batch)\n",
    "instantiate()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for batch in batches:\n",
    "        update_parameters(batch)  # ~1Î¼s\n",
    "        launch()                  # ~0.1ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d12cb6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Updating Kernel Parameters\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "This example shows how to efficiently update kernel parameters without rebuilding the graph - essential for training loops and batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_update_kernel.cu\n",
    "// graph_update_kernel.cu - Updating kernel parameters\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void scaleAdd(float* data, float scale, float add, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = data[tid] * scale + add;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    // Initial parameters\n",
    "    float scale = 2.0f;\n",
    "    float add = 1.0f;\n",
    "    int n = N;\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // ============================================\n",
    "    // Capture Initial Graph\n",
    "    // ============================================\n",
    "    cudaGraph_t graph;\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    scaleAdd<<<256, 256, 0, stream>>>(d_data, scale, add, n);\n",
    "    \n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // ============================================\n",
    "    // Method 1: Update via Node\n",
    "    // ============================================\n",
    "    \n",
    "    // Get the kernel node from graph\n",
    "    size_t numNodes;\n",
    "    cudaGraphGetNodes(graph, NULL, &numNodes);\n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    cudaGraphGetNodes(graph, nodes, &numNodes);\n",
    "    \n",
    "    // Find the kernel node\n",
    "    cudaGraphNode_t kernelNode = NULL;\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        cudaGraphNodeGetType(nodes[i], &type);\n",
    "        if (type == cudaGraphNodeTypeKernel) {\n",
    "            kernelNode = nodes[i];\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Update parameters\n",
    "    float newScale = 3.0f;\n",
    "    float newAdd = 2.0f;\n",
    "    \n",
    "    cudaKernelNodeParams params;\n",
    "    cudaGraphKernelNodeGetParams(kernelNode, &params);\n",
    "    \n",
    "    // Update kernel arguments\n",
    "    void* newArgs[] = { &d_data, &newScale, &newAdd, &n };\n",
    "    params.kernelParams = newArgs;\n",
    "    \n",
    "    // Apply update to executable graph\n",
    "    cudaGraphExecKernelNodeSetParams(graphExec, kernelNode, &params);\n",
    "    \n",
    "    // Launch with new parameters!\n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    printf(\"Updated kernel with scale=%.1f, add=%.1f\\n\", newScale, newAdd);\n",
    "    \n",
    "    // ============================================\n",
    "    // Method 2: cudaGraphExecUpdate (whole graph)\n",
    "    // ============================================\n",
    "    \n",
    "    // Capture a new graph with different parameters\n",
    "    cudaGraph_t newGraph;\n",
    "    float anotherScale = 4.0f;\n",
    "    \n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    scaleAdd<<<256, 256, 0, stream>>>(d_data, anotherScale, add, n);\n",
    "    cudaStreamEndCapture(stream, &newGraph);\n",
    "    \n",
    "    // Update executable from new graph (must have same topology!)\n",
    "    cudaGraphNode_t errorNode;\n",
    "    cudaGraphExecUpdateResult updateResult;\n",
    "    \n",
    "    cudaGraphExecUpdate(graphExec, newGraph, &errorNode, &updateResult);\n",
    "    \n",
    "    if (updateResult == cudaGraphExecUpdateSuccess) {\n",
    "        printf(\"Graph updated successfully!\\n\");\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "        cudaStreamSynchronize(stream);\n",
    "    } else {\n",
    "        printf(\"Update failed, need to reinstantiate\\n\");\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] nodes;\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaGraphDestroy(newGraph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_update_kernel graph_update_kernel.cu\n",
    "!./graph_update_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db2ee0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Updating Memcpy Nodes\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "This example demonstrates updating data pointers in memcpy nodes - useful for processing multiple buffers with the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419662b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_update_memcpy.cu\n",
    "// graph_update_memcpy.cu - Updating data pointers\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void process(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] *= 2.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    const size_t BYTES = N * sizeof(float);\n",
    "    const int NUM_BUFFERS = 4;\n",
    "    \n",
    "    // Multiple input/output buffers\n",
    "    float* h_inputs[NUM_BUFFERS];\n",
    "    float* h_outputs[NUM_BUFFERS];\n",
    "    for (int i = 0; i < NUM_BUFFERS; i++) {\n",
    "        cudaMallocHost(&h_inputs[i], BYTES);\n",
    "        cudaMallocHost(&h_outputs[i], BYTES);\n",
    "        for (int j = 0; j < N; j++) h_inputs[i][j] = (float)(i + 1);\n",
    "    }\n",
    "    \n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, BYTES);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // Capture with first buffer\n",
    "    cudaGraph_t graph;\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    cudaMemcpyAsync(d_data, h_inputs[0], BYTES, cudaMemcpyHostToDevice, stream);\n",
    "    process<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    cudaMemcpyAsync(h_outputs[0], d_data, BYTES, cudaMemcpyDeviceToHost, stream);\n",
    "    \n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // ============================================\n",
    "    // Get memcpy nodes\n",
    "    // ============================================\n",
    "    size_t numNodes;\n",
    "    cudaGraphGetNodes(graph, NULL, &numNodes);\n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    cudaGraphGetNodes(graph, nodes, &numNodes);\n",
    "    \n",
    "    cudaGraphNode_t h2dNode = NULL, d2hNode = NULL;\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        cudaGraphNodeGetType(nodes[i], &type);\n",
    "        if (type == cudaGraphNodeTypeMemcpy) {\n",
    "            // Determine if H2D or D2H by checking parameters\n",
    "            cudaMemcpy3DParms params;\n",
    "            cudaGraphMemcpyNodeGetParams(nodes[i], &params);\n",
    "            if (params.kind == cudaMemcpyHostToDevice) {\n",
    "                h2dNode = nodes[i];\n",
    "            } else {\n",
    "                d2hNode = nodes[i];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Process each buffer by updating graph\n",
    "    // ============================================\n",
    "    for (int buf = 0; buf < NUM_BUFFERS; buf++) {\n",
    "        // Update H2D source\n",
    "        cudaMemcpy3DParms h2dParams = {0};\n",
    "        h2dParams.srcPtr = make_cudaPitchedPtr(h_inputs[buf], BYTES, N, 1);\n",
    "        h2dParams.dstPtr = make_cudaPitchedPtr(d_data, BYTES, N, 1);\n",
    "        h2dParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "        h2dParams.kind = cudaMemcpyHostToDevice;\n",
    "        cudaGraphExecMemcpyNodeSetParams(graphExec, h2dNode, &h2dParams);\n",
    "        \n",
    "        // Update D2H destination\n",
    "        cudaMemcpy3DParms d2hParams = {0};\n",
    "        d2hParams.srcPtr = make_cudaPitchedPtr(d_data, BYTES, N, 1);\n",
    "        d2hParams.dstPtr = make_cudaPitchedPtr(h_outputs[buf], BYTES, N, 1);\n",
    "        d2hParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "        d2hParams.kind = cudaMemcpyDeviceToHost;\n",
    "        cudaGraphExecMemcpyNodeSetParams(graphExec, d2hNode, &d2hParams);\n",
    "        \n",
    "        // Launch with updated pointers\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "        cudaStreamSynchronize(stream);\n",
    "        \n",
    "        printf(\"Buffer %d: input=%.0f, output=%.0f\\n\", \n",
    "               buf, h_inputs[buf][0], h_outputs[buf][0]);\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] nodes;\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    for (int i = 0; i < NUM_BUFFERS; i++) {\n",
    "        cudaFreeHost(h_inputs[i]);\n",
    "        cudaFreeHost(h_outputs[i]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_update_memcpy graph_update_memcpy.cu\n",
    "!./graph_update_memcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e526a39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Update Limitations\n",
    "\n",
    "### What Can Be Updated\n",
    "\n",
    "```\n",
    "âœ… CAN update:\n",
    "â€¢ Kernel arguments (different values)\n",
    "â€¢ Memcpy source/destination pointers\n",
    "â€¢ Memcpy size (same or smaller)\n",
    "â€¢ Memset values\n",
    "\n",
    "âŒ CANNOT update:\n",
    "â€¢ Graph topology (add/remove nodes)\n",
    "â€¢ Kernel function (different kernel)\n",
    "â€¢ Block/grid dimensions\n",
    "â€¢ Dependency structure\n",
    "â€¢ Node types\n",
    "\n",
    "If you need to change these â†’ Reinstantiate!\n",
    "```\n",
    "\n",
    "### Update Error Handling\n",
    "\n",
    "```cpp\n",
    "cudaGraphNode_t errorNode;\n",
    "cudaGraphExecUpdateResult result;\n",
    "\n",
    "cudaGraphExecUpdate(graphExec, newGraph, &errorNode, &result);\n",
    "\n",
    "switch (result) {\n",
    "    case cudaGraphExecUpdateSuccess:\n",
    "        // Good to go!\n",
    "        break;\n",
    "    case cudaGraphExecUpdateError:\n",
    "        // General error\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorTopologyChanged:\n",
    "        // Graph structure changed - must reinstantiate\n",
    "        cudaGraphExecDestroy(graphExec);\n",
    "        cudaGraphInstantiate(&graphExec, newGraph, NULL, NULL, 0);\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorNodeTypeChanged:\n",
    "        // Node type changed - must reinstantiate\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorFunctionChanged:\n",
    "        // Kernel function changed - must reinstantiate\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorParametersChanged:\n",
    "        // Parameters incompatible\n",
    "        break;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d4c2a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffe8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_updates_exercises.cu\n",
    "/*\n",
    " * CUDA Graph Updates Exercises\n",
    " * Exercise 1: Iterative Updates - Measure update overhead\n",
    " * Exercise 2: Buffer Rotation - Double-buffering with graph updates\n",
    " * Exercise 3: Graceful Fallback - Update with fallback to reinstantiation\n",
    " */\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <chrono>\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA error at %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
    "                   cudaGetErrorString(err)); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// Simple processing kernel\n",
    "__global__ void processKernel(float* data, int n, float scale) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = data[idx] * scale + 1.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// =============================================================\n",
    "// Exercise 1: Iterative Updates\n",
    "// Measure the overhead of updating graph parameters 1000 times\n",
    "// =============================================================\n",
    "void exercise1_iterative_updates() {\n",
    "    printf(\"\\n=== Exercise 1: Iterative Updates ===\\n\");\n",
    "    \n",
    "    const int N = 1024 * 1024;\n",
    "    const int NUM_UPDATES = 1000;\n",
    "    float *d_data;\n",
    "    \n",
    "    CHECK_CUDA(cudaMalloc(&d_data, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMemset(d_data, 0, N * sizeof(float)));\n",
    "    \n",
    "    // Create graph via stream capture\n",
    "    cudaStream_t stream;\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    CHECK_CUDA(cudaStreamCreate(&stream));\n",
    "    CHECK_CUDA(cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal));\n",
    "    \n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    processKernel<<<numBlocks, blockSize, 0, stream>>>(d_data, N, 1.0f);\n",
    "    \n",
    "    CHECK_CUDA(cudaStreamEndCapture(stream, &graph));\n",
    "    CHECK_CUDA(cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0));\n",
    "    \n",
    "    // Get the kernel node\n",
    "    size_t numNodes = 0;\n",
    "    CHECK_CUDA(cudaGraphGetNodes(graph, nullptr, &numNodes));\n",
    "    printf(\"Graph has %zu nodes\\n\", numNodes);\n",
    "    \n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    CHECK_CUDA(cudaGraphGetNodes(graph, nodes, &numNodes));\n",
    "    \n",
    "    // Find the kernel node\n",
    "    cudaGraphNode_t kernelNode = nullptr;\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        CHECK_CUDA(cudaGraphNodeGetType(nodes[i], &type));\n",
    "        if (type == cudaGraphNodeTypeKernel) {\n",
    "            kernelNode = nodes[i];\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if (kernelNode == nullptr) {\n",
    "        printf(\"No kernel node found!\\n\");\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    // Measure update overhead\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    \n",
    "    for (int i = 0; i < NUM_UPDATES; i++) {\n",
    "        // Get current kernel params and update scale\n",
    "        cudaKernelNodeParams nodeParams;\n",
    "        CHECK_CUDA(cudaGraphKernelNodeGetParams(kernelNode, &nodeParams));\n",
    "        \n",
    "        float newScale = 1.0f + (float)i * 0.001f;\n",
    "        void* kernelArgs[] = { &d_data, (void*)&N, &newScale };\n",
    "        nodeParams.kernelParams = kernelArgs;\n",
    "        \n",
    "        CHECK_CUDA(cudaGraphExecKernelNodeSetParams(graphExec, kernelNode, &nodeParams));\n",
    "    }\n",
    "    \n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    double updateTime = std::chrono::duration<double, std::micro>(end - start).count();\n",
    "    \n",
    "    printf(\"Total time for %d updates: %.2f Âµs\\n\", NUM_UPDATES, updateTime);\n",
    "    printf(\"Average time per update: %.2f Âµs\\n\", updateTime / NUM_UPDATES);\n",
    "    \n",
    "    // Launch once to verify\n",
    "    CHECK_CUDA(cudaGraphLaunch(graphExec, stream));\n",
    "    CHECK_CUDA(cudaStreamSynchronize(stream));\n",
    "    printf(\"Graph executed successfully after updates\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] nodes;\n",
    "    CHECK_CUDA(cudaGraphExecDestroy(graphExec));\n",
    "    CHECK_CUDA(cudaGraphDestroy(graph));\n",
    "    CHECK_CUDA(cudaStreamDestroy(stream));\n",
    "    CHECK_CUDA(cudaFree(d_data));\n",
    "}\n",
    "\n",
    "// =============================================================\n",
    "// Exercise 2: Buffer Rotation\n",
    "// Implement double-buffering with graph updates\n",
    "// =============================================================\n",
    "void exercise2_buffer_rotation() {\n",
    "    printf(\"\\n=== Exercise 2: Buffer Rotation ===\\n\");\n",
    "    \n",
    "    const int N = 1024 * 1024;\n",
    "    const int NUM_ITERATIONS = 10;\n",
    "    float *d_bufferA, *d_bufferB;\n",
    "    float *d_buffers[2];\n",
    "    \n",
    "    CHECK_CUDA(cudaMalloc(&d_bufferA, N * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_bufferB, N * sizeof(float)));\n",
    "    d_buffers[0] = d_bufferA;\n",
    "    d_buffers[1] = d_bufferB;\n",
    "    \n",
    "    // Initialize buffer A\n",
    "    float* h_init = new float[N];\n",
    "    for (int i = 0; i < N; i++) h_init[i] = 1.0f;\n",
    "    CHECK_CUDA(cudaMemcpy(d_bufferA, h_init, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // Create graph with buffer A\n",
    "    cudaStream_t stream;\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    CHECK_CUDA(cudaStreamCreate(&stream));\n",
    "    CHECK_CUDA(cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal));\n",
    "    \n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    float* currentBuffer = d_bufferA;\n",
    "    processKernel<<<numBlocks, blockSize, 0, stream>>>(currentBuffer, N, 2.0f);\n",
    "    \n",
    "    CHECK_CUDA(cudaStreamEndCapture(stream, &graph));\n",
    "    CHECK_CUDA(cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0));\n",
    "    \n",
    "    // Get kernel node for updates\n",
    "    size_t numNodes = 0;\n",
    "    CHECK_CUDA(cudaGraphGetNodes(graph, nullptr, &numNodes));\n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    CHECK_CUDA(cudaGraphGetNodes(graph, nodes, &numNodes));\n",
    "    \n",
    "    cudaGraphNode_t kernelNode = nullptr;\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        CHECK_CUDA(cudaGraphNodeGetType(nodes[i], &type));\n",
    "        if (type == cudaGraphNodeTypeKernel) {\n",
    "            kernelNode = nodes[i];\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Alternate between buffers\n",
    "    for (int iter = 0; iter < NUM_ITERATIONS; iter++) {\n",
    "        int bufferIdx = iter % 2;\n",
    "        float* activeBuffer = d_buffers[bufferIdx];\n",
    "        \n",
    "        // Update kernel params to use current buffer\n",
    "        cudaKernelNodeParams nodeParams;\n",
    "        CHECK_CUDA(cudaGraphKernelNodeGetParams(kernelNode, &nodeParams));\n",
    "        \n",
    "        float scale = 2.0f;\n",
    "        int size = N;\n",
    "        void* kernelArgs[] = { &activeBuffer, &size, &scale };\n",
    "        nodeParams.kernelParams = kernelArgs;\n",
    "        \n",
    "        CHECK_CUDA(cudaGraphExecKernelNodeSetParams(graphExec, kernelNode, &nodeParams));\n",
    "        CHECK_CUDA(cudaGraphLaunch(graphExec, stream));\n",
    "        \n",
    "        printf(\"Iteration %d: Using buffer %c\\n\", iter, 'A' + bufferIdx);\n",
    "    }\n",
    "    \n",
    "    CHECK_CUDA(cudaStreamSynchronize(stream));\n",
    "    printf(\"Double-buffering completed successfully\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] h_init;\n",
    "    delete[] nodes;\n",
    "    CHECK_CUDA(cudaGraphExecDestroy(graphExec));\n",
    "    CHECK_CUDA(cudaGraphDestroy(graph));\n",
    "    CHECK_CUDA(cudaStreamDestroy(stream));\n",
    "    CHECK_CUDA(cudaFree(d_bufferA));\n",
    "    CHECK_CUDA(cudaFree(d_bufferB));\n",
    "}\n",
    "\n",
    "// =============================================================\n",
    "// Exercise 3: Graceful Fallback\n",
    "// Update logic with fallback to reinstantiation when needed\n",
    "// =============================================================\n",
    "void exercise3_graceful_fallback() {\n",
    "    printf(\"\\n=== Exercise 3: Graceful Fallback ===\\n\");\n",
    "    \n",
    "    const int N = 1024;\n",
    "    float *d_data;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, N * sizeof(float)));\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    CHECK_CUDA(cudaStreamCreate(&stream));\n",
    "    \n",
    "    // Create initial graph\n",
    "    CHECK_CUDA(cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal));\n",
    "    processKernel<<<4, 256, 0, stream>>>(d_data, N, 1.5f);\n",
    "    CHECK_CUDA(cudaStreamEndCapture(stream, &graph));\n",
    "    CHECK_CUDA(cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0));\n",
    "    \n",
    "    printf(\"Initial graph created and instantiated\\n\");\n",
    "    \n",
    "    // Simulate multiple updates with potential failures\n",
    "    int successfulUpdates = 0;\n",
    "    int fallbackCount = 0;\n",
    "    \n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        // Create a \"new\" graph (simulating topology change on some iterations)\n",
    "        cudaGraph_t newGraph;\n",
    "        CHECK_CUDA(cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal));\n",
    "        \n",
    "        if (i == 2) {\n",
    "            // Simulate topology change - add extra kernel\n",
    "            processKernel<<<4, 256, 0, stream>>>(d_data, N, 1.0f);\n",
    "            processKernel<<<4, 256, 0, stream>>>(d_data, N, 2.0f);\n",
    "            printf(\"Iteration %d: Changed topology (2 kernels)\\n\", i);\n",
    "        } else {\n",
    "            processKernel<<<4, 256, 0, stream>>>(d_data, N, 1.0f + i * 0.1f);\n",
    "            printf(\"Iteration %d: Same topology\\n\", i);\n",
    "        }\n",
    "        \n",
    "        CHECK_CUDA(cudaStreamEndCapture(stream, &newGraph));\n",
    "        \n",
    "        // Try to update existing graphExec\n",
    "        cudaGraphExecUpdateResult updateResult;\n",
    "        cudaGraphNode_t errorNode;\n",
    "        \n",
    "        cudaError_t updateErr = cudaGraphExecUpdate(graphExec, newGraph, &errorNode, &updateResult);\n",
    "        \n",
    "        if (updateErr == cudaSuccess && updateResult == cudaGraphExecUpdateSuccess) {\n",
    "            printf(\"  -> Update succeeded\\n\");\n",
    "            successfulUpdates++;\n",
    "        } else {\n",
    "            printf(\"  -> Update failed (result=%d), falling back to reinstantiation\\n\", updateResult);\n",
    "            \n",
    "            // Fallback: destroy old exec and reinstantiate\n",
    "            CHECK_CUDA(cudaGraphExecDestroy(graphExec));\n",
    "            CHECK_CUDA(cudaGraphInstantiate(&graphExec, newGraph, NULL, NULL, 0));\n",
    "            fallbackCount++;\n",
    "        }\n",
    "        \n",
    "        // Launch the graph\n",
    "        CHECK_CUDA(cudaGraphLaunch(graphExec, stream));\n",
    "        CHECK_CUDA(cudaStreamSynchronize(stream));\n",
    "        \n",
    "        CHECK_CUDA(cudaGraphDestroy(newGraph));\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nSummary:\\n\");\n",
    "    printf(\"  Successful updates: %d\\n\", successfulUpdates);\n",
    "    printf(\"  Fallback reinstantiations: %d\\n\", fallbackCount);\n",
    "    \n",
    "    // Cleanup\n",
    "    CHECK_CUDA(cudaGraphExecDestroy(graphExec));\n",
    "    CHECK_CUDA(cudaGraphDestroy(graph));\n",
    "    CHECK_CUDA(cudaStreamDestroy(stream));\n",
    "    CHECK_CUDA(cudaFree(d_data));\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"CUDA Graph Updates Exercises\\n\");\n",
    "    printf(\"============================\\n\");\n",
    "    \n",
    "    // Check CUDA device\n",
    "    int device;\n",
    "    cudaDeviceProp prop;\n",
    "    CHECK_CUDA(cudaGetDevice(&device));\n",
    "    CHECK_CUDA(cudaGetDeviceProperties(&prop, device));\n",
    "    printf(\"Device: %s\\n\", prop.name);\n",
    "    \n",
    "    exercise1_iterative_updates();\n",
    "    exercise2_buffer_rotation();\n",
    "    exercise3_graceful_fallback();\n",
    "    \n",
    "    printf(\"\\nâœ“ All exercises completed!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_updates_exercises graph_updates_exercises.cu && ./graph_updates_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e630a9",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "### Exercise 1: Iterative Updates\n",
    "Create a graph and update kernel parameters 1000 times, measuring update overhead.\n",
    "\n",
    "### Exercise 2: Buffer Rotation\n",
    "Implement double-buffering with graph updates.\n",
    "\n",
    "### Exercise 3: Graceful Fallback\n",
    "Implement update logic with fallback to reinstantiation when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1edba6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 GRAPH UPDATES                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Per-Node Updates:                                      â”‚\n",
    "â”‚  â€¢ cudaGraphExecKernelNodeSetParams()                   â”‚\n",
    "â”‚  â€¢ cudaGraphExecMemcpyNodeSetParams()                   â”‚\n",
    "â”‚  â€¢ cudaGraphExecMemsetNodeSetParams()                   â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Whole-Graph Update:                                    â”‚\n",
    "â”‚  â€¢ cudaGraphExecUpdate(exec, newGraph, ...)             â”‚\n",
    "â”‚  â€¢ Check result for success/failure                     â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Limitations:                                           â”‚\n",
    "â”‚  â€¢ Topology must stay the same                          â”‚\n",
    "â”‚  â€¢ Kernel function must stay the same                   â”‚\n",
    "â”‚  â€¢ Grid/block dims must stay the same                   â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Performance: Updates are ~1000x faster than rebuild    â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Next: Day 4 - Graph Optimization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
