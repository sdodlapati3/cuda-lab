{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1970b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "print(\"⚠️  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46367fce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Update Graphs?\n",
    "\n",
    "### The Problem\n",
    "\n",
    "```\n",
    "Scenario: Training loop with changing data\n",
    "\n",
    "Without Updates (slow):\n",
    "━━━━━━━━━━━━━━━━━━━━━━━\n",
    "for epoch in range(100):\n",
    "    for batch in batches:\n",
    "        # Rebuild graph every time! (expensive)\n",
    "        capture_graph(batch)  # ~100ms\n",
    "        instantiate()         # ~10ms\n",
    "        launch()              # ~0.1ms\n",
    "\n",
    "With Updates (fast):\n",
    "━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# Build once\n",
    "capture_graph(first_batch)\n",
    "instantiate()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for batch in batches:\n",
    "        update_parameters(batch)  # ~1μs\n",
    "        launch()                  # ~0.1ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d12cb6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Updating Kernel Parameters\n",
    "\n",
    "### CUDA C++ Kernel Node Updates (Primary)\n",
    "\n",
    "This example shows how to efficiently update kernel parameters without rebuilding the graph - essential for training loops and batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_update_kernel.cu\n",
    "// graph_update_kernel.cu - Updating kernel parameters\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void scaleAdd(float* data, float scale, float add, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] = data[tid] * scale + add;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    // Initial parameters\n",
    "    float scale = 2.0f;\n",
    "    float add = 1.0f;\n",
    "    int n = N;\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // ============================================\n",
    "    // Capture Initial Graph\n",
    "    // ============================================\n",
    "    cudaGraph_t graph;\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    scaleAdd<<<256, 256, 0, stream>>>(d_data, scale, add, n);\n",
    "    \n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // ============================================\n",
    "    // Method 1: Update via Node\n",
    "    // ============================================\n",
    "    \n",
    "    // Get the kernel node from graph\n",
    "    size_t numNodes;\n",
    "    cudaGraphGetNodes(graph, NULL, &numNodes);\n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    cudaGraphGetNodes(graph, nodes, &numNodes);\n",
    "    \n",
    "    // Find the kernel node\n",
    "    cudaGraphNode_t kernelNode = NULL;\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        cudaGraphNodeGetType(nodes[i], &type);\n",
    "        if (type == cudaGraphNodeTypeKernel) {\n",
    "            kernelNode = nodes[i];\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Update parameters\n",
    "    float newScale = 3.0f;\n",
    "    float newAdd = 2.0f;\n",
    "    \n",
    "    cudaKernelNodeParams params;\n",
    "    cudaGraphKernelNodeGetParams(kernelNode, &params);\n",
    "    \n",
    "    // Update kernel arguments\n",
    "    void* newArgs[] = { &d_data, &newScale, &newAdd, &n };\n",
    "    params.kernelParams = newArgs;\n",
    "    \n",
    "    // Apply update to executable graph\n",
    "    cudaGraphExecKernelNodeSetParams(graphExec, kernelNode, &params);\n",
    "    \n",
    "    // Launch with new parameters!\n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    printf(\"Updated kernel with scale=%.1f, add=%.1f\\n\", newScale, newAdd);\n",
    "    \n",
    "    // ============================================\n",
    "    // Method 2: cudaGraphExecUpdate (whole graph)\n",
    "    // ============================================\n",
    "    \n",
    "    // Capture a new graph with different parameters\n",
    "    cudaGraph_t newGraph;\n",
    "    float anotherScale = 4.0f;\n",
    "    \n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    scaleAdd<<<256, 256, 0, stream>>>(d_data, anotherScale, add, n);\n",
    "    cudaStreamEndCapture(stream, &newGraph);\n",
    "    \n",
    "    // Update executable from new graph (must have same topology!)\n",
    "    cudaGraphNode_t errorNode;\n",
    "    cudaGraphExecUpdateResult updateResult;\n",
    "    \n",
    "    cudaGraphExecUpdate(graphExec, newGraph, &errorNode, &updateResult);\n",
    "    \n",
    "    if (updateResult == cudaGraphExecUpdateSuccess) {\n",
    "        printf(\"Graph updated successfully!\\n\");\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "        cudaStreamSynchronize(stream);\n",
    "    } else {\n",
    "        printf(\"Update failed, need to reinstantiate\\n\");\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] nodes;\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaGraphDestroy(newGraph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_update_kernel graph_update_kernel.cu\n",
    "!./graph_update_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db2ee0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Updating Memcpy Nodes\n",
    "\n",
    "### CUDA C++ Memcpy Updates (Primary)\n",
    "\n",
    "This example demonstrates updating data pointers in memcpy nodes - useful for processing multiple buffers with the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419662b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_update_memcpy.cu\n",
    "// graph_update_memcpy.cu - Updating data pointers\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void process(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] *= 2.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    const size_t BYTES = N * sizeof(float);\n",
    "    const int NUM_BUFFERS = 4;\n",
    "    \n",
    "    // Multiple input/output buffers\n",
    "    float* h_inputs[NUM_BUFFERS];\n",
    "    float* h_outputs[NUM_BUFFERS];\n",
    "    for (int i = 0; i < NUM_BUFFERS; i++) {\n",
    "        cudaMallocHost(&h_inputs[i], BYTES);\n",
    "        cudaMallocHost(&h_outputs[i], BYTES);\n",
    "        for (int j = 0; j < N; j++) h_inputs[i][j] = (float)(i + 1);\n",
    "    }\n",
    "    \n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, BYTES);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // Capture with first buffer\n",
    "    cudaGraph_t graph;\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    cudaMemcpyAsync(d_data, h_inputs[0], BYTES, cudaMemcpyHostToDevice, stream);\n",
    "    process<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    cudaMemcpyAsync(h_outputs[0], d_data, BYTES, cudaMemcpyDeviceToHost, stream);\n",
    "    \n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // ============================================\n",
    "    // Get memcpy nodes\n",
    "    // ============================================\n",
    "    size_t numNodes;\n",
    "    cudaGraphGetNodes(graph, NULL, &numNodes);\n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    cudaGraphGetNodes(graph, nodes, &numNodes);\n",
    "    \n",
    "    cudaGraphNode_t h2dNode = NULL, d2hNode = NULL;\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        cudaGraphNodeGetType(nodes[i], &type);\n",
    "        if (type == cudaGraphNodeTypeMemcpy) {\n",
    "            // Determine if H2D or D2H by checking parameters\n",
    "            cudaMemcpy3DParms params;\n",
    "            cudaGraphMemcpyNodeGetParams(nodes[i], &params);\n",
    "            if (params.kind == cudaMemcpyHostToDevice) {\n",
    "                h2dNode = nodes[i];\n",
    "            } else {\n",
    "                d2hNode = nodes[i];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ============================================\n",
    "    // Process each buffer by updating graph\n",
    "    // ============================================\n",
    "    for (int buf = 0; buf < NUM_BUFFERS; buf++) {\n",
    "        // Update H2D source\n",
    "        cudaMemcpy3DParms h2dParams = {0};\n",
    "        h2dParams.srcPtr = make_cudaPitchedPtr(h_inputs[buf], BYTES, N, 1);\n",
    "        h2dParams.dstPtr = make_cudaPitchedPtr(d_data, BYTES, N, 1);\n",
    "        h2dParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "        h2dParams.kind = cudaMemcpyHostToDevice;\n",
    "        cudaGraphExecMemcpyNodeSetParams(graphExec, h2dNode, &h2dParams);\n",
    "        \n",
    "        // Update D2H destination\n",
    "        cudaMemcpy3DParms d2hParams = {0};\n",
    "        d2hParams.srcPtr = make_cudaPitchedPtr(d_data, BYTES, N, 1);\n",
    "        d2hParams.dstPtr = make_cudaPitchedPtr(h_outputs[buf], BYTES, N, 1);\n",
    "        d2hParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "        d2hParams.kind = cudaMemcpyDeviceToHost;\n",
    "        cudaGraphExecMemcpyNodeSetParams(graphExec, d2hNode, &d2hParams);\n",
    "        \n",
    "        // Launch with updated pointers\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "        cudaStreamSynchronize(stream);\n",
    "        \n",
    "        printf(\"Buffer %d: input=%.0f, output=%.0f\\n\", \n",
    "               buf, h_inputs[buf][0], h_outputs[buf][0]);\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] nodes;\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    for (int i = 0; i < NUM_BUFFERS; i++) {\n",
    "        cudaFreeHost(h_inputs[i]);\n",
    "        cudaFreeHost(h_outputs[i]);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_update_memcpy graph_update_memcpy.cu\n",
    "!./graph_update_memcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e526a39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Update Limitations\n",
    "\n",
    "### What Can Be Updated\n",
    "\n",
    "```\n",
    "✅ CAN update:\n",
    "• Kernel arguments (different values)\n",
    "• Memcpy source/destination pointers\n",
    "• Memcpy size (same or smaller)\n",
    "• Memset values\n",
    "\n",
    "❌ CANNOT update:\n",
    "• Graph topology (add/remove nodes)\n",
    "• Kernel function (different kernel)\n",
    "• Block/grid dimensions\n",
    "• Dependency structure\n",
    "• Node types\n",
    "\n",
    "If you need to change these → Reinstantiate!\n",
    "```\n",
    "\n",
    "### Update Error Handling\n",
    "\n",
    "```cpp\n",
    "cudaGraphNode_t errorNode;\n",
    "cudaGraphExecUpdateResult result;\n",
    "\n",
    "cudaGraphExecUpdate(graphExec, newGraph, &errorNode, &result);\n",
    "\n",
    "switch (result) {\n",
    "    case cudaGraphExecUpdateSuccess:\n",
    "        // Good to go!\n",
    "        break;\n",
    "    case cudaGraphExecUpdateError:\n",
    "        // General error\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorTopologyChanged:\n",
    "        // Graph structure changed - must reinstantiate\n",
    "        cudaGraphExecDestroy(graphExec);\n",
    "        cudaGraphInstantiate(&graphExec, newGraph, NULL, NULL, 0);\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorNodeTypeChanged:\n",
    "        // Node type changed - must reinstantiate\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorFunctionChanged:\n",
    "        // Kernel function changed - must reinstantiate\n",
    "        break;\n",
    "    case cudaGraphExecUpdateErrorParametersChanged:\n",
    "        // Parameters incompatible\n",
    "        break;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d4c2a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Iterative Updates\n",
    "Create a graph and update kernel parameters 1000 times, measuring update overhead.\n",
    "\n",
    "### Exercise 2: Buffer Rotation\n",
    "Implement double-buffering with graph updates.\n",
    "\n",
    "### Exercise 3: Graceful Fallback\n",
    "Implement update logic with fallback to reinstantiation when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1edba6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                 GRAPH UPDATES                           │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│                                                         │\n",
    "│  Per-Node Updates:                                      │\n",
    "│  • cudaGraphExecKernelNodeSetParams()                   │\n",
    "│  • cudaGraphExecMemcpyNodeSetParams()                   │\n",
    "│  • cudaGraphExecMemsetNodeSetParams()                   │\n",
    "│                                                         │\n",
    "│  Whole-Graph Update:                                    │\n",
    "│  • cudaGraphExecUpdate(exec, newGraph, ...)             │\n",
    "│  • Check result for success/failure                     │\n",
    "│                                                         │\n",
    "│  Limitations:                                           │\n",
    "│  • Topology must stay the same                          │\n",
    "│  • Kernel function must stay the same                   │\n",
    "│  • Grid/block dims must stay the same                   │\n",
    "│                                                         │\n",
    "│  Performance: Updates are ~1000x faster than rebuild    │\n",
    "│                                                         │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Next: Day 4 - Graph Optimization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
