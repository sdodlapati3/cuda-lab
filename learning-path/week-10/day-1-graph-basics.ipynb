{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"âš ï¸  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fa35d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Problem Graphs Solve\n",
    "\n",
    "### Kernel Launch Overhead\n",
    "\n",
    "```\n",
    "Traditional Stream Execution:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CPU: [Launch K1][Launch K2][Launch K3][Launch K4]\n",
    "          â†“          â†“          â†“          â†“\n",
    "GPU:   [  K1  ]  [  K2  ]  [  K3  ]  [  K4  ]\n",
    "\n",
    "Each launch: ~5-10 Î¼s overhead\n",
    "If kernels are fast (10 Î¼s), overhead = 50% of time!\n",
    "\n",
    "With CUDA Graph:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CPU: [Launch Graph]  (single call!)\n",
    "          â†“\n",
    "GPU: [K1][K2][K3][K4]  (all pre-planned)\n",
    "\n",
    "Launch overhead: ~5-10 Î¼s TOTAL\n",
    "```\n",
    "\n",
    "### When Graphs Help\n",
    "\n",
    "```\n",
    "âœ… Good for Graphs:\n",
    "â€¢ Repetitive workflows (training loops)\n",
    "â€¢ Many small kernels\n",
    "â€¢ Fixed computation pattern\n",
    "â€¢ Inference pipelines\n",
    "\n",
    "âŒ Not Ideal:\n",
    "â€¢ Dynamic control flow\n",
    "â€¢ Frequently changing shapes\n",
    "â€¢ Single large kernel\n",
    "â€¢ One-time computations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a252e4b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Stream Capture\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "The following example demonstrates creating CUDA graphs via stream capture - the easiest way to create graphs from existing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_capture.cu\n",
    "// graph_capture.cu - Creating graphs via stream capture\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void scaleKernel(float* data, float scale, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] *= scale;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void addKernel(float* data, float value, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) {\n",
    "        data[tid] += value;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    const size_t BYTES = N * sizeof(float);\n",
    "    \n",
    "    // Allocate pinned host and device memory\n",
    "    float *h_data, *d_data;\n",
    "    cudaMallocHost(&h_data, BYTES);\n",
    "    cudaMalloc(&d_data, BYTES);\n",
    "    \n",
    "    for (int i = 0; i < N; i++) h_data[i] = 1.0f;\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // ============================================\n",
    "    // STEP 1: Begin Stream Capture\n",
    "    // ============================================\n",
    "    cudaGraph_t graph;\n",
    "    \n",
    "    // Start capturing operations\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    // All operations on this stream are now recorded (not executed!)\n",
    "    cudaMemcpyAsync(d_data, h_data, BYTES, cudaMemcpyHostToDevice, stream);\n",
    "    scaleKernel<<<256, 256, 0, stream>>>(d_data, 2.0f, N);\n",
    "    addKernel<<<256, 256, 0, stream>>>(d_data, 1.0f, N);\n",
    "    scaleKernel<<<256, 256, 0, stream>>>(d_data, 0.5f, N);\n",
    "    cudaMemcpyAsync(h_data, d_data, BYTES, cudaMemcpyDeviceToHost, stream);\n",
    "    \n",
    "    // ============================================\n",
    "    // STEP 2: End Capture and Get Graph\n",
    "    // ============================================\n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    // ============================================\n",
    "    // STEP 3: Instantiate Graph (compile it)\n",
    "    // ============================================\n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // ============================================\n",
    "    // STEP 4: Launch Graph (can do many times!)\n",
    "    // ============================================\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    const int ITERATIONS = 100;\n",
    "    \n",
    "    // Time graph launches\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    float graphTime;\n",
    "    cudaEventElapsedTime(&graphTime, start, stop);\n",
    "    \n",
    "    printf(\"Graph: %d iterations in %.2f ms (%.2f us/iter)\\n\",\n",
    "           ITERATIONS, graphTime, graphTime * 1000 / ITERATIONS);\n",
    "    \n",
    "    // ============================================\n",
    "    // Compare with Stream (no graph)\n",
    "    // ============================================\n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        cudaMemcpyAsync(d_data, h_data, BYTES, cudaMemcpyHostToDevice, stream);\n",
    "        scaleKernel<<<256, 256, 0, stream>>>(d_data, 2.0f, N);\n",
    "        addKernel<<<256, 256, 0, stream>>>(d_data, 1.0f, N);\n",
    "        scaleKernel<<<256, 256, 0, stream>>>(d_data, 0.5f, N);\n",
    "        cudaMemcpyAsync(h_data, d_data, BYTES, cudaMemcpyDeviceToHost, stream);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    float streamTime;\n",
    "    cudaEventElapsedTime(&streamTime, start, stop);\n",
    "    \n",
    "    printf(\"Stream: %d iterations in %.2f ms (%.2f us/iter)\\n\",\n",
    "           ITERATIONS, streamTime, streamTime * 1000 / ITERATIONS);\n",
    "    printf(\"Speedup: %.2fx\\n\", streamTime / graphTime);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFreeHost(h_data);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad919d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_capture graph_capture.cu\n",
    "!./graph_capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c271e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Graph Lifecycle\n",
    "\n",
    "### The Three Objects\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  CUDA GRAPH LIFECYCLE                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  1. cudaGraph_t (Template)                              â”‚\n",
    "â”‚     â””â”€ Definition of operations and dependencies       â”‚\n",
    "â”‚     â””â”€ Created by capture or explicit construction     â”‚\n",
    "â”‚     â””â”€ Can be inspected, modified, cloned              â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  2. cudaGraphExec_t (Executable)                        â”‚\n",
    "â”‚     â””â”€ Compiled/instantiated version of graph          â”‚\n",
    "â”‚     â””â”€ Ready for launch                                 â”‚\n",
    "â”‚     â””â”€ Some parameters can be updated                   â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  3. cudaStream_t (Where it runs)                        â”‚\n",
    "â”‚     â””â”€ Graph launches into a stream                     â”‚\n",
    "â”‚     â””â”€ Follows stream ordering rules                    â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Workflow:                                              â”‚\n",
    "â”‚  Capture/Build â†’ Graph â†’ Instantiate â†’ GraphExec       â”‚\n",
    "â”‚                                            â†“            â”‚\n",
    "â”‚                              Launch (many times!)       â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Capture Modes\n",
    "\n",
    "```cpp\n",
    "// Capture mode options:\n",
    "\n",
    "// cudaStreamCaptureModeGlobal\n",
    "// - Any operation in any thread on capturing stream is captured\n",
    "// - Most common for single-threaded code\n",
    "cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "\n",
    "// cudaStreamCaptureModeThreadLocal  \n",
    "// - Only operations from this thread are captured\n",
    "cudaStreamBeginCapture(stream, cudaStreamCaptureModeThreadLocal);\n",
    "\n",
    "// cudaStreamCaptureModeRelaxed\n",
    "// - Doesn't insert sync barriers, slightly faster capture\n",
    "cudaStreamBeginCapture(stream, cudaStreamCaptureModeRelaxed);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715bdf8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Capture Rules and Restrictions\n",
    "\n",
    "### What Can Be Captured?\n",
    "\n",
    "```\n",
    "âœ… CAN be captured:\n",
    "â€¢ Kernel launches\n",
    "â€¢ cudaMemcpyAsync\n",
    "â€¢ cudaMemsetAsync\n",
    "â€¢ Events (record/wait)\n",
    "â€¢ Child graph launches\n",
    "\n",
    "âŒ CANNOT be captured:\n",
    "â€¢ cudaMemcpy (synchronous!)\n",
    "â€¢ cudaMalloc/cudaFree\n",
    "â€¢ cudaDeviceSynchronize\n",
    "â€¢ CPU operations\n",
    "â€¢ Cross-stream sync (without events)\n",
    "```\n",
    "\n",
    "### ğŸ”· CUDA C++ Implementation (Primary)\n",
    "\n",
    "The following example shows how to capture operations across multiple streams into a single graph, creating parallel execution branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multi_stream_capture.cu\n",
    "// multi_stream_capture.cu - Capturing multiple streams\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void workA(float* a, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) a[tid] *= 2.0f;\n",
    "}\n",
    "\n",
    "__global__ void workB(float* b, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) b[tid] += 1.0f;\n",
    "}\n",
    "\n",
    "__global__ void combine(float* a, float* b, float* c, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) c[tid] = a[tid] + b[tid];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, N * sizeof(float));\n",
    "    cudaMalloc(&d_b, N * sizeof(float));\n",
    "    cudaMalloc(&d_c, N * sizeof(float));\n",
    "    \n",
    "    cudaStream_t streamMain, streamA, streamB;\n",
    "    cudaStreamCreate(&streamMain);\n",
    "    cudaStreamCreate(&streamA);\n",
    "    cudaStreamCreate(&streamB);\n",
    "    \n",
    "    cudaEvent_t forkEvent, joinA, joinB;\n",
    "    cudaEventCreate(&forkEvent);\n",
    "    cudaEventCreate(&joinA);\n",
    "    cudaEventCreate(&joinB);\n",
    "    \n",
    "    cudaGraph_t graph;\n",
    "    \n",
    "    // Begin capture on main stream\n",
    "    cudaStreamBeginCapture(streamMain, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    // Record fork point\n",
    "    cudaEventRecord(forkEvent, streamMain);\n",
    "    \n",
    "    // Stream A waits for fork, does work\n",
    "    cudaStreamWaitEvent(streamA, forkEvent);\n",
    "    workA<<<256, 256, 0, streamA>>>(d_a, N);\n",
    "    cudaEventRecord(joinA, streamA);\n",
    "    \n",
    "    // Stream B waits for fork, does work\n",
    "    cudaStreamWaitEvent(streamB, forkEvent);\n",
    "    workB<<<256, 256, 0, streamB>>>(d_b, N);\n",
    "    cudaEventRecord(joinB, streamB);\n",
    "    \n",
    "    // Main stream waits for both, combines\n",
    "    cudaStreamWaitEvent(streamMain, joinA);\n",
    "    cudaStreamWaitEvent(streamMain, joinB);\n",
    "    combine<<<256, 256, 0, streamMain>>>(d_a, d_b, d_c, N);\n",
    "    \n",
    "    // End capture\n",
    "    cudaStreamEndCapture(streamMain, &graph);\n",
    "    \n",
    "    // Graph now contains:\n",
    "    //     fork\n",
    "    //    /    \\\n",
    "    // workA  workB\n",
    "    //    \\    /\n",
    "    //   combine\n",
    "    \n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // Launch!\n",
    "    cudaGraphLaunch(graphExec, streamMain);\n",
    "    cudaStreamSynchronize(streamMain);\n",
    "    \n",
    "    printf(\"Multi-stream graph executed!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(streamMain);\n",
    "    cudaStreamDestroy(streamA);\n",
    "    cudaStreamDestroy(streamB);\n",
    "    cudaEventDestroy(forkEvent);\n",
    "    cudaEventDestroy(joinA);\n",
    "    cudaEventDestroy(joinB);\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o multi_stream_capture multi_stream_capture.cu\n",
    "!./multi_stream_capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d922317",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba (Optional - Quick Testing)\n",
    "\n",
    "CUDA Graphs are not directly supported in Numba. For graph functionality, use CUDA C++ or libraries like CuPy. Here's a simulation of the concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def kernel1(data):\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < data.shape[0]:\n",
    "        data[tid] *= 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def kernel2(data):\n",
    "    tid = cuda.grid(1)\n",
    "    if tid < data.shape[0]:\n",
    "        data[tid] += 1.0\n",
    "\n",
    "# Without graphs: each call has overhead\n",
    "n = 1 << 18\n",
    "d_data = cuda.device_array(n, dtype=np.float32)\n",
    "\n",
    "# Warmup\n",
    "kernel1[(n+255)//256, 256](d_data)\n",
    "kernel2[(n+255)//256, 256](d_data)\n",
    "cuda.synchronize()\n",
    "\n",
    "# Time\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    kernel1[(n+255)//256, 256](d_data)\n",
    "    kernel2[(n+255)//256, 256](d_data)\n",
    "cuda.synchronize()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"100 iterations (no graphs): {elapsed*1000:.2f} ms\")\n",
    "print(\"Note: CUDA Graphs require CUDA C++ for direct usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3cd2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Exercises\n",
    "\n",
    "### ğŸ”· CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e881b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_basics_exercises.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA Error: %s at line %d\\n\", cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void simpleKernel(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = sinf(data[idx]) + 1.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 1: Basic Capture - 5-Kernel Pipeline\n",
    "// ============================================================\n",
    "\n",
    "void exercise1_basicCapture() {\n",
    "    printf(\"=== Exercise 1: Basic Capture (5 Kernels) ===\\n\");\n",
    "    \n",
    "    const int n = 1 << 18;\n",
    "    const int numKernels = 5;\n",
    "    const int iterations = 100;\n",
    "    \n",
    "    float* d_data;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, n * sizeof(float)));\n",
    "    \n",
    "    int grid = (n + 255) / 256;\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Without graphs\n",
    "    cudaEventRecord(start, stream);\n",
    "    for (int iter = 0; iter < iterations; iter++) {\n",
    "        for (int k = 0; k < numKernels; k++) {\n",
    "            simpleKernel<<<grid, 256, 0, stream>>>(d_data, n);\n",
    "        }\n",
    "    }\n",
    "    cudaEventRecord(stop, stream);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float noGraphMs;\n",
    "    cudaEventElapsedTime(&noGraphMs, start, stop);\n",
    "    \n",
    "    // With CUDA Graph\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    // Capture the graph\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    for (int k = 0; k < numKernels; k++) {\n",
    "        simpleKernel<<<grid, 256, 0, stream>>>(d_data, n);\n",
    "    }\n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // Execute graph\n",
    "    cudaEventRecord(start, stream);\n",
    "    for (int iter = 0; iter < iterations; iter++) {\n",
    "        cudaGraphLaunch(graphExec, stream);\n",
    "    }\n",
    "    cudaEventRecord(stop, stream);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float withGraphMs;\n",
    "    cudaEventElapsedTime(&withGraphMs, start, stop);\n",
    "    \n",
    "    printf(\"Without graph: %.2f ms\\n\", noGraphMs);\n",
    "    printf(\"With graph:    %.2f ms\\n\", withGraphMs);\n",
    "    printf(\"Speedup:       %.2fx\\n\\n\", noGraphMs / withGraphMs);\n",
    "    \n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaFree(d_data);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 2: Find Break-Even Point\n",
    "// ============================================================\n",
    "\n",
    "void exercise2_findBreakEven() {\n",
    "    printf(\"=== Exercise 2: Find Break-Even Point ===\\n\");\n",
    "    \n",
    "    const int n = 1 << 16;  // Smaller for more kernel overhead visibility\n",
    "    const int iterations = 100;\n",
    "    \n",
    "    float* d_data;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, n * sizeof(float)));\n",
    "    \n",
    "    int grid = (n + 255) / 256;\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    int kernelCounts[] = {1, 2, 3, 4, 5, 10, 20, 50};\n",
    "    int numTests = sizeof(kernelCounts) / sizeof(kernelCounts[0]);\n",
    "    \n",
    "    printf(\"%-10s %-15s %-15s %-10s\\n\", \"Kernels\", \"No Graph\", \"With Graph\", \"Speedup\");\n",
    "    printf(\"------------------------------------------------------\\n\");\n",
    "    \n",
    "    int breakEven = -1;\n",
    "    \n",
    "    for (int t = 0; t < numTests; t++) {\n",
    "        int numKernels = kernelCounts[t];\n",
    "        \n",
    "        // Without graph\n",
    "        cudaEventRecord(start, stream);\n",
    "        for (int iter = 0; iter < iterations; iter++) {\n",
    "            for (int k = 0; k < numKernels; k++) {\n",
    "                simpleKernel<<<grid, 256, 0, stream>>>(d_data, n);\n",
    "            }\n",
    "        }\n",
    "        cudaEventRecord(stop, stream);\n",
    "        cudaEventSynchronize(stop);\n",
    "        float noGraphMs;\n",
    "        cudaEventElapsedTime(&noGraphMs, start, stop);\n",
    "        \n",
    "        // With graph\n",
    "        cudaGraph_t graph;\n",
    "        cudaGraphExec_t graphExec;\n",
    "        \n",
    "        cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "        for (int k = 0; k < numKernels; k++) {\n",
    "            simpleKernel<<<grid, 256, 0, stream>>>(d_data, n);\n",
    "        }\n",
    "        cudaStreamEndCapture(stream, &graph);\n",
    "        cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "        \n",
    "        cudaEventRecord(start, stream);\n",
    "        for (int iter = 0; iter < iterations; iter++) {\n",
    "            cudaGraphLaunch(graphExec, stream);\n",
    "        }\n",
    "        cudaEventRecord(stop, stream);\n",
    "        cudaEventSynchronize(stop);\n",
    "        float withGraphMs;\n",
    "        cudaEventElapsedTime(&withGraphMs, start, stop);\n",
    "        \n",
    "        float speedup = noGraphMs / withGraphMs;\n",
    "        printf(\"%-10d %-12.2f ms %-12.2f ms %.2fx\", numKernels, noGraphMs, withGraphMs, speedup);\n",
    "        \n",
    "        if (speedup > 1.0 && breakEven == -1) {\n",
    "            breakEven = numKernels;\n",
    "            printf(\" <- break-even\");\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "        \n",
    "        cudaGraphExecDestroy(graphExec);\n",
    "        cudaGraphDestroy(graph);\n",
    "    }\n",
    "    \n",
    "    printf(\"\\nBreak-even point: %d kernels\\n\\n\", breakEven);\n",
    "    \n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaFree(d_data);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 3: Multi-Stream Graph (Fork-Join)\n",
    "// ============================================================\n",
    "\n",
    "__global__ void branchKernel(float* data, int n, float multiplier) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        data[idx] = data[idx] * multiplier;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void joinKernel(const float* a, const float* b, const float* c, \n",
    "                            float* result, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        result[idx] = a[idx] + b[idx] + c[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "void exercise3_forkJoinGraph() {\n",
    "    printf(\"=== Exercise 3: Fork-Join Graph ===\\n\");\n",
    "    printf(\"Graph structure: Fork into 3 branches, then join\\n\\n\");\n",
    "    \n",
    "    const int n = 1 << 18;\n",
    "    const int iterations = 100;\n",
    "    \n",
    "    float *d_input, *d_a, *d_b, *d_c, *d_output;\n",
    "    CHECK_CUDA(cudaMalloc(&d_input, n * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_a, n * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_b, n * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_c, n * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_output, n * sizeof(float)));\n",
    "    \n",
    "    int grid = (n + 255) / 256;\n",
    "    \n",
    "    // Create multiple streams for fork-join\n",
    "    cudaStream_t mainStream, branchA, branchB, branchC;\n",
    "    cudaStreamCreate(&mainStream);\n",
    "    cudaStreamCreate(&branchA);\n",
    "    cudaStreamCreate(&branchB);\n",
    "    cudaStreamCreate(&branchC);\n",
    "    \n",
    "    cudaEvent_t forkEvent, joinEventA, joinEventB, joinEventC;\n",
    "    cudaEventCreate(&forkEvent);\n",
    "    cudaEventCreate(&joinEventA);\n",
    "    cudaEventCreate(&joinEventB);\n",
    "    cudaEventCreate(&joinEventC);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Capture fork-join pattern into graph\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphExec_t graphExec;\n",
    "    \n",
    "    cudaStreamBeginCapture(mainStream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    // Initial processing\n",
    "    simpleKernel<<<grid, 256, 0, mainStream>>>(d_input, n);\n",
    "    cudaEventRecord(forkEvent, mainStream);\n",
    "    \n",
    "    // Fork to 3 branches\n",
    "    cudaStreamWaitEvent(branchA, forkEvent);\n",
    "    cudaMemcpyAsync(d_a, d_input, n * sizeof(float), cudaMemcpyDeviceToDevice, branchA);\n",
    "    branchKernel<<<grid, 256, 0, branchA>>>(d_a, n, 1.5f);\n",
    "    cudaEventRecord(joinEventA, branchA);\n",
    "    \n",
    "    cudaStreamWaitEvent(branchB, forkEvent);\n",
    "    cudaMemcpyAsync(d_b, d_input, n * sizeof(float), cudaMemcpyDeviceToDevice, branchB);\n",
    "    branchKernel<<<grid, 256, 0, branchB>>>(d_b, n, 2.0f);\n",
    "    cudaEventRecord(joinEventB, branchB);\n",
    "    \n",
    "    cudaStreamWaitEvent(branchC, forkEvent);\n",
    "    cudaMemcpyAsync(d_c, d_input, n * sizeof(float), cudaMemcpyDeviceToDevice, branchC);\n",
    "    branchKernel<<<grid, 256, 0, branchC>>>(d_c, n, 2.5f);\n",
    "    cudaEventRecord(joinEventC, branchC);\n",
    "    \n",
    "    // Join\n",
    "    cudaStreamWaitEvent(mainStream, joinEventA);\n",
    "    cudaStreamWaitEvent(mainStream, joinEventB);\n",
    "    cudaStreamWaitEvent(mainStream, joinEventC);\n",
    "    joinKernel<<<grid, 256, 0, mainStream>>>(d_a, d_b, d_c, d_output, n);\n",
    "    \n",
    "    cudaStreamEndCapture(mainStream, &graph);\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    // Execute graph multiple times\n",
    "    cudaEventRecord(start, mainStream);\n",
    "    for (int iter = 0; iter < iterations; iter++) {\n",
    "        cudaGraphLaunch(graphExec, mainStream);\n",
    "    }\n",
    "    cudaEventRecord(stop, mainStream);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    printf(\"Fork-join graph (%d iterations): %.2f ms\\n\", iterations, ms);\n",
    "    printf(\"Per-iteration: %.3f ms\\n\\n\", ms / iterations);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(mainStream);\n",
    "    cudaStreamDestroy(branchA);\n",
    "    cudaStreamDestroy(branchB);\n",
    "    cudaStreamDestroy(branchC);\n",
    "    cudaEventDestroy(forkEvent);\n",
    "    cudaEventDestroy(joinEventA);\n",
    "    cudaEventDestroy(joinEventB);\n",
    "    cudaEventDestroy(joinEventC);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    cudaFree(d_output);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\");\n",
    "    printf(\"â•‘              CUDA Graph Basics Exercises                     â•‘\\n\");\n",
    "    printf(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\");\n",
    "    \n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    printf(\"Device: %s\\n\\n\", prop.name);\n",
    "    \n",
    "    exercise1_basicCapture();\n",
    "    exercise2_findBreakEven();\n",
    "    exercise3_forkJoinGraph();\n",
    "    \n",
    "    printf(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    printf(\"                    All exercises completed!\\n\");\n",
    "    printf(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19492f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_basics_exercises graph_basics_exercises.cu && ./graph_basics_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c629f",
   "metadata": {},
   "source": [
    "### ğŸ”¶ Python/Numba Exercises (Optional)\n",
    "\n",
    "### Exercise 1: Basic Capture\n",
    "Capture a pipeline with 5 kernels and measure speedup.\n",
    "\n",
    "### Exercise 2: Find Break-Even\n",
    "At what number of kernels does graph overhead pay off?\n",
    "\n",
    "### Exercise 3: Multi-Stream Graph\n",
    "Create a graph with fork-join pattern (parallel branches)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0811e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 GRAPH BASICS                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Stream Capture:                                        â”‚\n",
    "â”‚  1. cudaStreamBeginCapture(stream, mode)                â”‚\n",
    "â”‚  2. ... operations ...                                  â”‚\n",
    "â”‚  3. cudaStreamEndCapture(stream, &graph)                â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Execution:                                             â”‚\n",
    "â”‚  4. cudaGraphInstantiate(&exec, graph, ...)             â”‚\n",
    "â”‚  5. cudaGraphLaunch(exec, stream)                       â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Benefits:                                              â”‚\n",
    "â”‚  â€¢ Reduced launch overhead                              â”‚\n",
    "â”‚  â€¢ Pre-planned dependencies                             â”‚\n",
    "â”‚  â€¢ Good for repetitive patterns                         â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Next: Day 2 - Explicit Graph Construction"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
