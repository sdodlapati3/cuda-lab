{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c32303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"⚠️  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e472d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Explicit Construction?\n",
    "\n",
    "### Capture vs Explicit\n",
    "\n",
    "```\n",
    "Stream Capture:\n",
    "━━━━━━━━━━━━━━━\n",
    "✅ Easy - just run code in capture mode\n",
    "✅ Natural for converting existing code\n",
    "❌ Limited control over structure\n",
    "❌ Can't build graphs dynamically\n",
    "\n",
    "Explicit Construction:\n",
    "━━━━━━━━━━━━━━━━━━━━━\n",
    "✅ Full control over graph structure\n",
    "✅ Can build programmatically\n",
    "✅ More flexible dependencies\n",
    "❌ More verbose code\n",
    "❌ Need to manage node handles\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c31796",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building a Simple Graph\n",
    "\n",
    "### CUDA C++ Explicit Graph (Primary)\n",
    "\n",
    "This example demonstrates building a graph node by node, giving you full control over the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1da4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile explicit_graph.cu\n",
    "// explicit_graph.cu - Building graphs node by node\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void kernelA(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] *= 2.0f;\n",
    "}\n",
    "\n",
    "__global__ void kernelB(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] += 1.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    const size_t BYTES = N * sizeof(float);\n",
    "    \n",
    "    float *h_data, *d_data;\n",
    "    cudaMallocHost(&h_data, BYTES);\n",
    "    cudaMalloc(&d_data, BYTES);\n",
    "    \n",
    "    for (int i = 0; i < N; i++) h_data[i] = 1.0f;\n",
    "    \n",
    "    // ============================================\n",
    "    // Create Empty Graph\n",
    "    // ============================================\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphCreate(&graph, 0);  // 0 = flags (none)\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Memcpy Node (H2D)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t h2dNode;\n",
    "    cudaMemcpy3DParms h2dParams = {0};\n",
    "    h2dParams.srcPtr = make_cudaPitchedPtr((void*)h_data, BYTES, N, 1);\n",
    "    h2dParams.dstPtr = make_cudaPitchedPtr((void*)d_data, BYTES, N, 1);\n",
    "    h2dParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "    h2dParams.kind = cudaMemcpyHostToDevice;\n",
    "    \n",
    "    cudaGraphAddMemcpyNode(&h2dNode, graph, \n",
    "                           NULL, 0,  // No dependencies\n",
    "                           &h2dParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Kernel Node A (depends on H2D)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t kernelANode;\n",
    "    \n",
    "    cudaKernelNodeParams kernelAParams = {0};\n",
    "    void* argsA[] = { &d_data, (void*)&N };\n",
    "    \n",
    "    kernelAParams.func = (void*)kernelA;\n",
    "    kernelAParams.gridDim = dim3(256);\n",
    "    kernelAParams.blockDim = dim3(256);\n",
    "    kernelAParams.sharedMemBytes = 0;\n",
    "    kernelAParams.kernelParams = argsA;\n",
    "    kernelAParams.extra = NULL;\n",
    "    \n",
    "    cudaGraphNode_t depA[] = { h2dNode };  // Depends on H2D\n",
    "    cudaGraphAddKernelNode(&kernelANode, graph, \n",
    "                           depA, 1,  // 1 dependency\n",
    "                           &kernelAParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Kernel Node B (depends on Kernel A)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t kernelBNode;\n",
    "    \n",
    "    cudaKernelNodeParams kernelBParams = {0};\n",
    "    void* argsB[] = { &d_data, (void*)&N };\n",
    "    \n",
    "    kernelBParams.func = (void*)kernelB;\n",
    "    kernelBParams.gridDim = dim3(256);\n",
    "    kernelBParams.blockDim = dim3(256);\n",
    "    kernelBParams.sharedMemBytes = 0;\n",
    "    kernelBParams.kernelParams = argsB;\n",
    "    kernelBParams.extra = NULL;\n",
    "    \n",
    "    cudaGraphNode_t depB[] = { kernelANode };  // Depends on A\n",
    "    cudaGraphAddKernelNode(&kernelBNode, graph, \n",
    "                           depB, 1,\n",
    "                           &kernelBParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Memcpy Node (D2H, depends on Kernel B)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t d2hNode;\n",
    "    cudaMemcpy3DParms d2hParams = {0};\n",
    "    d2hParams.srcPtr = make_cudaPitchedPtr((void*)d_data, BYTES, N, 1);\n",
    "    d2hParams.dstPtr = make_cudaPitchedPtr((void*)h_data, BYTES, N, 1);\n",
    "    d2hParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "    d2hParams.kind = cudaMemcpyDeviceToHost;\n",
    "    \n",
    "    cudaGraphNode_t depD2H[] = { kernelBNode };\n",
    "    cudaGraphAddMemcpyNode(&d2hNode, graph, \n",
    "                           depD2H, 1,\n",
    "                           &d2hParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Instantiate and Execute\n",
    "    // ============================================\n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    // Verify\n",
    "    printf(\"Result[0] = %.1f (expected 3.0)\\n\", h_data[0]);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFreeHost(h_data);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e480be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o explicit_graph explicit_graph.cu\n",
    "!./explicit_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e1bc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Node Types\n",
    "\n",
    "### Available Node Types\n",
    "\n",
    "```cpp\n",
    "// All available graph node types:\n",
    "\n",
    "// 1. Kernel Node\n",
    "cudaGraphAddKernelNode(&node, graph, deps, numDeps, &kernelParams);\n",
    "\n",
    "// 2. Memcpy Node\n",
    "cudaGraphAddMemcpyNode(&node, graph, deps, numDeps, &memcpyParams);\n",
    "\n",
    "// 3. Memset Node\n",
    "cudaGraphAddMemsetNode(&node, graph, deps, numDeps, &memsetParams);\n",
    "\n",
    "// 4. Host Node (CPU callback)\n",
    "cudaGraphAddHostNode(&node, graph, deps, numDeps, &hostParams);\n",
    "\n",
    "// 5. Child Graph Node (nested graph)\n",
    "cudaGraphAddChildGraphNode(&node, graph, deps, numDeps, childGraph);\n",
    "\n",
    "// 6. Empty Node (synchronization point)\n",
    "cudaGraphAddEmptyNode(&node, graph, deps, numDeps);\n",
    "\n",
    "// 7. Event Record Node\n",
    "cudaGraphAddEventRecordNode(&node, graph, deps, numDeps, event);\n",
    "\n",
    "// 8. Event Wait Node\n",
    "cudaGraphAddEventWaitNode(&node, graph, deps, numDeps, event);\n",
    "```\n",
    "\n",
    "### Empty Nodes for Synchronization\n",
    "\n",
    "```cpp\n",
    "// Use empty nodes as synchronization barriers\n",
    "//\n",
    "//    A1    A2    A3\n",
    "//     \\    |    /\n",
    "//      [Empty]     <- Sync point\n",
    "//         |\n",
    "//         B\n",
    "\n",
    "cudaGraphNode_t syncNode;\n",
    "cudaGraphNode_t deps[] = { nodeA1, nodeA2, nodeA3 };\n",
    "cudaGraphAddEmptyNode(&syncNode, graph, deps, 3);\n",
    "\n",
    "// B depends on sync point\n",
    "cudaGraphNode_t depB[] = { syncNode };\n",
    "cudaGraphAddKernelNode(&nodeB, graph, depB, 1, &paramsB);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba693f5a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Complex DAG Patterns\n",
    "\n",
    "### Fork-Join Pattern\n",
    "\n",
    "This example demonstrates creating a graph with parallel branches that merge - a common pattern for concurrent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fork_join_graph.cu\n",
    "// fork_join_graph.cu - Parallel branches that merge\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processA(float* a, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) a[tid] = a[tid] * 2.0f;\n",
    "}\n",
    "\n",
    "__global__ void processB(float* b, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) b[tid] = b[tid] + 1.0f;\n",
    "}\n",
    "\n",
    "__global__ void combine(float* a, float* b, float* c, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) c[tid] = a[tid] + b[tid];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, N * sizeof(float));\n",
    "    cudaMalloc(&d_b, N * sizeof(float));\n",
    "    cudaMalloc(&d_c, N * sizeof(float));\n",
    "    \n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphCreate(&graph, 0);\n",
    "    \n",
    "    // ============================================\n",
    "    // Fork: Two independent parallel kernels\n",
    "    // ============================================\n",
    "    cudaGraphNode_t nodeA, nodeB;\n",
    "    \n",
    "    cudaKernelNodeParams paramsA = {0};\n",
    "    void* argsA[] = { &d_a, (void*)&N };\n",
    "    paramsA.func = (void*)processA;\n",
    "    paramsA.gridDim = dim3(256);\n",
    "    paramsA.blockDim = dim3(256);\n",
    "    paramsA.kernelParams = argsA;\n",
    "    \n",
    "    cudaKernelNodeParams paramsB = {0};\n",
    "    void* argsB[] = { &d_b, (void*)&N };\n",
    "    paramsB.func = (void*)processB;\n",
    "    paramsB.gridDim = dim3(256);\n",
    "    paramsB.blockDim = dim3(256);\n",
    "    paramsB.kernelParams = argsB;\n",
    "    \n",
    "    // No dependencies - they can run in parallel!\n",
    "    cudaGraphAddKernelNode(&nodeA, graph, NULL, 0, &paramsA);\n",
    "    cudaGraphAddKernelNode(&nodeB, graph, NULL, 0, &paramsB);\n",
    "    \n",
    "    // ============================================\n",
    "    // Join: Combine depends on both A and B\n",
    "    // ============================================\n",
    "    cudaGraphNode_t nodeC;\n",
    "    \n",
    "    cudaKernelNodeParams paramsC = {0};\n",
    "    void* argsC[] = { &d_a, &d_b, &d_c, (void*)&N };\n",
    "    paramsC.func = (void*)combine;\n",
    "    paramsC.gridDim = dim3(256);\n",
    "    paramsC.blockDim = dim3(256);\n",
    "    paramsC.kernelParams = argsC;\n",
    "    \n",
    "    cudaGraphNode_t depsC[] = { nodeA, nodeB };  // Depends on BOTH\n",
    "    cudaGraphAddKernelNode(&nodeC, graph, depsC, 2, &paramsC);\n",
    "    \n",
    "    /*\n",
    "    Graph structure:\n",
    "    \n",
    "    [processA]    [processB]\n",
    "           \\      /\n",
    "          [combine]\n",
    "    */\n",
    "    \n",
    "    // Instantiate and run\n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    printf(\"Fork-join graph executed!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67284c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o fork_join_graph fork_join_graph.cu\n",
    "!./fork_join_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161c6a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Graph Inspection\n",
    "\n",
    "### Querying Graph Structure\n",
    "\n",
    "This example demonstrates how to examine a graph's properties, including the number of nodes, node types, and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_inspection.cu\n",
    "// graph_inspection.cu - Examining graph properties\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void dummyKernel(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] *= 2.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // Capture a sample graph\n",
    "    cudaGraph_t graph;\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    dummyKernel<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    dummyKernel<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    dummyKernel<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    \n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    // Get number of nodes\n",
    "    size_t numNodes;\n",
    "    cudaGraphGetNodes(graph, NULL, &numNodes);\n",
    "    printf(\"Graph has %zu nodes\\n\", numNodes);\n",
    "    \n",
    "    // Get all nodes\n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    cudaGraphGetNodes(graph, nodes, &numNodes);\n",
    "    \n",
    "    // For each node, get type\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        cudaGraphNodeGetType(nodes[i], &type);\n",
    "        \n",
    "        switch (type) {\n",
    "            case cudaGraphNodeTypeKernel:\n",
    "                printf(\"Node %zu: Kernel\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeMemcpy:\n",
    "                printf(\"Node %zu: Memcpy\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeMemset:\n",
    "                printf(\"Node %zu: Memset\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeHost:\n",
    "                printf(\"Node %zu: Host callback\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeGraph:\n",
    "                printf(\"Node %zu: Child graph\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeEmpty:\n",
    "                printf(\"Node %zu: Empty (sync)\\n\", i);\n",
    "                break;\n",
    "            default:\n",
    "                printf(\"Node %zu: Other\\n\", i);\n",
    "        }\n",
    "        \n",
    "        // Get dependencies\n",
    "        size_t numDeps;\n",
    "        cudaGraphNodeGetDependencies(nodes[i], NULL, &numDeps);\n",
    "        printf(\"  Has %zu dependencies\\n\", numDeps);\n",
    "    }\n",
    "    \n",
    "    delete[] nodes;\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_inspection graph_inspection.cu\n",
    "!./graph_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199a1e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Pipeline Graph\n",
    "Build a 4-stage pipeline graph explicitly (H2D → K1 → K2 → D2H).\n",
    "\n",
    "### Exercise 2: Diamond Pattern\n",
    "```\n",
    "    A\n",
    "   / \\\n",
    "  B   C\n",
    "   \\ /\n",
    "    D\n",
    "```\n",
    "\n",
    "### Exercise 3: Graph Cloning\n",
    "Use `cudaGraphClone` to create a modified copy of a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d49eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│           EXPLICIT GRAPH CONSTRUCTION                   │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│                                                         │\n",
    "│  Create Graph:                                          │\n",
    "│  • cudaGraphCreate(&graph, 0)                           │\n",
    "│                                                         │\n",
    "│  Add Nodes:                                             │\n",
    "│  • cudaGraphAddKernelNode(&node, graph, deps, n, &p)    │\n",
    "│  • cudaGraphAddMemcpyNode(...)                          │\n",
    "│  • cudaGraphAddEmptyNode(...)  // sync barrier          │\n",
    "│                                                         │\n",
    "│  Dependencies:                                          │\n",
    "│  • Pass array of dependency nodes                       │\n",
    "│  • NULL, 0 = no dependencies                            │\n",
    "│  • Multiple deps = waits for ALL                        │\n",
    "│                                                         │\n",
    "│  Fork-Join:                                             │\n",
    "│  • No deps = parallel (fork)                            │\n",
    "│  • Multiple deps = sync (join)                          │\n",
    "│                                                         │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Next: Day 3 - Graph Updates"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
