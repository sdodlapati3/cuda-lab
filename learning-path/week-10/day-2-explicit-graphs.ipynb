{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c32303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Setup\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "print(\"‚ö†Ô∏è  CUDA C++ is PRIMARY. Python/Numba for quick testing only.\")\n",
    "if cuda.is_available():\n",
    "    print(f\"GPU: {cuda.get_current_device().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e472d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Explicit Construction?\n",
    "\n",
    "### Capture vs Explicit\n",
    "\n",
    "```\n",
    "Stream Capture:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "‚úÖ Easy - just run code in capture mode\n",
    "‚úÖ Natural for converting existing code\n",
    "‚ùå Limited control over structure\n",
    "‚ùå Can't build graphs dynamically\n",
    "\n",
    "Explicit Construction:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "‚úÖ Full control over graph structure\n",
    "‚úÖ Can build programmatically\n",
    "‚úÖ More flexible dependencies\n",
    "‚ùå More verbose code\n",
    "‚ùå Need to manage node handles\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c31796",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building a Simple Graph\n",
    "\n",
    "### üî∑ CUDA C++ Implementation (Primary)\n",
    "\n",
    "This example demonstrates building a graph node by node, giving you full control over the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1da4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile explicit_graph.cu\n",
    "// explicit_graph.cu - Building graphs node by node\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void kernelA(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] *= 2.0f;\n",
    "}\n",
    "\n",
    "__global__ void kernelB(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] += 1.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    const size_t BYTES = N * sizeof(float);\n",
    "    \n",
    "    float *h_data, *d_data;\n",
    "    cudaMallocHost(&h_data, BYTES);\n",
    "    cudaMalloc(&d_data, BYTES);\n",
    "    \n",
    "    for (int i = 0; i < N; i++) h_data[i] = 1.0f;\n",
    "    \n",
    "    // ============================================\n",
    "    // Create Empty Graph\n",
    "    // ============================================\n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphCreate(&graph, 0);  // 0 = flags (none)\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Memcpy Node (H2D)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t h2dNode;\n",
    "    cudaMemcpy3DParms h2dParams = {0};\n",
    "    h2dParams.srcPtr = make_cudaPitchedPtr((void*)h_data, BYTES, N, 1);\n",
    "    h2dParams.dstPtr = make_cudaPitchedPtr((void*)d_data, BYTES, N, 1);\n",
    "    h2dParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "    h2dParams.kind = cudaMemcpyHostToDevice;\n",
    "    \n",
    "    cudaGraphAddMemcpyNode(&h2dNode, graph, \n",
    "                           NULL, 0,  // No dependencies\n",
    "                           &h2dParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Kernel Node A (depends on H2D)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t kernelANode;\n",
    "    \n",
    "    cudaKernelNodeParams kernelAParams = {0};\n",
    "    void* argsA[] = { &d_data, (void*)&N };\n",
    "    \n",
    "    kernelAParams.func = (void*)kernelA;\n",
    "    kernelAParams.gridDim = dim3(256);\n",
    "    kernelAParams.blockDim = dim3(256);\n",
    "    kernelAParams.sharedMemBytes = 0;\n",
    "    kernelAParams.kernelParams = argsA;\n",
    "    kernelAParams.extra = NULL;\n",
    "    \n",
    "    cudaGraphNode_t depA[] = { h2dNode };  // Depends on H2D\n",
    "    cudaGraphAddKernelNode(&kernelANode, graph, \n",
    "                           depA, 1,  // 1 dependency\n",
    "                           &kernelAParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Kernel Node B (depends on Kernel A)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t kernelBNode;\n",
    "    \n",
    "    cudaKernelNodeParams kernelBParams = {0};\n",
    "    void* argsB[] = { &d_data, (void*)&N };\n",
    "    \n",
    "    kernelBParams.func = (void*)kernelB;\n",
    "    kernelBParams.gridDim = dim3(256);\n",
    "    kernelBParams.blockDim = dim3(256);\n",
    "    kernelBParams.sharedMemBytes = 0;\n",
    "    kernelBParams.kernelParams = argsB;\n",
    "    kernelBParams.extra = NULL;\n",
    "    \n",
    "    cudaGraphNode_t depB[] = { kernelANode };  // Depends on A\n",
    "    cudaGraphAddKernelNode(&kernelBNode, graph, \n",
    "                           depB, 1,\n",
    "                           &kernelBParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Add Memcpy Node (D2H, depends on Kernel B)\n",
    "    // ============================================\n",
    "    cudaGraphNode_t d2hNode;\n",
    "    cudaMemcpy3DParms d2hParams = {0};\n",
    "    d2hParams.srcPtr = make_cudaPitchedPtr((void*)d_data, BYTES, N, 1);\n",
    "    d2hParams.dstPtr = make_cudaPitchedPtr((void*)h_data, BYTES, N, 1);\n",
    "    d2hParams.extent = make_cudaExtent(BYTES, 1, 1);\n",
    "    d2hParams.kind = cudaMemcpyDeviceToHost;\n",
    "    \n",
    "    cudaGraphNode_t depD2H[] = { kernelBNode };\n",
    "    cudaGraphAddMemcpyNode(&d2hNode, graph, \n",
    "                           depD2H, 1,\n",
    "                           &d2hParams);\n",
    "    \n",
    "    // ============================================\n",
    "    // Instantiate and Execute\n",
    "    // ============================================\n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    // Verify\n",
    "    printf(\"Result[0] = %.1f (expected 3.0)\\n\", h_data[0]);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFreeHost(h_data);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e480be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o explicit_graph explicit_graph.cu\n",
    "!./explicit_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e1bc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Node Types\n",
    "\n",
    "### Available Node Types\n",
    "\n",
    "```cpp\n",
    "// All available graph node types:\n",
    "\n",
    "// 1. Kernel Node\n",
    "cudaGraphAddKernelNode(&node, graph, deps, numDeps, &kernelParams);\n",
    "\n",
    "// 2. Memcpy Node\n",
    "cudaGraphAddMemcpyNode(&node, graph, deps, numDeps, &memcpyParams);\n",
    "\n",
    "// 3. Memset Node\n",
    "cudaGraphAddMemsetNode(&node, graph, deps, numDeps, &memsetParams);\n",
    "\n",
    "// 4. Host Node (CPU callback)\n",
    "cudaGraphAddHostNode(&node, graph, deps, numDeps, &hostParams);\n",
    "\n",
    "// 5. Child Graph Node (nested graph)\n",
    "cudaGraphAddChildGraphNode(&node, graph, deps, numDeps, childGraph);\n",
    "\n",
    "// 6. Empty Node (synchronization point)\n",
    "cudaGraphAddEmptyNode(&node, graph, deps, numDeps);\n",
    "\n",
    "// 7. Event Record Node\n",
    "cudaGraphAddEventRecordNode(&node, graph, deps, numDeps, event);\n",
    "\n",
    "// 8. Event Wait Node\n",
    "cudaGraphAddEventWaitNode(&node, graph, deps, numDeps, event);\n",
    "```\n",
    "\n",
    "### Empty Nodes for Synchronization\n",
    "\n",
    "```cpp\n",
    "// Use empty nodes as synchronization barriers\n",
    "//\n",
    "//    A1    A2    A3\n",
    "//     \\    |    /\n",
    "//      [Empty]     <- Sync point\n",
    "//         |\n",
    "//         B\n",
    "\n",
    "cudaGraphNode_t syncNode;\n",
    "cudaGraphNode_t deps[] = { nodeA1, nodeA2, nodeA3 };\n",
    "cudaGraphAddEmptyNode(&syncNode, graph, deps, 3);\n",
    "\n",
    "// B depends on sync point\n",
    "cudaGraphNode_t depB[] = { syncNode };\n",
    "cudaGraphAddKernelNode(&nodeB, graph, depB, 1, &paramsB);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba693f5a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Complex DAG Patterns\n",
    "\n",
    "### üî∑ CUDA C++ Implementation (Primary)\n",
    "\n",
    "This example demonstrates creating a graph with parallel branches that merge - a common pattern for concurrent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fork_join_graph.cu\n",
    "// fork_join_graph.cu - Parallel branches that merge\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void processA(float* a, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) a[tid] = a[tid] * 2.0f;\n",
    "}\n",
    "\n",
    "__global__ void processB(float* b, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) b[tid] = b[tid] + 1.0f;\n",
    "}\n",
    "\n",
    "__global__ void combine(float* a, float* b, float* c, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) c[tid] = a[tid] + b[tid];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, N * sizeof(float));\n",
    "    cudaMalloc(&d_b, N * sizeof(float));\n",
    "    cudaMalloc(&d_c, N * sizeof(float));\n",
    "    \n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphCreate(&graph, 0);\n",
    "    \n",
    "    // ============================================\n",
    "    // Fork: Two independent parallel kernels\n",
    "    // ============================================\n",
    "    cudaGraphNode_t nodeA, nodeB;\n",
    "    \n",
    "    cudaKernelNodeParams paramsA = {0};\n",
    "    void* argsA[] = { &d_a, (void*)&N };\n",
    "    paramsA.func = (void*)processA;\n",
    "    paramsA.gridDim = dim3(256);\n",
    "    paramsA.blockDim = dim3(256);\n",
    "    paramsA.kernelParams = argsA;\n",
    "    \n",
    "    cudaKernelNodeParams paramsB = {0};\n",
    "    void* argsB[] = { &d_b, (void*)&N };\n",
    "    paramsB.func = (void*)processB;\n",
    "    paramsB.gridDim = dim3(256);\n",
    "    paramsB.blockDim = dim3(256);\n",
    "    paramsB.kernelParams = argsB;\n",
    "    \n",
    "    // No dependencies - they can run in parallel!\n",
    "    cudaGraphAddKernelNode(&nodeA, graph, NULL, 0, &paramsA);\n",
    "    cudaGraphAddKernelNode(&nodeB, graph, NULL, 0, &paramsB);\n",
    "    \n",
    "    // ============================================\n",
    "    // Join: Combine depends on both A and B\n",
    "    // ============================================\n",
    "    cudaGraphNode_t nodeC;\n",
    "    \n",
    "    cudaKernelNodeParams paramsC = {0};\n",
    "    void* argsC[] = { &d_a, &d_b, &d_c, (void*)&N };\n",
    "    paramsC.func = (void*)combine;\n",
    "    paramsC.gridDim = dim3(256);\n",
    "    paramsC.blockDim = dim3(256);\n",
    "    paramsC.kernelParams = argsC;\n",
    "    \n",
    "    cudaGraphNode_t depsC[] = { nodeA, nodeB };  // Depends on BOTH\n",
    "    cudaGraphAddKernelNode(&nodeC, graph, depsC, 2, &paramsC);\n",
    "    \n",
    "    /*\n",
    "    Graph structure:\n",
    "    \n",
    "    [processA]    [processB]\n",
    "           \\      /\n",
    "          [combine]\n",
    "    */\n",
    "    \n",
    "    // Instantiate and run\n",
    "    cudaGraphExec_t graphExec;\n",
    "    cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    cudaGraphLaunch(graphExec, stream);\n",
    "    cudaStreamSynchronize(stream);\n",
    "    \n",
    "    printf(\"Fork-join graph executed!\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67284c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o fork_join_graph fork_join_graph.cu\n",
    "!./fork_join_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161c6a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Graph Inspection\n",
    "\n",
    "### üî∑ CUDA C++ Implementation (Primary)\n",
    "\n",
    "This example demonstrates how to examine a graph's properties, including the number of nodes, node types, and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_inspection.cu\n",
    "// graph_inspection.cu - Examining graph properties\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void dummyKernel(float* data, int n) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (tid < n) data[tid] *= 2.0f;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 20;\n",
    "    float *d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    \n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    \n",
    "    // Capture a sample graph\n",
    "    cudaGraph_t graph;\n",
    "    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);\n",
    "    \n",
    "    dummyKernel<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    dummyKernel<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    dummyKernel<<<256, 256, 0, stream>>>(d_data, N);\n",
    "    \n",
    "    cudaStreamEndCapture(stream, &graph);\n",
    "    \n",
    "    // Get number of nodes\n",
    "    size_t numNodes;\n",
    "    cudaGraphGetNodes(graph, NULL, &numNodes);\n",
    "    printf(\"Graph has %zu nodes\\n\", numNodes);\n",
    "    \n",
    "    // Get all nodes\n",
    "    cudaGraphNode_t* nodes = new cudaGraphNode_t[numNodes];\n",
    "    cudaGraphGetNodes(graph, nodes, &numNodes);\n",
    "    \n",
    "    // For each node, get type\n",
    "    for (size_t i = 0; i < numNodes; i++) {\n",
    "        cudaGraphNodeType type;\n",
    "        cudaGraphNodeGetType(nodes[i], &type);\n",
    "        \n",
    "        switch (type) {\n",
    "            case cudaGraphNodeTypeKernel:\n",
    "                printf(\"Node %zu: Kernel\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeMemcpy:\n",
    "                printf(\"Node %zu: Memcpy\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeMemset:\n",
    "                printf(\"Node %zu: Memset\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeHost:\n",
    "                printf(\"Node %zu: Host callback\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeGraph:\n",
    "                printf(\"Node %zu: Child graph\\n\", i);\n",
    "                break;\n",
    "            case cudaGraphNodeTypeEmpty:\n",
    "                printf(\"Node %zu: Empty (sync)\\n\", i);\n",
    "                break;\n",
    "            default:\n",
    "                printf(\"Node %zu: Other\\n\", i);\n",
    "        }\n",
    "        \n",
    "        // Get dependencies\n",
    "        size_t numDeps;\n",
    "        cudaGraphNodeGetDependencies(nodes[i], NULL, &numDeps);\n",
    "        printf(\"  Has %zu dependencies\\n\", numDeps);\n",
    "    }\n",
    "    \n",
    "    delete[] nodes;\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o graph_inspection graph_inspection.cu\n",
    "!./graph_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199a1e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Exercises\n",
    "\n",
    "### üî∑ CUDA C++ Exercises (Primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a33ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile explicit_graph_exercises.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define CHECK_CUDA(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            printf(\"CUDA Error: %s at line %d\\n\", cudaGetErrorString(err), __LINE__); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "__global__ void kernel1(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = data[idx] + 1.0f;\n",
    "}\n",
    "\n",
    "__global__ void kernel2(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = data[idx] * 2.0f;\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 1: Pipeline Graph (H2D -> K1 -> K2 -> D2H)\n",
    "// ============================================================\n",
    "\n",
    "void exercise1_pipelineGraph() {\n",
    "    printf(\"=== Exercise 1: Pipeline Graph ===\\n\");\n",
    "    \n",
    "    const int n = 1 << 18;\n",
    "    size_t bytes = n * sizeof(float);\n",
    "    \n",
    "    float *h_data, *d_data;\n",
    "    CHECK_CUDA(cudaMallocHost(&h_data, bytes));\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, bytes));\n",
    "    \n",
    "    for (int i = 0; i < n; i++) h_data[i] = 1.0f;\n",
    "    \n",
    "    int grid = (n + 255) / 256;\n",
    "    \n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphNode_t h2dNode, k1Node, k2Node, d2hNode;\n",
    "    \n",
    "    CHECK_CUDA(cudaGraphCreate(&graph, 0));\n",
    "    \n",
    "    // H2D memcpy node\n",
    "    cudaMemcpy3DParms h2dParams = {0};\n",
    "    h2dParams.srcPtr = make_cudaPitchedPtr(h_data, bytes, n, 1);\n",
    "    h2dParams.dstPtr = make_cudaPitchedPtr(d_data, bytes, n, 1);\n",
    "    h2dParams.extent = make_cudaExtent(bytes, 1, 1);\n",
    "    h2dParams.kind = cudaMemcpyHostToDevice;\n",
    "    CHECK_CUDA(cudaGraphAddMemcpyNode(&h2dNode, graph, NULL, 0, &h2dParams));\n",
    "    \n",
    "    // Kernel 1 node\n",
    "    cudaKernelNodeParams k1Params = {0};\n",
    "    void* k1Args[] = {&d_data, (void*)&n};\n",
    "    k1Params.func = (void*)kernel1;\n",
    "    k1Params.gridDim = dim3(grid);\n",
    "    k1Params.blockDim = dim3(256);\n",
    "    k1Params.kernelParams = k1Args;\n",
    "    CHECK_CUDA(cudaGraphAddKernelNode(&k1Node, graph, &h2dNode, 1, &k1Params));\n",
    "    \n",
    "    // Kernel 2 node\n",
    "    cudaKernelNodeParams k2Params = {0};\n",
    "    void* k2Args[] = {&d_data, (void*)&n};\n",
    "    k2Params.func = (void*)kernel2;\n",
    "    k2Params.gridDim = dim3(grid);\n",
    "    k2Params.blockDim = dim3(256);\n",
    "    k2Params.kernelParams = k2Args;\n",
    "    CHECK_CUDA(cudaGraphAddKernelNode(&k2Node, graph, &k1Node, 1, &k2Params));\n",
    "    \n",
    "    // D2H memcpy node\n",
    "    cudaMemcpy3DParms d2hParams = {0};\n",
    "    d2hParams.srcPtr = make_cudaPitchedPtr(d_data, bytes, n, 1);\n",
    "    d2hParams.dstPtr = make_cudaPitchedPtr(h_data, bytes, n, 1);\n",
    "    d2hParams.extent = make_cudaExtent(bytes, 1, 1);\n",
    "    d2hParams.kind = cudaMemcpyDeviceToHost;\n",
    "    CHECK_CUDA(cudaGraphAddMemcpyNode(&d2hNode, graph, &k2Node, 1, &d2hParams));\n",
    "    \n",
    "    // Instantiate and execute\n",
    "    cudaGraphExec_t graphExec;\n",
    "    CHECK_CUDA(cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0));\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        cudaGraphLaunch(graphExec, 0);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    printf(\"Pipeline: H2D -> K1 -> K2 -> D2H\\n\");\n",
    "    printf(\"100 iterations: %.2f ms (%.3f ms/iter)\\n\", ms, ms / 100);\n",
    "    printf(\"Result check: h_data[0] = %.1f (expected: 4.0)\\n\\n\", h_data[0]);\n",
    "    \n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaFreeHost(h_data);\n",
    "    cudaFree(d_data);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 2: Diamond Pattern\n",
    "// ============================================================\n",
    "\n",
    "__global__ void kernelB(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = sinf(data[idx]);\n",
    "}\n",
    "\n",
    "__global__ void kernelC(float* data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) data[idx] = cosf(data[idx]);\n",
    "}\n",
    "\n",
    "__global__ void kernelD(const float* b, const float* c, float* out, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) out[idx] = b[idx] + c[idx];\n",
    "}\n",
    "\n",
    "void exercise2_diamondPattern() {\n",
    "    printf(\"=== Exercise 2: Diamond Pattern ===\\n\");\n",
    "    printf(\"    A\\n   / \\\\\\n  B   C\\n   \\\\ /\\n    D\\n\\n\");\n",
    "    \n",
    "    const int n = 1 << 18;\n",
    "    \n",
    "    float *d_input, *d_b, *d_c, *d_output;\n",
    "    CHECK_CUDA(cudaMalloc(&d_input, n * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_b, n * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_c, n * sizeof(float)));\n",
    "    CHECK_CUDA(cudaMalloc(&d_output, n * sizeof(float)));\n",
    "    \n",
    "    int grid = (n + 255) / 256;\n",
    "    \n",
    "    cudaGraph_t graph;\n",
    "    cudaGraphNode_t nodeA, nodeB, nodeC, nodeD;\n",
    "    \n",
    "    CHECK_CUDA(cudaGraphCreate(&graph, 0));\n",
    "    \n",
    "    // Node A\n",
    "    cudaKernelNodeParams aParams = {0};\n",
    "    void* aArgs[] = {&d_input, (void*)&n};\n",
    "    aParams.func = (void*)kernel1;\n",
    "    aParams.gridDim = dim3(grid);\n",
    "    aParams.blockDim = dim3(256);\n",
    "    aParams.kernelParams = aArgs;\n",
    "    CHECK_CUDA(cudaGraphAddKernelNode(&nodeA, graph, NULL, 0, &aParams));\n",
    "    \n",
    "    // Node B (depends on A)\n",
    "    cudaKernelNodeParams bParams = {0};\n",
    "    void* bArgs[] = {&d_b, (void*)&n};\n",
    "    bParams.func = (void*)kernelB;\n",
    "    bParams.gridDim = dim3(grid);\n",
    "    bParams.blockDim = dim3(256);\n",
    "    bParams.kernelParams = bArgs;\n",
    "    CHECK_CUDA(cudaGraphAddKernelNode(&nodeB, graph, &nodeA, 1, &bParams));\n",
    "    \n",
    "    // Node C (depends on A)\n",
    "    cudaKernelNodeParams cParams = {0};\n",
    "    void* cArgs[] = {&d_c, (void*)&n};\n",
    "    cParams.func = (void*)kernelC;\n",
    "    cParams.gridDim = dim3(grid);\n",
    "    cParams.blockDim = dim3(256);\n",
    "    cParams.kernelParams = cArgs;\n",
    "    CHECK_CUDA(cudaGraphAddKernelNode(&nodeC, graph, &nodeA, 1, &cParams));\n",
    "    \n",
    "    // Node D (depends on B and C)\n",
    "    cudaGraphNode_t bcDeps[] = {nodeB, nodeC};\n",
    "    cudaKernelNodeParams dParams = {0};\n",
    "    void* dArgs[] = {&d_b, &d_c, &d_output, (void*)&n};\n",
    "    dParams.func = (void*)kernelD;\n",
    "    dParams.gridDim = dim3(grid);\n",
    "    dParams.blockDim = dim3(256);\n",
    "    dParams.kernelParams = dArgs;\n",
    "    CHECK_CUDA(cudaGraphAddKernelNode(&nodeD, graph, bcDeps, 2, &dParams));\n",
    "    \n",
    "    // Instantiate and execute\n",
    "    cudaGraphExec_t graphExec;\n",
    "    CHECK_CUDA(cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0));\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        cudaGraphLaunch(graphExec, 0);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    printf(\"Diamond graph 100 iterations: %.2f ms\\n\\n\", ms);\n",
    "    \n",
    "    cudaGraphExecDestroy(graphExec);\n",
    "    cudaGraphDestroy(graph);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    cudaFree(d_output);\n",
    "}\n",
    "\n",
    "// ============================================================\n",
    "// Exercise 3: Graph Cloning\n",
    "// ============================================================\n",
    "\n",
    "void exercise3_graphCloning() {\n",
    "    printf(\"=== Exercise 3: Graph Cloning ===\\n\");\n",
    "    \n",
    "    const int n = 1 << 18;\n",
    "    \n",
    "    float *d_data;\n",
    "    CHECK_CUDA(cudaMalloc(&d_data, n * sizeof(float)));\n",
    "    \n",
    "    int grid = (n + 255) / 256;\n",
    "    \n",
    "    // Create original graph\n",
    "    cudaGraph_t originalGraph;\n",
    "    cudaGraphNode_t k1Node;\n",
    "    \n",
    "    CHECK_CUDA(cudaGraphCreate(&originalGraph, 0));\n",
    "    \n",
    "    cudaKernelNodeParams k1Params = {0};\n",
    "    void* k1Args[] = {&d_data, (void*)&n};\n",
    "    k1Params.func = (void*)kernel1;\n",
    "    k1Params.gridDim = dim3(grid);\n",
    "    k1Params.blockDim = dim3(256);\n",
    "    k1Params.kernelParams = k1Args;\n",
    "    CHECK_CUDA(cudaGraphAddKernelNode(&k1Node, originalGraph, NULL, 0, &k1Params));\n",
    "    \n",
    "    // Clone the graph\n",
    "    cudaGraph_t clonedGraph;\n",
    "    CHECK_CUDA(cudaGraphClone(&clonedGraph, originalGraph));\n",
    "    \n",
    "    // Get nodes from cloned graph and modify\n",
    "    size_t numNodes;\n",
    "    cudaGraphGetNodes(clonedGraph, NULL, &numNodes);\n",
    "    printf(\"Original graph has %zu nodes\\n\", numNodes);\n",
    "    \n",
    "    cudaGraphNode_t* nodes = (cudaGraphNode_t*)malloc(numNodes * sizeof(cudaGraphNode_t));\n",
    "    cudaGraphGetNodes(clonedGraph, nodes, &numNodes);\n",
    "    \n",
    "    // Modify the cloned node (change grid size)\n",
    "    cudaKernelNodeParams modifiedParams;\n",
    "    cudaGraphKernelNodeGetParams(nodes[0], &modifiedParams);\n",
    "    modifiedParams.gridDim = dim3(grid * 2);  // Double the grid\n",
    "    cudaGraphKernelNodeSetParams(nodes[0], &modifiedParams);\n",
    "    \n",
    "    printf(\"Cloned and modified graph (doubled grid size)\\n\");\n",
    "    \n",
    "    // Instantiate both\n",
    "    cudaGraphExec_t origExec, cloneExec;\n",
    "    CHECK_CUDA(cudaGraphInstantiate(&origExec, originalGraph, NULL, NULL, 0));\n",
    "    CHECK_CUDA(cudaGraphInstantiate(&cloneExec, clonedGraph, NULL, NULL, 0));\n",
    "    \n",
    "    printf(\"Both graphs instantiated successfully\\n\\n\");\n",
    "    \n",
    "    free(nodes);\n",
    "    cudaGraphExecDestroy(origExec);\n",
    "    cudaGraphExecDestroy(cloneExec);\n",
    "    cudaGraphDestroy(originalGraph);\n",
    "    cudaGraphDestroy(clonedGraph);\n",
    "    cudaFree(d_data);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\\n\");\n",
    "    printf(\"‚ïë           Explicit Graph Construction Exercises              ‚ïë\\n\");\n",
    "    printf(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\\n\\n\");\n",
    "    \n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    printf(\"Device: %s\\n\\n\", prop.name);\n",
    "    \n",
    "    exercise1_pipelineGraph();\n",
    "    exercise2_diamondPattern();\n",
    "    exercise3_graphCloning();\n",
    "    \n",
    "    printf(\"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\");\n",
    "    printf(\"                    All exercises completed!\\n\");\n",
    "    printf(\"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\");\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f38551",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -o explicit_graph_exercises explicit_graph_exercises.cu && ./explicit_graph_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a61d8c",
   "metadata": {},
   "source": [
    "### üî∂ Python/Numba Exercises (Optional)\n",
    "\n",
    "### Exercise 1: Pipeline Graph\n",
    "Build a 4-stage pipeline graph explicitly (H2D ‚Üí K1 ‚Üí K2 ‚Üí D2H).\n",
    "\n",
    "### Exercise 2: Diamond Pattern\n",
    "```\n",
    "    A\n",
    "   / \\\n",
    "  B   C\n",
    "   \\ /\n",
    "    D\n",
    "```\n",
    "\n",
    "### Exercise 3: Graph Cloning\n",
    "Use `cudaGraphClone` to create a modified copy of a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d49eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ           EXPLICIT GRAPH CONSTRUCTION                   ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                         ‚îÇ\n",
    "‚îÇ  Create Graph:                                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ cudaGraphCreate(&graph, 0)                           ‚îÇ\n",
    "‚îÇ                                                         ‚îÇ\n",
    "‚îÇ  Add Nodes:                                             ‚îÇ\n",
    "‚îÇ  ‚Ä¢ cudaGraphAddKernelNode(&node, graph, deps, n, &p)    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ cudaGraphAddMemcpyNode(...)                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ cudaGraphAddEmptyNode(...)  // sync barrier          ‚îÇ\n",
    "‚îÇ                                                         ‚îÇ\n",
    "‚îÇ  Dependencies:                                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Pass array of dependency nodes                       ‚îÇ\n",
    "‚îÇ  ‚Ä¢ NULL, 0 = no dependencies                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Multiple deps = waits for ALL                        ‚îÇ\n",
    "‚îÇ                                                         ‚îÇ\n",
    "‚îÇ  Fork-Join:                                             ‚îÇ\n",
    "‚îÇ  ‚Ä¢ No deps = parallel (fork)                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Multiple deps = sync (join)                          ‚îÇ\n",
    "‚îÇ                                                         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Next: Day 3 - Graph Updates"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
