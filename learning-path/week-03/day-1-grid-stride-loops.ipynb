{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b718310",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02124ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Verify GPU\n",
    "print(f\"CUDA available: {cuda.is_available()}\")\n",
    "if cuda.is_available():\n",
    "    device = cuda.get_current_device()\n",
    "    print(f\"Device: {device.name}\")\n",
    "    print(f\"Compute capability: {device.compute_capability}\")\n",
    "    print(f\"Max threads per block: {device.MAX_THREADS_PER_BLOCK}\")\n",
    "    print(f\"Max blocks per grid: {device.MAX_GRID_DIM_X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da705d12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Problem with Naive Kernels\n",
    "\n",
    "### Naive Approach: One Thread Per Element\n",
    "\n",
    "The simplest approach assigns exactly one thread to each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def naive_add(a, b, out, n):\n",
    "    \"\"\"Naive: One thread handles exactly one element.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    \n",
    "    if tid < n:  # Bounds check\n",
    "        out[tid] = a[tid] + b[tid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef1641",
   "metadata": {},
   "source": [
    "### Problems with Naive Approach\n",
    "\n",
    "```\n",
    "Problem 1: Block Size Dependency\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "N = 1000 elements\n",
    "Block size = 256\n",
    "Blocks needed = ceil(1000/256) = 4\n",
    "Total threads = 4 Ã— 256 = 1024\n",
    "Wasted threads = 1024 - 1000 = 24 (2.4%)\n",
    "\n",
    "Problem 2: Large Data\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "N = 1 billion elements\n",
    "Block size = 256\n",
    "Blocks needed = ceil(1B/256) = 3,906,250\n",
    "Max blocks (on some GPUs) = 65,535\n",
    "âŒ FAILS for very large data!\n",
    "\n",
    "Problem 3: Fixed Launch Config\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Every different N requires different grid size.\n",
    "Can't tune for occupancy independently of data size.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b34284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the limitation\n",
    "device = cuda.get_current_device()\n",
    "max_blocks = device.MAX_GRID_DIM_X\n",
    "threads_per_block = 256\n",
    "max_elements_naive = max_blocks * threads_per_block\n",
    "\n",
    "print(f\"Max blocks in X dimension: {max_blocks:,}\")\n",
    "print(f\"Threads per block: {threads_per_block}\")\n",
    "print(f\"Max elements with naive approach: {max_elements_naive:,}\")\n",
    "print(f\"That's only {max_elements_naive / 1e9:.2f} billion elements\")\n",
    "print(f\"\\nModern datasets can have billions of elements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ff382",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The Grid-Stride Loop Pattern\n",
    "\n",
    "### The Solution: Each Thread Processes Multiple Elements\n",
    "\n",
    "```\n",
    "Grid-Stride Loop Concept:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Data: [0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]...\n",
    "       â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚\n",
    "Grid:  T0 T1 T2 T3 T0 T1 T2 T3 T0  T1  T2  T3  T0  T1  T2  T3\n",
    "       \\________/  \\________/  \\_________/   \\__________/\n",
    "        Pass 1      Pass 2       Pass 3         Pass 4\n",
    "\n",
    "Each thread processes elements at: tid, tid+gridsize, tid+2*gridsize, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45079b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def grid_stride_add(a, b, out, n):\n",
    "    \"\"\"Grid-stride loop: Each thread processes multiple elements.\"\"\"\n",
    "    tid = cuda.grid(1)           # Global thread ID\n",
    "    stride = cuda.gridsize(1)    # Total number of threads in grid\n",
    "    \n",
    "    # Each thread processes elements at tid, tid+stride, tid+2*stride, ...\n",
    "    for i in range(tid, n, stride):\n",
    "        out[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02754b1c",
   "metadata": {},
   "source": [
    "### Key Functions\n",
    "\n",
    "| Function | Returns | Description |\n",
    "|----------|---------|-------------|\n",
    "| `cuda.grid(1)` | int | Global thread ID (1D) |\n",
    "| `cuda.gridsize(1)` | int | Total threads in grid = blocks Ã— threads_per_block |\n",
    "| `cuda.grid(2)` | (x, y) | Global thread ID (2D) |\n",
    "| `cuda.gridsize(2)` | (x, y) | Total threads in each dimension |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid-stride pattern\n",
    "@cuda.jit\n",
    "def show_grid_stride(output, n):\n",
    "    \"\"\"Store which thread processed each element.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    for i in range(tid, n, stride):\n",
    "        output[i] = tid  # Store thread ID\n",
    "\n",
    "# Small example\n",
    "n = 20\n",
    "blocks = 2\n",
    "threads = 4\n",
    "total_threads = blocks * threads\n",
    "\n",
    "output = np.zeros(n, dtype=np.int32)\n",
    "d_output = cuda.to_device(output)\n",
    "\n",
    "show_grid_stride[blocks, threads](d_output, n)\n",
    "result = d_output.copy_to_host()\n",
    "\n",
    "print(f\"Configuration: {blocks} blocks Ã— {threads} threads = {total_threads} total threads\")\n",
    "print(f\"Processing {n} elements\")\n",
    "print(f\"\\nElement index:  {list(range(n))}\")\n",
    "print(f\"Processed by:   {list(result)}\")\n",
    "print(f\"\\nEach thread processes {n // total_threads} elements (plus remainder)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e853ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Benefits of Grid-Stride Loops\n",
    "\n",
    "### Benefit 1: Handle ANY Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same kernel config works for different sizes\n",
    "def test_sizes(kernel, sizes, blocks=256, threads=256):\n",
    "    \"\"\"Test kernel with various data sizes.\"\"\"\n",
    "    for n in sizes:\n",
    "        a = np.random.rand(n).astype(np.float32)\n",
    "        b = np.random.rand(n).astype(np.float32)\n",
    "        out = np.zeros(n, dtype=np.float32)\n",
    "        \n",
    "        d_a = cuda.to_device(a)\n",
    "        d_b = cuda.to_device(b)\n",
    "        d_out = cuda.to_device(out)\n",
    "        \n",
    "        kernel[blocks, threads](d_a, d_b, d_out, n)\n",
    "        result = d_out.copy_to_host()\n",
    "        \n",
    "        # Verify\n",
    "        expected = a + b\n",
    "        is_correct = np.allclose(result, expected)\n",
    "        status = \"âœ“\" if is_correct else \"âœ—\"\n",
    "        print(f\"{status} N = {n:>12,} | Blocks = {blocks}, Threads = {threads}\")\n",
    "\n",
    "# Test grid-stride with various sizes\n",
    "print(\"Grid-Stride Loop (same config for all sizes):\")\n",
    "test_sizes(grid_stride_add, [100, 1000, 10000, 100000, 1000000, 10000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfd5ba",
   "metadata": {},
   "source": [
    "### Benefit 2: Tune for Occupancy, Not Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different launch configs, same result\n",
    "n = 1_000_000\n",
    "a = np.random.rand(n).astype(np.float32)\n",
    "b = np.random.rand(n).astype(np.float32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_out = cuda.to_device(out)\n",
    "\n",
    "configs = [\n",
    "    (32, 64),    # Few threads\n",
    "    (128, 128),  # Moderate\n",
    "    (256, 256),  # Typical\n",
    "    (512, 512),  # High occupancy\n",
    "]\n",
    "\n",
    "print(f\"Testing different configs with N = {n:,}\\n\")\n",
    "for blocks, threads in configs:\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(100):\n",
    "        grid_stride_add[blocks, threads](d_a, d_b, d_out, n)\n",
    "    cuda.synchronize()\n",
    "    elapsed = (time.perf_counter() - start) / 100 * 1000\n",
    "    \n",
    "    total_threads = blocks * threads\n",
    "    elements_per_thread = n / total_threads\n",
    "    print(f\"Blocks={blocks:3}, Threads={threads:3} | \"\n",
    "          f\"Total={total_threads:>7,} | \"\n",
    "          f\"Elem/Thread={elements_per_thread:>6.1f} | \"\n",
    "          f\"Time={elapsed:.3f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751a109",
   "metadata": {},
   "source": [
    "### Benefit 3: Better Memory Access Patterns\n",
    "\n",
    "Grid-stride loops naturally provide **coalesced memory access**:\n",
    "\n",
    "```\n",
    "Pass 1: Threads 0,1,2,...,31 access elements 0,1,2,...,31  â† Coalesced!\n",
    "Pass 2: Threads 0,1,2,...,31 access elements 256,257,...,287  â† Coalesced!\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604caaf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Common Patterns\n",
    "\n",
    "### Pattern 1: Basic 1D Grid-Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb5c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def grid_stride_1d(data, n):\n",
    "    \"\"\"Basic 1D grid-stride pattern.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    for i in range(tid, n, stride):\n",
    "        data[i] = data[i] * 2  # Some operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e689f",
   "metadata": {},
   "source": [
    "### Pattern 2: 2D Grid-Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def grid_stride_2d(data, height, width):\n",
    "    \"\"\"2D grid-stride for images/matrices.\"\"\"\n",
    "    start_x, start_y = cuda.grid(2)\n",
    "    stride_x, stride_y = cuda.gridsize(2)\n",
    "    \n",
    "    for y in range(start_y, height, stride_y):\n",
    "        for x in range(start_x, width, stride_x):\n",
    "            data[y, x] = data[y, x] * 2\n",
    "\n",
    "# Test 2D grid-stride\n",
    "height, width = 1000, 1000\n",
    "data = np.random.rand(height, width).astype(np.float32)\n",
    "d_data = cuda.to_device(data)\n",
    "\n",
    "threads = (16, 16)\n",
    "blocks = (32, 32)  # Can be any size, not dependent on image size\n",
    "\n",
    "grid_stride_2d[blocks, threads](d_data, height, width)\n",
    "result = d_data.copy_to_host()\n",
    "\n",
    "print(f\"Image: {height}x{width} = {height*width:,} pixels\")\n",
    "print(f\"Grid: {blocks[0]*blocks[1]*threads[0]*threads[1]:,} threads\")\n",
    "print(f\"Correct: {np.allclose(result, data * 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f834c7c",
   "metadata": {},
   "source": [
    "### Pattern 3: Grid-Stride with Local Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def grid_stride_sum(data, partial_sums, n):\n",
    "    \"\"\"Each thread computes partial sum of its elements.\"\"\"\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    local_sum = 0.0\n",
    "    for i in range(tid, n, stride):\n",
    "        local_sum += data[i]\n",
    "    \n",
    "    # Store partial sum (will need reduction to complete)\n",
    "    partial_sums[tid] = local_sum\n",
    "\n",
    "# Test\n",
    "n = 1_000_000\n",
    "data = np.random.rand(n).astype(np.float32)\n",
    "blocks, threads = 256, 256\n",
    "total_threads = blocks * threads\n",
    "\n",
    "d_data = cuda.to_device(data)\n",
    "d_partial = cuda.device_array(total_threads, dtype=np.float32)\n",
    "\n",
    "grid_stride_sum[blocks, threads](d_data, d_partial, n)\n",
    "partial = d_partial.copy_to_host()\n",
    "\n",
    "gpu_sum = partial.sum()  # Final reduction on CPU\n",
    "cpu_sum = data.sum()\n",
    "\n",
    "print(f\"CPU sum: {cpu_sum:.6f}\")\n",
    "print(f\"GPU sum: {gpu_sum:.6f}\")\n",
    "print(f\"Match: {np.isclose(cpu_sum, gpu_sum, rtol=1e-4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459d3fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Optimal Launch Configuration\n",
    "\n",
    "### Guidelines for Choosing Blocks and Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb48d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()\n",
    "\n",
    "print(\"Device Properties:\")\n",
    "print(f\"  Max threads per block: {device.MAX_THREADS_PER_BLOCK}\")\n",
    "print(f\"  Warp size: {device.WARP_SIZE}\")\n",
    "print(f\"  Max blocks per SM: {device.MAX_BLOCK_DIM_X}\")\n",
    "print(f\"  Multiprocessors: {device.MULTIPROCESSOR_COUNT}\")\n",
    "\n",
    "# Recommended config\n",
    "threads = 256  # Multiple of warp size (32)\n",
    "blocks = device.MULTIPROCESSOR_COUNT * 4  # Enough for good occupancy\n",
    "\n",
    "print(f\"\\nRecommended starting config:\")\n",
    "print(f\"  Threads per block: {threads}\")\n",
    "print(f\"  Blocks: {blocks}\")\n",
    "print(f\"  Total threads: {blocks * threads:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9c095",
   "metadata": {},
   "source": [
    "### Rules of Thumb\n",
    "\n",
    "```\n",
    "Thread count per block:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "â€¢ Always multiple of 32 (warp size)\n",
    "â€¢ 128-256 is usually good\n",
    "â€¢ 512 for compute-heavy kernels\n",
    "â€¢ Max 1024 on most GPUs\n",
    "\n",
    "Block count:\n",
    "â”â”â”â”â”â”â”â”â”â”â”\n",
    "â€¢ At least SMs Ã— 2 (hide latency)\n",
    "â€¢ SMs Ã— 4 to SMs Ã— 8 is often optimal\n",
    "â€¢ More blocks = more flexibility for scheduler\n",
    "\n",
    "With grid-stride, you can always use:\n",
    "  blocks = SM_count * 4\n",
    "  threads = 256\n",
    "And it will work for any data size!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58cb8e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851de17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_add(n, iterations=100):\n",
    "    \"\"\"Compare naive vs grid-stride for vector addition.\"\"\"\n",
    "    a = np.random.rand(n).astype(np.float32)\n",
    "    b = np.random.rand(n).astype(np.float32)\n",
    "    out = np.zeros(n, dtype=np.float32)\n",
    "    \n",
    "    d_a = cuda.to_device(a)\n",
    "    d_b = cuda.to_device(b)\n",
    "    d_out = cuda.to_device(out)\n",
    "    \n",
    "    # Naive config: one thread per element\n",
    "    threads_naive = 256\n",
    "    blocks_naive = (n + threads_naive - 1) // threads_naive\n",
    "    \n",
    "    # Grid-stride config: fixed size\n",
    "    threads_gs = 256\n",
    "    blocks_gs = 256\n",
    "    \n",
    "    # Warmup\n",
    "    naive_add[blocks_naive, threads_naive](d_a, d_b, d_out, n)\n",
    "    grid_stride_add[blocks_gs, threads_gs](d_a, d_b, d_out, n)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Benchmark naive\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        naive_add[blocks_naive, threads_naive](d_a, d_b, d_out, n)\n",
    "    cuda.synchronize()\n",
    "    naive_time = (time.perf_counter() - start) / iterations * 1000\n",
    "    \n",
    "    # Benchmark grid-stride\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        grid_stride_add[blocks_gs, threads_gs](d_a, d_b, d_out, n)\n",
    "    cuda.synchronize()\n",
    "    gs_time = (time.perf_counter() - start) / iterations * 1000\n",
    "    \n",
    "    # NumPy baseline\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iterations):\n",
    "        _ = a + b\n",
    "    numpy_time = (time.perf_counter() - start) / iterations * 1000\n",
    "    \n",
    "    return naive_time, gs_time, numpy_time, blocks_naive\n",
    "\n",
    "print(f\"{'N':>12} | {'Naive (ms)':>10} | {'Grid-Stride':>11} | {'NumPy':>10} | {'GPU Speedup':>11}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for n in [10_000, 100_000, 1_000_000, 10_000_000]:\n",
    "    naive_t, gs_t, np_t, blocks = benchmark_add(n)\n",
    "    speedup = np_t / gs_t\n",
    "    print(f\"{n:>12,} | {naive_t:>10.3f} | {gs_t:>11.3f} | {np_t:>10.3f} | {speedup:>10.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f89ae3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Vector Scaling\n",
    "\n",
    "Implement a grid-stride kernel that multiplies every element by a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3455355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement grid-stride vector scaling\n",
    "@cuda.jit\n",
    "def vector_scale(data, scalar, n):\n",
    "    \"\"\"Multiply every element by scalar: data[i] *= scalar\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test\n",
    "# data = np.array([1, 2, 3, 4, 5], dtype=np.float32)\n",
    "# Expected after scale by 3: [3, 6, 9, 12, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade333c",
   "metadata": {},
   "source": [
    "### Exercise 2: Vector Square Root\n",
    "\n",
    "Apply `sqrt` to every element using grid-stride pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41611f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement grid-stride sqrt\n",
    "@cuda.jit\n",
    "def vector_sqrt(input_data, output_data, n):\n",
    "    \"\"\"Compute sqrt of every element.\"\"\"\n",
    "    # Hint: Use math.sqrt(x) inside the kernel\n",
    "    pass\n",
    "\n",
    "# Test with input = [1, 4, 9, 16, 25]\n",
    "# Expected output = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44974cf5",
   "metadata": {},
   "source": [
    "### Exercise 3: Conditional Processing\n",
    "\n",
    "Apply a function only to elements meeting a condition (e.g., positive numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3996b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Double only positive values\n",
    "@cuda.jit\n",
    "def double_positives(data, n):\n",
    "    \"\"\"Double the value of positive elements, leave others unchanged.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test with input = [-2, -1, 0, 1, 2]\n",
    "# Expected output = [-2, -1, 0, 2, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98916fb",
   "metadata": {},
   "source": [
    "### Exercise 4: 2D Grid-Stride Image Processing\n",
    "\n",
    "Apply a brightness adjustment to an image using 2D grid-stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust image brightness\n",
    "@cuda.jit\n",
    "def adjust_brightness(image, factor, height, width):\n",
    "    \"\"\"Multiply all pixel values by factor, clamping to [0, 1].\"\"\"\n",
    "    # Use 2D grid-stride pattern\n",
    "    # Clamp: max(0, min(1, value))\n",
    "    pass\n",
    "\n",
    "# Test with a 100x100 image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb426a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Grid-Stride Loop Template\n",
    "\n",
    "```python\n",
    "@cuda.jit\n",
    "def kernel_1d(data, n):\n",
    "    tid = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    for i in range(tid, n, stride):\n",
    "        data[i] = process(data[i])\n",
    "\n",
    "@cuda.jit\n",
    "def kernel_2d(data, height, width):\n",
    "    x, y = cuda.grid(2)\n",
    "    stride_x, stride_y = cuda.gridsize(2)\n",
    "    \n",
    "    for row in range(y, height, stride_y):\n",
    "        for col in range(x, width, stride_x):\n",
    "            data[row, col] = process(data[row, col])\n",
    "```\n",
    "\n",
    "### Key Benefits\n",
    "1. âœ“ Handle any data size with fixed launch config\n",
    "2. âœ“ Tune occupancy independently of data\n",
    "3. âœ“ Natural coalesced access\n",
    "4. âœ“ Professional, reusable pattern\n",
    "\n",
    "### Recommended Config\n",
    "```python\n",
    "threads = 256  # Multiple of 32\n",
    "blocks = num_SMs * 4  # Good occupancy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91190d1b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "ðŸ“‹ **Day 2:** Element-wise vector operations (add, sub, mul, div, math functions)\n",
    "\n",
    "We'll use grid-stride loops as the foundation for all our vector operations!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
